[
    {
      "title": "Machine learning for science and society",
      "authors": "Rudin, C; Wagstaff, KL",
      "published_date": "January 1, 2014",
      "doi": "10.1007/s10994-013-5425-9",
      "abstract": "The special issue on \"Machine Learning for Science and Society\" showcases machine learning work with influence on our current and future society. These papers address several key problems such as how we perform repairs on critical infrastructure, how we predict severe weather and aviation turbulence, how we conduct tax audits, whether we can detect privacy breaches in access to healthcare data, and how we link individuals across census data sets for new insights into population changes. In this introduction, we discuss the need for such a special issue within the context of our field and its relationship to the broader world. In the era of \"big data,\" there is a need for machine learning to address important large-scale applied problems, yet it is difficult to find top venues in machine learning where such work is encouraged. We discuss the ramifications of this contradictory situation and encourage further discussion on the best strategy that we as a field may adopt. We also summarize key lessons learned from individual papers in the special issue so that the community as a whole can benefit. © 2013 The Author(s).",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-013-5425-9",
      "citations": 25,
      "readership": 143,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Machine learning with operational costs",
      "authors": "Tulabandhula, T; Rudin, C",
      "published_date": "June 1, 2013",
      "doi": "",
      "abstract": "This work proposes a way to align statistical modeling with decision making. We provide a method that propagates the uncertainty in predictive modeling to the uncertainty in operational cost, where operational cost is the amount spent by the practitioner in solving the problem. The method allows us to explore the range of operational costs associated with the set of reasonable statistical models, so as to provide a useful way for practitioners to understand uncertainty. To do this, the operational cost is cast as a regularization term in a learning algorithm's objective function, allowing either an optimistic or pessimistic view of possible costs, depending on the regularization parameter. From another perspective, if we have prior knowledge about the operational cost, for instance that it should be low, this knowledge can help to restrict the hypothesis space, and can help with generalization. We provide a theoretical generalization bound for this scenario. We also show that learning with operational costs is related to robust optimization. © 2013 Theja Tulabandhula and Cynthia Rudin.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stealing Hyperparameters in Machine Learning",
      "authors": "",
      "published_date": "May 2018",
      "doi": "10.1109/sp.2018.00038",
      "abstract": "",
      "publication_location": "IEEE",
      "link": "http://dx.doi.org/10.1109/sp.2018.00038",
      "citations": 30,
      "readership": 176,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Clearing Opacity through Machine Learning",
      "authors": "Rai, A; II, W",
      "published_date": 2020,
      "doi": "",
      "abstract": "",
      "publication_location": "Iowa Law Review",
      "link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3536983",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "On combining machine learning with decision making",
      "authors": "Tulabandhula, T; Rudin, C",
      "published_date": "January 1, 2014",
      "doi": "10.1007/s10994-014-5459-7",
      "abstract": "We present a new application and covering number bound for the framework of \"Machine Learning with Operational Costs (MLOC),\" which is an exploratory form of decision theory. The MLOC framework incorporates knowledge about how a predictive model will be used for a subsequent task, thus combining machine learning with the decision that is made afterwards. In this work, we use the MLOC framework to study a problem that has implications for power grid reliability and maintenance, called the Machine Learning and Traveling Repairman Problem (ML&TRP). The goal of the ML&TRP is to determine a route for a \"repair crew,\" which repairs nodes on a graph. The repair crew aims to minimize the cost of failures at the nodes, but as in many real situations, the failure probabilities are not known and must be estimated. The MLOC framework allows us to understand how this uncertainty influences the repair route. We also present new covering number generalization bounds for the MLOC framework. © 2014 The Author(s).",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-014-5459-7",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning for phenotyping opioid overdose events.",
      "authors": "Badger, J; LaRose, E; Mayer, J; Bashiri, F; Page, D; Peissig, P",
      "published_date": "June 2019",
      "doi": "10.1016/j.jbi.2019.103185",
      "abstract": "OBJECTIVE: To develop machine learning models for classifying the severity of opioid overdose events from clinical data. MATERIALS AND METHODS: Opioid overdoses were identified by diagnoses codes from the Marshfield Clinic population and assigned a severity score via chart review to form a gold standard set of labels. Three primary feature sets were constructed from disparate data sources surrounding each event and used to train machine learning models for phenotyping. RESULTS: Random forest and penalized logistic regression models gave the best performance with cross-validated mean areas under the ROC curves (AUCs) for all severity classes of 0.893 and 0.882 respectively. Features derived from a common data model outperformed features collected from disparate data sources for the same cohort of patients (AUCs 0.893 versus 0.837, p value = 0.002). The addition of features extracted from free text to machine learning models also increased AUCs from 0.827 to 0.893 (p value < 0.0001). Key word features extracted using natural language processing (NLP) such as 'Narcan' and 'Endotracheal Tube' are important for classifying overdose event severity. CONCLUSION: Random forest models using features derived from a common data model and free text can be effective for classifying opioid overdose events.",
      "publication_location": "J Biomed Inform",
      "link": "http://dx.doi.org/10.1016/j.jbi.2019.103185",
      "citations": 2,
      "readership": 20,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Machine-learning phenotypic classification of bicuspid aortopathy.",
      "authors": "Wojnarski, CM; Roselli, EE; Idrees, JJ; Zhu, Y; Carnes, TA; Lowry, AM; Collier, PH; Griffin, B; Ehrlinger, J; Blackstone, EH; Svensson, LG; Lytle, BW",
      "published_date": "February 2018",
      "doi": "10.1016/j.jtcvs.2017.08.123",
      "abstract": "BACKGROUND:Bicuspid aortic valves (BAV) are associated with incompletely characterized aortopathy. Our objectives were to identify distinct patterns of aortopathy using machine-learning methods and characterize their association with valve morphology and patient characteristics. METHODS:We analyzed preoperative 3-dimensional computed tomography reconstructions for 656 patients with BAV undergoing ascending aorta surgery between January 2002 and January 2014. Unsupervised partitioning around medoids was used to cluster aortic dimensions. Group differences were identified using polytomous random forest analysis. RESULTS:Three distinct aneurysm phenotypes were identified: root (n = 83; 13%), with predominant dilatation at sinuses of Valsalva; ascending (n = 364; 55%), with supracoronary enlargement rarely extending past the brachiocephalic artery; and arch (n = 209; 32%), with aortic arch dilatation. The arch phenotype had the greatest association with right-noncoronary cusp fusion: 29%, versus 13% for ascending and 15% for root phenotypes (P < .0001). Severe valve regurgitation was most prevalent in root phenotype (57%), followed by ascending (34%) and arch phenotypes (25%; P < .0001). Aortic stenosis was most prevalent in arch phenotype (62%), followed by ascending (50%) and root phenotypes (28%; P < .0001). Patient age increased as the extent of aneurysm became more distal (root, 49 years; ascending, 53 years; arch, 57 years; P < .0001), and root phenotype was associated with greater male predominance compared with ascending and arch phenotypes (94%, 76%, and 70%, respectively; P < .0001). Phenotypes were visually recognizable with 94% accuracy. CONCLUSIONS:Three distinct phenotypes of bicuspid valve-associated aortopathy were identified using machine-learning methodology. Patient characteristics and valvular dysfunction vary by phenotype, suggesting that the location of aortic pathology may be related to the underlying pathophysiology of this disease.",
      "publication_location": "The Journal of Thoracic and Cardiovascular Surgery",
      "link": "http://dx.doi.org/10.1016/j.jtcvs.2017.08.123",
      "citations": 10,
      "readership": 32,
      "tweets": 39,
      "news_mentions": ""
    },
    {
      "title": "Development of New Diagnostic Techniques - Machine Learning.",
      "authors": "",
      "published_date": "January 2017",
      "doi": "10.1007/978-981-10-5562-1_10",
      "abstract": "Traditional diagnoses on addiction reply on the patients' self-reports, which are easy to be dampened by false memory or malingering. Machine learning (ML) is a data-driven procedure that learns algorithms from training data and makes predictions. It is quickly developed and is more and more utilized into clinical applications including diagnoses of addiction. This chapter reviewed the basic concepts and processes of ML. Some studies utilizing ML to classify addicts and non-addicts, separate different types of addiction, and evaluate the effects of treatment are also reviewed. Both advantages and shortcomings of ML in diagnoses of addiction are discussed.",
      "publication_location": "Advances in Experimental Medicine and Biology",
      "link": "http://dx.doi.org/10.1007/978-981-10-5562-1_10",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A Shared Vision for Machine Learning in Neuroscience.",
      "authors": "Vu, M-AT; Adalı, T; Ba, D; Buzsáki, G; Carlson, D; Heller, K; Liston, C; Rudin, C; Sohal, VS; Widge, AS; Mayberg, HS; Sapiro, G; Dzirasa, K",
      "published_date": "February 14, 2018",
      "doi": "10.1523/JNEUROSCI.0508-17.2018",
      "abstract": "With ever-increasing advancements in technology, neuroscientists are able to collect data in greater volumes and with finer resolution. The bottleneck in understanding how the brain works is consequently shifting away from the amount and type of data we can collect and toward what we actually do with the data. There has been a growing interest in leveraging this vast volume of data across levels of analysis, measurement techniques, and experimental paradigms to gain more insight into brain function. Such efforts are visible at an international scale, with the emergence of big data neuroscience initiatives, such as the BRAIN initiative (Bargmann et al., 2014), the Human Brain Project, the Human Connectome Project, and the National Institute of Mental Health's Research Domain Criteria initiative. With these large-scale projects, much thought has been given to data-sharing across groups (Poldrack and Gorgolewski, 2014; Sejnowski et al., 2014); however, even with such data-sharing initiatives, funding mechanisms, and infrastructure, there still exists the challenge of how to cohesively integrate all the data. At multiple stages and levels of neuroscience investigation, machine learning holds great promise as an addition to the arsenal of analysis tools for discovering how the brain works.",
      "publication_location": "Journal of Neuroscience",
      "link": "http://dx.doi.org/10.1523/JNEUROSCI.0508-17.2018",
      "citations": 26,
      "readership": 326,
      "tweets": 179,
      "news_mentions": ""
    },
    {
      "title": "The machine learning and traveling repairman problem",
      "authors": "Tulabandhula, T; Rudin, C; Jaillet, P",
      "published_date": "October 31, 2011",
      "doi": "10.1007/978-3-642-24873-3_20",
      "abstract": "The goal of the Machine Learning and Traveling Repairman Problem (ML&TRP) is to determine a route for a \"repair crew,\" which repairs nodes on a graph. The repair crew aims to minimize the cost of failures at the nodes, but the failure probabilities are not known and must be estimated. If there is uncertainty in the failure probability estimates, we take this uncertainty into account in an unusual way; from the set of acceptable models, we choose the model that has the lowest cost of applying it to the subsequent routing task. In a sense, this procedure agrees with a managerial goal, which is to show that the data can support choosing a low-cost solution. © 2011 Springer-Verlag.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "http://dx.doi.org/10.1007/978-3-642-24873-3_20",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "What can machine learning teach us about communications?",
      "authors": "Lian, M; Häger, C; Pfister, HD",
      "published_date": "January 15, 2019",
      "doi": "10.1109/ITW.2018.8613331",
      "abstract": "© 2018 IEEE Information Theory Workshop, ITW 2018. All rights reserved. Rapid improvements in machine learning over the past decade are beginning to have far-reaching effects. For communications, engineers with limited domain expertise can now use off-the-shelf learning packages to design high-performance systems based on simulations. Prior to the current revolution in machine learning, the majority of communication engineers were quite aware that system parameters (such as filter coefficients) could be learned using stochastic gradient descent. It was not at all clear, however, that more complicated parts of the system architecture could be learned as well. In this paper, we discuss the application of machine-learning techniques to two communications problems and focus on what can be learned from the resulting systems. We were pleasantly surprised that the observed gains in one example have a simple explanation that only became clear in hindsight. In essence, deep learning discovered a simple and effective strategy that had not been considered earlier.",
      "publication_location": "2018 Ieee Information Theory Workshop, Itw 2018",
      "link": "http://dx.doi.org/10.1109/ITW.2018.8613331",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deeper into the Machine: Learning to Speak Digital",
      "authors": "Hayles, NK",
      "published_date": 2002,
      "doi": "",
      "abstract": "",
      "publication_location": "Electronic Literature Organizaton",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deeper into the Machine: Learning to Speak Digital",
      "authors": "Hayles, NK",
      "published_date": "December 2002",
      "doi": "10.1016/S8755-4615(02)00140-8",
      "abstract": "",
      "publication_location": "Computers and Composition",
      "link": "http://dx.doi.org/10.1016/S8755-4615(02)00140-8",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Chemometrics and machine learning for spectral analysis",
      "authors": "Collins, L",
      "published_date": 2012,
      "doi": "",
      "abstract": "In this talk, we will review the current state of the art chemometric data processing techniques for LIBS and will highlight techniques we believe hold promise for improving detection and identification using LIBS spectra. © 2012 OSA.",
      "publication_location": "Laser Applications to Chemical, Security and Environmental Analysis, Lacsea 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Chemometrics and machine learning for spectral analysis",
      "authors": "Collins, L",
      "published_date": "January 1, 2012",
      "doi": "",
      "abstract": "In this talk, we will review the current state of the art chemometric data processing techniques for LIBS and will highlight techniques we believe hold promise for improving detection and identification using LIBS spectra. © 2012 OSA.",
      "publication_location": "Laser Applications to Chemical, Security and Environmental Analysis, Lacsea 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning for meeting analysis",
      "authors": "Kim, B; Rudin, C",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "Most people participate in meetings almost every day, multiple times a day. The study of meetings is important, but also challenging, as it requires an understanding of social signals and complex interpersonal dynamics. Our aim this work is to use a data-driven approach to the science of meetings. We provide tentative evidence that: i) there are common macro-patterns in the way social dialogue acts are interspersed throughout a meeting, and ii) it is often possible to predict whether a proposal during a meeting will be accepted or rejected based entirely on the language (the set of persuasive words) used by the speaker. Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved.",
      "publication_location": "Aaai Workshop   Technical Report",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Artificial Intelligence and Machine Learning in Cardiology.",
      "authors": "Westcott, RJ; Tcheng, JE",
      "published_date": "July 22, 2019",
      "doi": "10.1016/j.jcin.2019.03.026",
      "abstract": "",
      "publication_location": "Jacc. Cardiovascular Interventions",
      "link": "http://dx.doi.org/10.1016/j.jcin.2019.03.026",
      "citations": 1,
      "readership": 16,
      "tweets": 4,
      "news_mentions": 5
    },
    {
      "title": "Clearing Opacity through Machine Learning",
      "authors": "Rai, A; II, W",
      "published_date": 2020,
      "doi": "",
      "abstract": "",
      "publication_location": "",
      "link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3536983",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning and Cochlear Implantation-A Structured Review of Opportunities and Challenges.",
      "authors": "Crowson, MG; Lin, V; Chen, JM; Chan, TCY",
      "published_date": "January 2020",
      "doi": "10.1097/MAO.0000000000002440",
      "abstract": "OBJECTIVE: The use of machine learning technology to automate intellectual processes and boost clinical process efficiency in medicine has exploded in the past 5 years. Machine learning excels in automating pattern recognition and in adapting learned representations to new settings. Moreover, machine learning techniques have the advantage of incorporating complexity and are free from many of the limitations of traditional deterministic approaches. Cochlear implants (CI) are a unique fit for machine learning techniques given the need for optimization of signal processing to fit complex environmental scenarios and individual patients' CI MAPping. However, there are many other opportunities where machine learning may assist in CI beyond signal processing. The objective of this review was to synthesize past applications of machine learning technologies for pediatric and adult CI and describe novel opportunities for research and development. DATA SOURCES: The PubMed/MEDLINE, EMBASE, Scopus, and ISI Web of Knowledge databases were mined using a directed search strategy to identify the nexus between CI and artificial intelligence/machine learning literature. STUDY SELECTION: Non-English language articles, articles without an available abstract or full-text, and nonrelevant articles were manually appraised and excluded. Included articles were evaluated for specific machine learning methodologies, content, and application success. DATA SYNTHESIS: The database search identified 298 articles. Two hundred fifty-nine articles (86.9%) were excluded based on the available abstract/full-text, language, and relevance. The remaining 39 articles were included in the review analysis. There was a marked increase in year-over-year publications from 2013 to 2018. Applications of machine learning technologies involved speech/signal processing optimization (17; 43.6% of articles), automated evoked potential measurement (6; 15.4%), postoperative performance/efficacy prediction (5; 12.8%), and surgical anatomy location prediction (3; 7.7%), and 2 (5.1%) in each of robotics, electrode placement performance, and biomaterials performance. CONCLUSION: The relationship between CI and artificial intelligence is strengthening with a recent increase in publications reporting successful applications. Considerable effort has been directed toward augmenting signal processing and automating postoperative MAPping using machine learning algorithms. Other promising applications include augmenting CI surgery mechanics and personalized medicine approaches for boosting CI patient performance. Future opportunities include addressing scalability and the research and clinical communities' acceptance of machine learning algorithms as effective techniques.",
      "publication_location": "Otol Neurotol",
      "link": "http://dx.doi.org/10.1097/MAO.0000000000002440",
      "citations": 1,
      "readership": 8,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "A contemporary review of machine learning in otolaryngology-head and neck surgery.",
      "authors": "Crowson, MG; Ranisau, J; Eskander, A; Babier, A; Xu, B; Kahmke, RR; Chen, JM; Chan, TCY",
      "published_date": "January 2020",
      "doi": "10.1002/lary.27850",
      "abstract": "One of the key challenges with big data is leveraging the complex network of information to yield useful clinical insights. The confluence of massive amounts of health data and a desire to make inferences and insights on these data has produced a substantial amount of interest in machine-learning analytic methods. There has been a drastic increase in the otolaryngology literature volume describing novel applications of machine learning within the past 5 years. In this timely contemporary review, we provide an overview of popular machine-learning techniques, and review recent machine-learning applications in otolaryngology-head and neck surgery including neurotology, head and neck oncology, laryngology, and rhinology. Investigators have realized significant success in validated models with model sensitivities and specificities approaching 100%. Challenges remain in the implementation of machine-learning algorithms. This may be in part the unfamiliarity of these techniques to clinician leaders on the front lines of patient care. Spreading awareness and confidence in machine learning will follow with further validation and proof-of-value analyses that demonstrate model performance superiority over established methods. We are poised to see a greater influx of machine-learning applications to clinical problems in otolaryngology-head and neck surgery, and it is prudent for providers to understand the potential benefits and limitations of these technologies. Laryngoscope, 130:45-51, 2020.",
      "publication_location": "Laryngoscope",
      "link": "http://dx.doi.org/10.1002/lary.27850",
      "citations": 8,
      "readership": 34,
      "tweets": 11,
      "news_mentions": ""
    },
    {
      "title": "Decision fusion of machine learning models to predict radiotherapyinduced lung pneumonitis",
      "authors": "Das, SK; Chen, S; Deasy, JO; Zhou, S; Yin, FF; Marks, LB",
      "published_date": "December 1, 2008",
      "doi": "10.1109/ICMLA.2008.122",
      "abstract": "Combining different machine learning models (decision fusion) has been shown to be an effective method for estimating the underlying physical mechanism by allowing the models to reinforce each other when consensus exists, or, conversely, negate each other when there is no consensus. To be effective, decision fusion requires that the different models provide some degree of complementary information. In this work, we fuse the results of four different machine learning models (Boosted Decision Trees, Neural Networks, Support Vector Machines, Self Organizing Maps) to predict the risk of lung pneumonitis in patients undergoing thoracic radiotherapy. Fusion was achieved by simple averaging of the 10-fold cross validated predictions for each patient from all four models. To reduce prediction dependence on the manner in which the data set was split, 10-fold cross-validation was repeated 100 times for random data splitting. The area under the receiver operating characteristics curve for the fused cross-validated results was 0.79, higher than the individual models and with (generally) lower variance. The fusion extracted three important features as the consensus among all four models in predicting radiation pneumonitis risk: chemotherapy prior to radiotherapy, equivalent Uniform Dose (EUD) for exponent a = 1.2 to 3, and female gender. The results show great promise for machine learning in radiotherapy outcomes modeling. © 2008 IEEE.",
      "publication_location": "Proceedings   7th International Conference on Machine Learning and Applications, Icmla 2008",
      "link": "http://dx.doi.org/10.1109/ICMLA.2008.122",
      "citations": 4,
      "readership": 15,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning for Hardware Security: Opportunities and Risks",
      "authors": "Elnaggar, R; Chakrabarty, K",
      "published_date": "April 1, 2018",
      "doi": "10.1007/s10836-018-5726-9",
      "abstract": "© 2018, Springer Science+Business Media, LLC, part of Springer Nature. Recently, machine learning algorithms have been utilized by system defenders and attackers to secure and attack hardware, respectively. In this work, we investigate the impact of machine learning on hardware security. We explore the defense and attack mechanisms for hardware that are based on machine learning. Moreover, we identify suitable machine learning algorithms for each category of hardware security problems. Finally, we highlight some important aspects related to the application of machine learning to hardware security problems and show how the practice of applying machine learning to hardware security problems has changed over the past decade.",
      "publication_location": "Journal of Electronic Testing: Theory and Applications (Jetta)",
      "link": "http://dx.doi.org/10.1007/s10836-018-5726-9",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning and modeling: Data, validation, communication challenges.",
      "authors": "El Naqa, I; Ruan, D; Valdes, G; Dekker, A; McNutt, T; Ge, Y; Wu, QJ; Oh, JH; Thor, M; Smith, W; Rao, A; Fuller, C; Xiao, Y; Manion, F; Schipper, M; Mayo, C; Moran, JM; Ten Haken, R",
      "published_date": "October 2018",
      "doi": "10.1002/mp.12811",
      "abstract": "With the era of big data, the utilization of machine learning algorithms in radiation oncology is rapidly growing with applications including: treatment response modeling, treatment planning, contouring, organ segmentation, image-guidance, motion tracking, quality assurance, and more. Despite this interest, practical clinical implementation of machine learning as part of the day-to-day clinical operations is still lagging. The aim of this white paper is to further promote progress in this new field of machine learning in radiation oncology by highlighting its untapped advantages and potentials for clinical advancement, while also presenting current challenges and open questions for future research. The targeted audience of this paper includes newcomers as well as practitioners in the field of medical physics/radiation oncology. The paper also provides general recommendations to avoid common pitfalls when applying these powerful data analytic tools to medical physics and radiation oncology problems and suggests some guidelines for transparent and informative reporting of machine learning results.",
      "publication_location": "Med Phys",
      "link": "http://dx.doi.org/10.1002/mp.12811",
      "citations": 13,
      "readership": 51,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "An investigation of machine learning methods in delta-radiomics feature analysis.",
      "authors": "Chang, Y; Lafata, K; Sun, W; Wang, C; Chang, Z; Kirkpatrick, JP; Yin, F-F",
      "published_date": 2019,
      "doi": "10.1371/journal.pone.0226348",
      "abstract": "PURPOSE: This study aimed to investigate the effectiveness of using delta-radiomics to predict overall survival (OS) for patients with recurrent malignant gliomas treated by concurrent stereotactic radiosurgery and bevacizumab, and to investigate the effectiveness of machine learning methods for delta-radiomics feature selection and building classification models. METHODS: The pre-treatment, one-week post-treatment, and two-month post-treatment T1 and T2 fluid-attenuated inversion recovery (FLAIR) MRI were acquired. 61 radiomic features (intensity histogram-based, morphological, and texture features) were extracted from the gross tumor volume in each image. Delta-radiomics were calculated between the pre-treatment and post-treatment features. Univariate Cox regression and 3 multivariate machine learning methods (L1-regularized logistic regression [L1-LR], random forest [RF] or neural networks [NN]) were used to select a reduced number of features, and 7 machine learning methods (L1-LR, L2-LR, RF, NN, kernel support vector machine [KSVM], linear support vector machine [LSVM], or naïve bayes [NB]) was used to build classification models for predicting OS. The performances of the total 21 model combinations built based on single-time-point radiomics (pre-treatment, one-week post-treatment, and two-month post-treatment) and delta-radiomics were evaluated by the area under the receiver operating characteristic curve (AUC). RESULTS: For a small cohort of 12 patients, delta-radiomics resulted in significantly higher AUC than pre-treatment radiomics (p-value<0.01). One-week/two-month delta-features resulted in significantly higher AUC (p-value<0.01) than the one-week/two-month post-treatment features, respectively. 18/21 model combinations were with higher AUC from one-week delta-features than two-month delta-features. With one-week delta-features, RF feature selector + KSVM classifier and RF feature selector + NN classifier showed the highest AUC of 0.889. CONCLUSIONS: The results indicated that delta-features could potentially provide better treatment assessment than single-time-point features. The treatment assessment is substantially affected by the time point for computing the delta-features and the combination of machine learning methods for feature selection and classification.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0226348",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Using Machine Learning to Design and Interpret Gene-Expression Microarrays",
      "authors": "Molla, M; Waddell, M; Page, D; Shavlik, J",
      "published_date": "March 1, 2004",
      "doi": "",
      "abstract": "Gene-expression microarrays, commonly called gene chips, make It possible to simultaneously measure the rate at which a cell or tissue is expressing - translating into a protein - each of its thousands of genes. One can use these comprehensive snapshots of biological activity to infer regulatory pathways in cells; identify novel targets for drug design; and improve the diagnosis, prognosis, and treatment planning for those suffering from disease. However, the amount of data this new technology produces is more than one can manually analyze. Hence, the need for automated analysis of microarray data offers an opportunity for machine learning to have a significant impact on biology and medicine. This article describes microarray technology, the data it produces, and the types of machine learning tasks that naturally arise with these data. It also reviews some of the recent prominent applications of machine learning to gene-chip data, points to related tasks where machine learning might have a further impact on biology and medicine, and describes additional types of interesting data that recent advances in biotechnology allow biomedical researchers to collect.",
      "publication_location": "Ai Magazine",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Modeling and debugging engineering decision procedures with machine learning",
      "authors": "Reich, Y; Jr, MAM; Shieh, TY; Jacobs, TL",
      "published_date": 1996,
      "doi": "",
      "abstract": "This paper reports on the use of machine learning programs for modeling existing engineering decision procedures. In this acitivity, different models of a decision procedure are constructed by using different machine learning programs as well as by varying their operational parameters and input. These models serve to focus on different aspects of the decision procedure thus improving its understandability, which, in turn, can assist in its evaluation and subsequent debugging. This important modeling role of machine learning programs is exemplified by modeling an existing decision procedure that is used by engineers when they need guidance in selecting among available techniques for modeling ground-water flow in a process of environmental decision making. This decision procedure was corrected and improved in the course of this work. The example demonstrates the practical utility of the modeling role of machine learning for engineering applications.",
      "publication_location": "Journal of Computing in Civil Engineering",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "AFLOW-ML: A RESTful API for machine-learning predictions of materials properties",
      "authors": "Gossett, E; Toher, C; Oses, C; Isayev, O; Legrain, F; Rose, F; Zurek, E; Carrete, J; Mingo, N; Tropsha, A; Curtarolo, S",
      "published_date": "September 1, 2018",
      "doi": "10.1016/j.commatsci.2018.03.075",
      "abstract": "© 2018 Elsevier B.V. Machine learning approaches, enabled by the emergence of comprehensive databases of materials properties, are becoming a fruitful direction for materials analysis. As a result, a plethora of models have been constructed and trained on existing data to predict properties of new systems. These powerful methods allow researchers to target studies only at interesting materials – neglecting the non-synthesizable systems and those without the desired properties – thus reducing the amount of resources spent on expensive computations and/or time-consuming experimental synthesis. However, using these predictive models is not always straightforward. Often, they require a panoply of technical expertise, creating barriers for general users. AFLOW-ML (AFLOW Machine Learning) overcomes the problem by streamlining the use of the machine learning methods developed within the AFLOW consortium. The framework provides an open RESTful API to directly access the continuously updated algorithms, which can be transparently integrated into any workflow to retrieve predictions of electronic, thermal and mechanical properties. These types of interconnected cloud-based applications are envisioned to be capable of further accelerating the adoption of machine learning methods into materials development.",
      "publication_location": "Computational Materials Science",
      "link": "http://dx.doi.org/10.1016/j.commatsci.2018.03.075",
      "citations": 18,
      "readership": 129,
      "tweets": 22,
      "news_mentions": ""
    },
    {
      "title": "Do no harm: a roadmap for responsible machine learning for health care.",
      "authors": "Wiens, J; Saria, S; Sendak, M; Ghassemi, M; Liu, VX; Doshi-Velez, F; Jung, K; Heller, K; Kale, D; Saeed, M; Ossorio, PN; Thadaney-Israni, S; Goldenberg, A",
      "published_date": "September 2019",
      "doi": "10.1038/s41591-019-0548-6",
      "abstract": "Interest in machine-learning applications within medicine has been growing, but few studies have progressed to deployment in patient care. We present a framework, context and ultimately guidelines for accelerating the translation of machine-learning-based interventions in health care. To be successful, translation will require a team of engaged stakeholders and a systematic process from beginning (problem formulation) to end (widespread deployment).",
      "publication_location": "Nature Medicine",
      "link": "http://dx.doi.org/10.1038/s41591-019-0548-6",
      "citations": 22,
      "readership": 253,
      "tweets": 740,
      "news_mentions": 33
    },
    {
      "title": "AUCµ: A Performance Metric for Multi-Class Machine Learning Models",
      "authors": "Page, D; Kleiman, R",
      "published_date": "July 1, 2019",
      "doi": "",
      "abstract": "The area under the receiver operating characteristic curve (AUC) is arguably the most common metric in machine learning for assessing the quality of a two-class classification model. As the number and complexity of machine learning applications grows, so too does the need for measures that can gracefully extend to classification models trained for more than two classes. Prior work in this area has proven computationally intractable and/or inconsistent with known properties of AUC, and thus there is still a need for an improved multi-class efficacy metric. We provide in this work a multi-class extension of AUC that we call AUCµ that is derived from first principles of the binary class AUC. AUCµ has similar computational complexity to AUC and maintains the properties of AUC critical to its interpretation and use.",
      "publication_location": "",
      "link": "https://icml.cc/Conferences/2019/ScheduleMultitrack?event=4252",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning for Treatment Assignment: Improving Individualized Risk Attribution.",
      "authors": "Weiss, J; Kuusisto, F; Boyd, K; Liu, J; Page, D",
      "published_date": 2015,
      "doi": "",
      "abstract": "Clinical studies model the average treatment effect (ATE), but apply this population-level effect to future individuals. Due to recent developments of machine learning algorithms with useful statistical guarantees, we argue instead for modeling the individualized treatment effect (ITE), which has better applicability to new patients. We compare ATE-estimation using randomized and observational analysis methods against ITE-estimation using machine learning, and describe how the ITE theoretically generalizes to new population distributions, whereas the ATE may not. On a synthetic data set of statin use and myocardial infarction (MI), we show that a learned ITE model improves true ITE estimation and outperforms the ATE. We additionally argue that ITE models should be learned with a consistent, nonparametric algorithm from unweighted examples and show experiments in favor of our argument using our synthetic data model and a real data set of D-penicillamine use for primary biliary cirrhosis.",
      "publication_location": "Amia ... Annual Symposium Proceedings. Amia Symposium",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/26958271",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning for early detection of sepsis: an internal and temporal validation study",
      "authors": "Bedoya, AD; Futoma, J; Clement, ME; Corey, K; Brajer, N; Lin, A; Simons, MG; Gao, M; Nichols, M; Balu, S; Heller, K; Sendak, M; O’Brien, C",
      "published_date": "",
      "doi": "10.1093/jamiaopen/ooaa006",
      "abstract": "Abstract\n               \n                  Objective\n                  Determine if deep learning detects sepsis earlier and more accurately than other models. To evaluate model performance using implementation-oriented metrics that simulate clinical practice.\n               \n               \n                  Materials and Methods\n                  We trained internally and temporally validated a deep learning model (multi-output Gaussian process and recurrent neural network [MGP–RNN]) to detect sepsis using encounters from adult hospitalized patients at a large tertiary academic center. Sepsis was defined as the presence of 2 or more systemic inflammatory response syndrome (SIRS) criteria, a blood culture order, and at least one element of end-organ failure. The training dataset included demographics, comorbidities, vital signs, medication administrations, and labs from October 1, 2014 to December 1, 2015, while the temporal validation dataset was from March 1, 2018 to August 31, 2018. Comparisons were made to 3 machine learning methods, random forest (RF), Cox regression (CR), and penalized logistic regression (PLR), and 3 clinical scores used to detect sepsis, SIRS, quick Sequential Organ Failure Assessment (qSOFA), and National Early Warning Score (NEWS). Traditional discrimination statistics such as the C-statistic as well as metrics aligned with operational implementation were assessed.\n               \n               \n                  Results\n                  The training set and internal validation included 42 979 encounters, while the temporal validation set included 39 786 encounters. The C-statistic for predicting sepsis within 4 h of onset was 0.88 for the MGP–RNN compared to 0.836 for RF, 0.849 for CR, 0.822 for PLR, 0.756 for SIRS, 0.619 for NEWS, and 0.481 for qSOFA. MGP–RNN detected sepsis a median of 5 h in advance. Temporal validation assessment continued to show the MGP–RNN outperform all 7 clinical risk score and machine learning comparisons.\n               \n               \n                  Conclusions\n                  We developed and validated a novel deep learning model to detect sepsis. Using our data elements and feature set, our modeling approach outperformed other machine learning methods and clinical scores.",
      "publication_location": "Jamia Open",
      "link": "http://dx.doi.org/10.1093/jamiaopen/ooaa006",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning for the New York City power grid",
      "authors": "Rudin, C; Waltz, D; Anderson, R; Boulanger, A; Salleb-Aouissi, A; Chow, M; Dutta, H; Gross, P; Huang, B; Ierome, S; Isaac, DF; Kressner, A; Passonneau, RJ; Radeva, A; Wu, L",
      "published_date": "January 1, 2012",
      "doi": "10.1109/TPAMI.2011.108",
      "abstract": "Power companies can benefit from the use of knowledge discovery methods and statistical machine learning for preventive maintenance. We introduce a general process for transforming historical electrical grid data into models that aim to predict the risk of failures for components and systems. These models can be used directly by power companies to assist with prioritization of maintenance and repair work. Specialized versions of this process are used to produce 1) feeder failure rankings, 2) cable, joint, terminator, and transformer rankings, 3) feeder Mean Time Between Failure (MTBF) estimates, and 4) manhole events vulnerability rankings. The process in its most general form can handle diverse, noisy, sources that are historical (static), semi-real-time, or real-time, incorporates state-of-the-art machine learning algorithms for prioritization (supervised ranking or MTBF), and includes an evaluation of results via cross-validation and blind test. Above and beyond the ranked lists and MTBF estimates are business management interfaces that allow the prediction capability to be integrated directly into corporate planning and decision support; such interfaces rely on several important properties of our general modeling approach: that machine learning features are meaningful to domain experts, that the processing of data is transparent, and that prediction results are accurate enough to support sound decision making. We discuss the challenges in working with historical electrical grid data that were not designed for predictive purposes. The rawness of these data contrasts with the accuracy of the statistical models that can be obtained from the process; these models are sufficiently accurate to assist in maintaining New York City's electrical grid. © 2011 IEEE.",
      "publication_location": "Ieee Transactions on Pattern Analysis and Machine Intelligence",
      "link": "http://dx.doi.org/10.1109/TPAMI.2011.108",
      "citations": 97,
      "readership": 238,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Microbiome composition and implications for ballast water classification using machine learning.",
      "authors": "Gerhard, WA; Gunsch, CK",
      "published_date": "November 2019",
      "doi": "10.1016/j.scitotenv.2019.07.053",
      "abstract": "Ballast water is a vector for global translocation of microorganisms, and should be monitored to protect human and environmental health. This study utilizes high throughput sequencing (HTS) and machine learning to examine the bacterial and fungal microbiomes of ballast water to identify associations between 16S and 18S rRNA genes and the fungal ITS region. These sequencing regions were examined using the SILVA v132 and UNITE reference databases. The highest correlation was found between the communities in Silva_16S and UNITE_ITS (0.74). There was a higher proportion of positive inter-kingdom correlations than positive intra-kingdom interactions (p = 0.032). Understanding the reasons for this difference requires additional research under more controlled conditions. Finally, a machine learning model was used to examine the classification accuracy when using each sequencing region and reference database to identify ballast residence time and ballast sample location. There was significantly higher accuracy using SILVA (0.843) compared to UNITE (0.614) (p < 0.001). In the short term, future research with the goal of classifying ballast water samples based on location or ballast water residence time should be performed using the 16S rRNA gene and SILVA reference database. Research to curate other sequencing regions or the UNITE reference database in the aquatic ecosystem may improve the utility of these tools.",
      "publication_location": "The Science of the Total Environment",
      "link": "http://dx.doi.org/10.1016/j.scitotenv.2019.07.053",
      "citations": 1,
      "readership": 14,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Machine Learning and Statistical Models to Predict Postpartum Hemorrhage.",
      "authors": "Venkatesh, KK; Strauss, RA; Grotegut, CA; Heine, RP; Chescheir, NC; Stringer, JSA; Stamilio, DM; Menard, KM; Jelovsek, JE",
      "published_date": "April 2020",
      "doi": "10.1097/AOG.0000000000003759",
      "abstract": "OBJECTIVE: To predict a woman's risk of postpartum hemorrhage at labor admission using machine learning and statistical models. METHODS: Predictive models were constructed and compared using data from 10 of 12 sites in the U.S. Consortium for Safe Labor Study (2002-2008) that consistently reported estimated blood loss at delivery. The outcome was postpartum hemorrhage, defined as an estimated blood loss at least 1,000 mL. Fifty-five candidate risk factors routinely available on labor admission were considered. We used logistic regression with and without lasso regularization (lasso regression) as the two statistical models, and random forest and extreme gradient boosting as the two machine learning models to predict postpartum hemorrhage. Model performance was measured by C statistics (ie, concordance index), calibration, and decision curves. Models were constructed from the first phase (2002-2006) and externally validated (ie, temporally) in the second phase (2007-2008). Further validation was performed combining both temporal and site-specific validation. RESULTS: Of the 152,279 assessed births, 7,279 (4.8%, 95% CI 4.7-4.9) had postpartum hemorrhage. All models had good-to-excellent discrimination. The extreme gradient boosting model had the best discriminative ability to predict postpartum hemorrhage (C statistic: 0.93; 95% CI 0.92-0.93), followed by random forest (C statistic: 0.92; 95% CI 0.91-0.92). The lasso regression model (C statistic: 0.87; 95% CI 0.86-0.88) and logistic regression (C statistic: 0.87; 95% CI 0.86-0.87) had lower-but-good discriminative ability. The above results held with validation across both time and sites. Decision curve analysis demonstrated that, although all models provided superior net benefit when clinical decision thresholds were between 0% and 80% predicted risk, the extreme gradient boosting model provided the greatest net benefit. CONCLUSION: Postpartum hemorrhage on labor admission can be predicted with excellent discriminative ability using machine learning and statistical models. Further clinical application is needed, which may assist health care providers to be prepared and triage at-risk women.",
      "publication_location": "Obstet Gynecol",
      "link": "http://dx.doi.org/10.1097/AOG.0000000000003759",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 23,
      "news_mentions": ""
    },
    {
      "title": "Efficient statistical validation of machine learning systems for autonomous driving",
      "authors": "Shi, W; Alawieh, MB; Li, X; Yu, H; Arechiga, N; Tomatsu, N",
      "published_date": "November 7, 2016",
      "doi": "10.1145/2966986.2980077",
      "abstract": "© 2016 ACM. Today's automotive industry is making a bold move to equip vehicles with intelligent driver assistance features. A modern automobile is now equipped with a powerful computing platform to run multiple machine learning algorithms for environment perception (e.g., pedestrian detection) and motion control (e.g., vehicle stabilization). These machine learning systems must be highly robust with extremely small failure rate in order to ensure safe and reliable driving. In this paper, we propose a novel Subset Sampling (SUS) algorithm to efficiently validate a machine learning system. In particular, a Markov Chain Monte Carlo algorithm based on graph mapping is developed to accurately estimate the rare failure rate with a minimal amount of test data, thereby minimizing the validation cost. Our numerical experiments show that SUS achieves 15.2x runtime speed-up over the conventional brute-force Monte Carlo method.",
      "publication_location": "Ieee/Acm International Conference on Computer Aided Design, Digest of Technical Papers, Iccad",
      "link": "http://dx.doi.org/10.1145/2966986.2980077",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Quantifying Risk for Anxiety Disorders in Preschool Children: A Machine Learning Approach.",
      "authors": "Carpenter, KLH; Sprechmann, P; Calderbank, R; Sapiro, G; Egger, HL",
      "published_date": 2016,
      "doi": "10.1371/journal.pone.0165524",
      "abstract": "Early childhood anxiety disorders are common, impairing, and predictive of anxiety and mood disorders later in childhood. Epidemiological studies over the last decade find that the prevalence of impairing anxiety disorders in preschool children ranges from 0.3% to 6.5%. Yet, less than 15% of young children with an impairing anxiety disorder receive a mental health evaluation or treatment. One possible reason for the low rate of care for anxious preschoolers is the lack of affordable, timely, reliable and valid tools for identifying young children with clinically significant anxiety. Diagnostic interviews assessing psychopathology in young children require intensive training, take hours to administer and code, and are not available for use outside of research settings. The Preschool Age Psychiatric Assessment (PAPA) is a reliable and valid structured diagnostic parent-report interview for assessing psychopathology, including anxiety disorders, in 2 to 5 year old children. In this paper, we apply machine-learning tools to already collected PAPA data from two large community studies to identify sub-sets of PAPA items that could be developed into an efficient, reliable, and valid screening tool to assess a young child's risk for an anxiety disorder. Using machine learning, we were able to decrease by an order of magnitude the number of items needed to identify a child who is at risk for an anxiety disorder with an accuracy of over 96% for both generalized anxiety disorder (GAD) and separation anxiety disorder (SAD). Additionally, rather than considering GAD or SAD as discrete/binary entities, we present a continuous risk score representing the child's risk of meeting criteria for GAD or SAD. Identification of a short question-set that assesses risk for an anxiety disorder could be a first step toward development and validation of a relatively short screening tool feasible for use in pediatric clinics and daycare/preschool settings.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0165524",
      "citations": 8,
      "readership": 77,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "Emergence and distinction of classes in XRD data via machine learning",
      "authors": "Royse, C; Wolter, S; Greenberg, JA",
      "published_date": "January 1, 2019",
      "doi": "10.1117/12.2519500",
      "abstract": "© 2019 SPIE. Downloading of the abstract is permitted for personal use only. The material-specific information contained in X-ray diffraction (XRD) measurements make it attractive for the detection of threats in airport baggage. Spatially-localized XRD signatures at each voxel in a bag may be obtained with a snapshot via coded aperture XRD tomography, but measurement unceratinty due to data processing and low SNR can lead to loss in information. We use machine learning and non-linear dimension reduction to identify threat and non-threat items in a way that overcomes these variations in the data. We observe the emergence of clusters from the data, possibly providing new prospects for XRD-based classification. We further show improved performance using machine learning methods relative to a conventional, correlation-based classifier in the low-SNR regime.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2519500",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning Estimates of Global Marine Nitrogen Fixation",
      "authors": "Tang, W; Li, Z; Cassar, N",
      "published_date": "March 1, 2019",
      "doi": "10.1029/2018JG004828",
      "abstract": "© 2019. American Geophysical Union. All Rights Reserved. Marine nitrogen (N2) fixation supplies “new” nitrogen to the global ocean, supporting uptake and sequestration of carbon. Despite its central role, marine N2 fixation and its controlling factors remain elusive. In this study, we compile over 1,100 published observations to identify the dominant predictors of marine N2 fixation and derive global estimates based on the machine learning algorithms of random forest and support vector regression. We find that no single environmental property predicts N2 fixation at global scales. Our random forest and support vector regression algorithms, trained with sampling coordinates and month, solar radiation, wind speed, sea surface temperature, sea surface salinity, surface nitrate, surface phosphate, surface excess phosphorus, minimum oxygen in upper 500 m, photosynthetically available radiation, mixed layer depth, averaged photosynthetically available radiation in the mixed layer, and chlorophyll-a concentration, estimate global marine N2 fixation ranging from 68 to 90 Tg N/year. Comparison of our machine learning estimates and 11 other model outputs currently available in literature shows substantial discrepancies in the global magnitude and spatial distribution of marine N2 fixation, especially in the tropics and in high latitudes. The large uncertainties in marine N2 fixation highlighted in our study argue for increased and more coordinated efforts using geochemical tracers, modeling, and observations over broad ocean regions.",
      "publication_location": "Journal of Geophysical Research: Biogeosciences",
      "link": "http://dx.doi.org/10.1029/2018JG004828",
      "citations": 2,
      "readership": 36,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Vibrational Properties of Metastable Polymorph Structures by Machine Learning.",
      "authors": "Legrain, F; van Roekeghem, A; Curtarolo, S; Carrete, J; Madsen, GKH; Mingo, N",
      "published_date": "December 2018",
      "doi": "10.1021/acs.jcim.8b00279",
      "abstract": "Despite vibrational properties being critical for the ab initio prediction of finite-temperature stability as well as thermal conductivity and other transport properties of solids, their inclusion in ab initio materials repositories has been hindered by expensive computational requirements. Here we tackle the challenge, by showing that a good estimation of force constants and vibrational properties can be quickly achieved from the knowledge of atomic equilibrium positions using machine learning. A random-forest algorithm trained on 121 different mechanically stable structures of KZnF3 reaches a mean absolute error of 0.17 eV/Å2 for the interatomic force constants, and it is less expensive than training the complete force field for such compounds. The predicted force constants are then used to estimate phonon spectral features, heat capacities, vibrational entropies, and vibrational free energies, which compare well with the ab initio ones. The approach can be used for the rapid estimation of stability at finite temperatures.",
      "publication_location": "Journal of Chemical Information and Modeling",
      "link": "http://dx.doi.org/10.1021/acs.jcim.8b00279",
      "citations": 1,
      "readership": 29,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Machine Learning Identifies Stemness Features Associated with Oncogenic Dedifferentiation.",
      "authors": "Malta, TM; Sokolov, A; Gentles, AJ; Burzykowski, T; Poisson, L; Weinstein, JN; Kamińska, B; Huelsken, J; Omberg, L; Gevaert, O; Colaprico, A; Czerwińska, P; Mazurek, S; Mishra, L; Heyn, H; Krasnitz, A; Godwin, AK; Lazar, AJ; Cancer Genome Atlas Research Network, ; Stuart, JM; Hoadley, KA; Laird, PW; Noushmehr, H; Wiznerowicz, M",
      "published_date": "April 5, 2018",
      "doi": "10.1016/j.cell.2018.03.034",
      "abstract": "Cancer progression involves the gradual loss of a differentiated phenotype and acquisition of progenitor and stem-cell-like features. Here, we provide novel stemness indices for assessing the degree of oncogenic dedifferentiation. We used an innovative one-class logistic regression (OCLR) machine-learning algorithm to extract transcriptomic and epigenetic feature sets derived from non-transformed pluripotent stem cells and their differentiated progeny. Using OCLR, we were able to identify previously undiscovered biological mechanisms associated with the dedifferentiated oncogenic state. Analyses of the tumor microenvironment revealed unanticipated correlation of cancer stemness with immune checkpoint expression and infiltrating immune cells. We found that the dedifferentiated oncogenic phenotype was generally most prominent in metastatic tumors. Application of our stemness indices to single-cell data revealed patterns of intra-tumor molecular heterogeneity. Finally, the indices allowed for the identification of novel targets and possible targeted therapies aimed at tumor differentiation.",
      "publication_location": "Cell",
      "link": "http://dx.doi.org/10.1016/j.cell.2018.03.034",
      "citations": 172,
      "readership": 824,
      "tweets": 150,
      "news_mentions": 28
    },
    {
      "title": "Machine learning methods for credibility assessment of interviewees based on posturographic data.",
      "authors": "Saripalle, SK; Vemulapalli, S; King, GW; Burgoon, JK; Derakhshani, R",
      "published_date": 2015,
      "doi": "10.1109/EMBC.2015.7319932",
      "abstract": "This paper discusses the advantages of using posturographic signals from force plates for non-invasive credibility assessment. The contributions of our work are two fold: first, the proposed method is highly efficient and non invasive. Second, feasibility for creating an autonomous credibility assessment system using machine-learning algorithms is studied. This study employs an interview paradigm that includes subjects responding with truthful and deceptive intent while their center of pressure (COP) signal is being recorded. Classification models utilizing sets of COP features for deceptive responses are derived and best accuracy of 93.5% for test interval is reported.",
      "publication_location": "Conference Proceedings : ... Annual International Conference of the Ieee Engineering in Medicine and Biology Society. Ieee Engineering in Medicine and Biology Society. Annual Conference",
      "link": "http://dx.doi.org/10.1109/EMBC.2015.7319932",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning derived segmentation of phase velocity encoded cardiovascular magnetic resonance for fully automated aortic flow quantification.",
      "authors": "Bratt, A; Kim, J; Pollie, M; Beecy, AN; Tehrani, NH; Codella, N; Perez-Johnston, R; Palumbo, MC; Alakbarli, J; Colizza, W; Drexler, IR; Azevedo, CF; Kim, RJ; Devereux, RB; Weinsaft, JW",
      "published_date": "January 7, 2019",
      "doi": "10.1186/s12968-018-0509-0",
      "abstract": "BACKGROUND: Phase contrast (PC) cardiovascular magnetic resonance (CMR) is widely employed for flow quantification, but analysis typically requires time consuming manual segmentation which can require human correction. Advances in machine learning have markedly improved automated processing, but have yet to be applied to PC-CMR. This study tested a novel machine learning model for fully automated analysis of PC-CMR aortic flow. METHODS: A machine learning model was designed to track aortic valve borders based on neural network approaches. The model was trained in a derivation cohort encompassing 150 patients who underwent clinical PC-CMR then compared to manual and commercially-available automated segmentation in a prospective validation cohort. Further validation testing was performed in an external cohort acquired from a different site/CMR vendor. RESULTS: Among 190 coronary artery disease patients prospectively undergoing CMR on commercial scanners (84% 1.5T, 16% 3T), machine learning segmentation was uniformly successful, requiring no human intervention: Segmentation time was < 0.01 min/case (1.2 min for entire dataset); manual segmentation required 3.96 ± 0.36 min/case (12.5 h for entire dataset). Correlations between machine learning and manual segmentation-derived flow approached unity (r = 0.99, p < 0.001). Machine learning yielded smaller absolute differences with manual segmentation than did commercial automation (1.85 ± 1.80 vs. 3.33 ± 3.18 mL, p < 0.01): Nearly all (98%) of cases differed by ≤5 mL between machine learning and manual methods. Among patients without advanced mitral regurgitation, machine learning correlated well (r = 0.63, p < 0.001) and yielded small differences with cine-CMR stroke volume (∆ 1.3 ± 17.7 mL, p = 0.36). Among advanced mitral regurgitation patients, machine learning yielded lower stroke volume than did volumetric cine-CMR (∆ 12.6 ± 20.9 mL, p = 0.005), further supporting validity of this method. Among the external validation cohort (n = 80) acquired using a different CMR vendor, the algorithm yielded equivalently small differences (∆ 1.39 ± 1.77 mL, p = 0.4) and high correlations (r = 0.99, p < 0.001) with manual segmentation, including similar results in 20 patients with bicuspid or stenotic aortic valve pathology (∆ 1.71 ± 2.25 mL, p = 0.25). CONCLUSION: Fully automated machine learning PC-CMR segmentation performs robustly for aortic flow quantification - yielding rapid segmentation, small differences with manual segmentation, and identification of differential forward/left ventricular volumetric stroke volume in context of concomitant mitral regurgitation. Findings support use of machine learning for analysis of large scale CMR datasets.",
      "publication_location": "Journal of Cardiovascular Magnetic Resonance",
      "link": "http://dx.doi.org/10.1186/s12968-018-0509-0",
      "citations": 10,
      "readership": 50,
      "tweets": 29,
      "news_mentions": ""
    },
    {
      "title": "Enhancement of Risk Prediction With Machine Learning: Rise of the Machines.",
      "authors": "Rymer, JA; Rao, SV",
      "published_date": "July 3, 2019",
      "doi": "10.1001/jamanetworkopen.2019.6823",
      "abstract": "",
      "publication_location": "Jama Network Open",
      "link": "http://dx.doi.org/10.1001/jamanetworkopen.2019.6823",
      "citations": "(None,)",
      "readership": 8,
      "tweets": 22,
      "news_mentions": 2
    },
    {
      "title": "Relational machine learning for electronic health record-driven phenotyping.",
      "authors": "Peissig, PL; Santos Costa, V; Caldwell, MD; Rottscheit, C; Berg, RL; Mendonca, EA; Page, D",
      "published_date": "December 2014",
      "doi": "10.1016/j.jbi.2014.07.007",
      "abstract": "OBJECTIVE: Electronic health records (EHR) offer medical and pharmacogenomics research unprecedented opportunities to identify and classify patients at risk. EHRs are collections of highly inter-dependent records that include biological, anatomical, physiological, and behavioral observations. They comprise a patient's clinical phenome, where each patient has thousands of date-stamped records distributed across many relational tables. Development of EHR computer-based phenotyping algorithms require time and medical insight from clinical experts, who most often can only review a small patient subset representative of the total EHR records, to identify phenotype features. In this research we evaluate whether relational machine learning (ML) using inductive logic programming (ILP) can contribute to addressing these issues as a viable approach for EHR-based phenotyping. METHODS: Two relational learning ILP approaches and three well-known WEKA (Waikato Environment for Knowledge Analysis) implementations of non-relational approaches (PART, J48, and JRIP) were used to develop models for nine phenotypes. International Classification of Diseases, Ninth Revision (ICD-9) coded EHR data were used to select training cohorts for the development of each phenotypic model. Accuracy, precision, recall, F-Measure, and Area Under the Receiver Operating Characteristic (AUROC) curve statistics were measured for each phenotypic model based on independent manually verified test cohorts. A two-sided binomial distribution test (sign test) compared the five ML approaches across phenotypes for statistical significance. RESULTS: We developed an approach to automatically label training examples using ICD-9 diagnosis codes for the ML approaches being evaluated. Nine phenotypic models for each ML approach were evaluated, resulting in better overall model performance in AUROC using ILP when compared to PART (p=0.039), J48 (p=0.003) and JRIP (p=0.003). DISCUSSION: ILP has the potential to improve phenotyping by independently delivering clinically expert interpretable rules for phenotype definitions, or intuitive phenotypes to assist experts. CONCLUSION: Relational learning using ILP offers a viable approach to EHR-driven phenotyping.",
      "publication_location": "J Biomed Inform",
      "link": "http://dx.doi.org/10.1016/j.jbi.2014.07.007",
      "citations": 29,
      "readership": "(None,)",
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Application of machine learning to X-ray diffraction-based classification",
      "authors": "Zhao, B; Wolter, S; Greenberg, JA",
      "published_date": "January 1, 2018",
      "doi": "10.1117/12.2304683",
      "abstract": "© Copyright 2018 SPIE. X-ray diffraction-based baggage screening provides the potential for the material sensitivity needed to realize high detection probabilities and low false alarm rates. However, the combination of noisy signals, variability in the XRD form factors based on slight material differences, and incomplete material libraries lead to decreased system performance. By using a machine learning classification approach to XRD-based explosives detection, we show that the probability of error can be reduced relative to traditional, correlation-based classifiers. This improved performance exists at a variety of noise levels and degrees of library completeness, and indicates a path toward increased XRD-based classifier robustness.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2304683",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Chip health monitoring using machine learning",
      "authors": "Firouzi, F; Ye, F; Chakrabarty, K; Tahoori, MB",
      "published_date": "January 1, 2014",
      "doi": "10.1109/ISVLSI.2014.119",
      "abstract": "© 2014 IEEE. In nanoscale technology nodes, process and runtime variations have emerged as the major sources of timing uncertainties which may ultimately result in circuit failure due to timing violation. Therefore, in-field chip health monitoring is essential to track workload-induced variations at runtime in a per-chip basis. There exist a variety of monitoring circuits to track the delay changes of different on-chip components. However, existing techniques either need to stop normal execution of the chip or introduce a significant overhead unless they are carefully placed for very selective locations. Another challenge is to infer the information regarding the health of every critical paths of the chip with limited information obtained by the monitoring system. We address these challenges in this work using a representative path-selection technique based on machine learning. This technique allows us to measure the delay of a small subset of paths and assess the circuit-level impact of workload for a larger pool of reliability-critical paths.",
      "publication_location": "Proceedings of Ieee Computer Society Annual Symposium on Vlsi, Isvlsi",
      "link": "http://dx.doi.org/10.1109/ISVLSI.2014.119",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Using machine learning to mitigate the effects of reverberation and noise in cochlear implants",
      "authors": "Chu, K; Throckmorton, C; Collins, L; Mainsah, B",
      "published_date": "January 1, 2018",
      "doi": "10.1121/2.0000905",
      "abstract": "© 2018 Acoustical Society of America. In listening environments with room reverberation and background noise, cochlear implant (CI) users experience substantial difficulties in understanding speech. Because everyday environments have different combinations of reverberation and noise, there is a need to develop algorithms that can mitigate both effects to improve speech intelligibility. Desmond et al. (2014) developed a machine learning approach to mitigate the adverse effects of late reverberant reflections of speech signals by using a classifier to detect and remove affected segments in CI pulse trains. This study aimed to investigate the robustness of the reverberation mitigation algorithm in environments with both reverberation and noise. Sentence recognition tests were conducted in normal hearing listeners using vocoded speech with unmitigated and mitigated reverberant-only or noisy reverberant speech signals, across different reverberation times and noise types. Improvements in speech intelligibility were observed in mitigated reverberant-only conditions. However, mixed results were obtained in the mitigated noisy reverberant conditions as a reduction in speech intelligibility was observed for noise types whose spectra were similar to that of anechoic speech. Based on these results, the focus of future work is to develop a context-dependent approach that activates different mitigation strategies for different acoustic environments.",
      "publication_location": "Proceedings of Meetings on Acoustics",
      "link": "http://dx.doi.org/10.1121/2.0000905",
      "citations": "(None,)",
      "readership": 2,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "A machine learning approach for the prediction of protein surface loop flexibility.",
      "authors": "Hwang, H; Vreven, T; Whitfield, TW; Wiehe, K; Weng, Z",
      "published_date": "August 2011",
      "doi": "10.1002/prot.23070",
      "abstract": "Proteins often undergo conformational changes when binding to each other. A major fraction of backbone conformational changes involves motion on the protein surface, particularly in loops. Accounting for the motion of protein surface loops represents a challenge for protein-protein docking algorithms. A first step in addressing this challenge is to distinguish protein surface loops that are likely to undergo backbone conformational changes upon protein-protein binding (mobile loops) from those that are not (stationary loops). In this study, we developed a machine learning strategy based on support vector machines (SVMs). Our SVM uses three features of loop residues in the unbound protein structures-Ramachandran angles, crystallographic B-factors, and relative accessible surface area-to distinguish mobile loops from stationary ones. This method yields an average prediction accuracy of 75.3% compared with a random prediction accuracy of 50%, and an average of 0.79 area under the receiver operating characteristic (ROC) curve using cross-validation. Testing the method on an independent dataset, we obtained a prediction accuracy of 70.5%. Finally, we applied the method to 11 complexes that involve members from the Ras superfamily and achieved prediction accuracy of 92.8% for the Ras superfamily proteins and 74.4% for their binding partners.",
      "publication_location": "Proteins",
      "link": "http://dx.doi.org/10.1002/prot.23070",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Special session on machine learning for test and diagnosis",
      "authors": "Chakrabarty, K; Wang, LC; Veda, G; Huang, Y",
      "published_date": "May 29, 2018",
      "doi": "10.1109/VTS.2018.8368658",
      "abstract": "© 2018 IEEE. The special session focuses on using Machine Learning (ML) techniques on different applications in test and diagnosis. The first contribution discusses how to close the gap between working silicon and a working system by using ML. The second presentation then talks an alternative ML view and its various applications such as functional verification, Fmax prediction, and production yield optimization. The last presentation discusses using supervised ML on volume diagnosis to further improve the accuracy of identifying root causes.",
      "publication_location": "Proceedings of the Ieee Vlsi Test Symposium",
      "link": "http://dx.doi.org/10.1109/VTS.2018.8368658",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Data management in machine learning: Challenges, techniques, and systems",
      "authors": "Kumar, A; Boehm, M; Yang, J",
      "published_date": "May 9, 2017",
      "doi": "10.1145/3035918.3054775",
      "abstract": "© 2017 ACM. Large-scale data analytics using statistical machine learning (ML), popularly called advanced analytics, underpins many modern data-driven applications. The data management community has been working for over a decade on tackling data management-related challenges that arise in ML workloads, and has built several systems for advanced analytics. This tutorial provides a comprehensive review of such systems and analyzes key data management challenges and techniques. We focus on three complementary lines of work: (1) integrating ML algorithms and languages with existing data systems such as RDBMSs, (2) adapting data management-inspired techniques such as query optimization, partitioning, and compression to new systems that target ML workloads, and (3) combining data management and ML ideas to build systems that improve ML lifecycle-related tasks. Finally, we identify key open data management challenges for future research in this important area.",
      "publication_location": "Proceedings of the Acm Sigmod International Conference on Management of Data",
      "link": "http://dx.doi.org/10.1145/3035918.3054775",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning modeling of superconducting critical temperature",
      "authors": "Stanev, V; Oses, C; Kusne, AG; Rodriguez, E; Paglione, J; Curtarolo, S; Takeuchi, I",
      "published_date": "December 1, 2018",
      "doi": "10.1038/s41524-018-0085-8",
      "abstract": "© 2018 The Author(s). Superconductivity has been the focus of enormous research effort since its discovery more than a century ago. Yet, some features of this unique phenomenon remain poorly understood; prime among these is the connection between superconductivity and chemical/structural properties of materials. To bridge the gap, several machine learning schemes are developed herein to model the critical temperatures (T c) of the 12,000+ known superconductors available via the SuperCon database. Materials are first divided into two classes based on their T c values, above and below 10 K, and a classification model predicting this label is trained. The model uses coarse-grained features based only on the chemical compositions. It shows strong predictive power, with out-of-sample accuracy of about 92%. Separate regression models are developed to predict the values of T c for cuprate, iron-based, and low-T c compounds. These models also demonstrate good performance, with learned predictors offering potential insights into the mechanisms behind superconductivity in different families of materials. To improve the accuracy and interpretability of these models, new features are incorporated using materials data from the AFLOW Online Repositories. Finally, the classification and regression models are combined into a single-integrated pipeline and employed to search the entire Inorganic Crystallographic Structure Database (ICSD) for potential new superconductors. We identify >30 non-cuprate and non-iron-based oxides as candidate materials.",
      "publication_location": "Npj Computational Materials",
      "link": "http://dx.doi.org/10.1038/s41524-018-0085-8",
      "citations": 51,
      "readership": 224,
      "tweets": 49,
      "news_mentions": ""
    },
    {
      "title": "Building virtual community in computational intelligence and machine learning",
      "authors": "Zurada, JM; Mazurowski, MA; Ragade, R; Abdullin, A; Wojtudiak, J; Gentle, J",
      "published_date": "November 6, 2009",
      "doi": "10.1109/MCI.2008.930986",
      "abstract": "Researchers are making efforts to build a virtual community In computational intelligence (CI) and machine learning (ML). A virtual organization is a group of geographically distributed individuals or institutions that cooperate with each other concurrently. These organizations have become feasible and more convenient than traditional forms of organizations due to the introduction of information technologies to help facilitate them. A number of significant factors drive the development and establishment of these organizations. These organizations are being established to help CI and ML researchers review research papers frequently. These organizations help in interacting with other researchers, quickly obtain relevant reference material, or find programs that are easily adaptable to the project. These organizations are playing a key role in solving many problems in the fields of medicine, genomics, earth sciences, and some engineering areas.",
      "publication_location": "Ieee Computational Intelligence Magazine",
      "link": "http://dx.doi.org/10.1109/MCI.2008.930986",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Development and validation of a machine learning, smartphone-based tonometer.",
      "authors": "Wu, Y; Luttrell, I; Feng, S; Chen, PP; Spaide, T; Lee, AY; Wen, JC",
      "published_date": "December 23, 2019",
      "doi": "10.1136/bjophthalmol-2019-315446",
      "abstract": "BACKGROUND/AIMS: To compare intraocular pressure (IOP) measurements using a prototype smartphone tonometer with other tonometers used in clinical practice. METHODS: Patients from an academic glaucoma practice were recruited. The smartphone tonometer uses fixed force applanation and in conjunction with a machine-learning computer algorithm is able to calculate the IOP. IOP was also measured using Goldmann applanation tonometry (GAT) in all subjects. A subset of patients were also measured using ICare, pneumotonometry (upright and supine positions) and Tono-Pen (upright and supine positions) and the results were compared. RESULTS: 92 eyes of 81 subjects were successfully measured. The mean difference (in mm Hg) for IOP measurements of the smartphone tonometer versus other devices was +0.24 mm Hg for GAT, -1.39 mm Hg for ICare, -3.71 mm Hg for pneumotonometry and -1.30 mm Hg for Tono-Pen. The 95% limits of agreement for the smartphone tonometer versus other devices was -4.35 to 4.83 mm Hg for GAT, -6.48 to 3.70 mm Hg for ICare, -7.66 to -0.15 mm Hg for pneumotonometry and -5.72 to 3.12 mm Hg for Tono-Pen. Overall, the smartphone tonometer results correlated best with GAT (R2=0.67, p<0.001). Of the 92 videos, 90 (97.8%) were within ±5 mm Hg of GAT and 58 (63.0%) were within ±2 mm Hg of GAT. CONCLUSIONS: Preliminary IOP measurements using a prototype smartphone-based tonometer was grossly equivalent to the reference standard.",
      "publication_location": "British Journal of Ophthalmology",
      "link": "http://dx.doi.org/10.1136/bjophthalmol-2019-315446",
      "citations": 1,
      "readership": "(None,)",
      "tweets": 9,
      "news_mentions": ""
    },
    {
      "title": "The big Data newsvendor: Practical insights from machine learning",
      "authors": "Ban, GY; Rudin, C",
      "published_date": "January 1, 2019",
      "doi": "10.1287/opre.2018.1757",
      "abstract": "© 2018 INFORM. We investigate the data-driven newsvendor problem when one has n observations of p features related to the demand as well as historical demand data. Rather than a two-step process of first estimating a demand distribution then optimizing for the optimal order quantity, we propose solving the “big data” newsvendor problem via single-step machine-learning algorithms. Specifically, we propose algorithms based on the empirical risk minimization (ERM) principle, with and without regularization, and an algorithm based on kernel-weights optimization (KO). The ERM approaches, equivalent to high-dimensional quantile regression, can be solved by convex optimization problems and the KO approach by a sorting algorithm. We analytically justify the use of features by showing that their omission yields inconsistent decisions. We then derive finite-sample performance bounds on the out-of-sample costs of the feature-based algorithms, which quantify the effects of dimensionality and cost parameters. Our bounds, based on algorithmic stability theory, generalize known analyses for the newsvendor problem without feature information. Finally, we apply the feature-based algorithms for nurse staffing in a hospital emergency room using a data set from a large UK teaching hospital and find that (1) the best ERM and KO algorithms beat the best practice benchmark by 23% and 24%, respectively, in the out-of-sample cost, and (2) the best KO algorithm is faster than the best ERM algorithm by three orders of magnitude and the best practice benchmark by two orders of magnitude.",
      "publication_location": "Operations Research",
      "link": "http://dx.doi.org/10.1287/opre.2018.1757",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Subject Matter Knowledge in the Age of Big Data and Machine Learning.",
      "authors": "Goldstein, BA; Carlson, D; Bhavsar, NA",
      "published_date": "August 3, 2018",
      "doi": "10.1001/jamanetworkopen.2018.1568",
      "abstract": "",
      "publication_location": "Jama Network Open",
      "link": "http://dx.doi.org/10.1001/jamanetworkopen.2018.1568",
      "citations": 4,
      "readership": 21,
      "tweets": 68,
      "news_mentions": 3
    },
    {
      "title": "Stylistic analysis of paintings using wavelets and machine learning",
      "authors": "Jafarpour, S; Polatkan, G; Brevdo, E; Hughes, S; Brasoveanu, A; Daubechies, I",
      "published_date": "December 1, 2009",
      "doi": "",
      "abstract": "Wavelet transforms and machine learning tools can be used to assist art experts in the stylistic analysis of paintings. A dual-tree complex wavelet transform, Hidden Markov Tree modeling and Random Forest classifiers are used here for a stylistic analysis of Vincent van Gogh's paintings with results on two stylometry challenges that concern \"dating, resp. extracting distinguishing features\". © EURASIP, 2009.",
      "publication_location": "European Signal Processing Conference",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Discovery of high-entropy ceramics via machine learning",
      "authors": "Kaufmann, K; Maryanovsky, D; Mellor, WM; Zhu, C; Rosengarten, AS; Harrington, TJ; Oses, C; Toher, C; Curtarolo, S; Vecchio, KS",
      "published_date": "December 1, 2020",
      "doi": "10.1038/s41524-020-0317-6",
      "abstract": "© 2020, The Author(s). Although high-entropy materials are attracting considerable interest due to a combination of useful properties and promising applications, predicting their formation remains a hindrance for rational discovery of new systems. Experimental approaches are based on physical intuition and/or expensive trial and error strategies. Most computational methods rely on the availability of sufficient experimental data and computational power. Machine learning (ML) applied to materials science can accelerate development and reduce costs. In this study, we propose an ML method, leveraging thermodynamic and compositional attributes of a given material for predicting the synthesizability (i.e., entropy-forming ability) of disordered metal carbides. The relative importance of the thermodynamic and compositional features for the predictions are then explored. The approach’s suitability is demonstrated by comparing values calculated with density functional theory to ML predictions. Finally, the model is employed to predict the entropy-forming ability of 70 new compositions; several predictions are validated by additional density functional theory calculations and experimental synthesis, corroborating the effectiveness in exploring vast compositional spaces in a high-throughput manner. Importantly, seven compositions are selected specifically, because they contain all three of the Group VI elements (Cr, Mo, and W), which do not form room temperature-stable rock-salt monocarbides. Incorporating the Group VI elements into the rock-salt structure provides further opportunity for tuning the electronic structure and potentially material performance.",
      "publication_location": "Npj Computational Materials",
      "link": "http://dx.doi.org/10.1038/s41524-020-0317-6",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "Optimizing Count Responses in Surveys: A Machine-learning Approach",
      "authors": "Fu, Q; Guo, X; Land, KC",
      "published_date": "January 1, 2018",
      "doi": "10.1177/0049124117747302",
      "abstract": "© 2018, The Author(s) 2018. Count responses with grouping and right censoring have long been used in surveys to study a variety of behaviors, status, and attitudes. Yet grouping or right-censoring decisions of count responses still rely on arbitrary choices made by researchers. We develop a new method for evaluating grouping and right-censoring decisions of count responses from a (semisupervised) machine-learning perspective. This article uses Poisson multinomial mixture models to conceptualize the data-generating process of count responses with grouping and right censoring and demonstrates the link between grouping-scheme choices and asymptotic distributions of the Poisson mixture. To search for the optimal grouping scheme maximizing objective functions of the Fisher information (matrix), an innovative three-step M algorithm is then proposed to process infinitely many grouping schemes based on Bayesian A-, D-, and E-optimalities. A new R package is developed to implement this algorithm and evaluate grouping schemes of count responses. Results show that an optimal grouping scheme not only leads to a more efficient sampling design but also outperforms a nonoptimal one even if the latter has more groups.",
      "publication_location": "Sociological Methods & Research",
      "link": "http://dx.doi.org/10.1177/0049124117747302",
      "citations": 1,
      "readership": 4,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Application of a machine learning algorithm to predict malignancy in thyroid cytopathology.",
      "authors": "Elliott Range, DD; Dov, D; Kovalsky, SZ; Henao, R; Carin, L; Cohen, J",
      "published_date": "April 2020",
      "doi": "10.1002/cncy.22238",
      "abstract": "BACKGROUND: The Bethesda System for Reporting Thyroid Cytopathology (TBSRTC) comprises 6 categories used for the diagnosis of thyroid fine-needle aspiration biopsy (FNAB). Each category has an associated risk of malignancy, which is important in the management of a thyroid nodule. More accurate predictions of malignancy may help to reduce unnecessary surgery. A machine learning algorithm (MLA) was developed to evaluate thyroid FNAB via whole slide images (WSIs) to predict malignancy. METHODS: Files were searched for all thyroidectomy specimens with preceding FNAB over 8 years. All cytologic and surgical pathology diagnoses were recorded and correlated for each nodule. One representative slide from each case was scanned to create a WSI. An MLA was designed to identify follicular cells and predict the malignancy of the final pathology. The test set comprised cases blindly reviewed by a cytopathologist who assigned a TBSRTC category. The area under the receiver operating characteristic curve was used to assess the MLA performance. RESULTS: Nine hundred eight FNABs met the criteria. The MLA predicted malignancy with a sensitivity and specificity of 92.0% and 90.5%, respectively. The areas under the curve for the prediction of malignancy by the cytopathologist and the MLA were 0.931 and 0.932, respectively. CONCLUSIONS: The performance of the MLA in predicting thyroid malignancy from FNAB WSIs is comparable to the performance of an expert cytopathologist. When the MLA and electronic medical record diagnoses are combined, the performance is superior to the performance of either alone. An MLA may be used as an adjunct to FNAB to assist in refining the indeterminate categories.",
      "publication_location": "Cancer Cytopathol",
      "link": "http://dx.doi.org/10.1002/cncy.22238",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 19,
      "news_mentions": ""
    },
    {
      "title": "Machine-Learning-Driven Matrix Ordering for Power Grid Analysis",
      "authors": "Cui, G; Yu, W; Li, X; Zeng, Z; Gu, B",
      "published_date": "May 14, 2019",
      "doi": "10.23919/DATE.2019.8715086",
      "abstract": "© 2019 EDAA. A machine-learning-driven approach for matrix ordering is proposed for power grid analysis based on domain decomposition. It utilizes support vector machine or artificial neural network to learn a classifier to automatically choose the optimal ordering algorithm, thereby reducing the expense of solving the subdomain equations. Based on the feature selection considering sparse matrix properties, the proposed method achieves superior efficiency in runtime and memory usage over conventional methods, as demonstrated by industrial test cases.",
      "publication_location": "Proceedings of the 2019 Design, Automation and Test in Europe Conference and Exhibition, Date 2019",
      "link": "http://dx.doi.org/10.23919/DATE.2019.8715086",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Investigating Predictors of Cognitive Decline Using Machine Learning.",
      "authors": "Casanova, R; Saldana, S; Lutz, MW; Plassman, BL; Kuchibhatla, M; Hayden, KM",
      "published_date": "March 9, 2020",
      "doi": "10.1093/geronb/gby054",
      "abstract": "OBJECTIVES: Genetic risks for cognitive decline are not modifiable; however their relative importance compared to modifiable factors is unclear. We used machine learning to evaluate modifiable and genetic risk factors for Alzheimer's disease (AD), to predict cognitive decline. METHODS: Health and Retirement Study participants, aged 65-90 years, with DNA and >2 cognitive evaluations, were included (n = 7,142). Predictors included age, body mass index, gender, education, APOE ε4, cardiovascular, hypertension, diabetes, stroke, neighborhood socioeconomic status (NSES), and AD risk genes. Latent class trajectory analyses of cognitive scores determined the form and number of classes. Random Forests (RF) classification investigated predictors of cognitive trajectories. Performance metrics (accuracy, sensitivity, and specificity) were reported. RESULTS: Three classes were identified. Discriminating highest from lowest classes produced the best RF performance: accuracy = 78% (1.0%), sensitivity = 75% (1.0%), and specificity = 81% (1.0%). Top ranked predictors were education, age, gender, stroke, NSES, and diabetes, APOE ε4 carrier status, and body mass index (BMI). When discriminating high from medium classes, top predictors were education, age, gender, stroke, diabetes, NSES, and BMI. When discriminating medium from the low classes, education, NSES, age, diabetes, and stroke were top predictors. DISCUSSION: The combination of latent trajectories and RF classification techniques suggested that nongenetic factors contribute more to cognitive decline than genetic factors. Education was the most relevant predictor for discrimination.",
      "publication_location": "Journals of Gerontology: Series B",
      "link": "http://dx.doi.org/10.1093/geronb/gby054",
      "citations": 2,
      "readership": 21,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Assessing intervention timing in computer-based education using machine learning algorithms",
      "authors": "Stimpson, AJ; Cummings, ML",
      "published_date": "January 1, 2014",
      "doi": "10.1109/ACCESS.2014.2303071",
      "abstract": "The use of computer-based and online education systems has made new data available that can describe the temporal and process-level progression of learning. To date, machine learning research has not considered the impacts of these properties on the machine learning prediction task in educational settings. Machine learning algorithms may have applications in supporting targeted intervention approaches. The goals of this paper are to: 1) determine the impact of process-level information on machine learning prediction results and 2) establish the effect of type of machine learning algorithm used on prediction results. Data were collected from a university level course in human factors engineering (n =35), which included both traditional classroom assessment and computer-based assessment methods. A set of common regression and classification algorithms were applied to the data to predict final course score. The overall prediction accuracy as well as the chronological progression of prediction accuracy was analyzed for each algorithm. Simple machine learning algorithms (linear regression, logistic regression) had comparable performance with more complex methods (support vector machines, artificial neural networks). Process-level information was not useful in post-hoc predictions, but contributed significantly to allowing for accurate predictions to be made earlier in the course. Process level information provides useful prediction features for development of targeted intervention techniques, as it allows more accurate predictions to be made earlier in the course. For small course data sets, the prediction accuracy and simplicity of linear regression and logistic regression make these methods preferable to more complex algorithms. © © 2014 IEEE.",
      "publication_location": "Ieee Access",
      "link": "http://dx.doi.org/10.1109/ACCESS.2014.2303071",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Integrating machine learning and physician knowledge to improve the accuracy of breast biopsy.",
      "authors": "Dutra, I; Nassif, H; Page, D; Shavlik, J; Strigel, RM; Wu, Y; Elezaby, ME; Burnside, E",
      "published_date": 2011,
      "doi": "",
      "abstract": "In this work we show that combining physician rules and machine learned rules may improve the performance of a classifier that predicts whether a breast cancer is missed on percutaneous, image-guided breast core needle biopsy (subsequently referred to as \"breast core biopsy\"). Specifically, we show how advice in the form of logical rules, derived by a sub-specialty, i.e. fellowship trained breast radiologists (subsequently referred to as \"our physicians\") can guide the search in an inductive logic programming system, and improve the performance of a learned classifier. Our dataset of 890 consecutive benign breast core biopsy results along with corresponding mammographic findings contains 94 cases that were deemed non-definitive by a multidisciplinary panel of physicians, from which 15 were upgraded to malignant disease at surgery. Our goal is to predict upgrade prospectively and avoid surgery in women who do not have breast cancer. Our results, some of which trended toward significance, show evidence that inductive logic programming may produce better results for this task than traditional propositional algorithms with default parameters. Moreover, we show that adding knowledge from our physicians into the learning process may improve the performance of the learned classifier trained only on data.",
      "publication_location": "Amia ... Annual Symposium Proceedings. Amia Symposium",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/22195087",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning based identification of pathological heart sounds",
      "authors": "Gokhale, T",
      "published_date": "March 1, 2016",
      "doi": "",
      "abstract": "© 2016 CCAL. Automated interpretation of heart sounds holds great promise in increasing the diagnostic accuracy and consistency of cardiac auscultation and allowing for use in remote, tele-health settings. However, existing algorithms for classification of hearts sounds have been constrained by limited idealized training sets and methodological issues with validation. As part of the 2016 PhysioNet Challenge competition, we present an algorithm for automated heart sound classification sthat uses Hilbert-envelope and wavelet features to attempt to capture the qualities of the heart sounds that physicians are trained to interpret. We perform a two-step classification of heart sounds into poor quality, normal or abnormal with sensitivity of 0.7958 and specificity of 0.7459.",
      "publication_location": "Computing in Cardiology",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Revisiting Multi-Step Nonlinearity Compensation with Machine Learning.",
      "authors": "Häger, C; Pfister, HD; Bütler, RM; Liga, G; Alvarado, A",
      "published_date": 2019,
      "doi": "",
      "abstract": "",
      "publication_location": "Corr",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Topology, geometry, and machine-learning for tracking and sensor fusion",
      "authors": "Bendich, P",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning in Medical Imaging: All Journeys Begin With a Single Step.",
      "authors": "Judd, RM",
      "published_date": "March 2020",
      "doi": "10.1016/j.jcmg.2019.08.028",
      "abstract": "",
      "publication_location": "Jacc Cardiovasc Imaging",
      "link": "http://dx.doi.org/10.1016/j.jcmg.2019.08.028",
      "citations": "(None,)",
      "readership": 2,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Robust optimization using machine learning for uncertainty sets",
      "authors": "Tulabandhula, T; Rudin, C",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "© 2014 University of Illinois at Chicago. All rights reserved. Our goal is to build robust optimization problems that make decisions about the future, and where complex data from the past are used to model uncertainty. In robust optimization (RO) generally, the goal is to create a policy for decision-making that is robust to our uncertainty about the future. In particular, we want our policy to best handle the the worst possible situation that could arise, out of an uncertainty set of possible situations. Classically, the uncertainty set is simply chosen by the user, or it might be estimated in overly simplistic ways with strong assumptions; whereas in this work, we learn the uncertainty set from complex data from the past. The past data are drawn randomly from an (unknown) possibly complicated high-dimensional distribution. We propose a new uncertainty set design and show how tools from statistical learning theory can be employed to provide probabilistic guarantees on the robustness of the policy.",
      "publication_location": "International Symposium on Artificial Intelligence and Mathematics, Isaim 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Robust optimization using machine learning for uncertainty sets",
      "authors": "Tulabandhula, T; Rudin, C",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "© 2014 University of Illinois at Chicago. All rights reserved. Our goal is to build robust optimization problems that make decisions about the future, and where complex data from the past are used to model uncertainty. In robust optimization (RO) generally, the goal is to create a policy for decision-making that is robust to our uncertainty about the future. In particular, we want our policy to best handle the the worst possible situation that could arise, out of an uncertainty set of possible situations. Classically, the uncertainty set is simply chosen by the user, or it might be estimated in overly simplistic ways with strong assumptions; whereas in this work, we learn the uncertainty set from complex data from the past. The past data are drawn randomly from an (unknown) possibly complicated high-dimensional distribution. We propose a new uncertainty set design and show how tools from statistical learning theory can be employed to provide probabilistic guarantees on the robustness of the policy.",
      "publication_location": "International Symposium on Artificial Intelligence and Mathematics, Isaim 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Using machine learning to advance synthesis and use of conservation and environmental evidence",
      "authors": "Cheng, SH; Augustin, C; Bethel, A; Gill, D; Anzaroot, S; Brun, J; DeWilde, B; Minnich, RC; Garside, R; Masuda, YJ; Miller, DC; Wilkie, D; Wongbusarakum, S; McKinnon, MC",
      "published_date": "August 2018",
      "doi": "10.1111/cobi.13117",
      "abstract": "",
      "publication_location": "Conservation Biology : the Journal of the Society for Conservation Biology",
      "link": "http://dx.doi.org/10.1111/cobi.13117",
      "citations": 13,
      "readership": 67,
      "tweets": 88,
      "news_mentions": ""
    },
    {
      "title": "Machine learning in 'big data': handle with care.",
      "authors": "Loring, Z; Mehrotra, S; Piccini, JP",
      "published_date": "September 1, 2019",
      "doi": "10.1093/europace/euz130",
      "abstract": "",
      "publication_location": "Europace",
      "link": "http://dx.doi.org/10.1093/europace/euz130",
      "citations": 2,
      "readership": 3,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "256: Machine learning-based prediction models for postpartum hemorrhage",
      "authors": "Venkatesh, KK; Strauss, R; Grotegut, C; Heine, P; Stamilio, DM; Menard, K; Jelovsek, E",
      "published_date": "January 2020",
      "doi": "10.1016/j.ajog.2019.11.272",
      "abstract": "",
      "publication_location": "American Journal of Obstetrics and Gynecology",
      "link": "http://dx.doi.org/10.1016/j.ajog.2019.11.272",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Recognizing patterns of visual field loss using unsupervised machine learning",
      "authors": "Yousefi, S; Goldbaum, MH; Zangwill, LM; Medeiros, FA; Bowd, C",
      "published_date": "January 1, 2014",
      "doi": "10.1117/12.2043145",
      "abstract": "Glaucoma is a potentially blinding optic neuropathy that results in a decrease in visual sensitivity. Visual field abnormalities (decreased visual sensitivity on psychophysical tests) are the primary means of glaucoma diagnosis. One form of visual field testing is Frequency Doubling Technology (FDT) that tests sensitivity at 52 points within the visual field. Like other psychophysical tests used in clinical practice, FDT results yield specific patterns of defect indicative of the disease. We used Gaussian Mixture Model with Expectation Maximization (GEM), (EM is used to estimate the model parameters) to automatically separate FDT data into clusters of normal and abnormal eyes. Principal component analysis (PCA) was used to decompose each cluster into different axes (patterns). FDT measurements were obtained from 1,190 eyes with normal FDT results and 786 eyes with abnormal (i.e., glaucomatous) FDT results, recruited from a university-based, longitudinal, multi-center, clinical study on glaucoma. The GEM input was the 52-point FDT threshold sensitivities for all eyes. The optimal GEM model separated the FDT fields into 3 clusters. Cluster 1 contained 94% normal fields (94% specificity) and clusters 2 and 3 combined, contained 77% abnormal fields (77% sensitivity). For clusters 1, 2 and 3 the optimal number of PCA-identified axes were 2, 2 and 5, respectively. GEM with PCA successfully separated FDT fields from healthy and glaucoma eyes and identified familiar glaucomatous patterns of loss. © 2014 SPIE.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2043145",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Discussion of “Machine learning applications in non-life insurance”",
      "authors": "Banks, D",
      "published_date": "January 1, 2020",
      "doi": "10.1002/asmb.2537",
      "abstract": "",
      "publication_location": "Applied Stochastic Models in Business and Industry",
      "link": "http://dx.doi.org/10.1002/asmb.2537",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Spatially regularized machine learning for task and resting-state fMRI.",
      "authors": "Song, X; Panych, LP; Chen, N-K",
      "published_date": "January 15, 2016",
      "doi": "10.1016/j.jneumeth.2015.10.001",
      "abstract": "BACKGROUND: Reliable mapping of brain function across sessions and/or subjects in task- and resting-state has been a critical challenge for quantitative fMRI studies although it has been intensively addressed in the past decades. NEW METHOD: A spatially regularized support vector machine (SVM) technique was developed for the reliable brain mapping in task- and resting-state. Unlike most existing SVM-based brain mapping techniques, which implement supervised classifications of specific brain functional states or disorders, the proposed method performs a semi-supervised classification for the general brain function mapping where spatial correlation of fMRI is integrated into the SVM learning. The method can adapt to intra- and inter-subject variations induced by fMRI nonstationarity, and identify a true boundary between active and inactive voxels, or between functionally connected and unconnected voxels in a feature space. RESULTS: The method was evaluated using synthetic and experimental data at the individual and group level. Multiple features were evaluated in terms of their contributions to the spatially regularized SVM learning. Reliable mapping results in both task- and resting-state were obtained from individual subjects and at the group level. COMPARISON WITH EXISTING METHODS: A comparison study was performed with independent component analysis, general linear model, and correlation analysis methods. Experimental results indicate that the proposed method can provide a better or comparable mapping performance at the individual and group level. CONCLUSIONS: The proposed method can provide accurate and reliable mapping of brain function in task- and resting-state, and is applicable to a variety of quantitative fMRI studies.",
      "publication_location": "J Neurosci Methods",
      "link": "http://dx.doi.org/10.1016/j.jneumeth.2015.10.001",
      "citations": 1,
      "readership": 37,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Compressive classification: Where wireless communications meets machine learning",
      "authors": "Rodrigues, M; Nokleby, M; Renna, F; Calderbank, R",
      "published_date": "January 1, 2015",
      "doi": "10.1007/978-3-319-16042-9_15",
      "abstract": "© Springer International Publishing Switzerland 2015. This chapter introduces Shannon-inspired performance limits associated with the classification of low-dimensional subspaces embedded in a high-dimensional ambient space from compressive and noisy measurements. In particular, it introduces the diversity-discrimination tradeoff that describes the interplay between the number of classes that can be separated by a compressive classifier—measured via the discrimination gain—and the performance of such a classifier—measured via the diversity gain—and the relation of such an interplay to the underlying problem geometry, including the ambient space dimension, the subspaces dimension, and the number of compressive measurements. Such a fundamental limit on performance is derived from a syntactic equivalence between the compressive classification problem and certain wireless communications problems. This equivalence provides an opportunity to cross-pollinate ideas between the wireless information theory domain and the compressive classification domain. This chapter also demonstrates how theory aligns with practice in a concrete application: face recognition from a set of noisy compressive measurements.",
      "publication_location": "",
      "link": "http://dx.doi.org/10.1007/978-3-319-16042-9_15",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A comparative study of feature selection and machine learning techniques for sentiment analysis.",
      "authors": "Sharma, A; Dey, S",
      "published_date": 2012,
      "doi": "",
      "abstract": "",
      "publication_location": "ACM",
      "link": "http://dl.acm.org/citation.cfm?id=2401603",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning at the Patent Office: Lessons for Patents and Administrative Law",
      "authors": "Rai, A",
      "published_date": 2019,
      "doi": "",
      "abstract": "",
      "publication_location": "Iowa Law Review",
      "link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3393942",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.",
      "authors": "",
      "published_date": "October 5, 2018",
      "doi": "10.1186/s13014-018-1140-9",
      "abstract": "BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis. METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests. RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~ 0.74). CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.",
      "publication_location": "Radiation Oncology",
      "link": "http://dx.doi.org/10.1186/s13014-018-1140-9",
      "citations": 6,
      "readership": 48,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Machine Learning Algorithm Predicts Cardiac Resynchronization Therapy Outcomes: Lessons From the COMPANION Trial.",
      "authors": "Kalscheur, MM; Kipp, RT; Tattersall, MC; Mei, C; Buhr, KA; DeMets, DL; Field, ME; Eckhardt, LL; Page, CD",
      "published_date": "January 2018",
      "doi": "10.1161/CIRCEP.117.005499",
      "abstract": "BACKGROUND: Cardiac resynchronization therapy (CRT) reduces morbidity and mortality in heart failure patients with reduced left ventricular function and intraventricular conduction delay. However, individual outcomes vary significantly. This study sought to use a machine learning algorithm to develop a model to predict outcomes after CRT. METHODS AND RESULTS: Models were developed with machine learning algorithms to predict all-cause mortality or heart failure hospitalization at 12 months post-CRT in the COMPANION trial (Comparison of Medical Therapy, Pacing, and Defibrillation in Heart Failure). The best performing model was developed with the random forest algorithm. The ability of this model to predict all-cause mortality or heart failure hospitalization and all-cause mortality alone was compared with discrimination obtained using a combination of bundle branch block morphology and QRS duration. In the 595 patients with CRT-defibrillator in the COMPANION trial, 105 deaths occurred (median follow-up, 15.7 months). The survival difference across subgroups differentiated by bundle branch block morphology and QRS duration did not reach significance (P=0.08). The random forest model produced quartiles of patients with an 8-fold difference in survival between those with the highest and lowest predicted probability for events (hazard ratio, 7.96; P<0.0001). The model also discriminated the risk of the composite end point of all-cause mortality or heart failure hospitalization better than subgroups based on bundle branch block morphology and QRS duration. CONCLUSIONS: In the COMPANION trial, a machine learning algorithm produced a model that predicted clinical outcomes after CRT. Applied before device implant, this model may better differentiate outcomes over current clinical discriminators and improve shared decision-making with patients.",
      "publication_location": "Circ Arrhythm Electrophysiol",
      "link": "http://dx.doi.org/10.1161/CIRCEP.117.005499",
      "citations": 18,
      "readership": 44,
      "tweets": 9,
      "news_mentions": ""
    },
    {
      "title": "Identifying predictors of antimicrobial exposure in hospitalized patients using a machine learning approach.",
      "authors": "Chowdhury, AS; Lofgren, ET; Moehring, RW; Broschat, SL",
      "published_date": "March 2020",
      "doi": "10.1111/jam.14499",
      "abstract": "AIMS: Analysis and tracking of antimicrobial utilization (AU) are crucial in antimicrobial stewardship efforts which are used to find effective interventions for controlling antimicrobial resistance. In antimicrobial stewardship, standard risk adjustment models are needed for benchmarking appropriate AU and for fair inter-facility comparison. In this study we identify patient- and facility-level predictors of antimicrobial usage in hospitalized patients using a machine learning approach, which can be used to inform a risk adjustment model to facilitate assessment of AU. To our knowledge, this is the first time machine learning has been applied for this purpose. METHODS AND RESULTS: Patient admission records were retrieved from the Duke Antimicrobial Stewardship Outreach Network which include clinical data for 27 community hospitals in the southeastern United States. Candidate features (predictors) were then generated from these records. The number of features was reduced using a statistical approach, and missing values of the reduced feature set were imputed using bootstrapping and expectation-maximization algorithm. Finally, support vector regression (SVR) and cubist regression (CB) models were applied to find root-mean-square error values which were used to evaluate the selected feature set. The performance of the SVR and CB models was found to be better than that of linear null and negative binomial null models, thereby demonstrating the effectiveness of our selected features. CONCLUSIONS: Relevant patient- and facility-level predictors of antimicrobial usage in days of therapy were obtained and evaluated. The potential predictor set can be used in risk adjustment strategies for benchmarking antimicrobial use. SIGNIFICANCE AND IMPACT OF THE STUDY: One reason for the rapid emergence of antimicrobial resistance is inappropriate use of antibiotics in hospitalized patients. Identifying predictors of antimicrobial exposure using a machine learning technique can improve the use of AU, enhance patient health outcomes, and reduce the infection spread caused by antimicrobial-resistant organisms.",
      "publication_location": "J Appl Microbiol",
      "link": "http://dx.doi.org/10.1111/jam.14499",
      "citations": "(None,)",
      "readership": 3,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Machine Learning for Pattern Detection in Cochlear Implant FDA Adverse Event Reports",
      "authors": "Crowson, MG; Hamour, A; Lin, V; Chen, JM; Chan, TCY",
      "published_date": "",
      "doi": "10.1101/2020.04.30.20086660",
      "abstract": "Importance:  The United States Food & Drug Administration (FDA) passively monitors medical device performance and safety through submitted medical device reports (MDRs) in the Manufacturer and User Facility Device Experience (MAUDE) database. These databases can be analyzed for patterns and novel opportunities for improving patient safety and/or device design. \n\nObjectives: The objective of this analysis was to use supervised machine learning to explore patterns in reported adverse events involving cochlear implants. \n\nDesign: The MDRs for the top three CI manufacturers by volume from January 1st 2009 to August 30th 2019 were retained for the analysis. Natural language processing was used to measure the importance of specific words. Four supervised machine learning algorithms were used to predict which adverse event narrative description pattern corresponded with a specific cochlear implant manufacturer and adverse event type - injury, malfunction, or death.  \n\nSetting:  U.S. government public database.\n\nParticipants: Adult and pediatric cochlear patients. \n\nExposure: Surgical placement of a cochlear implant.\n\nMain Outcome Measure: Machine learning model classification prediction accuracy (% correct predictions).\n\nResults: 27,511 adverse events related to cochlear implant devices were submitted to the MAUDE database during the study period. Most adverse events involved patient injury (n = 16,736), followed by device malfunction (n = 10,760), and death (n = 16). Submissions to the database were dominated by Cochlear Corporation (n = 13,897), followed by MedEL (n = 7,125), and Advanced Bionics (n = 6,489).  The random forest, linear SVC, naive Bayes and logistic algorithms were able to predict the specific CI manufacturer based on the adverse event narrative with an average accuracy of 74.8%, 86.0%, 88.5% and 88.6%, respectively.\n\nConclusions & Relevance: Using supervised machine learning algorithms, our classification models were able to predict the CI manufacturer and event type with high accuracy based on patterns in adverse event text descriptions.",
      "publication_location": "",
      "link": "http://dx.doi.org/10.1101/2020.04.30.20086660",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Author Correction: Do no harm: a roadmap for responsible machine learning for health care.",
      "authors": "Wiens, J; Saria, S; Sendak, M; Ghassemi, M; Liu, VX; Doshi-Velez, F; Jung, K; Heller, K; Kale, D; Saeed, M; Ossorio, PN; Thadaney-Israni, S; Goldenberg, A",
      "published_date": "October 2019",
      "doi": "10.1038/s41591-019-0609-x",
      "abstract": "An amendment to this paper has been published and can be accessed via a link at the top of the paper.",
      "publication_location": "Nature Medicine",
      "link": "http://dx.doi.org/10.1038/s41591-019-0609-x",
      "citations": "(None,)",
      "readership": 5,
      "tweets": 2,
      "news_mentions": 32
    },
    {
      "title": "Can machine learning and combinatorial chemistry coexist? An antimicrobial peptide case study",
      "authors": "Spatola, AF; Page, CD; Vogel, DM; Crozet, Y; Blondelle, S",
      "published_date": "January 1, 2000",
      "doi": "",
      "abstract": "",
      "publication_location": "SPRINGER",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000166856900293&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning, Predictive Analytics, and Clinical Practice: Can the Past Inform the Present?",
      "authors": "Peterson, ED",
      "published_date": "November 22, 2019",
      "doi": "10.1001/jama.2019.17831",
      "abstract": "",
      "publication_location": "Jama",
      "link": "http://dx.doi.org/10.1001/jama.2019.17831",
      "citations": 5,
      "readership": 29,
      "tweets": 133,
      "news_mentions": ""
    },
    {
      "title": "Training and Interpreting Machine Learning Algorithms to Evaluate Fall Risk After Emergency Department Visits.",
      "authors": "Patterson, BW; Engstrom, CJ; Sah, V; Smith, MA; Mendonça, EA; Pulia, MS; Repplinger, MD; Hamedani, AG; Page, D; Shah, MN",
      "published_date": "July 2019",
      "doi": "10.1097/MLR.0000000000001140",
      "abstract": "BACKGROUND: Machine learning is increasingly used for risk stratification in health care. Achieving accurate predictive models do not improve outcomes if they cannot be translated into efficacious intervention. Here we examine the potential utility of automated risk stratification and referral intervention to screen older adults for fall risk after emergency department (ED) visits. OBJECTIVE: This study evaluated several machine learning methodologies for the creation of a risk stratification algorithm using electronic health record data and estimated the effects of a resultant intervention based on algorithm performance in test data. METHODS: Data available at the time of ED discharge were retrospectively collected and separated into training and test datasets. Algorithms were developed to predict the outcome of a return visit for fall within 6 months of an ED index visit. Models included random forests, AdaBoost, and regression-based methods. We evaluated models both by the area under the receiver operating characteristic (ROC) curve, also referred to as area under the curve (AUC), and by projected clinical impact, estimating number needed to treat (NNT) and referrals per week for a fall risk intervention. RESULTS: The random forest model achieved an AUC of 0.78, with slightly lower performance in regression-based models. Algorithms with similar performance, when evaluated by AUC, differed when placed into a clinical context with the defined task of estimated NNT in a real-world scenario. CONCLUSION: The ability to translate the results of our analysis to the potential tradeoff between referral numbers and NNT offers decisionmakers the ability to envision the effects of a proposed intervention before implementation.",
      "publication_location": "Med Care",
      "link": "http://dx.doi.org/10.1097/MLR.0000000000001140",
      "citations": "(None,)",
      "readership": 25,
      "tweets": 14,
      "news_mentions": ""
    },
    {
      "title": "Optimized scoring systems: Toward trust in machine learning for healthcare and criminal justice",
      "authors": "Rudin, C; Ustunb, B",
      "published_date": "September 1, 2018",
      "doi": "10.1287/inte.2018.0957",
      "abstract": "© 2018 INFORMS. Abstract. Questions of trust in machine-learning models are becoming increasingly important as these tools are starting to be used widely for high-stakes decisions in medicine and criminal justice. Transparency of models is a key aspect affecting trust. This paper reveals that there is new technology to build transparent machine-learning models that are often as accurate as black-box machine-learning models. These methods have already had an impact in medicine and criminal justice. This work calls into question the overall need for black-box models in these applications. Copyright:",
      "publication_location": "Interfaces",
      "link": "http://dx.doi.org/10.1287/inte.2018.0957",
      "citations": 8,
      "readership": 65,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Machine Learning Detects Pan-cancer Ras Pathway Activation in The Cancer Genome Atlas.",
      "authors": "Way, GP; Sanchez-Vega, F; La, K; Armenia, J; Chatila, WK; Luna, A; Sander, C; Cherniack, AD; Mina, M; Ciriello, G; Schultz, N; Cancer Genome Atlas Research Network, ; Sanchez, Y; Greene, CS",
      "published_date": "April 3, 2018",
      "doi": "10.1016/j.celrep.2018.03.046",
      "abstract": "Precision oncology uses genomic evidence to match patients with treatment but often fails to identify all patients who may respond. The transcriptome of these \"hidden responders\" may reveal responsive molecular states. We describe and evaluate a machine-learning approach to classify aberrant pathway activity in tumors, which may aid in hidden responder identification. The algorithm integrates RNA-seq, copy number, and mutations from 33 different cancer types across The Cancer Genome Atlas (TCGA) PanCanAtlas project to predict aberrant molecular states in tumors. Applied to the Ras pathway, the method detects Ras activation across cancer types and identifies phenocopying variants. The model, trained on human tumors, can predict response to MEK inhibitors in wild-type Ras cell lines. We also present data that suggest that multiple hits in the Ras pathway confer increased Ras activity. The transcriptome is underused in precision oncology and, combined with machine learning, can aid in the identification of hidden responders.",
      "publication_location": "Cell Reports",
      "link": "http://dx.doi.org/10.1016/j.celrep.2018.03.046",
      "citations": 36,
      "readership": 401,
      "tweets": 176,
      "news_mentions": 12
    },
    {
      "title": "Dry eye is matched by increased intrasubject variability in tear osmolarity as confirmed by machine learning approach.",
      "authors": "Cartes, C; López, D; Salinas, D; Segovia, C; Ahumada, C; Pérez, N; Valenzuela, F; Lanza, N; López Solís, RO; Perez, VL; Zegers, P; Fuentes, A; Alarcón, C; Traipe, L",
      "published_date": "July 2019",
      "doi": "10.1016/j.oftal.2019.03.007",
      "abstract": "OBJECTIVE: Because of high variability, tear film osmolarity measures have been questioned in dry eye assessment. Understanding the origin of such variability would aid data interpretation. This study aims to evaluate osmolarity variability in a clinical setting. MATERIAL AND METHODS: Twenty dry eyes and 20 control patients were evaluated. Three consecutive osmolarity measurements per eye at 5min intervals were obtained. Variability was represented by the difference between both extreme readings per eye. Machine learning techniques were used to quantify discrimination capacity of tear osmolarity for dry eye. RESULTS: Mean osmolarities in the control and dry eye groups were 295.1±7.3mOsm/L and 300.6±11.2mOsm/L, respectively (P=.004). Osmolarity variabilities were 7.5±3.6mOsm/L and 16.7±11.9mOsm/L, for the control and dry eye groups, respectively (P<.001). Based on osmolarity, a logistic classifier showed an 85% classification accuracy. CONCLUSIONS: In the clinical setting, both mean osmolarity and osmolarity variability in the dry eye group were significantly higher than in the control group. Machine learning techniques showed good classification accuracy. It is concluded that higher variability of tear osmolarity is a dry eye feature.",
      "publication_location": "Arch Soc Esp Oftalmol",
      "link": "http://dx.doi.org/10.1016/j.oftal.2019.03.007",
      "citations": "(None,)",
      "readership": 4,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Prediction of insemination outcomes in Holstein dairy cattle using alternative machine learning algorithms.",
      "authors": "Shahinfar, S; Page, D; Guenther, J; Cabrera, V; Fricke, P; Weigel, K",
      "published_date": "February 2014",
      "doi": "10.3168/jds.2013-6693",
      "abstract": "When making the decision about whether or not to breed a given cow, knowledge about the expected outcome would have an economic impact on profitability of the breeding program and net income of the farm. The outcome of each breeding can be affected by many management and physiological features that vary between farms and interact with each other. Hence, the ability of machine learning algorithms to accommodate complex relationships in the data and missing values for explanatory variables makes these algorithms well suited for investigation of reproduction performance in dairy cattle. The objective of this study was to develop a user-friendly and intuitive on-farm tool to help farmers make reproduction management decisions. Several different machine learning algorithms were applied to predict the insemination outcomes of individual cows based on phenotypic and genotypic data. Data from 26 dairy farms in the Alta Genetics (Watertown, WI) Advantage Progeny Testing Program were used, representing a 10-yr period from 2000 to 2010. Health, reproduction, and production data were extracted from on-farm dairy management software, and estimated breeding values were downloaded from the US Department of Agriculture Agricultural Research Service Animal Improvement Programs Laboratory (Beltsville, MD) database. The edited data set consisted of 129,245 breeding records from primiparous Holstein cows and 195,128 breeding records from multiparous Holstein cows. Each data point in the final data set included 23 and 25 explanatory variables and 1 binary outcome for of 0.756 ± 0.005 and 0.736 ± 0.005 for primiparous and multiparous cows, respectively. The naïve Bayes algorithm, Bayesian network, and decision tree algorithms showed somewhat poorer classification performance. An information-based variable selection procedure identified herd average conception rate, incidence of ketosis, number of previous (failed) inseminations, days in milk at breeding, and mastitis as the most effective explanatory variables in predicting pregnancy outcome.",
      "publication_location": "J Dairy Sci",
      "link": "http://dx.doi.org/10.3168/jds.2013-6693",
      "citations": 36,
      "readership": 102,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Using machine learning to identify patterns of lifetime health problems in decedents with autism spectrum disorder.",
      "authors": "Bishop-Fitzpatrick, L; Movaghar, A; Greenberg, JS; Page, D; DaWalt, LS; Brilliant, MH; Mailick, MR",
      "published_date": "August 2018",
      "doi": "10.1002/aur.1960",
      "abstract": "Very little is known about the health problems experienced by individuals with autism spectrum disorder (ASD) throughout their life course. We retrospectively analyzed diagnostic codes associated with de-identified electronic health records using a machine learning algorithm to characterize diagnostic patterns in decedents with ASD and matched decedent community controls. Participants were 91 decedents with ASD and 6,186 sex and birth year matched decedent community controls who had died since 1979, the majority of whom were middle aged or older adults at the time of their death. We analyzed all ICD-9 codes, V-codes, and E-codes available in the electronic health record and Elixhauser comorbidity categories associated with those codes. Diagnostic patterns distinguished decedents with ASD from decedent community controls with 75% sensitivity and 94% specificity solely based on their lifetime ICD-9 codes, V-codes, and E-codes. Decedents with ASD had higher rates of most conditions, including cardiovascular disease, motor problems, ear problems, urinary problems, digestive problems, side effects from long-term medication use, and nonspecific lab tests and encounters. In contrast, decedents with ASD had lower rates of cancer. Findings suggest distinctive lifetime diagnostic patterns among decedents with ASD and highlight the need for more research on health outcomes across the lifespan as the population of individuals with ASD ages. As a large wave of individuals with ASD diagnosed in the 1990s enters adulthood and middle age, knowledge about lifetime health problems will become increasingly important for care and prevention efforts. Autism Res 2018, 11: 1120-1128. © 2018 International Society for Autism Research, Wiley Periodicals, Inc. LAY SUMMARY: This study looked at patterns of lifetime health problems to find differences between people with autism who had died and community controls who had died. People with autism had higher rates of most health problems, including cardiovascular, urinary, respiratory, digestive, and motor problems, in their electronic health records. They also had lower rates of cancer. More research is needed to understand these potential health risks as a large number of individuals with autism enter adulthood and middle age.",
      "publication_location": "Autism Res",
      "link": "http://dx.doi.org/10.1002/aur.1960",
      "citations": 14,
      "readership": 57,
      "tweets": 66,
      "news_mentions": 3
    },
    {
      "title": "Metabarcoding and machine learning analysis of environmental DNA in ballast water arriving to hub ports.",
      "authors": "Gerhard, WA; Gunsch, CK",
      "published_date": "March 2019",
      "doi": "10.1016/j.envint.2018.12.038",
      "abstract": "While ballast water has long been linked to the global transport of invasive species, little is known about its microbiome. Herein, we used 16S rRNA gene sequencing and metabarcoding to perform the most comprehensive microbiological survey of ballast water arriving to hub ports to date. In total, we characterized 41 ballast, 20 harbor, and 6 open ocean water samples from four world ports (Shanghai, China; Singapore; Durban, South Africa; Los Angeles, California). In addition, we cultured Enterococcus and E. coli to evaluate adherence to International Maritime Organization standards for ballast discharge. Five of the 41 vessels - all of which were loaded in China - did not comply with standards for at least one indicator organism. Dominant bacterial taxa of ballast water at the class level were Alphaproteobacteria, Gammaproteobacteria, and Bacteroidia. Ballast water samples were composed of significantly lower proportions of Oxyphotobacteria than either ocean or harbor samples. Linear discriminant analysis (LDA) effect size (LEfSe) and machine learning were used to identify and test potential biomarkers for classifying sample types (ocean, harbor, ballast). Eight candidate biomarkers were used to achieve 81% (k nearest neighbors) to 88% (random forest) classification accuracy. Further research of these biomarkers could aid the development of techniques to rapidly assess ballast water origin.",
      "publication_location": "Environment International",
      "link": "http://dx.doi.org/10.1016/j.envint.2018.12.038",
      "citations": 5,
      "readership": 70,
      "tweets": 22,
      "news_mentions": ""
    },
    {
      "title": "A planning quality evaluation tool for prostate adaptive IMRT based on machine learning.",
      "authors": "Zhu, X; Ge, Y; Li, T; Thongphiew, D; Yin, F-F; Wu, QJ",
      "published_date": "February 2011",
      "doi": "10.1118/1.3539749",
      "abstract": "PURPOSE: To ensure plan quality for adaptive IMRT of the prostate, we developed a quantitative evaluation tool using a machine learning approach. This tool generates dose volume histograms (DVHs) of organs-at-risk (OARs) based on prior plans as a reference, to be compared with the adaptive plan derived from fluence map deformation. METHODS: Under the same configuration using seven-field 15 MV photon beams, DVHs of OARs (bladder and rectum) were estimated based on anatomical information of the patient and a model learned from a database of high quality prior plans. In this study, the anatomical information was characterized by the organ volumes and distance-to-target histogram (DTH). The database consists of 198 high quality prostate plans and was validated with 14 cases outside the training pool. Principal component analysis (PCA) was applied to DVHs and DTHs to quantify their salient features. Then, support vector regression (SVR) was implemented to establish the correlation between the features of the DVH and the anatomical information. RESULTS: DVH/DTH curves could be characterized sufficiently just using only two or three truncated principal components, thus, patient anatomical information was quantified with reduced numbers of variables. The evaluation of the model using the test data set demonstrated its accuracy approximately 80% in prediction and effectiveness in improving ART planning quality. CONCLUSIONS: An adaptive IMRT plan quality evaluation tool based on machine learning has been developed, which estimates OAR sparing and provides reference in evaluating ART.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3539749",
      "citations": 189,
      "readership": 131,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Internal force corrections with machine learning for quantum mechanics/molecular mechanics simulations.",
      "authors": "Wu, J; Shen, L; Yang, W",
      "published_date": "October 2017",
      "doi": "10.1063/1.5006882",
      "abstract": "Ab initio quantum mechanics/molecular mechanics (QM/MM) molecular dynamics simulation is a useful tool to calculate thermodynamic properties such as potential of mean force for chemical reactions but intensely time consuming. In this paper, we developed a new method using the internal force correction for low-level semiempirical QM/MM molecular dynamics samplings with a predefined reaction coordinate. As a correction term, the internal force was predicted with a machine learning scheme, which provides a sophisticated force field, and added to the atomic forces on the reaction coordinate related atoms at each integration step. We applied this method to two reactions in aqueous solution and reproduced potentials of mean force at the ab initio QM/MM level. The saving in computational cost is about 2 orders of magnitude. The present work reveals great potentials for machine learning in QM/MM simulations to study complex chemical processes.",
      "publication_location": "The Journal of Chemical Physics",
      "link": "http://dx.doi.org/10.1063/1.5006882",
      "citations": 7,
      "readership": 37,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Using Machine Learning to Discover Latent Social Phenotypes in Free-Ranging Macaques.",
      "authors": "Madlon-Kay, S; Brent, L; Montague, M; Heller, K; Platt, M",
      "published_date": "July 21, 2017",
      "doi": "10.3390/brainsci7070091",
      "abstract": "Investigating the biological bases of social phenotypes is challenging because social behavior is both high-dimensional and richly structured, and biological factors are more likely to influence complex patterns of behavior rather than any single behavior in isolation. The space of all possible patterns of interactions among behaviors is too large to investigate using conventional statistical methods. In order to quantitatively define social phenotypes from natural behavior, we developed a machine learning model to identify and measure patterns of behavior in naturalistic observational data, as well as their relationships to biological, environmental, and demographic sources of variation. We applied this model to extensive observations of natural behavior in free-ranging rhesus macaques, and identified behavioral states that appeared to capture periods of social isolation, competition over food, conflicts among groups, and affiliative coexistence. Phenotypes, represented as the rate of being in each state for a particular animal, were strongly and broadly influenced by dominance rank, sex, and social group membership. We also identified two states for which variation in rates had a substantial genetic component. We discuss how this model can be extended to identify the contributions to social phenotypes of particular genetic pathways.",
      "publication_location": "Brain Sciences",
      "link": "http://dx.doi.org/10.3390/brainsci7070091",
      "citations": 2,
      "readership": 32,
      "tweets": 40,
      "news_mentions": ""
    },
    {
      "title": "Deriving global parameter estimates for the Noah land surface model using FLUXNET and machine learning",
      "authors": "Chaney, NW; Herman, JD; Ek, MB; Wood, EF",
      "published_date": "November 27, 2016",
      "doi": "10.1002/2016JD024821",
      "abstract": "©2016. American Geophysical Union. All Rights Reserved. With their origins in numerical weather prediction and climate modeling, land surface models aim to accurately partition the surface energy balance. An overlooked challenge in these schemes is the role of model parameter uncertainty, particularly at unmonitored sites. This study provides global parameter estimates for the Noah land surface model using 85 eddy covariance sites in the global FLUXNET network. The at-site parameters are first calibrated using a Latin Hypercube-based ensemble of the most sensitive parameters, determined by the Sobol method, to be the minimum stomatal resistance (rs,min), the Zilitinkevich empirical constant (Czil), and the bare soil evaporation exponent (fxexp). Calibration leads to an increase in the mean Kling-Gupta Efficiency performance metric from 0.54 to 0.71. These calibrated parameter sets are then related to local environmental characteristics using the Extra-Trees machine learning algorithm. The fitted Extra-Trees model is used to map the optimal parameter sets over the globe at a 5 km spatial resolution. The leave-one-out cross validation of the mapped parameters using the Noah land surface model suggests that there is the potential to skillfully relate calibrated model parameter sets to local environmental characteristics. The results demonstrate the potential to use FLUXNET to tune the parameterizations of surface fluxes in land surface models and to provide improved parameter estimates over the globe.",
      "publication_location": "Journal of Geophysical Research: Atmospheres",
      "link": "http://dx.doi.org/10.1002/2016JD024821",
      "citations": 13,
      "readership": 56,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Optimizing 3D NoC design for energy efficiency: A machine learning approach",
      "authors": "Das, S; Doppa, JR; Kim, DH; Pande, PP; Chakrabarty, K",
      "published_date": "January 5, 2016",
      "doi": "10.1109/ICCAD.2015.7372639",
      "abstract": "© 2015 IEEE. Three-dimensional (3D) Network-on-Chip (NoC) is an emerging technology that has the potential to achieve high performance with low power consumption for multicore chips. However, to fully realize their potential, we need to consider novel 3D NoC architectures. In this paper, inspired by the inherent advantages of small-world (SW) 2D NoCs, we explore the design space of SW network-based 3D NoC architectures. We leverage machine learning to intelligently explore the design space to optimize the placement of both planar and vertical communication links for energy efficiency. We demonstrate that the optimized 3D SW NoC designs perform significantly better than their 3D MESH counterparts. On an average, the 3D SW NoC shows 35% energy-delay-product (EDP) improvement over 3D MESH for the nine PARSEC and SPLASH2 benchmarks considered in this work. The highest performance improvement of 43% was achieved for RADIX. Interestingly, even after reducing the number of vertical links by 50%, the optimized 3D SW NoC performs 25% better than the fully connected 3D MESH, which is a strong indication of the effectiveness of our optimization methodology.",
      "publication_location": "2015 Ieee/Acm International Conference on Computer Aided Design, Iccad 2015",
      "link": "http://dx.doi.org/10.1109/ICCAD.2015.7372639",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning-based pre-routing timing prediction with reduced pessimism",
      "authors": "",
      "published_date": "June 2, 2019",
      "doi": "10.1145/3316781.3317857",
      "abstract": "© 2019 Association for Computing Machinery. Optimizations at placement stage need to be guided by timing estimation prior to routing. To handle timing uncertainty due to the lack of routing information, people tend to make very pessimistic predictions such that performance specification can be ensured in the worst case. Such pessimism causes over-design that wastes chip resources or design effort. In this work, a machine learning-based pre-routing timing prediction approach is introduced. Experimental results show that it can reach accuracy near post-routing sign-off analysis. Compared to a commercial pre-routing timing estimation tool, it reduces false positive rate by about 2/3 in reporting timing violations.",
      "publication_location": "Proceedings   Design Automation Conference",
      "link": "http://dx.doi.org/10.1145/3316781.3317857",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Upstream fusion of multiple sensing modalities using machine learning and topological analysis: An initial exploration",
      "authors": "Garagić, D; Peskoe, J; Liu, F; Claffey, MS; Bendich, P; Hineman, J; Borggren, N; Harer, J; Zulch, P; Rhodes, BJ",
      "published_date": "June 25, 2018",
      "doi": "10.1109/AERO.2018.8396737",
      "abstract": "© 2018 IEEE. This paper presents a processing pipeline for fusing 'raw' and / or feature-level multi-sensor data - upstream fusion - and initial results from this pipeline using imagery, radar, and radio frequency (RF) signals data to determine which tracked object, among several, hosts an emitter of interest. Correctly making this determination requires fusing data across these modalities. Our approach performs better than standard fusion approaches that make detection / characterization decisions for each modality individually and then try to fuse those decisions - downstream (or post-decision) fusion. Our approach (1) fully exploits the inter-modality dependencies and phenomenologies inherent in different sensing modes, (2) automatically discovers compressive hierarchical representations that integrate structural and statistical characteristics to enhance target / event discriminability, and (3) completely obviates the need to specify features, manifolds, or model scope a priori. This approach comprises a unique synthesis of Deep Learning (DL), topological analysis over probability measure (TAPM), and hierarchical Bayesian non-parametric (HBNP) recognition models. Deep Generative Networks (DGNs - a deep generative statistical form of DL) create probability measures that provide a basis for calculating homologies (topological summaries over the probability measures). The statistics of the resulting persistence diagrams are inputs to HBNP methods that learn to discriminate between target types and distinguish emitting targets from non-emitting targets, for example. HBNP learning obviates batch-mode off-line learning. This approach overcomes the inadequacy of pre-defined features as a means for creating efficient, discriminating, low-dimensional representations from high-dimensional multi-modality sensor data collected under difficult, dynamic sensing conditions. The invariant properties in the resulting compact representations afford multiple compressive sensing benefits, including concise information sharing and enhanced performance. Machine learning makes adaptivity a central feature of our approach. Adaptivity is critical because it enables flexible processing that automatically accommodates a broad range of challenges that non-adaptive, standard fusion approaches would typically require manual intervention to begin to address. These include (a) interest in unknown or unanticipated targets, (b) desire to be rapidly able to fuse between different combinations of sensor modalities, and (c) potential need to transfer information between platforms that host different sensors. This paper presents results that demonstrate our approach enables accurate, real-time target detection, tracking, and recognition of known and unknown moving or stationary targets or events and their activities evolving over space and time.",
      "publication_location": "Ieee Aerospace Conference Proceedings",
      "link": "http://dx.doi.org/10.1109/AERO.2018.8396737",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multi-scale local shape analysis and feature selection in machine learning applications",
      "authors": "Bendich, P; Gasparovic, E; Harer, J; Izmailov, R; Ness, L",
      "published_date": "September 28, 2015",
      "doi": "10.1109/IJCNN.2015.7280428",
      "abstract": "© 2015 IEEE. We introduce a method called multi-scale local shape analysis for extracting features that describe the local structure of points within a dataset. The method uses both geometric and topological features at multiple levels of granularity to capture diverse types of local information for subsequent machine learning algorithms operating on the dataset. Using synthetic and real dataset examples, we demonstrate significant performance improvement of classification algorithms constructed for these datasets with correspondingly augmented features.",
      "publication_location": "Proceedings of the International Joint Conference on Neural Networks",
      "link": "http://dx.doi.org/10.1109/IJCNN.2015.7280428",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Solvation Free Energy Calculations with Quantum Mechanics/Molecular Mechanics and Machine Learning Models.",
      "authors": "Zhang, P; Shen, L; Yang, W",
      "published_date": "January 15, 2019",
      "doi": "10.1021/acs.jpcb.8b11905",
      "abstract": "For exploration of chemical and biological systems, the combined quantum mechanics and molecular mechanics (QM/MM) and machine learning (ML) models have been developed recently to achieve high accuracy and efficiency for molecular dynamics (MD) simulations. Despite its success on reaction free energy calculations, how to identify new configurations on insufficiently sampled regions during MD and how to update the current ML models with the growing database on the fly are both very important but still challenging. In this article, we apply the QM/MM ML method to solvation free energy calculations and address these two challenges. We employ three approaches to detect new data points and introduce the gradient boosting algorithm to reoptimize efficiently the ML model during ML-based MD sampling. The solvation free energy calculations on several typical organic molecules demonstrate that our developed method provides a systematic, robust, and efficient way to explore new chemistry using ML-based QM/MM MD simulations.",
      "publication_location": "Journal of Physical Chemistry B",
      "link": "http://dx.doi.org/10.1021/acs.jpcb.8b11905",
      "citations": 1,
      "readership": 39,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Predicting superhard materials via a machine learning informed evolutionary structure search",
      "authors": "Avery, P; Wang, X; Oses, C; Gossett, E; Proserpio, DM; Toher, C; Curtarolo, S; Zurek, E",
      "published_date": "December 1, 2019",
      "doi": "10.1038/s41524-019-0226-8",
      "abstract": "© 2019, The Author(s). The computational prediction of superhard materials would enable the in silico design of compounds that could be used in a wide variety of technological applications. Herein, good agreement was found between experimental Vickers hardnesses, Hv, of a wide range of materials and those calculated by three macroscopic hardness models that employ the shear and/or bulk moduli obtained from: (i) first principles via AFLOW-AEL (AFLOW Automatic Elastic Library), and (ii) a machine learning (ML) model trained on materials within the AFLOW repository. Because HvML values can be quickly estimated, they can be used in conjunction with an evolutionary search to predict stable, superhard materials. This methodology is implemented in the XtalOpt evolutionary algorithm. Each crystal is minimized to the nearest local minimum, and its Vickers hardness is computed via a linear relationship with the shear modulus discovered by Teter. Both the energy/enthalpy and Hv,TeterML are employed to determine a structure’s fitness. This implementation is applied towards the carbon system, and 43 new superhard phases are found. A topological analysis reveals that phases estimated to be slightly harder than diamond contain a substantial fraction of diamond and/or lonsdaleite.",
      "publication_location": "Npj Computational Materials",
      "link": "http://dx.doi.org/10.1038/s41524-019-0226-8",
      "citations": 4,
      "readership": 29,
      "tweets": 6,
      "news_mentions": 12
    },
    {
      "title": "Bayesian machine learning classifiers for combining structural and functional measurements to classify healthy and glaucomatous eyes.",
      "authors": "Bowd, C; Hao, J; Tavares, IM; Medeiros, FA; Zangwill, LM; Lee, T-W; Sample, PA; Weinreb, RN; Goldbaum, MH",
      "published_date": "March 2008",
      "doi": "10.1167/iovs.07-1083",
      "abstract": "PURPOSE: To determine whether combining structural (optical coherence tomography, OCT) and functional (standard automated perimetry, SAP) measurements as input for machine learning classifiers (MLCs; relevance vector machine, RVM; and subspace mixture of Gaussians, SSMoG) improves diagnostic accuracy for detecting glaucomatous eyes compared with using each measurement method alone. METHODS: Sixty-nine eyes of 69 healthy control subjects (average age, 62.0, SD 9.7 years; visual field mean deviation [MD], -0.70, SD 1.41 dB) and 156 eyes of 156 patients with glaucoma (average age, 66.4, SD 10.2 years; visual field MD, -3.12, SD 3.43 dB) were imaged with OCT (Stratus OCT, Carl Zeiss Meditec, Inc., Dublin, CA) and tested with SAP (Humphrey Field Analyzer II with Swedish Interactive Thresholding Algorithm, SITA; Carl Zeiss Meditec, Inc.) within 3 months of each other. RVM and SSMoG MLCs were trained and tested on OCT-determined RNFL thickness measurements from 32 sectors ( approximately 11.25 degrees each) obtained in the circumpapillary area under the instrument-defined measurement ellipse and SAP pattern deviation values from 52 points from the 24-2 grid, independently and in combination. Tenfold cross-validation was used to train and test classifiers on unique subsets of the full 225-eye data set, and areas under the receiver operating characteristic curve (AUROC) for the classification of eyes in the test set were generated. AUROC results from classifiers trained on OCT and SAP alone and those trained on OCT and SAP in combination were compared. In addition, these results were compared to currently available OCT measurements (mean retinal nerve fiber layer [RNFL] thickness, inferior RNFL thickness, and superior RNFL thickness) and SAP indices (MD and pattern standard deviation [PSD]). RESULTS: The AUROCs for RVM trained on OCT parameters alone, SAP parameters alone and OCT and SAP parameters combined were 0.809, 0.815, and 0.845, respectively. The AUROCs for SSMoG trained on OCT parameters alone, SAP parameters alone, and OCT and SAP parameters combined were 0.817, 0.841, and 0.869, respectively. Combining techniques using both RVM and SSMoG significantly improved on MLC analysis of OCT, but not SAP, measurements alone. Classification performance using RVM and SSMoG was statistically similar. CONCLUSIONS: RVM and SSMoG Bayesian MLCs trained on OCT and SAP data can successfully discriminate between healthy and early glaucomatous eyes. Combining OCT and SAP measurements using RVM and SSMoG increased diagnostic performance marginally compared with MLC analysis of data obtained using each technology alone.",
      "publication_location": "Investigative Ophthalmology & Visual Science",
      "link": "http://dx.doi.org/10.1167/iovs.07-1083",
      "citations": 45,
      "readership": 58,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Unsupervised machine learning with independent component analysis to identify areas of progression in glaucomatous visual fields.",
      "authors": "Sample, PA; Boden, C; Zhang, Z; Pascual, J; Lee, T-W; Zangwill, LM; Weinreb, RN; Crowston, JG; Hoffmann, EM; Medeiros, FA; Sejnowski, T; Goldbaum, M",
      "published_date": "October 2005",
      "doi": "10.1167/iovs.04-1168",
      "abstract": "PURPOSE: To determine whether a variational Bayesian independent component analysis mixture model (vB-ICA-mm), a form of unsupervised machine learning, can be used to identify and quantify areas of progression in standard automated perimetry fields. METHODS: In an earlier study, it was shown that a model using vB-ICA-mm can separate normal fields from fields with six different patterns of visual field loss related to glaucomatous optic neuropathy (GON) along maximally independent axes. In the present study, an independent group of 191 patient eyes (66 with ocular hypertension (OHT), 12 with suspected glaucoma by field, 61 with suspected glaucoma by disc, and 52 with glaucoma) with five or more standard visual fields under observation for a mean of 6.24 +/- 2.65 years and 8.11 +/- 2.42 visual fields were evaluated with the vB-ICA-mm. In addition, eyes with progressive GON (PGON) were identified (n = 39). Each participant had a series of fields tested, with each field entered independently and placed along the axes of the previously developed model. This allowed change in one pattern of visual field defect (along one axis) to be assessed relative to results other areas of that same field (no change along other axes). Progression was based on a slope falling outside the 5th and the 95th percentile limits of all slopes, with at least two axes not showing such a deviation in a given individual's series of fields. Fields were also scored using Advanced Glaucoma Intervention Study (AGIS) and the Early Manifest Glaucoma Treatment Trial (EMGT) criteria. RESULTS: Thirty-two of 191 eyes progressed on vB-ICA-mm by this definition. Of the 32, 22 had field loss at baseline, 7 had only GON, 3 were OHTs and 12 were from the 39 eyes (31%) with PGON. The vB-ICA-mm identified a higher percentage of progressing eyes in each diagnostic category than did AGIS or and the EMGT. CONCLUSIONS: The vB-ICA-mm can quantitatively identify progression in eyes with glaucoma by evaluating change in one or more patterns of the visual field loss while other areas or patterns remain stable. This may enable each eye to contribute to the determination of whether change is caused by true progression or by variability.",
      "publication_location": "Investigative Ophthalmology & Visual Science",
      "link": "http://dx.doi.org/10.1167/iovs.04-1168",
      "citations": 33,
      "readership": 51,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "A unified machine learning method for task-related and resting state fMRI data analysis.",
      "authors": "Song, X; Chen, N-K",
      "published_date": 2014,
      "doi": "10.1109/EMBC.2014.6945099",
      "abstract": "Functional magnetic resonance imaging (fMRI) aims to localize task-related brain activation or resting-state functional connectivity. Most existing fMRI data analysis techniques rely on fixed thresholds to identify active voxels under a task condition or functionally connected voxels in the resting state. Due to fMRI non-stationarity, a fixed threshold cannot adapt to intra- and inter-subject variation and provide a reliable mapping of brain function. In this work, a machine learning method is proposed for a unified analysis of both task-related and resting state fMRI data. Specifically, the mapping of brain function in a task condition or resting state is formulated as an outlier detection process. Support vector machines are used to provide an initial mapping and refine mapping results. The method does not require a fixed threshold for the final decision, and can adapt to fMRI non-stationarity. The proposed method was evaluated using experimental data acquired from multiple human subjects. The results indicate that the proposed method can provide reliable mapping of brain function, and is applicable to various quantitative fMRI studies.",
      "publication_location": "Conference Proceedings : ... Annual International Conference of the Ieee Engineering in Medicine and Biology Society. Ieee Engineering in Medicine and Biology Society. Annual Conference",
      "link": "http://dx.doi.org/10.1109/EMBC.2014.6945099",
      "citations": 1,
      "readership": 21,
      "tweets": 10,
      "news_mentions": ""
    },
    {
      "title": "AUCμ: A performance metric for multi-class machine learning models",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "Copyright © 2019 ASME The area under the receiver operating characteristic curve (AUC) is arguably the most common metric in machine learning for assessing the quality of a two-class classification model. As the number and complexity of machine learning applications grows, so too does the need for measures that can gracefully extend to classification models trained for more than two classes. Prior work in this area has proven computationally intractable and/or inconsistent with known properties of AUC, and thus there is still a need for an improved multi-class efficacy metric. We provide in this work a multi-class extension of AUC that we call AUCμ that is derived from first principles of the binary class AUC. AUCμ has similar computational complexity to AUC and maintains the properties of AUC critical to its interpretation and use.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges.",
      "authors": "Goldstein, BA; Navar, AM; Carter, RE",
      "published_date": "June 14, 2017",
      "doi": "10.1093/eurheartj/ehw302",
      "abstract": "Risk prediction plays an important role in clinical cardiology research. Traditionally, most risk models have been based on regression models. While useful and robust, these statistical methods are limited to using a small number of predictors which operate in the same way on everyone, and uniformly throughout their range. The purpose of this review is to illustrate the use of machine-learning methods for development of risk prediction models. Typically presented as black box approaches, most machine-learning methods are aimed at solving particular challenges that arise in data analysis that are not well addressed by typical regression approaches. To illustrate these challenges, as well as how different methods can address them, we consider trying to predicting mortality after diagnosis of acute myocardial infarction. We use data derived from our institution's electronic health record and abstract data on 13 regularly measured laboratory markers. We walk through different challenges that arise in modelling these data and then introduce different machine-learning approaches. Finally, we discuss general issues in the application of machine-learning methods including tuning parameters, loss functions, variable importance, and missing data. Overall, this review serves as an introduction for those working on risk modelling to approach the diffuse field of machine learning.",
      "publication_location": "European Heart Journal",
      "link": "http://dx.doi.org/10.1093/eurheartj/ehw302",
      "citations": 90,
      "readership": 233,
      "tweets": 13,
      "news_mentions": ""
    },
    {
      "title": "A Structural and Functional Machine Learning Classifier Improves Prediction of Patient-Reported Disability in Glaucoma",
      "authors": "",
      "published_date": "July 1, 2018",
      "doi": "",
      "abstract": "",
      "publication_location": "Investigative Ophthalmology & Visual Science",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000442932805034&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning for personalized medicine: Predicting primary myocardial infarction from electronic health records",
      "authors": "Weiss, JC; Natarajan, S; Peissig, PL; McCarty, CA; Page, D",
      "published_date": "January 1, 2012",
      "doi": "10.1609/aimag.v33i4.2438",
      "abstract": "Electronic health records (EHRs) are an emerging relational domain with large potential to improve clinical outcomes. We apply two statistical relational learning (SRL) algorithms to the task of predicting primary myocardial infarction. We show that one SRL algorithm, relational functional gradient boosting, outperforms propositional learners particularly in the medically relevant high-recall region. We observe that both SRL algorithms predict outcomes better than their propositional analogs and suggest how our methods can augment current epidemiological practices. Copyright © 2012, Association for the Advancement of Artificial Intelligence.",
      "publication_location": "Ai Magazine",
      "link": "http://dx.doi.org/10.1609/aimag.v33i4.2438",
      "citations": 37,
      "readership": 94,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Predicting X-Sensitivity of Circuit-Inputs on Test-Coverage: A Machine-Learning Approach",
      "authors": "",
      "published_date": "December 1, 2019",
      "doi": "10.1109/TCAD.2018.2878169",
      "abstract": "© 1982-2012 IEEE. Digital circuits are often prone to suffer from uncertain timing, inadequate sensor feedback, limited controllability of past states or inability of initializing memory-banks, and erroneous behavior of analog-to-digital converters, which may produce an unknown (X) logic value at various circuit nodes. Additionally, many design bugs that are identified during the post-silicon validation phase manifest themselves as X-values. The presence of such X-sources on certain primary or secondary inputs of a logic circuit may cause loss of fault-coverage of a test set, which, in turn, may impact its reliability and robustness. In this paper, we provide a mechanism for predicting the sensitivity of X-sources in terms of loss of fault-coverage, on the basis of learning only a few structural features of the circuit that are easy to extract from the netlist. We show that the X-sources can be graded satisfactorily according to their sensitivity using support vector regression, thereby obviating the need for costly explicit simulation. Experimental results on several benchmark circuits demonstrate the efficacy, speed, and accuracy of prediction.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2018.2878169",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "DeepConf: Automating data center network topologies management with machine learning",
      "authors": "",
      "published_date": "August 7, 2018",
      "doi": "10.1145/3229543.3229554",
      "abstract": "© 2018 Association for Computing Machinery. In recent years, many techniques have been developed to improve the performance and efficiency of data center networks. While these techniques provide high accuracy, they are often designed using heuristics that leverage domain-specific properties of the workload or hardware. In this vision paper, we argue that many data center networking techniques, e.g., routing, topology augmentation, energy savings, with diverse goals share design and architectural similarities. We present a framework for developing general intermediate representations of network topologies using deep learning that is amenable to solving a large class of data center problems. We develop a framework, DeepConf, that simplifies the process of configuring and training deep learning agents by using our intermediate representation to learn different tasks. To illustrate the strength of our approach, we implemented and evaluated a DeepConf-agent that tackles the data center topology augmentation problem. Our initial results are promising - DeepConf performs comparably to the optimal solution.",
      "publication_location": "Netai 2018   Proceedings of the 2018 Workshop on Network Meets Ai and Ml, Part of Sigcomm 2018",
      "link": "http://dx.doi.org/10.1145/3229543.3229554",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Resting State Functional Connectivity Machine Learning Classification of Chronic Back Pain",
      "authors": "Weber, KA; Law, CS; Asher, YK; Martucci, KT; Gilam, G; Lewis, B; Narayan, S; Hastie, T; Wager, TD; Mackey, S",
      "published_date": "October 1, 2019",
      "doi": "",
      "abstract": "",
      "publication_location": "Annals of Neurology",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000488891800418&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "USE OF A NOVEL MACHINE LEARNING APPROACH TO IDENTIFY HIGH-RISK GROUPS FOR IN-HOSPITAL MORTALITY",
      "authors": "Allareddy, V; Wang, T; Caplin, J; Badheka, A; Nalliah, R; Rampa, S; Allareddy, V",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "",
      "publication_location": "Critical Care Medicine",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000498593401620&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "NOVEL MACHINE LEARNING APPROACH TO PREDICT CLOSTRIDIUM DIFFICILE INFECTIONS IN US SURGICAL COHORTS",
      "authors": "Allareddy, V; Wang, T; Rampa, S; Badheka, A; Nalliah, R; Caplin, J; Allareddy, V",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "",
      "publication_location": "Critical Care Medicine",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000498593400285&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning approaches for slum detection using very high resolution satellite images",
      "authors": "Gadiraju, KK; Vatsavai, RR; Kaza, N; Wibbels, E; Krishna, A",
      "published_date": "February 7, 2019",
      "doi": "10.1109/ICDMW.2018.00198",
      "abstract": "© 2018 IEEE. Detecting informal settlements has become an important area of research in the past decade, owing to the availability of high resolution satellite imagery. Traditional per-pixel based classification methods provide high degree of accuracy in distinguishing primitive instances such as buildings, roads, forests and water. However, these methods fail to capture the complex relationships between neighboring pixels that is necessary for distinguishing complex objects such as informal and formal settlements. In this paper, we perform several experiments to compare and contrast how various per-pixel based classification methods, when combined with various features perform in detecting slums. In addition, we also explored a deep neural network, which showed better accuracy than the pixel based methods.",
      "publication_location": "Ieee International Conference on Data Mining Workshops, Icdmw",
      "link": "http://dx.doi.org/10.1109/ICDMW.2018.00198",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Voxel-Wise Dose Prediction for Prostate Cancer Patients Using a Novel Machine Learning Model",
      "authors": "Jensen, PJ; Sheng, Y; Ge, Y; Yin, F; Wu, QJ",
      "published_date": "June 1, 2019",
      "doi": "",
      "abstract": "",
      "publication_location": "Medical Physics",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000471277702207&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine-Learning-Based Multiple Abnormality Prediction with Large-Scale Chest Computed Tomography Volumes.",
      "authors": "Draelos, RL; Dov, D; Mazurowski, MA; Lo, JY; Henao, R; Rubin, GD; Carin, L",
      "published_date": 2020,
      "doi": "",
      "abstract": "",
      "publication_location": "Corr",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Automatic Planning of Whole Breast Radiation Therapy Using Machine Learning Models.",
      "authors": "Sheng, Y; Li, T; Yoo, S; Yin, F-F; Blitzblau, R; Horton, JK; Ge, Y; Wu, QJ",
      "published_date": 2019,
      "doi": "10.3389/fonc.2019.00750",
      "abstract": "Purpose: To develop an automatic treatment planning system for whole breast radiation therapy (WBRT) based on two intensity-modulated tangential fields, enabling near-real-time planning. Methods and Materials: A total of 40 WBRT plans from a single institution were included in this study under IRB approval. Twenty WBRT plans, 10 with single energy (SE, 6MV) and 10 with mixed energy (ME, 6/15MV), were randomly selected as training dataset to develop the methodology for automatic planning. The rest 10 SE cases and 10 ME cases served as validation. The auto-planning process consists of three steps. First, an energy prediction model was developed to automate energy selection. This model establishes an anatomy-energy relationship based on principle component analysis (PCA) of the gray level histograms from training cases' digitally reconstructed radiographs (DRRs). Second, a random forest (RF) model generates an initial fluence map using the selected energies. Third, the balance of overall dose contribution throughout the breast tissue is realized by automatically selecting anchor points and applying centrality correction. The proposed method was tested on the validation dataset. Non-parametric equivalence test was performed for plan quality metrics using one-sided Wilcoxon Signed-Rank test. Results: For validation, the auto-planning system suggested same energy choices as clinical-plans in 19 out of 20 cases. The mean (standard deviation, SD) of percent target volume covered by 100% prescription dose was 82.5% (4.2%) for auto-plans, and 79.3% (4.8%) for clinical-plans (p > 0.999). Mean (SD) volume receiving 105% Rx were 95.2 cc (90.7 cc) for auto-plans and 83.9 cc (87.2 cc) for clinical-plans (p = 0.108). Optimization time for auto-plan was <20 s while clinical manual planning takes between 30 min and 4 h. Conclusions: We developed an automatic treatment planning system that generates WBRT plans with optimal energy selection, clinically comparable plan quality, and significant reduction in planning time, allowing for near-real-time planning.",
      "publication_location": "Frontiers in Oncology",
      "link": "http://dx.doi.org/10.3389/fonc.2019.00750",
      "citations": 1,
      "readership": 10,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Non-invasive diagnosis of endometriosis: using machine learning instead of the operating room",
      "authors": "Shaia, KL; Acharya, CR; Smeltzer, S; Lyerly, HK; Acharya, KS",
      "published_date": "September 2019",
      "doi": "10.1016/j.fertnstert.2019.07.331",
      "abstract": "",
      "publication_location": "Fertility and Sterility",
      "link": "http://dx.doi.org/10.1016/j.fertnstert.2019.07.331",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine Learning for Noise Sensor Placement and Full-Chip Voltage Emergency Detection",
      "authors": "Liu, X; Sun, S; Li, X; Qian, H; Zhou, P",
      "published_date": "March 1, 2017",
      "doi": "10.1109/TCAD.2016.2611502",
      "abstract": "© 1982-2012 IEEE. Power supply fluctuation can be potential threat to the correct operations of processors, in the form of voltage emergency that happens when supply voltage drops below a certain threshold. Noise sensors (with either analog or digital outputs) can be placed in the nonfunction area of processors to detect voltage emergencies by monitoring the runtime voltage fluctuations. Our work addresses two important problems related to building a sensor-based voltage emergency detection system: 1) offline sensor placement, i.e., where to place the noise sensors so that the number and locations of sensors are optimized in order to strike a balance between design cost and chip reliability and 2) online voltage emergency detection, i.e., how to use these placed sensors to detect voltage emergencies in the hotspot locations. In this paper, we propose integrated solutions to these two problems, respectively, for analog and digital (more specifically, binary) sensor outputs, by exploiting the voltage correlation between the sensor candidate locations and the hotspot locations. For the analog case, we use the Group Lasso and an ordinary least squares approach; for the binary case, we integrate the Group Lasso and the SVM approach. Experimental results show that, our approach can achieve 2.3X-2.7X better voltage emergency detection results on average for analog outputs when compared to the state-of-the-art work; and for the binary case, on average our methodology can achieve up to 21% improvement in prediction accuracy compared to an approach called max-probability-no-prediction.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2016.2611502",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Smarter Cancer Detection Through Machine-Learning Applied to High-Resolution Diffraction Tissue Scanning",
      "authors": "Nacouzi, D; Spencer, J; Zhao, B; Leung, C; McCall, S; Greenberg, J; Kapadia, A",
      "published_date": "June 1, 2018",
      "doi": "",
      "abstract": "",
      "publication_location": "Medical Physics",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000434978003325&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "fastJT: An R package for robust and efficient feature selection for machine learning and genome-wide association studies.",
      "authors": "Lin, J; Sibley, A; Shterev, I; Nixon, A; Innocenti, F; Chan, C; Owzar, K",
      "published_date": "June 13, 2019",
      "doi": "10.1186/s12859-019-2869-3",
      "abstract": "BACKGROUND: Parametric feature selection methods for machine learning and association studies based on genetic data are not robust with respect to outliers or influential observations. While rank-based, distribution-free statistics offer a robust alternative to parametric methods, their practical utility can be limited, as they demand significant computational resources when analyzing high-dimensional data. For genetic studies that seek to identify variants, the hypothesis is constrained, since it is typically assumed that the effect of the genotype on the phenotype is monotone (e.g., an additive genetic effect). Similarly, predictors for machine learning applications may have natural ordering constraints. Cross-validation for feature selection in these high-dimensional contexts necessitates highly efficient computational algorithms for the robust evaluation of many features. RESULTS: We have developed an R extension package, fastJT, for conducting genome-wide association studies and feature selection for machine learning using the Jonckheere-Terpstra statistic for constrained hypotheses. The kernel of the package features an efficient algorithm for calculating the statistics, replacing the pairwise comparison and counting processes with a data sorting and searching procedure, reducing computational complexity from O(n2) to O(n log(n)). The computational efficiency is demonstrated through extensive benchmarking, and example applications to real data are presented. CONCLUSIONS: fastJT is an open-source R extension package, applying the Jonckheere-Terpstra statistic for robust feature selection for machine learning and association studies. The package implements an efficient algorithm which leverages internal information among the samples to avoid unnecessary computations, and incorporates shared-memory parallel programming to further boost performance on multi-core machines.",
      "publication_location": "Bmc Bioinformatics",
      "link": "http://dx.doi.org/10.1186/s12859-019-2869-3",
      "citations": 1,
      "readership": 17,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning",
      "authors": "",
      "published_date": 2018,
      "doi": "",
      "abstract": "Users in various web and mobile applications are vulnerable to attribute inference attacks, in which an attacker\nleverages a machine learning classifier to infer a target\nuser’s private attributes (e.g., location, sexual orientation,\npolitical view) from its public data (e.g., rating scores,\npage likes). Existing defenses leverage game theory or\nheuristics based on correlations between the public data\nand attributes. These defenses are not practical. Specifically, game-theoretic defenses require solving intractable\noptimization problems, while correlation-based defenses\nincur large utility loss of users’ public data.\nIn this paper, we present AttriGuard, a practical defense against attribute inference attacks. AttriGuard is\ncomputationally tractable and has small utility loss. Our\nAttriGuard works in two phases. Suppose we aim to protect a user’s private attribute. In Phase I, for each value\nof the attribute, we find a minimum noise such that if\nwe add the noise to the user’s public data, then the attacker’s classifier is very likely to infer the attribute value\nfor the user. We find the minimum noise via adapting\nexisting evasion attacks in adversarial machine learning.\nIn Phase II, we sample one attribute value according to\na certain probability distribution and add the corresponding noise found in Phase I to the user’s public data. We\nformulate finding the probability distribution as solving\na constrained convex optimization problem. We extensively evaluate AttriGuard and compare it with existing\nmethods using a real-world dataset. Our results show that\nAttriGuard substantially outperforms existing methods.\nOur work is the first one that shows evasion attacks can\nbe used as defensive techniques for privacy protection.",
      "publication_location": "Usenix Security Symposium",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Performance of a Machine Learning Classifier of Knee MRI Reports in Two Large Academic Radiology Practices: A Tool to Estimate Diagnostic Yield.",
      "authors": "Hassanpour, S; Langlotz, CP; Amrhein, TJ; Befera, NT; Lungren, MP",
      "published_date": "April 2017",
      "doi": "10.2214/AJR.16.16128",
      "abstract": "OBJECTIVE: The purpose of this study is to evaluate the performance of a natural language processing (NLP) system in classifying a database of free-text knee MRI reports at two separate academic radiology practices. MATERIALS AND METHODS: An NLP system that uses terms and patterns in manually classified narrative knee MRI reports was constructed. The NLP system was trained and tested on expert-classified knee MRI reports from two major health care organizations. Radiology reports were modeled in the training set as vectors, and a support vector machine framework was used to train the classifier. A separate test set from each organization was used to evaluate the performance of the system. We evaluated the performance of the system both within and across organizations. Standard evaluation metrics, such as accuracy, precision, recall, and F1 score (i.e., the weighted average of the precision and recall), and their respective 95% CIs were used to measure the efficacy of our classification system. RESULTS: The accuracy for radiology reports that belonged to the model's clinically significant concept classes after training data from the same institution was good, yielding an F1 score greater than 90% (95% CI, 84.6-97.3%). Performance of the classifier on cross-institutional application without institution-specific training data yielded F1 scores of 77.6% (95% CI, 69.5-85.7%) and 90.2% (95% CI, 84.5-95.9%) at the two organizations studied. CONCLUSION: The results show excellent accuracy by the NLP machine learning classifier in classifying free-text knee MRI reports, supporting the institution-independent reproducibility of knee MRI report classification. Furthermore, the machine learning classifier performed well on free-text knee MRI reports from another institution. These data support the feasibility of multiinstitutional classification of radiologic imaging text reports with a single machine learning classifier without requiring institution-specific training data.",
      "publication_location": "Ajr. American Journal of Roentgenology",
      "link": "http://dx.doi.org/10.2214/AJR.16.16128",
      "citations": 16,
      "readership": 67,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Machine-learning prediction of cancer survival: a retrospective study using electronic administrative records and a cancer registry.",
      "authors": "Gupta, S; Tran, T; Luo, W; Phung, D; Kennedy, RL; Broad, A; Campbell, D; Kipp, D; Singh, M; Khasraw, M; Matheson, L; Ashley, DM; Venkatesh, S",
      "published_date": "March 17, 2014",
      "doi": "10.1136/bmjopen-2013-004007",
      "abstract": "OBJECTIVES: Using the prediction of cancer outcome as a model, we have tested the hypothesis that through analysing routinely collected digital data contained in an electronic administrative record (EAR), using machine-learning techniques, we could enhance conventional methods in predicting clinical outcomes. SETTING: A regional cancer centre in Australia. PARTICIPANTS: Disease-specific data from a purpose-built cancer registry (Evaluation of Cancer Outcomes (ECO)) from 869 patients were used to predict survival at 6, 12 and 24 months. The model was validated with data from a further 94 patients, and results compared to the assessment of five specialist oncologists. Machine-learning prediction using ECO data was compared with that using EAR and a model combining ECO and EAR data. PRIMARY AND SECONDARY OUTCOME MEASURES: Survival prediction accuracy in terms of the area under the receiver operating characteristic curve (AUC). RESULTS: The ECO model yielded AUCs of 0.87 (95% CI 0.848 to 0.890) at 6 months, 0.796 (95% CI 0.774 to 0.823) at 12 months and 0.764 (95% CI 0.737 to 0.789) at 24 months. Each was slightly better than the performance of the clinician panel. The model performed consistently across a range of cancers, including rare cancers. Combining ECO and EAR data yielded better prediction than the ECO-based model (AUCs ranging from 0.757 to 0.997 for 6 months, AUCs from 0.689 to 0.988 for 12 months and AUCs from 0.713 to 0.973 for 24 months). The best prediction was for genitourinary, head and neck, lung, skin, and upper gastrointestinal tumours. CONCLUSIONS: Machine learning applied to information from a disease-specific (cancer) database and the EAR can be used to predict clinical outcomes. Importantly, the approach described made use of digital data that is already routinely collected but underexploited by clinical health systems.",
      "publication_location": "Bmj Open",
      "link": "http://dx.doi.org/10.1136/bmjopen-2013-004007",
      "citations": 33,
      "readership": 150,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Assessment of genetic and nongenetic interactions for the prediction of depressive symptomatology: an analysis of the Wisconsin Longitudinal Study using machine learning algorithms.",
      "authors": "Roetker, NS; Page, CD; Yonker, JA; Chang, V; Roan, CL; Herd, P; Hauser, TS; Hauser, RM; Atwood, CS",
      "published_date": "October 2013",
      "doi": "10.2105/AJPH.2012.301141",
      "abstract": "OBJECTIVES: We examined depression within a multidimensional framework consisting of genetic, environmental, and sociobehavioral factors and, using machine learning algorithms, explored interactions among these factors that might better explain the etiology of depressive symptoms. METHODS: We measured current depressive symptoms using the Center for Epidemiologic Studies Depression Scale (n = 6378 participants in the Wisconsin Longitudinal Study). Genetic factors were 78 single nucleotide polymorphisms (SNPs); environmental factors-13 stressful life events (SLEs), plus a composite proportion of SLEs index; and sociobehavioral factors-18 personality, intelligence, and other health or behavioral measures. We performed traditional SNP associations via logistic regression likelihood ratio testing and explored interactions with support vector machines and Bayesian networks. RESULTS: After correction for multiple testing, we found no significant single genotypic associations with depressive symptoms. Machine learning algorithms showed no evidence of interactions. Naïve Bayes produced the best models in both subsets and included only environmental and sociobehavioral factors. CONCLUSIONS: We found no single or interactive associations with genetic factors and depressive symptoms. Various environmental and sociobehavioral factors were more predictive of depressive symptoms, yet their impacts were independent of one another. A genome-wide analysis of genetic alterations using machine learning methodologies will provide a framework for identifying genetic-environmental-sociobehavioral interactions in depressive symptoms.",
      "publication_location": "Am J Public Health",
      "link": "http://dx.doi.org/10.2105/AJPH.2012.301141",
      "citations": 24,
      "readership": 79,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Prospective and External Evaluation of a Machine Learning Model to Predict In-Hospital Mortality of Adults at Time of Admission.",
      "authors": "",
      "published_date": "February 5, 2020",
      "doi": "10.1001/jamanetworkopen.2019.20733",
      "abstract": "Importance: The ability to accurately predict in-hospital mortality for patients at the time of admission could improve clinical and operational decision-making and outcomes. Few of the machine learning models that have been developed to predict in-hospital death are both broadly applicable to all adult patients across a health system and readily implementable. Similarly, few have been implemented, and none have been evaluated prospectively and externally validated. Objectives: To prospectively and externally validate a machine learning model that predicts in-hospital mortality for all adult patients at the time of hospital admission and to design the model using commonly available electronic health record data and accessible computational methods. Design, Setting, and Participants: In this prognostic study, electronic health record data from a total of 43 180 hospitalizations representing 31 003 unique adult patients admitted to a quaternary academic hospital (hospital A) from October 1, 2014, to December 31, 2015, formed a training and validation cohort. The model was further validated in additional cohorts spanning from March 1, 2018, to August 31, 2018, using 16 122 hospitalizations representing 13 094 unique adult patients admitted to hospital A, 6586 hospitalizations representing 5613 unique adult patients admitted to hospital B, and 4086 hospitalizations representing 3428 unique adult patients admitted to hospital C. The model was integrated into the production electronic health record system and prospectively validated on a cohort of 5273 hospitalizations representing 4525 unique adult patients admitted to hospital A between February 14, 2019, and April 15, 2019. Main Outcomes and Measures: The main outcome was in-hospital mortality. Model performance was quantified using the area under the receiver operating characteristic curve and area under the precision recall curve. Results: A total of 75 247 hospital admissions (median [interquartile range] patient age, 59.5 [29.0] years; 45.9% involving male patients) were included in the study. The in-hospital mortality rates for the training validation; retrospective validations at hospitals A, B, and C; and prospective validation cohorts were 3.0%, 2.7%, 1.8%, 2.1%, and 1.6%, respectively. The area under the receiver operating characteristic curves were 0.87 (95% CI, 0.83-0.89), 0.85 (95% CI, 0.83-0.87), 0.89 (95% CI, 0.86-0.92), 0.84 (95% CI, 0.80-0.89), and 0.86 (95% CI, 0.83-0.90), respectively. The area under the precision recall curves were 0.29 (95% CI, 0.25-0.37), 0.17 (95% CI, 0.13-0.22), 0.22 (95% CI, 0.14-0.31), 0.13 (95% CI, 0.08-0.21), and 0.14 (95% CI, 0.09-0.21), respectively. Conclusions and Relevance: Prospective and multisite retrospective evaluations of a machine learning model demonstrated good discrimination of in-hospital mortality for adult patients at the time of admission. The data elements, methods, and patient selection make the model implementable at a system level.",
      "publication_location": "Jama Network Open",
      "link": "http://dx.doi.org/10.1001/jamanetworkopen.2019.20733",
      "citations": "(None,)",
      "readership": 14,
      "tweets": 57,
      "news_mentions": ""
    },
    {
      "title": "A study of association of Oncotype DX recurrence score with DCE-MRI characteristics using multivariate machine learning models.",
      "authors": "Saha, A; Harowicz, MR; Wang, W; Mazurowski, MA",
      "published_date": "May 2018",
      "doi": "10.1007/s00432-018-2595-7",
      "abstract": "PURPOSE: To determine whether multivariate machine learning models of algorithmically assessed magnetic resonance imaging (MRI) features from breast cancer patients are associated with Oncotype DX (ODX) test recurrence scores. METHODS: A set of 261 female patients with invasive breast cancer, pre-operative dynamic contrast enhanced magnetic resonance (DCE-MR) images and available ODX score at our institution was identified. A computer algorithm extracted a comprehensive set of 529 features from the DCE-MR images of these patients. The set of patients was divided into a training set and a test set. Using the training set we developed two machine learning-based models to discriminate (1) high ODX scores from intermediate and low ODX scores, and (2) high and intermediate ODX scores from low ODX scores. The performance of these models was evaluated on the independent test set. RESULTS: High against low and intermediate ODX scores were predicted by the multivariate model with AUC 0.77 (95% CI 0.56-0.98, p < 0.003). Low against intermediate and high ODX score was predicted with AUC 0.51 (95% CI 0.41-0.61, p = 0.75). CONCLUSION: A moderate association between imaging and ODX score was identified. The evaluated models currently do not warrant replacement of ODX with imaging alone.",
      "publication_location": "J Cancer Res Clin Oncol",
      "link": "http://dx.doi.org/10.1007/s00432-018-2595-7",
      "citations": 14,
      "readership": 31,
      "tweets": 9,
      "news_mentions": ""
    },
    {
      "title": "TU‐E‐BRB‐03: A Planning Quality Evaluation Tool for Adaptive IMRT Treatment Based on Machine Learning",
      "authors": "Zhu, X; li, T; Thongphiew, D; ge, Y; Yin, F; wu, Q",
      "published_date": "January 1, 2010",
      "doi": "10.1118/1.3469286",
      "abstract": "Purpose: To monitor the quality of adaptive IMRT plans, especially dose sparing for the organs‐at‐risk (OARs), a plan evaluation tool is developed to predict the dose volume histogram (DVH) based on patient's anatomical information and a database of high quality prior treatment plans. The predicted DVH provides a guideline for judging the “goodness” of a new treatment plan. Materials and Method: First, using machine learning to establish a relationship between patient's anatomical information and the DVH curves in a database of high quality treatment plans. Anatomical information and DVHs of the PTV (encapsulates prostate and seminal vesicles) and OARs (rectum and bladder) were extracted from the CT/CBCT images and dose distributions. Principal Component Analysis (PCA) is used to characterize the DVH and the anatomical information. And a statistical analysis tool is used to seek the correlation between the DVH characteristics and anatomical features. The second is validation, in which treatment plans outside the database are used to test the performance of the tool. Result: A total of 198 treatment plans were included in the database for machine learning. DVHs of the OARs were characterized by two PCA components that cover 90% variances. Patient anatomical information is reduced to a set of variables, including the two PCA components of the distance volume histogram and organ volumes. Validation test used 14 treatment plans outside the database. The prediction is successful if the actual DVH falls in the 95% confidence band of the predicted DVH curve. Overall, 13 of 14 bladder DVH predications and 12 of 14 rectum DVH predications were successful. Conclusion: An IMRT plan quality evaluation tool based on machine learning is developed to assure the quality of treatment plans. The input is patient's anatomical information, and the output is the predicted DVHs for the OARs. (Research sponsored by Varian Corporation). © 2010, American Association of Physicists in Medicine. All rights reserved.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3469286",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Improving Pain Management in Patients with Sickle Cell Disease from Physiological Measures Using Machine Learning Techniques.",
      "authors": "Yang, F; Banerjee, T; Narine, K; Shah, N",
      "published_date": "June 2018",
      "doi": "10.1016/j.smhl.2018.01.002",
      "abstract": "Pain management is a crucial part in Sickle Cell Disease treatment. Accurate pain assessment is the first stage in pain management. However, pain is a subjective response and hard to assess via objective approaches. In this paper, we proposed a system to map objective physiological measures to subjective self-reported pain scores using machine learning techniques. Using Multinomial Logistic Regression and data from 40 patients, we were able to predict patients' pain scores on an 11-point rating scale with an average accuracy of 0.578 at the intra-individual level, and an accuracy of 0.429 at the inter-individual level. With a condensed 4-point rating scale, the accuracy at the inter-individual level was further improved to 0.681. Overall, we presented a preliminary machine learning model that can predict pain scores in SCD patients with promising results. To our knowledge, such a system has not been proposed earlier within the SCD or pain domains by exploiting machine learning concepts within the clinical framework.",
      "publication_location": "Smart Health (Amst)",
      "link": "http://dx.doi.org/10.1016/j.smhl.2018.01.002",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Using high-dimensional machine learning methods to estimate an anatomical risk factor for Alzheimer's disease across imaging databases.",
      "authors": "",
      "published_date": "December 2018",
      "doi": "10.1016/j.neuroimage.2018.08.040",
      "abstract": "INTRODUCTION:The main goal of this work is to investigate the feasibility of estimating an anatomical index that can be used as an Alzheimer's disease (AD) risk factor in the Women's Health Initiative Magnetic Resonance Imaging Study (WHIMS-MRI) using MRI data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), a well-characterized imaging database of AD patients and cognitively normal subjects. We called this index AD Pattern Similarity (AD-PS) scores. To demonstrate the construct validity of the scores, we investigated their associations with several AD risk factors. The ADNI and WHIMS imaging databases were collected with different goals, populations and data acquisition protocols: it is important to demonstrate that the approach to estimating AD-PS scores can bridge these differences. METHODS:MRI data from both studies were processed using high-dimensional warping methods. High-dimensional classifiers were then estimated using the ADNI MRI data. Next, the classifiers were applied to baseline and follow-up WHIMS-MRI GM data to generate the GM AD-PS scores. To study the validity of the scores we investigated associations between GM AD-PS scores at baseline (Scan 1) and their longitudinal changes (Scan 2 -Scan 1) with: 1) age, cognitive scores, white matter small vessel ischemic disease (WM SVID) volume at baseline and 2) age, cognitive scores, WM SVID volume longitudinal changes respectively. In addition, we investigated their associations with time until classification of independently adjudicated status in WHIMS-MRI. RESULTS:Higher GM AD-PS scores from WHIMS-MRI baseline data were associated with older age, lower cognitive scores, and higher WM SVID volume. Longitudinal changes in GM AD-PS scores (Scan 2 - Scan 1) were also associated with age and changes in WM SVID volumes and cognitive test scores. Increases in the GM AD-PS scores predicted decreases in cognitive scores and increases in WM SVID volume. GM AD-PS scores and their longitudinal changes also were associated with time until classification of cognitive impairment. Finally, receiver operating characteristic curves showed that baseline GM AD-PS scores of cognitively normal participants carried information about future cognitive status determined during follow-up. DISCUSSION:We applied a high-dimensional machine learning approach to estimate a novel AD risk factor for WHIMS-MRI study participants using ADNI data. The GM AD-PS scores showed strong associations with incident cognitive impairment and cross-sectional and longitudinal associations with age, cognitive function, cognitive status and WM SVID volume lending support to the ongoing validation of the GM AD-PS score.",
      "publication_location": "Neuroimage",
      "link": "http://dx.doi.org/10.1016/j.neuroimage.2018.08.040",
      "citations": 10,
      "readership": 58,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "A machine learning approach to radiogenomics of breast cancer: a study of 922 subjects and 529 DCE-MRI features.",
      "authors": "Saha, A; Harowicz, MR; Grimm, LJ; Kim, CE; Ghate, SV; Walsh, R; Mazurowski, MA",
      "published_date": "August 2018",
      "doi": "10.1038/s41416-018-0185-8",
      "abstract": "BACKGROUND: Recent studies showed preliminary data on associations of MRI-based imaging phenotypes of breast tumours with breast cancer molecular, genomic, and related characteristics. In this study, we present a comprehensive analysis of this relationship. METHODS: We analysed a set of 922 patients with invasive breast cancer and pre-operative MRI. The MRIs were analysed by a computer algorithm to extract 529 features of the tumour and the surrounding tissue. Machine-learning-based models based on the imaging features were trained using a portion of the data (461 patients) to predict the following molecular, genomic, and proliferation characteristics: tumour surrogate molecular subtype, oestrogen receptor, progesterone receptor and human epidermal growth factor status, as well as a tumour proliferation marker (Ki-67). Trained models were evaluated on the set of the remaining 461 patients. RESULTS: Multivariate models were predictive of Luminal A subtype with AUC = 0.697 (95% CI: 0.647-0.746, p < .0001), triple negative breast cancer with AUC = 0.654 (95% CI: 0.589-0.727, p < .0001), ER status with AUC = 0.649 (95% CI: 0.591-0.705, p < .001), and PR status with AUC = 0.622 (95% CI: 0.569-0.674, p < .0001). Associations between individual features and subtypes we also found. CONCLUSIONS: There is a moderate association between tumour molecular biomarkers and algorithmically assessed imaging features.",
      "publication_location": "Br J Cancer",
      "link": "http://dx.doi.org/10.1038/s41416-018-0185-8",
      "citations": 14,
      "readership": 39,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Automated Detection of P. falciparum Using Machine Learning Algorithms with Quantitative Phase Images of Unstained Cells.",
      "authors": "Park, HS; Rinehart, MT; Walzer, KA; Chi, J-TA; Wax, A",
      "published_date": 2016,
      "doi": "10.1371/journal.pone.0163045",
      "abstract": "Malaria detection through microscopic examination of stained blood smears is a diagnostic challenge that heavily relies on the expertise of trained microscopists. This paper presents an automated analysis method for detection and staging of red blood cells infected by the malaria parasite Plasmodium falciparum at trophozoite or schizont stage. Unlike previous efforts in this area, this study uses quantitative phase images of unstained cells. Erythrocytes are automatically segmented using thresholds of optical phase and refocused to enable quantitative comparison of phase images. Refocused images are analyzed to extract 23 morphological descriptors based on the phase information. While all individual descriptors are highly statistically different between infected and uninfected cells, each descriptor does not enable separation of populations at a level satisfactory for clinical utility. To improve the diagnostic capacity, we applied various machine learning techniques, including linear discriminant classification (LDC), logistic regression (LR), and k-nearest neighbor classification (NNC), to formulate algorithms that combine all of the calculated physical parameters to distinguish cells more effectively. Results show that LDC provides the highest accuracy of up to 99.7% in detecting schizont stage infected cells compared to uninfected RBCs. NNC showed slightly better accuracy (99.5%) than either LDC (99.0%) or LR (99.1%) for discriminating late trophozoites from uninfected RBCs. However, for early trophozoites, LDC produced the best accuracy of 98%. Discrimination of infection stage was less accurate, producing high specificity (99.8%) but only 45.0%-66.8% sensitivity with early trophozoites most often mistaken for late trophozoite or schizont stage and late trophozoite and schizont stage most often confused for each other. Overall, this methodology points to a significant clinical potential of using quantitative phase imaging to detect and stage malaria infection without staining or expert analysis.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0163045",
      "citations": 48,
      "readership": 77,
      "tweets": 26,
      "news_mentions": 14
    },
    {
      "title": "Predicting Emergency Visits and Hospital Admissions During Radiation and Chemoradiation: An Internally Validated Pretreatment Machine Learning Algorithm.",
      "authors": "Hong, JC; Niedzwiecki, D; Palta, M; Tenenbaum, JD",
      "published_date": "December 2018",
      "doi": "10.1200/CCI.18.00037",
      "abstract": "PURPOSE: Patients undergoing radiotherapy (RT) or chemoradiotherapy (CRT) may require emergency department evaluation or hospitalization. Early identification may direct preventative supportive care, improving outcomes and reducing health care costs. We developed and evaluated a machine learning (ML) approach to predict these events. METHODS: A total of 8,134 outpatient courses of RT and CRT from a single institution from 2013 to 2016 were identified. Extensive pretreatment data were programmatically extracted and processed from the electronic health record (EHR). Training and internal validation cohorts were randomly generated (3:1 ratio). Gradient tree boosting (GTB), random forest, support vector machine, and least absolute shrinkage and selection operator logistic regression approaches were trained and internally validated based on area under receiver operating characteristic (AUROC) curve. The most predictive ML approach was also evaluated using only disease- and treatment-related factors to assess predictive gain of extensive EHR data. RESULTS: All methods had high predictive accuracy, particularly GTB (validation AUROC, 0.798). Extensive EHR data beyond disease and treatment information improved accuracy (delta AUROC, 0.056). A Youden-based cutoff corresponded to validation sensitivity of 81.0% (175 of 216 courses with events) and specificity of 67.3% (1,218 of 1811 courses without events). Interpretability is an important advantage of GTB. Variable importance identified top predictive factors, including treatment (planned RT and systemic therapy), pretreatment encounters (emergency department visits and admissions in the year before treatment), vital signs (weight loss and pain score in the year before treatment), and laboratory values (albumin level at weeks before treatment). CONCLUSION: ML predicts emergency visits and hospitalization during cancer therapy. Incorporating predictions into clinical care algorithms may help direct personalized supportive care, improve quality of care, and reduce costs. A prospective trial investigating ML-assisted direction of increased clinical assessments during RT is planned.",
      "publication_location": "Jco Clinical Cancer Informatics",
      "link": "http://dx.doi.org/10.1200/CCI.18.00037",
      "citations": 2,
      "readership": 33,
      "tweets": 36,
      "news_mentions": ""
    },
    {
      "title": "Prediction of 30-Day All-Cause Readmissions in Patients Hospitalized for Heart Failure: Comparison of Machine Learning and Other Statistical Approaches.",
      "authors": "Frizzell, JD; Liang, L; Schulte, PJ; Yancy, CW; Heidenreich, PA; Hernandez, AF; Bhatt, DL; Fonarow, GC; Laskey, WK",
      "published_date": "February 1, 2017",
      "doi": "10.1001/jamacardio.2016.3956",
      "abstract": "Importance: Several attempts have been made at developing models to predict 30-day readmissions in patients with heart failure, but none have sufficient discriminatory capacity for clinical use. Machine-learning (ML) algorithms represent a novel approach and may have potential advantages over traditional statistical modeling. Objective: To develop models using a ML approach to predict all-cause readmissions 30 days after discharge from a heart failure hospitalization and to compare ML model performance with models developed using \"conventional\" statistically based methods. Design, Setting, and Participants: Models were developed using ML algorithms, specifically, a tree-augmented naive Bayesian network, a random forest algorithm, and a gradient-boosted model and compared with traditional statistical methods using 2 independently derived logistic regression models (a de novo model and an a priori model developed using electronic health records) and a least absolute shrinkage and selection operator method. The study sample was randomly divided into training (70%) and validation (30%) sets to develop and test model performance. This was a registry-based study, and the study sample was obtained by linking patients from the Get With the Guidelines Heart Failure registry with Medicare data. After applying appropriate inclusion and exclusion criteria, 56 477 patients were included in our analysis. The study was conducted between January 4, 2005, and December 1, 2010, and analysis of the data was conducted between November 25, 2014, and June 30, 2016. Main Outcomes and Measures: C statistics were used for comparison of discriminatory capacity across models in the validation sample. Results: The overall 30-day rehospitalization rate was 21.2% (11 959 of 56 477 patients). For the tree-augmented naive Bayesian network, random forest, gradient-boosted, logistic regression, and least absolute shrinkage and selection operator models, C statistics for the validation sets were similar: 0.618, 0.607, 0.614, 0.624, and 0.618, respectively. Applying the previously validated electronic health records model to our study sample yielded a C statistic of 0.589 for the validation set. Conclusions and Relevance: Use of a number of ML algorithms did not improve prediction of 30-day heart failure readmissions compared with more traditional prediction models. Although there will likely be further applications of ML approaches in prognostic modeling, our study fits within the literature of limited predictive ability for heart failure readmissions.",
      "publication_location": "Jama Cardiol",
      "link": "http://dx.doi.org/10.1001/jamacardio.2016.3956",
      "citations": 64,
      "readership": 142,
      "tweets": 47,
      "news_mentions": 10
    },
    {
      "title": "Use of Machine Learning on Contact Lens Sensor-Derived Parameters for the Diagnosis of Primary Open-angle Glaucoma.",
      "authors": "Martin, KR; Mansouri, K; Weinreb, RN; Wasilewicz, R; Gisler, C; Hennebert, J; Genoud, D; Research Consortium,",
      "published_date": "October 2018",
      "doi": "10.1016/j.ajo.2018.07.005",
      "abstract": "PURPOSE: To test the hypothesis that contact lens sensor (CLS)-based 24-hour profiles of ocular volume changes contain information complementary to intraocular pressure (IOP) to discriminate between primary open-angle glaucoma (POAG) and healthy (H) eyes. DESIGN: Development and evaluation of a diagnostic test with machine learning. METHODS: Subjects: From 435 subjects (193 healthy and 242 POAG), 136 POAG and 136 age-matched healthy subjects were selected. Subjects with contraindications for CLS wear were excluded. PROCEDURE: This is a pooled analysis of data from 24 prospective clinical studies and a registry. All subjects underwent 24-hour CLS recording on 1 eye. Statistical and physiological CLS parameters were derived from the signal recorded. CLS parameters frequently associated with the presence of POAG were identified using a random forest modeling approach. MAIN OUTCOME MEASURES: Area under the receiver operating characteristic curve (ROC AUC) for feature sets including CLS parameters and Start IOP, as well as a feature set with CLS parameters and Start IOP combined. RESULTS: The CLS parameters feature set discriminated POAG from H eyes with mean ROC AUCs of 0.611, confidence interval (CI) 0.493-0.722. Larger values of a given CLS parameter were in general associated with a diagnosis of POAG. The Start IOP feature set discriminated between POAG and H eyes with a mean ROC AUC of 0.681, CI 0.603-0.765. The combined feature set was the best indicator of POAG with an ROC AUC of 0.759, CI 0.654-0.855. This ROC AUC was statistically higher than for CLS parameters or Start IOP feature sets alone (both P < .0001). CONCLUSIONS: CLS recordings contain information complementary to IOP that enable discrimination between H and POAG. The feature set combining CLS parameters and Start IOP provide a better indication of the presence of POAG than each of the feature sets separately. As such, the CLS may be a new biomarker for POAG.",
      "publication_location": "American Journal of Ophthalmology",
      "link": "http://dx.doi.org/10.1016/j.ajo.2018.07.005",
      "citations": 8,
      "readership": 27,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Retinal Nerve Fiber Layer Features Identified by Unsupervised Machine Learning on Optical Coherence Tomography Scans Predict Glaucoma Progression.",
      "authors": "Christopher, M; Belghith, A; Weinreb, RN; Bowd, C; Goldbaum, MH; Saunders, LJ; Medeiros, FA; Zangwill, LM",
      "published_date": "June 1, 2018",
      "doi": "10.1167/iovs.17-23387",
      "abstract": "Purpose: To apply computational techniques to wide-angle swept-source optical coherence tomography (SS-OCT) images to identify novel, glaucoma-related structural features and improve detection of glaucoma and prediction of future glaucomatous progression. Methods: Wide-angle SS-OCT, OCT circumpapillary retinal nerve fiber layer (cpRNFL) circle scans spectral-domain (SD)-OCT, standard automated perimetry (SAP), and frequency doubling technology (FDT) visual field tests were completed every 3 months for 2 years from a cohort of 28 healthy participants (56 eyes) and 93 glaucoma participants (179 eyes). RNFL thickness maps were extracted from segmented SS-OCT images and an unsupervised machine learning approach based on principal component analysis (PCA) was used to identify novel structural features. Area under the receiver operating characteristic curve (AUC) was used to assess diagnostic accuracy of RNFL PCA for detecting glaucoma and progression compared to SAP, FDT, and cpRNFL measures. Results: The RNFL PCA features were significantly associated with mean deviation (MD) in both SAP (R2 = 0.49, P < 0.0001) and FDT visual field testing (R2 = 0.48, P < 0.0001), and with mean circumpapillary RNFL thickness (cpRNFLt) from SD-OCT (R2 = 0.58, P < 0.0001). The identified features outperformed each of these measures in detecting glaucoma with an AUC of 0.95 for RNFL PCA compared to an 0.90 for mean cpRNFLt (P = 0.09), 0.86 for SAP MD (P = 0.034), and 0.83 for FDT MD (P = 0.021). Accuracy in predicting progression was also significantly higher for RNFL PCA compared to SAP MD, FDT MD, and mean cpRNFLt (P = 0.046, P = 0.007, and P = 0.044, respectively). Conclusions: A computational approach can identify structural features that improve glaucoma detection and progression prediction.",
      "publication_location": "Investigative Opthalmology & Visual Science",
      "link": "http://dx.doi.org/10.1167/iovs.17-23387",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A traumatic brain injury prognostic model to support in-hospital triage in a low-income country: a machine learning-based approach.",
      "authors": "Hernandes Rocha, TA; Elahi, C; Cristina da Silva, N; Sakita, FM; Fuller, A; Mmbaga, BT; Green, EP; Haglund, MM; Staton, CA; Nickenig Vissoci, JR",
      "published_date": "May 10, 2019",
      "doi": "10.3171/2019.2.JNS182098",
      "abstract": "OBJECTIVETraumatic brain injury (TBI) is a leading cause of death and disability worldwide, with a disproportionate burden of this injury on low- and middle-income countries (LMICs). Limited access to diagnostic technologies and highly skilled providers combined with high patient volumes contributes to poor outcomes in LMICs. Prognostic modeling as a clinical decision support tool, in theory, could optimize the use of existing resources and support timely treatment decisions in LMICs. The objective of this study was to develop a machine learning-based prognostic model using data from Kilimanjaro Christian Medical Centre in Moshi, Tanzania.METHODSThis study is a secondary analysis of a TBI data registry including 3138 patients. The authors tested nine different machine learning techniques to identify the prognostic model with the greatest area under the receiver operating characteristic curve (AUC). Input data included demographics, vital signs, injury type, and treatment received. The outcome variable was the discharge score on the Glasgow Outcome Scale-Extended.RESULTSThe AUC for the prognostic models varied from 66.2% (k-nearest neighbors) to 86.5% (Bayesian generalized linear model). An increasing Glasgow Coma Scale score, increasing pulse oximetry values, and undergoing TBI surgery were predictive of a good recovery, while injuries suffered from a motor vehicle crash and increasing age were predictive of a poor recovery.CONCLUSIONSThe authors developed a TBI prognostic model with a substantial level of accuracy in a low-resource setting. Further research is needed to externally validate the model and test the algorithm as a clinical decision support tool.",
      "publication_location": "J Neurosurg",
      "link": "http://dx.doi.org/10.3171/2019.2.JNS182098",
      "citations": "(None,)",
      "readership": 10,
      "tweets": 29,
      "news_mentions": ""
    },
    {
      "title": "Automatic localization of the subthalamic nucleus on patient-specific clinical MRI by incorporating 7 T MRI and machine learning: Application in deep brain stimulation.",
      "authors": "Kim, J; Duchin, Y; Shamir, RR; Patriat, R; Vitek, J; Harel, N; Sapiro, G",
      "published_date": "February 2019",
      "doi": "10.1002/hbm.24404",
      "abstract": "Deep brain stimulation (DBS) of the subthalamic nucleus (STN) has shown clinical potential for relieving the motor symptoms of advanced Parkinson's disease. While accurate localization of the STN is critical for consistent across-patients effective DBS, clear visualization of the STN under standard clinical MR protocols is still challenging. Therefore, intraoperative microelectrode recordings (MER) are incorporated to accurately localize the STN. However, MER require significant neurosurgical expertise and lengthen the surgery time. Recent advances in 7 T MR technology facilitate the ability to clearly visualize the STN. The vast majority of centers, however, still do not have 7 T MRI systems, and fewer have the ability to collect and analyze the data. This work introduces an automatic STN localization framework based on standard clinical MRIs without additional cost in the current DBS planning protocol. Our approach benefits from a large database of 7 T MRI and its clinical MRI pairs. We first model in the 7 T database, using efficient machine learning algorithms, the spatial and geometric dependency between the STN and its adjacent structures (predictors). Given a standard clinical MRI, our method automatically computes the predictors and uses the learned information to predict the patient-specific STN. We validate our proposed method on clinical T2 W MRI of 80 subjects, comparing with experts-segmented STNs from the corresponding 7 T MRI pairs. The experimental results show that our framework provides more accurate and robust patient-specific STN localization than using state-of-the-art atlases. We also demonstrate the clinical feasibility of the proposed technique assessing the post-operative electrode active contact locations.",
      "publication_location": "Human Brain Mapping",
      "link": "http://dx.doi.org/10.1002/hbm.24404",
      "citations": 3,
      "readership": 32,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Machine learning to predict developmental neurotoxicity with high-throughput data from 2D bio-engineered tissues.",
      "authors": "Kuusisto, F; Costa, VS; Hou, Z; Thomson, J; Page, D; Stewart, R",
      "published_date": "December 2019",
      "doi": "10.1109/icmla.2019.00055",
      "abstract": "There is a growing need for fast and accurate methods for testing developmental neurotoxicity across several chemical exposure sources. Current approaches, such as \n                        in vivo\n                     animal studies, and assays of animal and human primary cell cultures, suffer from challenges related to time, cost, and applicability to human physiology. Prior work has demonstrated success employing machine learning to predict developmental neurotoxicity using gene expression data collected from human 3D tissue models exposed to various compounds. The 3D model is biologically similar to developing neural structures, but its complexity necessitates extensive expertise and effort to employ. By instead focusing solely on constructing an assay of developmental neurotoxicity, we propose that a simpler 2D tissue model may prove sufficient. We thus compare the accuracy of predictive models trained on data from a 2D tissue model with those trained on data from a 3D tissue model, and find the 2D model to be substantially more accurate. Furthermore, we find the 2D model to be more robust under stringent gene set selection, whereas the 3D model suffers substantial accuracy degradation. While both approaches have advantages and disadvantages, we propose that our described 2D approach could be a valuable tool for decision makers when prioritizing neurotoxicity screening.",
      "publication_location": "Proc Int Conf Mach Learn Appl",
      "link": "http://dx.doi.org/10.1109/icmla.2019.00055",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Standardized database development for EEG epileptiform transient detection: EEGnet scoring system and machine learning analysis.",
      "authors": "Halford, JJ; Schalkoff, RJ; Zhou, J; Benbadis, SR; Tatum, WO; Turner, RP; Sinha, SR; Fountain, NB; Arain, A; Pritchard, PB; Kutluay, E; Martz, G; Edwards, JC; Waters, C; Dean, BC",
      "published_date": "January 30, 2013",
      "doi": "10.1016/j.jneumeth.2012.11.005",
      "abstract": "The routine scalp electroencephalogram (rsEEG) is the most common clinical neurophysiology procedure. The most important role of rsEEG is to detect evidence of epilepsy, in the form of epileptiform transients (ETs), also known as spike or sharp wave discharges. Due to the wide variety of morphologies of ETs and their similarity to artifacts and waves that are part of the normal background activity, the task of ET detection is difficult and mistakes are frequently made. The development of reliable computerized detection of ETs in the EEG could assist physicians in interpreting rsEEGs. We report progress in developing a standardized database for testing and training ET detection algorithms. We describe a new version of our EEGnet software system for collecting expert opinion on EEG datasets, a completely web-browser based system. We report results of EEG scoring from a group of 11 board-certified academic clinical neurophysiologists who annotated 30-s excepts from rsEEG recordings from 100 different patients. The scorers had moderate inter-scorer reliability and low to moderate intra-scorer reliability. In order to measure the optimal size of this standardized rsEEG database, we used machine learning models to classify paroxysmal EEG activity in our database into ET and non-ET classes. Based on our results, it appears that our database will need to be larger than its current size. Also, our non-parametric classifier, an artificial neural network, performed better than our parametric Bayesian classifier. Of our feature sets, the wavelet feature set proved most useful for classification.",
      "publication_location": "J Neurosci Methods",
      "link": "http://dx.doi.org/10.1016/j.jneumeth.2012.11.005",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Prevalence and predictors of C. difficile infections in hospitalized patients with major surgical procedures in the USA: Analysis using traditional and machine learning methods.",
      "authors": "Allareddy, V; Wang, T; Rampa, S; Caplin, J; Nalliah, R; Badheka, A; Allareddy, V",
      "published_date": "September 2019",
      "doi": "10.1016/j.amjsurg.2018.11.014",
      "abstract": "",
      "publication_location": "Am J Surg",
      "link": "http://dx.doi.org/10.1016/j.amjsurg.2018.11.014",
      "citations": "(None,)",
      "readership": 2,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Applying Machine Learning to Investigate Long Term Insect-Plant Interactions Preserved on Digitized Herbarium Specimens",
      "authors": "",
      "published_date": "",
      "doi": "10.1101/790899",
      "abstract": "AbstractPremise of the studyDespite the economic importance of insect damage to plants, long-term data documenting changes in insect damage (‘herbivory’) and diversity are limited. Millions of pressed plant specimens are now available online for collecting big data on plant-insect interactions during the Anthropocene.MethodsWe initiated development of machine learning methods to automate extraction of herbivory data from herbarium specimens. We trained an insect damage detector and a damage type classifier on two distantly related plant species. We experimented with 1) classifying six types of herbivory and two control categories of undamaged leaf, and 2) detecting two of these damage categories for which several hundred annotations were available.ResultsClassification models identified the correct type of herbivory 81.5% of the time. The damage classifier was accurate for categories with at least one hundred test samples. We show anecdotally that the detector works well when asked to detect two types of damage.DiscussionThe classifier and detector together are a promising first step for the automation of herbivory data collection. We describe ongoing efforts to increase the accuracy of these models to allow other researchers to extract similar data and apply them to address a variety of biological hypotheses.",
      "publication_location": "",
      "link": "http://dx.doi.org/10.1101/790899",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Practical outcomes of applying ensemble machine learning classifiers to High-Throughput Screening (HTS) data analysis and screening.",
      "authors": "Simmons, K; Kinney, J; Owens, A; Kleier, DA; Bloch, K; Argentar, D; Walsh, A; Vaidyanathan, G",
      "published_date": "November 2008",
      "doi": "10.1021/ci800164u",
      "abstract": "Over the years numerous papers have presented the effectiveness of various machine learning methods in analyzing drug discovery biological screening data. The predictive performance of models developed using these methods has traditionally been evaluated by assessing performance of the developed models against a portion of the data randomly selected for holdout. It has been our experience that such assessments, while widely practiced, result in an optimistic assessment. This paper describes the development of a series of ensemble-based decision tree models, shares our experience at various stages in the model development process, and presents the impact of such models when they are applied to vendor offerings and the forecasted compounds are acquired and screened in the relevant assays. We have seen that well developed models can significantly increase the hit-rates observed in HTS campaigns.",
      "publication_location": "Journal of Chemical Information and Modeling",
      "link": "http://dx.doi.org/10.1021/ci800164u",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Comparative study of machine-learning and chemometric tools for analysis of in-vivo high-throughput screening data.",
      "authors": "Simmons, K; Kinney, J; Owens, A; Kleier, D; Bloch, K; Argentar, D; Walsh, A; Vaidyanathan, G",
      "published_date": "August 2008",
      "doi": "10.1021/ci800142d",
      "abstract": "High-throughput screening (HTS) has become a central tool of many pharmaceutical and crop-protection discovery operations. If HTS screening is carried out at the level of the intact organism, as is commonly done in crop protection, this strategy has the potential of uncovering a completely new mechanism of actions. The challenge in running a cost-effective HTS operation is to identify ways in which to improve the overall success rate in discovering new biologically active compounds. To this end, we describe our efforts directed at making full use of the data stream arising from HTS. This paper describes a comparative study in which several machine learning and chemometric methodologies were used to develop classifiers on the same data sets derived from in vivo HTS campaigns and their predictive performances compared in terms of false negative and false positive error profiles.",
      "publication_location": "Journal of Chemical Information and Modeling",
      "link": "http://dx.doi.org/10.1021/ci800142d",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Using Machine Learning to Identify Heterogeneous Effects in Randomized Clinical Trials-Moving Beyond the Forest Plot and Into the Forest.",
      "authors": "Goldstein, BA; Rigdon, J",
      "published_date": "March 1, 2019",
      "doi": "10.1001/jamanetworkopen.2019.0004",
      "abstract": "",
      "publication_location": "Jama Network Open",
      "link": "http://dx.doi.org/10.1001/jamanetworkopen.2019.0004",
      "citations": 1,
      "readership": 17,
      "tweets": 11,
      "news_mentions": 2
    },
    {
      "title": "Evidence for CRHR1 in multiple sclerosis using supervised machine learning and meta-analysis in 12,566 individuals.",
      "authors": "Briggs, FBS; Bartlett, SE; Goldstein, BA; Wang, J; McCauley, JL; Zuvich, RL; De Jager, PL; Rioux, JD; Ivinson, AJ; Compston, A; Hafler, DA; Hauser, SL; Oksenberg, JR; Sawcer, SJ; Pericak-Vance, MA; Haines, JL; International Multiple Sclerosis Genetics Consortium, ; Barcellos, LF",
      "published_date": "November 1, 2010",
      "doi": "10.1093/hmg/ddq328",
      "abstract": "The primary genetic risk factor in multiple sclerosis (MS) is the HLA-DRB1*1501 allele; however, much of the remaining genetic contribution to MS has yet to be elucidated. Several lines of evidence support a role for neuroendocrine system involvement in autoimmunity which may, in part, be genetically determined. Here, we comprehensively investigated variation within eight candidate hypothalamic-pituitary-adrenal (HPA) axis genes and susceptibility to MS. A total of 326 SNPs were investigated in a discovery dataset of 1343 MS cases and 1379 healthy controls of European ancestry using a multi-analytical strategy. Random Forests, a supervised machine-learning algorithm, identified eight intronic SNPs within the corticotrophin-releasing hormone receptor 1 or CRHR1 locus on 17q21.31 as important predictors of MS. On the basis of univariate analyses, six CRHR1 variants were associated with decreased risk for disease following a conservative correction for multiple tests. Independent replication was observed for CRHR1 in a large meta-analysis comprising 2624 MS cases and 7220 healthy controls of European ancestry. Results from a combined meta-analysis of all 3967 MS cases and 8599 controls provide strong evidence for the involvement of CRHR1 in MS. The strongest association was observed for rs242936 (OR = 0.82, 95% CI = 0.74-0.90, P = 9.7 × 10(-5)). Replicated CRHR1 variants appear to exist on a single associated haplotype. Further investigation of mechanisms involved in HPA axis regulation and response to stress in MS pathogenesis is warranted.",
      "publication_location": "Hum Mol Genet",
      "link": "http://dx.doi.org/10.1093/hmg/ddq328",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Glaucomatous patterns in Frequency Doubling Technology (FDT) perimetry data identified by unsupervised machine learning classifiers.",
      "authors": "Bowd, C; Weinreb, RN; Balasubramanian, M; Lee, I; Jang, G; Yousefi, S; Zangwill, LM; Medeiros, FA; Girkin, CA; Liebmann, JM; Goldbaum, MH",
      "published_date": 2014,
      "doi": "10.1371/journal.pone.0085941",
      "abstract": "PURPOSE: The variational Bayesian independent component analysis-mixture model (VIM), an unsupervised machine-learning classifier, was used to automatically separate Matrix Frequency Doubling Technology (FDT) perimetry data into clusters of healthy and glaucomatous eyes, and to identify axes representing statistically independent patterns of defect in the glaucoma clusters. METHODS: FDT measurements were obtained from 1,190 eyes with normal FDT results and 786 eyes with abnormal FDT results from the UCSD-based Diagnostic Innovations in Glaucoma Study (DIGS) and African Descent and Glaucoma Evaluation Study (ADAGES). For all eyes, VIM input was 52 threshold test points from the 24-2 test pattern, plus age. RESULTS: FDT mean deviation was -1.00 dB (S.D. = 2.80 dB) and -5.57 dB (S.D. = 5.09 dB) in FDT-normal eyes and FDT-abnormal eyes, respectively (p<0.001). VIM identified meaningful clusters of FDT data and positioned a set of statistically independent axes through the mean of each cluster. The optimal VIM model separated the FDT fields into 3 clusters. Cluster N contained primarily normal fields (1109/1190, specificity 93.1%) and clusters G1 and G2 combined, contained primarily abnormal fields (651/786, sensitivity 82.8%). For clusters G1 and G2 the optimal number of axes were 2 and 5, respectively. Patterns automatically generated along axes within the glaucoma clusters were similar to those known to be indicative of glaucoma. Fields located farther from the normal mean on each glaucoma axis showed increasing field defect severity. CONCLUSIONS: VIM successfully separated FDT fields from healthy and glaucoma eyes without a priori information about class membership, and identified familiar glaucomatous patterns of loss.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0085941",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Applying machine learning to understand write performance of large-scale parallel filesystems",
      "authors": "",
      "published_date": "November 1, 2019",
      "doi": "10.1109/PDSW49588.2019.00008",
      "abstract": "© 2019 IEEE. In high-performance computing (HPC), I/O performance prediction offers the potential to improve the efficiency of scientific computing. In particular, accurate prediction can make runtime estimates more precise, guide users toward optimal checkpoint strategies, and better inform facility provisioning and scheduling policies. HPC I/O performance is notoriously difficult to predict and model, however, in large part because of inherent variability and a lack of transparency in the behaviors of constituent storage system components. In this work we seek to advance the state of the art in HPC I/O performance prediction by (1) modeling the mean performance to address high variability, (2) deriving model features from write patterns, system architecture and system configurations, and (3) employing Lasso regression model to improve model accuracy. We demonstrate the efficacy of our approach by applying it to a crucial subset of common HPC I/O motifs, namely, file-per-process checkpoint write workloads. We conduct experiments on two distinct production HPC platforms-Titan at the Oak Ridge Leadership Computing Facility and Cetus at the Argonne Leadership Computing Facility-to train and evaluate our models. We find that we can attain ≤ 30% relative error for 92.79% and 99.64% of the samples in our test set on these platforms, respectively.",
      "publication_location": "Proceedings of Pdsw 2019: Ieee/Acm 4th International Parallel Data Systems Workshop   Held in Conjunction With Sc 2019: the International Conference for High Performance Computing, Networking, Storage and Analysis",
      "link": "http://dx.doi.org/10.1109/PDSW49588.2019.00008",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine learning-based prediction of future breast cancer using algorithmically measured background parenchymal enhancement on high-risk screening MRI.",
      "authors": "Saha, A; Grimm, LJ; Ghate, SV; Kim, CE; Soo, MS; Yoon, SC; Mazurowski, MA",
      "published_date": "August 2019",
      "doi": "10.1002/jmri.26636",
      "abstract": "BACKGROUND: Preliminary work has demonstrated that background parenchymal enhancement (BPE) assessed by radiologists is predictive of future breast cancer in women undergoing high-risk screening MRI. Algorithmically assessed measures of BPE offer a more precise and reproducible means of measuring BPE than human readers and thus might improve the predictive performance of future cancer development. PURPOSE: To determine if algorithmically extracted imaging features of BPE on screening breast MRI in high-risk women are associated with subsequent development of cancer. STUDY TYPE: Case-control study. POPULATION: In all, 133 women at high risk for developing breast cancer; 46 of these patients developed breast cancer subsequently over a follow-up period of 2 years. FIELD STRENGTH/SEQUENCE: 5 T or 3.0 T T1 -weighted precontrast fat-saturated and nonfat-saturated sequences and postcontrast nonfat-saturated sequences. ASSESSMENT: Automatic features of BPE were extracted with a computer algorithm. Subjective BPE scores from five breast radiologists (blinded to clinical outcomes) were also available. STATISTICAL TESTS: Leave-one-out crossvalidation for a multivariate logistic regression model developed using the automatic features and receiver operating characteristic (ROC) analysis were performed to calculate the area under the curve (AUC). Comparison of automatic features and subjective features was performed using a generalized regression model and the P-value was obtained. Odds ratios for automatic and subjective features were compared. RESULTS: The multivariate model discriminated patients who developed cancer from the patients who did not, with an AUC of 0.70 (95% confidence interval: 0.60-0.79, P < 0.001). The imaging features remained independently predictive of subsequent development of cancer (P < 0.003) when compared with the subjective BPE assessment of the readers. DATA CONCLUSION: Automatically extracted BPE measurements may potentially be used to further stratify risk in patients undergoing high-risk screening MRI. LEVEL OF EVIDENCE: 3 Technical Efficacy: Stage 5 J. Magn. Reson. Imaging 2019;50:456-464.",
      "publication_location": "J Magn Reson Imaging",
      "link": "http://dx.doi.org/10.1002/jmri.26636",
      "citations": 1,
      "readership": 18,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Globally-Consistent Rule-Based Summary-Explanations for Machine Learning Models: Application to Credit-Risk Evaluation",
      "authors": "Rudin, C; Shaposhnik, Y",
      "published_date": "May 28, 2019",
      "doi": "",
      "abstract": "",
      "publication_location": "",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Machine-learning prediction of cancer survival: A prospective study examining the impact of combining clinical and genomic data.",
      "authors": "Ashley, DM; Gupta, S; Tran, T; Wei, L; Lorgelly, PK; Thomas, DM; Fox, SB; Venkatesh, S",
      "published_date": "May 20, 2015",
      "doi": "10.1200/jco.2015.33.15_suppl.6521",
      "abstract": "",
      "publication_location": "Journal of Clinical Oncology : Official Journal of the American Society of Clinical Oncology",
      "link": "http://dx.doi.org/10.1200/jco.2015.33.15_suppl.6521",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Implementation of Machine Learning-Based Treatment Planning Tool for Whole Breast Radiotherapy Using Irregular Surface Compensator Technique",
      "authors": "Yoo, S; Sheng, Y; Blitzblau, RC; Suneja, G; O'Neill, L; Morrison, J; Catalano, S; Yin, FF; Wu, QJJ",
      "published_date": "September 2019",
      "doi": "10.1016/j.ijrobp.2019.06.572",
      "abstract": "",
      "publication_location": "International Journal of Radiation Oncology, Biology, Physics",
      "link": "http://dx.doi.org/10.1016/j.ijrobp.2019.06.572",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The Use of Artificial Intelligence (AI) Machine Learning to Determine Myocyte Damage in Cardiac Transplant Acute Cellular Rejection",
      "authors": "Glass, C; Davis, R; Xiong, B; Dov, D; Glass, M",
      "published_date": "April 1, 2020",
      "doi": "",
      "abstract": "",
      "publication_location": "Journal of Heart and Lung Transplantation",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000522637200121&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Active machine learning method for identification of cell types in multiplex-stained histopathology specimens imaged by multi-spectral microscopy",
      "authors": "Padmanabhan, R; Somasundar, V; Roysam, B; Liao, X; Carin, L; Hu, J; Zhu, J; Lee, W",
      "published_date": "January 1, 2012",
      "doi": "10.1017/S1431927612007933",
      "abstract": "",
      "publication_location": "Microscopy and Microanalysis : the Official Journal of Microscopy Society of America, Microbeam Analysis Society, Microscopical Society of Canada",
      "link": "http://dx.doi.org/10.1017/S1431927612007933",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Guest editors' introduction to the special section on hardware and algorithms for energy-constrained on-chip machine learning",
      "authors": "Seo, JS; Cao, Y; Li, X; Whatmough, P",
      "published_date": "June 1, 2019",
      "doi": "10.1145/3322433",
      "abstract": "",
      "publication_location": "Acm Journal on Emerging Technologies in Computing Systems",
      "link": "http://dx.doi.org/10.1145/3322433",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Computer-aided design of machine learning algorithm: Training fixed-point classifier for on-chip low-power implementation",
      "authors": "Albalawi, H; Li, Y; Li, X",
      "published_date": "January 1, 2014",
      "doi": "10.1145/2593069.2593110",
      "abstract": "In this paper, we propose a novel linear discriminant analysis algorithm, referred to as LDA-FP, to train on-chip classifiers that can be implemented with low-power fixed-point arithmetic with extremely small word length. LDA-FP incorporates the nonidealities (i.e., rounding and overflow) associated with fixed-point arithmetic into the training process so that the resulting classifiers are robust to these non-idealities. Mathematically, LDA-FP is formulated as a mixed integer programming problem that can be efficiently solved by a novel branch-and-bound method proposed in this paper. Our numerical experiments demonstrate that LDAFP substantially outperforms the conventional approach for the emerging biomedical application of brain computer interface. Copyright 2014 ACM.",
      "publication_location": "Proceedings   Design Automation Conference",
      "link": "http://dx.doi.org/10.1145/2593069.2593110",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Development of a Machine Learning Methodology to Estimate Lung Stereotactic Body Radiation Therapy Dosimetric Endpoints Based on Patient-Specific Anatomic Features.",
      "authors": "Lafata, K; Cai, J; Ren, L; Wu, Q; Hong, JC; Kelsey, CR; Yin, FF",
      "published_date": "October 1, 2016",
      "doi": "10.1016/j.ijrobp.2016.06.1687",
      "abstract": "",
      "publication_location": "Int J Radiat Oncol Biol Phys",
      "link": "http://dx.doi.org/10.1016/j.ijrobp.2016.06.1687",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Mammalian faunas, ecological indices, and machine-learning regression for the purpose of paleoenvironment reconstruction in the Miocene of South America",
      "authors": "Spradley, JP; Glazer, BJ; Kay, RF",
      "published_date": "March 15, 2019",
      "doi": "10.1016/j.palaeo.2019.01.014",
      "abstract": "© 2019 Elsevier B.V. Reconstructing paleoenvironments has long been considered a vital component for understanding community structure of extinct organisms, as well as patterns that guide evolutionary pathways of species and higher-level taxa. Given the relative geographic and phylogenetic isolation of the South American continent throughout much of the Cenozoic, the South American fossil record presents a unique perspective of mammalian community evolution in the context of changing climates and environments. Here we focus on one line of evidence for paleoenvironment reconstruction: ecological diversity, i.e. the number and types of ecological niches filled within a given fauna. We propose a novel approach by utilizing ecological indices as predictors in two regressive modeling techniques—Random Forest (RF) and Gaussian Process Regression (GPR)—which are applied to 85 extant Central and South American localities to produce paleoecological prediction models. Faunal richness is quantified via ratios of ecologies within the mammalian communities, i.e. ecological indices, which serve as predictor variables in our models. Six climate/habitat variables were then predicted using these ecological indices: mean annual temperature (MAT), mean annual precipitation (MAP), temperature seasonality, precipitation seasonality, canopy height, and net primary productivity (NPP). Predictive accuracy of RF and GPR is markedly higher when compared to previously published methods. MAT, MAP, and temperature seasonality have the lowest predictive error. We use these models to reconstruct paleoclimatic variables in two well-sampled Miocene faunas from South America: fossiliferous layers (FL) 1–7, Santa Cruz Formation (Early Miocene), Santa Cruz Province, Argentina; and the Monkey Beds unit, Villavieja Formation (Middle Miocene) Huila, Colombia. Results suggest general concordance with published estimations of precipitation and temperature, and add information with regards to the other climate/habitat variables included here. Ultimately, we believe that RF and GPR in conjunction with ecological indices have the potential to contribute to paleoenvironment reconstruction.",
      "publication_location": "Palaeogeography, Palaeoclimatology, Palaeoecology",
      "link": "http://dx.doi.org/10.1016/j.palaeo.2019.01.014",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Image processing and machine learning techniques to automate diagnosis of Lugol's iodine cervigrams for a low-cost point-of-care digital colposcope",
      "authors": "Asiedu, MN; Simhal, A; Lam, CT; Mueller, J; Chaudhary, U; Schmitt, JW; Sapiro, G; Ramanujam, N",
      "published_date": "January 1, 2018",
      "doi": "10.1117/12.2282792",
      "abstract": "Copyright © 2018 SPIE. The world health organization recommends visual inspection with acetic acid (VIA) and/or Lugol's Iodine (VILI) for cervical cancer screening in low-resource settings. Human interpretation of diagnostic indicators for visual inspection is qualitative, subjective, and has high inter-observer discordance, which could lead both to adverse outcomes for the patient and unnecessary follow-ups. In this work, we a simple method for automatic feature extraction and classification for Lugol's Iodine cervigrams acquired with a low-cost, miniature, digital colposcope. Algorithms to preprocess expert physician-labelled cervigrams and to extract simple but powerful color-based features are introduced. The features are used to train a support vector machine model to classify cervigrams based on expert physician labels. The selected framework achieved a sensitivity, specificity, and accuracy of 89.2%, 66.7% and 80.6% with majority diagnosis of the expert physicians in discriminating cervical intraepithelial neoplasia (CIN +) relative to normal tissues. The proposed classifier also achieved an area under the curve of 84 when trained with majority diagnosis of the expert physicians. The results suggest that utilizing simple color-based features may enable unbiased automation of VILI cervigrams, opening the door to a full system of low-cost data acquisition complemented with automatic interpretation.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2282792",
      "citations": 3,
      "readership": 9,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Development and validation of machine learning models to identify high-risk surgical patients using automatically curated electronic health record data (Pythia): A retrospective, single-site study.",
      "authors": "Corey, KM; Kashyap, S; Lorenzi, E; Lagoo-Deenadayalan, SA; Heller, K; Whalen, K; Balu, S; Heflin, MT; McDonald, SR; Swaminathan, M; Sendak, M",
      "published_date": "November 2018",
      "doi": "10.1371/journal.pmed.1002701",
      "abstract": "BACKGROUND: Pythia is an automated, clinically curated surgical data pipeline and repository housing all surgical patient electronic health record (EHR) data from a large, quaternary, multisite health institute for data science initiatives. In an effort to better identify high-risk surgical patients from complex data, a machine learning project trained on Pythia was built to predict postoperative complication risk. METHODS AND FINDINGS: A curated data repository of surgical outcomes was created using automated SQL and R code that extracted and processed patient clinical and surgical data across 37 million clinical encounters from the EHRs. A total of 194 clinical features including patient demographics (e.g., age, sex, race), smoking status, medications, comorbidities, procedure information, and proxies for surgical complexity were constructed and aggregated. A cohort of 66,370 patients that had undergone 99,755 invasive procedural encounters between January 1, 2014, and January 31, 2017, was studied further for the purpose of predicting postoperative complications. The average complication and 30-day postoperative mortality rates of this cohort were 16.0% and 0.51%, respectively. Least absolute shrinkage and selection operator (lasso) penalized logistic regression, random forest models, and extreme gradient boosted decision trees were trained on this surgical cohort with cross-validation on 14 specific postoperative outcome groupings. Resulting models had area under the receiver operator characteristic curve (AUC) values ranging between 0.747 and 0.924, calculated on an out-of-sample test set from the last 5 months of data. Lasso penalized regression was identified as a high-performing model, providing clinically interpretable actionable insights. Highest and lowest performing lasso models predicted postoperative shock and genitourinary outcomes with AUCs of 0.924 (95% CI: 0.901, 0.946) and 0.780 (95% CI: 0.752, 0.810), respectively. A calculator requiring input of 9 data fields was created to produce a risk assessment for the 14 groupings of postoperative outcomes. A high-risk threshold (15% risk of any complication) was determined to identify high-risk surgical patients. The model sensitivity was 76%, with a specificity of 76%. Compared to heuristics that identify high-risk patients developed by clinical experts and the ACS NSQIP calculator, this tool performed superiorly, providing an improved approach for clinicians to estimate postoperative risk for patients. Limitations of this study include the missingness of data that were removed for analysis. CONCLUSIONS: Extracting and curating a large, local institution's EHR data for machine learning purposes resulted in models with strong predictive performance. These models can be used in clinical settings as decision support tools for identification of high-risk patients as well as patient evaluation and care management. Further work is necessary to evaluate the impact of the Pythia risk calculator within the clinical workflow on postoperative outcomes and to optimize this data flow for future machine learning efforts.",
      "publication_location": "Plos Medicine",
      "link": "http://dx.doi.org/10.1371/journal.pmed.1002701",
      "citations": 22,
      "readership": 115,
      "tweets": 44,
      "news_mentions": ""
    },
    {
      "title": "Performance of a machine learning model vs. IMPROVE score for VTE prediction in acute medically ill patients: insights from the APEX trial",
      "authors": "Nafee, T; Gibson, CM; Travis, R; Kerneis, M; Yee, MK; Alkhalfan, F; Chi, G; Kalayci, A; Mir, M; Alihashemi, M; Hull, RD; Hernandez, AF; Cohen, AT; Harrington, RA; Goldhaber, SZ",
      "published_date": "August 1, 2018",
      "doi": "",
      "abstract": "",
      "publication_location": "European Heart Journal",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000459824001370&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multivariate machine learning models for prediction of pathologic response to neoadjuvant therapy in breast cancer using MRI features: a study using an independent validation set.",
      "authors": "Cain, EH; Saha, A; Harowicz, MR; Marks, JR; Marcom, PK; Mazurowski, MA",
      "published_date": "January 2019",
      "doi": "10.1007/s10549-018-4990-9",
      "abstract": "PURPOSE: To determine whether a multivariate machine learning-based model using computer-extracted features of pre-treatment dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) can predict pathologic complete response (pCR) to neoadjuvant therapy (NAT) in breast cancer patients. METHODS: Institutional review board approval was obtained for this retrospective study of 288 breast cancer patients at our institution who received NAT and had a pre-treatment breast MRI. A comprehensive set of 529 radiomic features was extracted from each patient's pre-treatment MRI. The patients were divided into equal groups to form a training set and an independent test set. Two multivariate machine learning models (logistic regression and a support vector machine) based on imaging features were trained to predict pCR in (a) all patients with NAT, (b) patients with neoadjuvant chemotherapy (NACT), and (c) triple-negative or human epidermal growth factor receptor 2-positive (TN/HER2+) patients who had NAT. The multivariate models were tested using the independent test set, and the area under the receiver operating characteristics (ROC) curve (AUC) was calculated. RESULTS: Out of the 288 patients, 64 achieved pCR. The AUC values for predicting pCR in TN/HER+ patients who received NAT were significant (0.707, 95% CI 0.582-0.833, p < 0.002). CONCLUSIONS: The multivariate models based on pre-treatment MRI features were able to predict pCR in TN/HER2+ patients.",
      "publication_location": "Breast Cancer Res Treat",
      "link": "http://dx.doi.org/10.1007/s10549-018-4990-9",
      "citations": 12,
      "readership": 41,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "A machine learning-based prediction model of H3K27M mutations in brainstem gliomas using conventional MRI and clinical features.",
      "authors": "Pan, C-C; Liu, J; Tang, J; Chen, X; Chen, F; Wu, Y-L; Geng, Y-B; Xu, C; Zhang, X; Wu, Z; Gao, P-Y; Zhang, J-T; Yan, H; Liao, H; Zhang, L-W",
      "published_date": "January 2019",
      "doi": "10.1016/j.radonc.2018.07.011",
      "abstract": "BACKGROUND: H3K27M is the most frequent mutation in brainstem gliomas (BSGs), and it has great significance in the differential diagnosis, prognostic prediction and treatment strategy selection of BSGs. There has been a lack of reliable noninvasive methods capable of accurately predicting H3K27M mutations in BSGs. METHODS: A total of 151 patients with newly diagnosed BSGs were included in this retrospective study. The H3K27M mutation status was obtained by whole-exome, whole-genome or Sanger's sequencing. A total of 1697 features, including 6 clinical parameters and 1691 imaging features, were extracted from pre- and post-contrast T1-weighted and T2-weighted images. Using a random forest algorithm, 36 selected MR image features were integrated with 3 selected clinical features to generate a model that was predictive of H3K27M mutations. Additionally, a simplified prediction model comprising the Karnofsky Performance Status (KPS) at diagnosis, symptom duration at diagnosis and edge sharpness on T2 was established for practical clinical utility using the least squares estimation method. RESULTS: H3K27M mutation was an independent prognostic factor that conferred a worse prognosis (p = 0.01, hazard ratio = 3.0, 95% confidence interval [CI], 1.57-5.74). The machine learning-based model achieved an accuracy of 84.44% (area under the curve [AUC] = 0.8298) in the test cohort. The simplified model achieved an AUC of 0.7839 in the test cohort. CONCLUSIONS: Using conventional MRI and clinical features, we established a machine learning-based model with high accuracy and a simplified model with improved clinical utility to predict H3K27M mutations in BSGs.",
      "publication_location": "Radiother Oncol",
      "link": "http://dx.doi.org/10.1016/j.radonc.2018.07.011",
      "citations": 6,
      "readership": 32,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Machine Learning Methods Improve Prognostication, Identify Clinically Distinct Phenotypes, and Detect Heterogeneity in Response to Therapy in a Large Cohort of Heart Failure Patients.",
      "authors": "Ahmad, T; Lund, LH; Rao, P; Ghosh, R; Warier, P; Vaccaro, B; Dahlström, U; O'Connor, CM; Felker, GM; Desai, NR",
      "published_date": "April 12, 2018",
      "doi": "10.1161/JAHA.117.008081",
      "abstract": "BACKGROUND: Whereas heart failure (HF) is a complex clinical syndrome, conventional approaches to its management have treated it as a singular disease, leading to inadequate patient care and inefficient clinical trials. We hypothesized that applying advanced analytics to a large cohort of HF patients would improve prognostication of outcomes, identify distinct patient phenotypes, and detect heterogeneity in treatment response. METHODS AND RESULTS: The Swedish Heart Failure Registry is a nationwide registry collecting detailed demographic, clinical, laboratory, and medication data and linked to databases with outcome information. We applied random forest modeling to identify predictors of 1-year survival. Cluster analysis was performed and validated using serial bootstrapping. Association between clusters and survival was assessed with Cox proportional hazards modeling and interaction testing was performed to assess for heterogeneity in response to HF pharmacotherapy across propensity-matched clusters. Our study included 44 886 HF patients enrolled in the Swedish Heart Failure Registry between 2000 and 2012. Random forest modeling demonstrated excellent calibration and discrimination for survival (C-statistic=0.83) whereas left ventricular ejection fraction did not (C-statistic=0.52): there were no meaningful differences per strata of left ventricular ejection fraction (1-year survival: 80%, 81%, 83%, and 84%). Cluster analysis using the 8 highest predictive variables identified 4 clinically relevant subgroups of HF with marked differences in 1-year survival. There were significant interactions between propensity-matched clusters (across age, sex, and left ventricular ejection fraction and the following medications: diuretics, angiotensin-converting enzyme inhibitors, β-blockers, and nitrates, P<0.001, all). CONCLUSIONS: Machine learning algorithms accurately predicted outcomes in a large data set of HF patients. Cluster analysis identified 4 distinct phenotypes that differed significantly in outcomes and in response to therapeutics. Use of these novel analytic approaches has the potential to enhance effectiveness of current therapies and transform future HF clinical trials.",
      "publication_location": "Journal of the American Heart Association",
      "link": "http://dx.doi.org/10.1161/JAHA.117.008081",
      "citations": 33,
      "readership": 81,
      "tweets": 44,
      "news_mentions": 4
    },
    {
      "title": "Microelectrode Recordings Validate the Clinical Visualization of Subthalamic-Nucleus Based on 7T Magnetic Resonance Imaging and Machine Learning for Deep Brain Stimulation Surgery.",
      "authors": "Shamir, RR; Duchin, Y; Kim, J; Patriat, R; Marmor, O; Bergman, H; Vitek, JL; Sapiro, G; Bick, A; Eliahou, R; Eitan, R; Israel, Z; Harel, N",
      "published_date": "March 2019",
      "doi": "10.1093/neuros/nyy212",
      "abstract": "BACKGROUND:Deep brain stimulation (DBS) of the subthalamic nucleus (STN) is a proven and effective therapy for the management of the motor symptoms of Parkinson's disease (PD). While accurate positioning of the stimulating electrode is critical for success of this therapy, precise identification of the STN based on imaging can be challenging. We developed a method to accurately visualize the STN on a standard clinical magnetic resonance imaging (MRI). The method incorporates a database of 7-Tesla (T) MRIs of PD patients together with machine-learning methods (hereafter 7 T-ML). OBJECTIVE:To validate the clinical application accuracy of the 7 T-ML method by comparing it with identification of the STN based on intraoperative microelectrode recordings. METHODS:Sixteen PD patients who underwent microelectrode-recordings guided STN DBS were included in this study (30 implanted leads and electrode trajectories). The length of the STN along the electrode trajectory and the position of its contacts to dorsal, inside, or ventral to the STN were compared using microelectrode-recordings and the 7 T-ML method computed based on the patient's clinical 3T MRI. RESULTS:All 30 electrode trajectories that intersected the STN based on microelectrode-recordings, also intersected it when visualized with the 7 T-ML method. STN trajectory average length was 6.2 ± 0.7 mm based on microelectrode recordings and 5.8 ± 0.9 mm for the 7 T-ML method. We observed a 93% agreement regarding contact location between the microelectrode-recordings and the 7 T-ML method. CONCLUSION:The 7 T-ML method is highly consistent with microelectrode-recordings data. This method provides a reliable and accurate patient-specific prediction for targeting the STN.",
      "publication_location": "Neurosurgery",
      "link": "http://dx.doi.org/10.1093/neuros/nyy212",
      "citations": 7,
      "readership": 33,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Identifying treatment effects of an informal caregiver education intervention to increase days in the community and decrease caregiver distress: a machine-learning secondary analysis of subgroup effects in the HI-FIVES randomized clinical trial.",
      "authors": "Shepherd-Banigan, M; Smith, VA; Lindquist, JH; Cary, MP; Miller, KEM; Chapman, JG; Van Houtven, CH",
      "published_date": "February 14, 2020",
      "doi": "10.1186/s13063-020-4113-x",
      "abstract": "BACKGROUND: Informal caregivers report substantial burden and depressive symptoms which predict higher rates of patient institutionalization. While caregiver education interventions may reduce caregiver distress and decrease the use of long-term institutional care, evidence is mixed. Inconsistent findings across studies may be the result of reporting average treatment effects which do not account for how effects differ by participant characteristics. We apply a machine-learning approach to randomized clinical trial (RCT) data of the Helping Invested Family Members Improve Veteran's Experiences Study (HI-FIVES) intervention to explore how intervention effects vary by caregiver and patient characteristics. METHODS: We used model-based recursive partitioning models. Caregivers of community-residing older adult US veterans with functional or cognitive impairment at a single VA Medical Center site were randomized to receive HI-FIVES (n = 118) vs. usual care (n = 123). The outcomes included cumulative days not in the community and caregiver depressive symptoms assessed at 12 months post intervention. Potential moderating characteristics were: veteran age, caregiver age, caregiver ethnicity and race, relationship satisfaction, caregiver burden, perceived financial strain, caregiver depressive symptoms, and patient risk score. RESULTS: The effect of HI-FIVES on days not at home was moderated by caregiver burden (p < 0.001); treatment effects were higher for caregivers with a Zarit Burden Scale score ≤ 28. Caregivers with lower baseline Center for Epidemiologic Studies Depression Scale (CESD-10) scores (≤ 8) had slightly lower CESD-10 scores at follow-up (p < 0.001). CONCLUSIONS: Family caregiver education interventions may be less beneficial for highly burdened and distressed caregivers; these caregivers may require a more tailored approach that involves assessing caregiver needs and developing personalized approaches. TRIAL REGISTRATION: ClinicalTrials.gov, ID:NCT01777490. Registered on 28 January 2013.",
      "publication_location": "Trials",
      "link": "http://dx.doi.org/10.1186/s13063-020-4113-x",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 16,
      "news_mentions": ""
    },
    {
      "title": "Utilizing Machine Learning for Pre- and Postoperative Assessment of Patients Undergoing Resection for BCLC-0, A and B Hepatocellular Carcinoma: Implications for Resection Beyond the BCLC Guidelines.",
      "authors": "Tsilimigras, DI; Mehta, R; Moris, D; Sahara, K; Bagante, F; Paredes, AZ; Farooq, A; Ratti, F; Marques, HP; Silva, S; Soubrane, O; Lam, V; Poultsides, GA; Popescu, I; Grigorie, R; Alexandrescu, S; Martel, G; Workneh, A; Guglielmi, A; Hugh, T; Aldrighetti, L; Endo, I; Pawlik, TM",
      "published_date": "March 2020",
      "doi": "10.1245/s10434-019-08025-z",
      "abstract": "BACKGROUND:There is an ongoing debate about expanding the resection criteria for hepatocellular carcinoma (HCC) beyond the Barcelona Clinic Liver Cancer (BCLC) guidelines. We sought to determine the factors that held the most prognostic weight in the pre- and postoperative setting for each BCLC stage by applying a machine learning method. METHODS:Patients who underwent resection for BCLC-0, A and B HCC between 2000 and 2017 were identified from an international multi-institutional database. A Classification and Regression Tree (CART) model was used to generate homogeneous groups of patients relative to overall survival (OS) based on pre- and postoperative factors. RESULTS:Among 976 patients, 63 (6.5%) had BCLC-0, 745 (76.3%) had BCLC-A, and 168 (17.2%) had BCLC-B HCC. Five-year OS among BCLC-0/A and BCLC-B patients was 64.2% versus 50.2%, respectively (p = 0.011). The preoperative CART model selected α-fetoprotein (AFP) and Charlson comorbidity score (CCS) as the first and second most important preoperative factors of OS among BCLC-0/A patients, whereas radiologic tumor burden score (TBS) was the best predictor of OS among BCLC-B patients. The postoperative CART model revealed lymphovascular invasion as the best postoperative predictor of OS among BCLC-0/A patients, whereas TBS remained the best predictor of long-term outcomes among BCLC-B patients in the postoperative setting. On multivariable analysis, pathologic TBS independently predicted worse OS among BCLC-0/A (hazard ratio [HR] 1.04, 95% confidence interval [CI] 1.02-1.07) and BCLC-B patients (HR 1.13, 95% CI 1.06-1.19) undergoing resection. CONCLUSION:Prognostic stratification of patients undergoing resection for HCC within and beyond the BCLC resection criteria should include assessment of AFP and comorbidities for BCLC-0/A patients, as well as tumor burden for BCLC-B patients.",
      "publication_location": "Annals of Surgical Oncology",
      "link": "http://dx.doi.org/10.1245/s10434-019-08025-z",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "SU-D-204-01: A Methodology Based On Machine Learning and Quantum Clustering to Predict Lung SBRT Dosimetric Endpoints From Patient Specific Anatomic Features.",
      "authors": "Lafata, K; Ren, L; Wu, Q; Kelsey, C; Hong, J; Cai, J; Yin, F",
      "published_date": "June 2016",
      "doi": "10.1118/1.4955606",
      "abstract": "PURPOSE: To develop a data-mining methodology based on quantum clustering and machine learning to predict expected dosimetric endpoints for lung SBRT applications based on patient-specific anatomic features. METHODS: Ninety-three patients who received lung SBRT at our clinic from 2011-2013 were retrospectively identified. Planning information was acquired for each patient, from which various features were extracted using in-house semi-automatic software. Anatomic features included tumor-to-OAR distances, tumor location, total-lung-volume, GTV and ITV. Dosimetric endpoints were adopted from RTOG-0195 recommendations, and consisted of various OAR-specific partial-volume doses and maximum point-doses. First, PCA analysis and unsupervised quantum-clustering was used to explore the feature-space to identify potentially strong classifiers. Secondly, a multi-class logistic regression algorithm was developed and trained to predict dose-volume endpoints based on patient-specific anatomic features. Classes were defined by discretizing the dose-volume data, and the feature-space was zero-mean normalized. Fitting parameters were determined by minimizing a regularized cost function, and optimization was performed via gradient descent. As a pilot study, the model was tested on two esophageal dosimetric planning endpoints (maximum point-dose, dose-to-5cc), and its generalizability was evaluated with leave-one-out cross-validation. RESULTS: Quantum-Clustering demonstrated a strong separation of feature-space at 15Gy across the first-and-second Principle Components of the data when the dosimetric endpoints were retrospectively identified. Maximum point dose prediction to the esophagus demonstrated a cross-validation accuracy of 87%, and the maximum dose to 5cc demonstrated a respective value of 79%. The largest optimized weighting factor was placed on GTV-to-esophagus distance (a factor of 10 greater than the second largest weighting factor), indicating an intuitively strong correlation between this feature and both endpoints. CONCLUSION: This pilot study shows that it is feasible to predict dose-volume endpoints based on patient-specific anatomic features. The developed methodology can potentially help to identify patients at risk for higher OAR doses, thus improving the efficiency of treatment planning. R01-184173.",
      "publication_location": "Med Phys",
      "link": "http://dx.doi.org/10.1118/1.4955606",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "High spatiotemporal resolution dynamic contrast-enhanced MRI improves the image-based discrimination of histopathology risk groups of peripheral zone prostate cancer: a supervised machine learning approach.",
      "authors": "Winkel, DJ; Breit, H-C; Block, TK; Boll, DT; Heye, TJ",
      "published_date": "April 23, 2020",
      "doi": "10.1007/s00330-020-06849-y",
      "abstract": "OBJECTIVE: To assess if adding perfusion information from dynamic contrast-enhanced (DCE MRI) acquisition schemes with high spatiotemporal resolution to T2w/DWI sequences as input features for a gradient boosting machine (GBM) machine learning (ML) classifier could better classify prostate cancer (PCa) risk groups than T2w/DWI sequences alone. MATERIALS AND METHODS: One hundred ninety patients (68 ± 9 years) were retrospectively evaluated at 3T MRI for clinical suspicion of PCa. Included were 201 peripheral zone (PZ) PCa lesions. Histopathological confirmation on fusion biopsy was matched with normal prostate parenchyma contralaterally. Biopsy results were grouped into benign tissue and low-, intermediate-, and high-risk groups (Gleason sum score 6, 7, and > 7, respectively). DCE MRI was performed using golden-angle radial sparse MRI. Perfusion maps (Ktrans, Kep, Ve), apparent diffusion coefficient (ADC), and absolute T2w signal intensity were determined and used as input features for building two ML models: GBM with/without perfusion maps. Areas under the receiver operating characteristic curve (AUC) values for correlated models were compared. RESULTS: For the classification of benign vs. malignant and intermediate- vs. high-grade PCa, perfusion information added relevant information (AUC values 1 vs. 0.953 and 0.909 vs. 0.700, p < 0.001 and p = 0.038), while no statistically significant effect was found for low- vs. intermediate- and high-grade PCa. CONCLUSION: Perfusion information from DCE MRI acquisition schemes with high spatiotemporal resolution to ML classifiers enables a superior risk stratification between benign and malignant and intermediate- and high-risk PCa in the PZ compared with classifiers based on T2w/DWI information alone. KEY POINTS: • In the recent guidelines, the role of DCE MRI has changed from a mandatory to recommended sequence. • DCE MRI acquisition schemes with high spatiotemporal resolution (e.g., GRASP) have been shown to improve the diagnostic performance compared with conventional DCE MRI sequences. • Using perfusion information acquired with GRASP in combination with ML classifiers significantly improved the prediction of benign vs. malignant and intermediate- vs. high-grade peripheral zone prostate cancer compared with non-contrast sequences.",
      "publication_location": "Eur Radiol",
      "link": "http://dx.doi.org/10.1007/s00330-020-06849-y",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Response to comment on: A planning quality evaluation tool for prostate adaptive IMRT based on machine learning' Med. Phys. 38, 719 (2011)",
      "authors": "Zhu, X; Li, T; Yin, FF; Wu, QJ; Ge, Y",
      "published_date": "January 1, 2011",
      "doi": "10.1118/1.3578613",
      "abstract": "",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3578613",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Predicting Emergency Visits and Hospital Admissions in Radiation and Chemoradiation: Performance of a Pre-Treatment Machine Learning Algorithm on Different Disease Sites in an Internal Validation Cohort",
      "authors": "Hong, JC; Niedzwiecki, D; Palta, M; Tenenbaum, JD",
      "published_date": "November 2018",
      "doi": "10.1016/j.ijrobp.2018.06.168",
      "abstract": "",
      "publication_location": "International Journal of Radiation Oncology, Biology, Physics",
      "link": "http://dx.doi.org/10.1016/j.ijrobp.2018.06.168",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Development of a Machine Learning Methodology to Estimate Lung Stereotactic Body Radiation Therapy Dosimetric Endpoints Based on Patient-Specific Anatomic Features",
      "authors": "Lafata, K; Cai, J; Ren, L; Wu, Q; Hong, JC; Kelsey, CR; Yin, FF",
      "published_date": "October 1, 2016",
      "doi": "",
      "abstract": "",
      "publication_location": "International Journal of Radiation Oncology, Biology, Physics",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000392528800298&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian machine learning on CALGB/SWOG 80405 (Alliance) and PEAK data identify a heterogeneous landscape of clinical predictors of overall survival (OS) in different populations of metastatic colorectal cancer (mCRC).",
      "authors": "Das, R; Ou, F; Washburn, C; Innocenti, F; Nixon, A; Lenz, H; Blanke, C; Niedzwiecki, D; Khalil, I; Harms, B; Venook, A",
      "published_date": "July 2019",
      "doi": "10.1093/annonc/mdz156.019",
      "abstract": "",
      "publication_location": "Ann Oncol",
      "link": "http://dx.doi.org/10.1093/annonc/mdz156.019",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Application of a Graphical Model to Investigate the Utility of Cross-channel Information for Mitigating Reverberation in Cochlear Implants.",
      "authors": "Shahidi, LK; Collins, LM; Mainsah, BO",
      "published_date": "December 2018",
      "doi": "10.1109/ICMLA.2018.00136",
      "abstract": "Individuals with cochlear implants (CIs) experience more difficulty understanding speech in reverberant environ-ments than normal hearing listeners. As a result, recent research has targeted mitigating the effects of late reverberant signal reflections in CIs by using a machine learning approach to detect and delete affected segments in the CI stimulus pattern. Previous work has trained electrode-specific classification models to mitigate late reverberant signal reflections based on features extracted from only the acoustic activity within the electrode of interest. Since adjacent CI electrodes tend to be activated concurrently during speech, we hypothesized that incorporating additional information from the other electrode channels, termed cross-channel information, as features could improve classification performance. Cross-channel information extracted in real-world conditions will likely contain errors that will impact classification performance. To simulate extracting cross-channel information in realistic conditions, we developed a graphical model based on the Ising model to systematically introduce errors to specific types of cross-channel information. The Ising-like model allows us to add errors while maintaining the important geometric information contained in cross-channel information, which is due to the spectro-temporal structure of speech. Results suggest the potential utility of leveraging cross-channel information to improve the performance of the reverberation mitigation algorithm from the baseline channel-based features, even when the cross-channel information contains errors.",
      "publication_location": "Proceedings of the ... International Conference on Machine Learning and Applications. International Conference on Machine Learning and Applications",
      "link": "http://dx.doi.org/10.1109/ICMLA.2018.00136",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Tree-Structured Infinite Sparse Factor Model.",
      "authors": "Zhang, X; Dunson, DB; Carin, L",
      "published_date": "January 2011",
      "doi": "",
      "abstract": "A tree-structured multiplicative gamma process (TMGP) is developed, for inferring the depth of a tree-based factor-analysis model. This new model is coupled with the nested Chinese restaurant process, to nonparametrically infer the depth and width (structure) of the tree. In addition to developing the model, theoretical properties of the TMGP are addressed, and a novel MCMC sampler is developed. The structure of the inferred tree is used to learn relationships between high-dimensional data, and the model is also applied to compressive sensing and interpolation of incomplete images.",
      "publication_location": "Proceedings of the ... International Conference on Machine Learning. International Conference on Machine Learning",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/25279389",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Topic Modeling with Nonparametric Markov Tree.",
      "authors": "Chen, H; Dunson, DB; Carin, L",
      "published_date": "January 2011",
      "doi": "",
      "abstract": "A new hierarchical tree-based topic model is developed, based on nonparametric Bayesian techniques. The model has two unique attributes: (i) a child node in the tree may have more than one parent, with the goal of eliminating redundant sub-topics deep in the tree; and (ii) parsimonious sub-topics are manifested, by removing redundant usage of words at multiple scales. The depth and width of the tree are unbounded within the prior, with a retrospective sampler employed to adaptively infer the appropriate tree size based upon the corpus under study. Excellent quantitative results are manifested on five standard data sets, and the inferred tree structure is also found to be highly interpretable.",
      "publication_location": "Proceedings of the ... International Conference on Machine Learning. International Conference on Machine Learning",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/25279387",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Pharmacophore discovery using the Inductive Logic Programming system PROGOL",
      "authors": "Finn, P; Muggleton, S; Page, D; Srinivasan, A",
      "published_date": "December 1, 1998",
      "doi": "",
      "abstract": "This paper presents a case study of a machine-aided knowledge discovery process within the general area of drug design. Within drug design, the particular problem of pharmacophore discovery is isolated, and the Inductive Logic Programming (ILP) system PROGOL is applied to the problem of identifying potential pharmacophores for ACE inhibition. The case study reported in this paper supports four general lessons for machine learning and knowledge discovery, as well as more specific lessons for pharmacophore discovery, for Inductive Logic Programming, and for ACE inhibition. The general lessons for machine learning and knowledge discovery are as follows. 1. An initial rediscovery step is a useful tool when approaching a new application domain. 2. General machine learning heuristics may fail to match the details of an application domain, but it may be possible to successfully apply a heuristic-based algorithm in spite of the mismatch. 3. A complete search for all plausible hypotheses can provide useful information to a user, although experimentation may be required to choose between competing hypotheses. 4. A declarative knowledge representation facilitates the development and debugging of background knowledge in collaboration with a domain expert, as well as the communication of final results.",
      "publication_location": "Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Reinforcement Learning as Classification: Leveraging Modern Classifiers",
      "authors": "",
      "published_date": "December 1, 2003",
      "doi": "",
      "abstract": "The basic tools of machine learning appear in the inner loop of most reinforcement learning algorithms, typically in the form of Monte Carlo methods or function approximation techniques. To a large extent, however, current reinforcement learning algorithms draw upon machine learning techniques that are at least ten years old and, with a few exceptions, very little has been done to exploit recent advances in classification learning for the purposes of reinforcement learning. We use a variant of approximate policy iteration based on rollouts that allows us to use a pure classification learner, such as a support vector machine (SVM), in the inner loop of the algorithm. We argue that the use of SVMs, particularly in combination with the kernel trick, can make it easier to apply reinforcement learning as an \"out-of-the-box\" technique, without extensive feature engineering. Our approach opens the door to modern classification methods, but does not preclude the use of classical methods. We present experimental results in the pendulum balancing and bicycle riding domains using both SVMs and neural networks for classifiers.",
      "publication_location": "Proceedings, Twentieth International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Report cards for manholes: Eliciting expert feedback for a learning task",
      "authors": "Radeva, A; Rudin, C; Passonneau, R; Isaac, D",
      "published_date": "December 1, 2009",
      "doi": "10.1109/ICMLA.2009.72",
      "abstract": "We present a manhole profiling tool, developed as part of the Columbia/Con Edison machine learning project on manhole event prediction, and discuss its role in evaluating our machine learning model in three important ways: elimination of outliers, elimination of falsely predictive features, and assessment of the quality of the model. The model produces a ranked list of tens of thousands of manholes in Manhattan, where the ranking criterion is vulnerability to serious events such as fires, explosions and smoking manholes. Con Edison set two goals for the model, namely accuracy and intuitiveness, and this tool made it possible for us to address both of these goals. The tool automatically assembles a \"report card or \"profile\" highlighting data associated with a given manhole. Prior to the processing work that underlies the profiling tool, case studies of a single manhole took several days and resulted in an incomplete study; locating manholes such as those we present in this work would have been extremely difficult. The model is currently assisting Con Edison in determining repair priorities for the secondary electrical grid. © 2009 IEEE.",
      "publication_location": "8th International Conference on Machine Learning and Applications, Icmla 2009",
      "link": "http://dx.doi.org/10.1109/ICMLA.2009.72",
      "citations": 5,
      "readership": 10,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Learning optimized risk scores",
      "authors": "Ustun, B; Rudin, C",
      "published_date": "June 1, 2019",
      "doi": "",
      "abstract": "© 2019 Berk Ustun and Cynthia Rudin. Risk scores are simple classification models that let users make quick risk predictions by adding and subtracting a few small numbers. These models are widely used in medicine and criminal justice, but are difficult to learn from data because they need to be calibrated, sparse, use small integer coefficients, and obey application-specific constraints. In this paper, we introduce a machine learning method to learn risk scores. We formulate the risk score problem as a mixed integer nonlinear program, and present a cutting plane algorithm to recover its optimal solution. We improve our algorithm with specialized techniques that generate feasible solutions, narrow the optimality gap, and reduce data-related computation. Our algorithm can train risk scores in a way that scales linearly in the number of samples in a dataset, and that allows practitioners to address application-specific constraints without parameter tuning or post-processing. We benchmark the performance of different methods to learn risk scores on publicly available datasets, comparing risk scores produced by our method to risk scores built using methods that are used in practice. We also discuss the practical benefits of our method through a real-world application where we build a customized risk score for ICU seizure prediction in collaboration with the Massachusetts General Hospital.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning classification models of cognitive conditions from subtle behaviors in the digital Clock Drawing Test",
      "authors": "Souillard-Mandar, W; Davis, R; Rudin, C; Au, R; Libon, DJ; Swenson, R; Price, CC; Lamar, M; Penney, DL",
      "published_date": "March 1, 2016",
      "doi": "10.1007/s10994-015-5529-5",
      "abstract": "© 2015, The Author(s). The Clock Drawing Test—a simple pencil and paper test—has been used for more than 50 years as a screening tool to differentiate normal individuals from those with cognitive impairment, and has proven useful in helping to diagnose cognitive dysfunction associated with neurological disorders such as Alzheimer’s disease, Parkinson’s disease, and other dementias and conditions. We have been administering the test using a digitizing ballpoint pen that reports its position with considerable spatial and temporal precision, making available far more detailed data about the subject’s performance. Using pen stroke data from these drawings categorized by our software, we designed and computed a large collection of features, then explored the tradeoffs in performance and interpretability in classifiers built using a number of different subsets of these features and a variety of different machine learning techniques. We used traditional machine learning methods to build prediction models that achieve high accuracy. We operationalized widely used manual scoring systems so that we could use them as benchmarks for our models. We worked with clinicians to define guidelines for model interpretability, and constructed sparse linear models and rule lists designed to be as easy to use as scoring systems currently used by clinicians, but more accurate. While our models will require additional testing for validation, they offer the possibility of substantial improvement in detecting cognitive impairment earlier than currently possible, a development with considerable potential impact in practice.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-015-5529-5",
      "citations": 34,
      "readership": 105,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Online dictionary learning for sparse coding",
      "authors": "Mairal, J; Bach, F; Ponce, J; Sapiro, G",
      "published_date": "January 1, 2009",
      "doi": "",
      "abstract": "Sparse coding - that is, modelling data vectors as sparse linear combinations of basis elements - is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on learning the basis set, also called dictionary, to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations, which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets.",
      "publication_location": "Proceedings of the 26th International Conference on Machine Learning, Icml 2009",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Unachievable region in precision-recall space and its effect on empirical evaluation",
      "authors": "Boyd, K; Costa, VS; Davis, J; Page, CD",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "Precision-recall (PR) curves and the areas under them are widely used to summarize machine learning results, especially for data sets exhibiting class skew. They are often used analogously to ROC curves and the area under ROC curves. It is known that PR curves vary as class skew changes. What was not recognized before this paper is that there is a region of PR space that is completely unachievable, and the size of this region depends only on the skew. This paper precisely characterizes the size of that region and discusses its implications for empirical evaluation methodology in machine learning. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "LEARNING CONSTRAINED ATOMS",
      "authors": "PAGE, CD; FRISCH, AM",
      "published_date": "January 1, 1991",
      "doi": "",
      "abstract": "",
      "publication_location": "MORGAN KAUFMANN PUB INC",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:A1991BA74J00083&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stochastic spectral descent for restricted boltzmann machines",
      "authors": "Carlson, D; Cevher, V; Carin, L",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "Copyright 2015 by the authors. Restricted Boltzmann Machines (RBMs) are widely used as building blocks for deep learning models. Learning typically proceeds by using stochastic gradient descent, and the gradients are estimated with sampling methods. However, the gradient estimation is a computational bottleneck, so better use of the gradients will speed up the descent algorithm. To this end, we first derive upper bounds on the RBM cost function, then show that descent methods can have natural advantages by operating in the ℓ∞ and Shatten-∞ norm. We introduce a new method called \"Stochastic Spectral Descent\" that updates parameters in the normed space. Empirical results show dramatic improvements over stochastic gradient descent, and have only have a fractional increase on the per-iteration cost.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multiscale dictionary learning: Non-asymptotic bounds and robustness",
      "authors": "",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 Mauro Maggioni, Stanislav Minsker, and Nate Strawn. High-dimensional datasets are well-approximated by low-dimensional structures. Over the past decade, this empirical observation motivated the investigation of detection, measurement, and modeling techniques to exploit these low-dimensional intrinsic structures, yielding numerous implications for high-dimensional statistics, machine learning, and signal processing. Manifold learning (where the low-dimensional structure is a manifold) and dictionary learning (where the low-dimensional structure is the set of sparse linear combinations of vectors from a finite dictionary) are two prominent theoretical and computational frameworks in this area. Despite their ostensible distinction, the recently-introduced Geometric Multi-Resolution Analysis (GMRA) provides a robust, computationally eficient, multiscale procedure for simultaneously learning manifolds and dictionaries. In this work, we prove non-asymptotic probabilistic bounds on the approximation error of GMRA for a rich class of data-generating statistical models that includes \"noisy\" manifolds, thereby establishing the theoretical robustness of the procedure and confirming empirical observations. In particular, if a dataset aggregates near a low-dimensional manifold, our results show that the approximation error of the GMRA is completely independent of the ambient dimension. Our work therefore establishes GMRA as a provably fast algorithm for dictionary learning with approximation and sparsity guarantees. We include several numerical experiments confirming these theoretical results, and our theoretical framework provides new tools for assessing the behavior of manifold learning and dictionary learning procedures on a large class of interesting models.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning probabilistic motion models for mobile robots",
      "authors": "",
      "published_date": "December 1, 2004",
      "doi": "",
      "abstract": "Machine learning methods are often applied to the problem of learning a map from a robot's sensor data, but they are rarely applied to the problem of learning a robot's motion model. The motion model, which can be influenced by robot idiosyncrasies and terrain properties, is a crucial aspect of current algorithms for Simultaneous Localization and Mapping (SLAM). In this paper we concentrate on generating the correct motion model for a robot by applying EM methods in conjunction with a current SLAM algorithm. In contrast to previous calibration approaches, we not only estimate the mean of the motion, but also the interdependencies between motion terms, and the variances in these terms. This can be used to provide a more focused proposal distribution to a particle filter used in a SLAM algorithm, which can reduce the resources needed for localization while decreasing the chance of losing track of the robot's position. We validate this approach by recovering a good motion model despite initialization with a poor one. Further experiments validate the generality of the learned model in similar circumstances.",
      "publication_location": "Proceedings, Twenty First International Conference on Machine Learning, Icml 2004",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Communication complexity as a lower bound for learning in games",
      "authors": "Conitzer, V; Sandholm, T",
      "published_date": "December 1, 2004",
      "doi": "",
      "abstract": "A fast-growing body of research in the AI and machine learning communities addresses learning in games, where there are multiple learners with different interests. This research adds to more established research on learning in games conducted in economics. In part because of a clash of fields, there are widely varying requirements on learning algorithms in this domain. The goal of this paper is to demonstrate how communication complexity can be used as a lower bound on the required learning time or cost. Because this lower bound does not assume any requirements on the learning algorithm, it is universal, applying under any set of requirements on the learning algorithm. We characterize exactly the communication complexity of various solution concepts from game theory, namely Nash equilibrium, iterated dominant strategies (both strict and weak), and backwards induction. This gives the tighest lower bounds on learning in games that can be obtained with this method.",
      "publication_location": "Proceedings, Twenty First International Conference on Machine Learning, Icml 2004",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "New algorithms for learning incoherent and overcomplete dictionaries",
      "authors": "Arora, S; Ge, R; Moitra, A",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "© 2014 S. Arora, R. Ge  &  A. Moitra. In sparse recovery we are given a matrix A ∈ R",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A Bayesian framework for learning rule sets for interpretable classification",
      "authors": "Wang, T; Rudin, C; Doshi-Velez, F; Liu, Y; Klampfl, E; MacNeille, P",
      "published_date": "August 1, 2017",
      "doi": "",
      "abstract": "©2017 Tong Wang, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. We present a machine learning algorithm for building classifiers that are comprised of a small number of short rules. These are restricted disjunctive normal form models. An example of a classifier of this form is as follows: If X satisfies (condition A AND condition B) OR (condition C) OR · · · , then Y = 1. Models of this form have the advantage of being interpretable to human experts since they produce a set of rules that concisely describe a specific class. We present two probabilistic models with prior parameters that the user can set to encourage the model to have a desired size and shape, to conform with a domain-specific definition of interpretability. We provide a scalable MAP inference approach and develop theoretical bounds to reduce computation by iteratively pruning the search space. We apply our method (Bayesian Rule Sets – BRS) to characterize and predict user behavior with respect to in-vehicle context-aware personalized recommender systems. Our method has a major advantage over classical associative classification methods and decision trees in that it does not greedily grow the model.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning theory analysis for association rules and sequential event prediction",
      "authors": "Rudin, C; Letham, B; Madigan, D",
      "published_date": "November 1, 2013",
      "doi": "",
      "abstract": "We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called \"sequential event prediction.\" In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer's online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the \"cold start\" problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classification, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an \"adjusted confidence\" measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. © 2013 Cynthia Rudin, Benjamin Letham and David Madigan.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "JointGAN: Multi-domain joint distribution learning with generative adversarial nets",
      "authors": "Pu, Y; Dai, S; Gan, Z; Wang, W; Wang, G; Zhang, Y; Henao, R; Carin, L",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "©35th International Conference on Machine Learning, ICML 2018.All Rights Reserved. A new generative adversarial network is developed for joint distribution matching. Distinct from most existing approaches, that only learn conditional distributions, the proposed model aims to learn a joint distribution of multiple random variables (domains). This is achieved by learning to sample from conditional distributions between the domains, while simultaneously learning to sample from the marginals of each individual domain. The proposed framework consists of multiple generators and a single softmax-based critic, all jointly trained via adversarial learning. From a simple noise source, the proposed framework allows synthesis of draws from the marginals, conditional draws given observations from a subset of random variables, or complete draws from the full joint distribution. Most examples considered are for joint analysis of two domains, with examples for three domains also presented.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning registered point processes from idiosyncratic observations",
      "authors": "Xu, H; Carin, L; Zha, H",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 35th International Conference on Machine Learning, ICML 2018.All Rights Reserved. A parametric point process model is developed, with modeling based on the assumption that sequential observations often share latent phenomena, while also possessing idiosyncratic effects. An alternating optimization method is proposed to learn a \"registered\" point process that accounts for shared structure, as well as \"warping\" functions that characterize idiosyncratic aspects of each observed sequence. Under reasonable constraints, in each iteration we update the sample-specific warping functions by solving a set of constrained nonlinear programming problems in parallel, and update the model by maximum likelihood estimation. The justifiability, complexity and robustness of the proposed method are investigated in detail, and the influence of sequence stitching on the learning results is discussed empirically. Experiments on both synthetic and real-world data demonstrate that the method yields explainable point process models, achieving encouraging results compared to state-of-the-art methods.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Online learning for matrix factorization and sparse coding",
      "authors": "Mairal, J; Bach, F; Ponce, J; Sapiro, G",
      "published_date": "February 22, 2010",
      "doi": "",
      "abstract": "Sparse coding-that is, modelling data vectors as sparse linear combinations of basis elements-is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on the large-scale matrix factorization problem that consists of learning the basis set in order to adapt it to specific data. Variations of this problem include dictionary learning in signal processing, non-negative matrix factorization and sparse principal component analysis. In this paper, we propose to address these tasks with a new online optimization algorithm, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various matrix factorization formulations, making it suitable for a wide range of learning problems. A proof of convergence is presented, along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large data sets. © 2010 Julien Mairal, Francis Bach, Jean Ponce and Guillermo Sapiro.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Adversarially learned representations for information obfuscation and inference",
      "authors": "Bertran, M; Martinez, N; Papadaki, A; Qiu, Q; Rodrigues, M; Reeves, G; Sapiro, G",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 36th International Conference on Machine Learning, ICML 2019. All rights reserved. Data collection and sharing are pervasive aspects of modern society. This process can either be voluntary, as in the case of a person taking a facial image to unlock his/her phone, or incidental, such as traffic cameras collecting videos on pedestrians. An undesirable side effect of these processes is that shared data can carry information about attributes that users might consider as sensitive, even when such information is of limited use for the task. It is therefore desirable for both data collectors and users to design procedures that minimize sensitive information leakage. Balancing the competing objectives of providing meaningful individualized service levels and inference while obfuscating sensitive information is still an open problem. In this work, we take an information theoretic approach that is implemented as an unconstrained adversarial game between Deep Neural Networks in a principled, data-driven manner. This approach enables us to learn domain-preserving stochastic transformations that maintain performance on existing algorithms while minimizing sensitive information leakage.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning parameterized skills",
      "authors": "Da Silva, BC; Konidaris, G; Barto, AG",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "We introduce a method for constructing skills capable of solving tasks drawn from a distribution of parameterized reinforcement learning problems. The method draws example tasks from a distribution of interest and uses the corresponding learned policies to estimate the topology of the lower-dimensional piecewise-smooth manifold on which the skill policies lie. This manifold models how policy parameters change as task parameters vary. The method identifies the number of charts that compose the manifold and then applies non-linear regression in each chart to construct a parameterized skill by predicting policy parameters from task parameters. We evaluate our method on an underactuated simulated robotic arm tasked with learning to accurately throw darts at a parameterized target location. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning transformations for clustering and classification",
      "authors": "Qiu, Q; Sapiro, G",
      "published_date": "February 1, 2015",
      "doi": "",
      "abstract": "©2015 Qiang Qiu and Guillermo Sapiro. A low-rank transformation learning framework for subspace clustering and classification is proposed here. Many high-dimensional data, such as face images and motion sequences, approximately lie in a union of low-dimensional subspaces. The corresponding subspace clustering problem has been extensively studied in the literature to partition such high-dimensional data into clusters corresponding to their underlying low-dimensional subspaces. Low-dimensional intrinsic structures are often violated for real-world observations, as they can be corrupted by errors or deviate from ideal models. We propose to address this by learning a linear transformation on subspaces using nuclear norm as the modeling and optimization criteria. The learned linear transformation restores a low-rank structure for data from the same subspace, and, at the same time, forces a maximally separated structure for data from different subspaces. In this way, we reduce variations within the subspaces, and increase separation between the subspaces for a more robust subspace clustering. This proposed learned robust subspace clustering framework significantly enhances the performance of existing subspace clustering methods. Basic theoretical results presented here help to further support the underlying framework. To exploit the low-rank structures of the transformed subspaces, we further introduce a fast subspace clustering technique, which efficiently combines robust PCA with sparse modeling. When class labels are present at the training stage, we show this low-rank transformation framework also significantly enhances classification performance. Extensive experiments using public data sets are presented, showing that the proposed approach significantly outperforms state-of-the-art methods for subspace clustering and classification. The learned low cost transform is also applicable to other classification frameworks.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A Deep Learning Approach to Unsupervised Ensemble Learning",
      "authors": "Cheng, X; Shaham, U; Dror, O; Jaffe, A; Nadler, B; Chang, J; Kluger, Y",
      "published_date": "June 2016",
      "doi": "",
      "abstract": "",
      "publication_location": "PMLR",
      "link": "http://proceedings.mlr.press/v48/shaham16.html",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "“The human body is a black box”: Supporting clinical decision-making with deep learning",
      "authors": "",
      "published_date": "January 27, 2020",
      "doi": "10.1145/3351095.3372827",
      "abstract": "© 2020 Copyright is held by the owner/author(s). ACM Machine learning technologies are increasingly developed for use in healthcare. While research communities have focused on creating state-of-the-art models, there has been less focus on real world implementation and the associated challenges to fairness, transparency, and accountability that come from actual, situated use. Serious questions remain underexamined regarding how to ethically build models, interpret and explain model output, recognize and account for biases, and minimize disruptions to professional expertise and work cultures. We address this gap in the literature and provide a detailed case study covering the development, implementation, and evaluation of Sepsis Watch, a machine learning-driven tool that assists hospital clinicians in the early diagnosis and treatment of sepsis. Sepsis is a severe infection that can lead to organ failure or death if not treated in time and is the leading cause of inpatient deaths in US hospitals. We, the team that developed and evaluated the tool, discuss our conceptualization of the tool not as a model deployed in the world but instead as a socio-technical system requiring integration into existing social and professional contexts. Rather than focusing solely on model interpretability to ensure fair and accountable machine learning, we point toward four key values and practices that should be considered when developing machine learning to support clinical decision-making: rigorously define the problem in context, build relationships with stakeholders, respect professional discretion, and create ongoing feedback loops with stakeholders. Our work has significant implications for future research regarding mechanisms of institutional accountability and considerations for responsibly designing machine learning systems. Our work underscores the limits of model interpretability as a solution to ensure transparency, accuracy, and accountability in practice. Instead, our work demonstrates other means and goals to achieve FATML values in design and in practice.",
      "publication_location": "Fat* 2020   Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",
      "link": "http://dx.doi.org/10.1145/3351095.3372827",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 21,
      "news_mentions": ""
    },
    {
      "title": "Sequential event prediction with association rules",
      "authors": "Rudin, C; Letham, B; Salleb-Aouissi, A; Kogan, E; Madigan, D",
      "published_date": "January 1, 2011",
      "doi": "",
      "abstract": "We consider a supervised learning problem in which data are revealed sequentially and the goal is to determine what will next be revealed. In the context of this problem, algorithms based on association rules have a distinct advantage over classical statistical and machine learning methods; however, there has not previously been a theoretical foundation established for using association rules in supervised learning. We present two simple algorithms that incorporate association rules, and provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an \"adjusted confidence\" measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. © 2011 C. Rudin, B. Letham, A. Salleb-Aouissi, E. Kogan & D. Madigan.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Revisiting the softmax bellman operator: New benefits and new perspective",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 2019 International Machine Learning Society (IMLS). The impact of softmax on the value function itself in reinforcement learning (RL) is often viewed as problematic because it leads to sub-optimal value (or Q) functions and interferes with the contraction properties of the Bellman operator. Surprisingly, despite these concerns, and independent of its effect on exploration, the softmax Bellman operator when combined with Deep Q-learning, leads to Q-functions with superior policies in practice, even outperforming its double Q-learning counterpart. To better understand how and why this occurs, wc revisit theoretical properties of the softmax Bellman operator, and prove that (i) it converges to the standard Bellman operator exponentially fast in the inverse temperature parameter, and (ii) the distance of its Q function from the optimal one can be bounded. These alone do not explain its superior performance, so we also show that the softmax operator can reduce the over-estimation error, which may give some insight into why a sub-optimal operator leads to better performance in the presence of value function approximation. A comparison among different Bellman operators is then presented, showing the trade-offs when selecting them.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A multitask point process predictive model",
      "authors": "Lian, W; Henao, R; Rao, V; Lucas, J; Carin, L",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© Copyright 2015 by International Machine Learning Society (IMLS). All rights reserved. Point process data are commonly observed in fields like healthcare and the social sciences. Designing predictive models for such event streams is an under-explored problem, due to often scarce training data. In this work we propose a multitask point process model, leveraging information from all tasks via a hierarchical Gaussian process (GP). Nonparametric learning functions implemented by a GP, which map from past events to future rates, allow analysis of flexible arrival patterns. To facilitate efficient inference, we propose a sparse construction for this hierarchical model, and derive a variational Bayes method for learning and inference. Experimental results are shown on both synthetic data and as well as real electronic health-records data.",
      "publication_location": "32nd International Conference on Machine Learning, Icml 2015",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning coordinate covariances via gradients",
      "authors": "",
      "published_date": "March 1, 2006",
      "doi": "",
      "abstract": "We introduce an algorithm that learns gradients from samples in the supervised learning framework. An error analysis is given for the convergence of the gradient estimated by the algorithm to the true gradient. The utility of the algorithm for the problem of variable selection as well as determining variable covariance is illustrated on simulated data as well as two gene expression data sets. For square loss we provide a very efficient implementation with respect to both memory and time.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multi-instance tree learning",
      "authors": "Blockeel, H; Page, D; Srinivasan, A",
      "published_date": "December 1, 2005",
      "doi": "10.1145/1102351.1102359",
      "abstract": "We introduce a novel algorithm for decision tree learning in the multi-instance setting as originally defined by Dietterich et al. It differs from existing multi-instance tree learners in a few crucial, well-motivated details. Experiments on synthetic and real-life datasets confirm the beneficial effect of these differences and show that the resulting system out-performs the existing multi-instance decision tree learners.",
      "publication_location": "Icml 2005   Proceedings of the 22nd International Conference on Machine Learning",
      "link": "http://dx.doi.org/10.1145/1102351.1102359",
      "citations": 48,
      "readership": 43,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Bayesian learning of dynamic multilayer networks",
      "authors": "Durante, D; Mukherjee, N; Steorts, RC",
      "published_date": "April 1, 2017",
      "doi": "",
      "abstract": "© 2017 Durante, Mukherjee and Steorts. A plethora of networks is being collected in a growing number of fields, including disease transmission, international relations, social interactions, and others. As data streams continue to grow, the complexity associated with these highly multidimensional connectivity data presents novel challenges. In this paper, we focus on the time-varying interconnections among a set of actors in multiple contexts, called layers. Current literature lacks flexible statistical models for dynamic multilayer networks, which can enhance quality in inference and prediction by efficiently borrowing information within each network, across time, and between layers. Motivated by this gap, we develop a Bayesian nonparametric model leveraging latent space representations. Our formulation characterizes the edge probabilities as a function of shared and layer-specific actors positions in a latent space, with these positions changing in time via Gaussian processes. This representation facilitates dimensionality reduction and incorporates different sources of information in the observed data. In addition, we obtain tractable procedures for posterior computation, inference, and prediction. We provide theoretical results on the flexibility of our model. Our methods are tested on simulations and infection studies monitoring dynamic face-to-face contacts among individuals in multiple days, where we perform better than current methods in inference and prediction. Keywords: Dynamic multilayer network, edge prediction, face-to-face contact network, Gaussian process, latent space model",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian learning of joint distributions of objects",
      "authors": "Banerjee, A; Murray, J; Dunson, DB",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "Copyright 2013 by the authors. There is increasing interest in broad application areas in defining flexible joint models for data having a variety of measurement scales, while also allowing data of complex types, such as functions, images and documents. We consider a general framework for nonparametric Bayes joint modeling through mixture models that incorporate dependence across data types through a joint mixing measure. The mixing measure is assigned a novel infinite tensor factorization (ITF) prior that allows flexible dependence in cluster allocation across data types. The ITF prior is formulated as a tensor product of stick-breaking processes. Focusing on a convenient special case corresponding to a Parafac factorization, we provide basic theory justifying the flexibility of the proposed prior and resulting asymptotic properties. Focusing on ITF mixtures of product kernels, we develop a new Gibbs sampling algorithm for routine implementation relying on slice sampling. The methods are compared with alternative joint mixture models based on Dirichlet processes and related approaches through simulations and real data applications.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Active learning of parameterized skills",
      "authors": "Da Silva, BC; Konidaris, G; Barto, A",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Copyright 2014 by the author(s). We introduce a method for actively learning parameterized skills. Parameterized skills are flexible behaviors that can solve any task drawn from a distribution of parameterized reinforcement learning problems. Approaches to learning such skills have been proposed, but limited attention has been given to identifying which training tasks allow for rapid skill acquisition. We construct a non-parametric Bayesian model of skill performance and derive analytical expressions for a novel acquisition criterion capable of identifying tasks that maximize expected improvement in skill performance. We also introduce a spatiotemporal kernel tailored for non-stationary skill performance models. The proposed method is agnostic to policy and skill representation and scales independently of task dimensionality. We evaluate it on a non-linear simulated catapult control problem over arbitrarily mountainous terrains.",
      "publication_location": "31st International Conference on Machine Learning, Icml 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Provable bounds for learning some deep representations",
      "authors": "Arora, S; Bhaskara, A; Ge, R; Ma, T",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "2014 We give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others. Our generative model is an n node multilayer network that has degree at most nγ for some γ < 1 and each edge has a random edge weight in [-1,1]. Our algorithm learns almost all networks in this class with polynomial running time. The sample complexity is quadratic or cubic depending upon the details of the model. The algorithm uses layerwise learning. It is based upon a novel idea of observing correlations among features and using these to infer the underlying edge structure via a global graph recovery procedure. The analysis of the algorithm reveals interesting structure of neural nets with random edge weights.",
      "publication_location": "31st International Conference on Machine Learning, Icml 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Regularized feature selection in reinforcement learning",
      "authors": "Wookey, DS; Konidaris, GD",
      "published_date": "September 17, 2015",
      "doi": "10.1007/s10994-015-5518-8",
      "abstract": "© 2015, The Author(s). We introduce feature regularization during feature selection for value function approximation. Feature regularization introduces a prior into the selection process, improving function approximation accuracy and reducing overfitting. We show that the smoothness prior is effective in the incremental feature selection setting and present closed-form smoothness regularizers for the Fourier and RBF bases. We present two methods for feature regularization which extend the temporal difference orthogonal matching pursuit (OMP-TD) algorithm and demonstrate the effectiveness of the smoothness prior; smooth Tikhonov OMP-TD and smoothness scaled OMP-TD. We compare these methods against OMP-TD, regularized OMP-TD and least squares TD with random projections, across six benchmark domains using two different types of basis functions.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-015-5518-8",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A rate-distortion framework for supervised learning",
      "authors": "Nokleby, M; Beirami, A; Calderbank, R",
      "published_date": "November 10, 2015",
      "doi": "10.1109/MLSP.2015.7324319",
      "abstract": "© 2015 IEEE. An information-theoretic framework is presented for bounding the number of samples needed for supervised learning in a parametric Bayesian setting. This framework is inspired by an analogy with rate-distortion theory, which characterizes tradeoffs in the lossy compression of random sources. In a parametric Bayesian environment, the maximum a posteriori classifier can be viewed as a random function of the model parameters. Labeled training data can be viewed as a finite-rate encoding of that source, and the excess loss due to using the learned classifier instead of the MAP classifier can be viewed as distortion. A strict bound on the loss-measured in terms of the expected total variation-is derived, providing a minimum number of training samples needed to drive the expected total variation to within a specified tolerance. The tightness of this bound is demonstrated on the classification of Gaus-sians, for which one can derive closed-form expressions for the bound.",
      "publication_location": "Ieee International Workshop on Machine Learning for Signal Processing, Mlsp",
      "link": "http://dx.doi.org/10.1109/MLSP.2015.7324319",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning efficient structured sparse models",
      "authors": "Sprechmann, P; Bronstein, A; Sapiro, G",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "We present a comprehensive framework for structured sparse coding and modeling extending the recent ideas of using learnable fast regressors to approximate exact sparse codes. For this purpose, we propose an efficient feed forward architecture derived from the iteration of the block-coordinate algorithm. This architecture approximates the exact structured sparse codes with a fraction of the complexity of the standard optimization methods. We also show that by using different training objective functions, the proposed learnable sparse encoders are not only restricted to be approximants of the exact sparse code for a pre-given dictionary, but can be rather used as full-featured sparse encoders or even modelers. A simple implementation shows several orders of magnitude speedup compared to the state-of-the-art exact optimization algorithms at minimal performance degradation, making the proposed framework suitable for real time and large-scale applications. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "On the integration of topic modeling and dictionary learning",
      "authors": "Li, L; Zhou, M; Sapiro, G; Carin, L",
      "published_date": "October 7, 2011",
      "doi": "",
      "abstract": "A new nonparametric Bayesian model is developed to integrate dictionary learning and topic model into a unified framework. The model is employed to analyze partially annotated images, with the dictionary learning performed directly on image patches. Efficient inference is performed with a Gibbs-slice sampler, and encouraging results are reported on widely used datasets. Copyright 2011 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 28th International Conference on Machine Learning, Icml 2011",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Scalable deep Poisson factor analysis for topic modeling",
      "authors": "Gan, Z; Chen, C; Henao, R; Carlson, D; Carin, L",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© Copyright 2015 by International Machine Learning Society (IMLS). All rights reserved. A new framework for topic modeling is developed, based on deep graphical models, where interactions between topics are inferred through deep latent binary hierarchies. The proposed multi-layer model employs a deep sigmoid belief network or restricted Boltzmann machine, the bottom binary layer of which selects topics for use in a Poisson factor analysis model. Under this setting, topics live on the bottom layer of the model, while the deep specification serves as a flexible prior for revealing topic structure. Scalable inference algorithms are derived by applying Bayesian conditional density filtering algorithm, in addition to extending recently proposed work on stochastic gradient thermostats. Experimental results on several corpora show that the proposed approach readily handles very large collections of text documents, infers structured topic representations, and obtains superior test perplexities when compared with related models.",
      "publication_location": "32nd International Conference on Machine Learning, Icml 2015",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Nonlinear information-theoretic compressive measurement design",
      "authors": "Wang, L; Razi, A; Dias Rodrigues, M; Calderbank, R; Carin, L",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Copyright © (2014) by the International Machine Learning Society (IMLS) All rights reserved. We investigate design of general nonlinear functions for mapping high-dimensional data into a lower-dimensional (compressive) space. The nonlinear measurements are assumed contaminated by additive Gaussian noise. Depending on the application, we are either interested in recovering the high-dimensional data from the nonlinear compressive measurements, or performing classification directly based on these measurements. The latter case corresponds to classification based on nonlinearly constituted and noisy features. The nonlinear measurement functions are designed based on constrained mutual- information optimization. New analytic results are developed for the gradient of mutual information in this setting, for arbitrary input-signal statistics. We make connections to kernel-based methods, such as the support vector machine. Encouraging results are presented on multiple datasets, for both signal recovery and classification. The nonlinear approach is shown to be particularly valuable in high-noise scenarios.",
      "publication_location": "31st International Conference on Machine Learning, Icml 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Temporal poisson square root graphical models",
      "authors": "",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 35th International Conference on Machine Learning, ICML 2018. All rights reserved. We propose temporal Poisson square root graphical models (TPSQRs), a generalization of Poisson square root graphical models (PSQRs) specifically designed for modeling longitudinal event data. By estimating the temporal relationships for all possible pairs of event types, TPSQRs can offer a holistic perspective about whether the occurrences of any given event type could excite or inhibit any other type. A TPSQR is learned by estimating a collection of interrelated PSQRs that share the same template parameterization. These PSQRs are estimated jointly in a pseudo-Jikelihood fashion, where Poisson pseudo-likelihood is used to approximate the original more computationally- intensive pseudo-likelihood problem stemming from PSQRs. Theoretically, we demonstrate that under mild assumptions, the Poisson pseudo- likelihood approximation is sparsistent for recovering the underlying PSQR. Empirically, we learn TPSQRs from Marshfield Clinic electronic health records (EHRs) with millions of drug prescription and condition diagnosis events, for adverse drug reaction (ADR) detection. Experimental results demonstrate that the learned TPSQRs can recover ADR signals from the EHR effectively and efficiently.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Regularization on graphs with function-adapted diffusion processes",
      "authors": "",
      "published_date": "August 1, 2008",
      "doi": "",
      "abstract": "Harmonic analysis and diffusion on discrete data has been shown to lead to state-of-the-art algorithms for machine learning tasks, especially in the context of semi-supervised and transductive learning. The success of these algorithms rests on the assumption that the function(s) to be studied (learned, interpolated, etc.) are smooth with respect to the geometry of the data. In this paper we present a method for modifying the given geometry so the function(s) to be studied are smoother with respect to the modified geometry, and thus more amenable to treatment using harmonic analysis methods. Among the many possible applications, we consider the problems of image denoising and transductive classification. In both settings, our approach improves on standard diffusion based methods.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "How to escape saddle points efficiently",
      "authors": "Jin, C; Ge, R; Netrapalli, P; Kakade, SM; Jordan, MI",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© Copyright 2017 by the author(s). This paper shows that a perturbed form of gradient descent converges to a second-order stationary point in a number iterations which depends only poly-logarithmically on dimension (i.e., it is almost \"dimension-free\"). The convergence rate of this procedure matches the well-known convergence rate of gradient descent to first-order stationary points, up to log factors. When all saddle points are non-degenerate, all second-order stationary points are local minima, and our result thus shows that perturbed gradient descent can escape saddle points almost for free. Our results can be directly applied to many machine learning applications, including deep learning. As a particular concrete example of such an application, we show that our results can be used directly to establish sharp global convergence rates for matrix factorization. Our results rely on a novel characterization of the geometry around saddle points, which may be of independent interest to the non-convex optimization community.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator",
      "authors": "Fazel, M; Ge, R; Kakade, SM; Mesbahi, M",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 35th International Conference on Machine Learning, ICML 2018. All rights reserved. Direct policy gradient methods for reinforcement learning and continuous control problems arc a popular approach for a variety of reasons: 1) they are easy to implement without explicit knowledge of the underlying model, 2) they are an \"end- to-end\" approach, directly optimizing the performance metric of interest, 3) they inherently allow for richly parameterized policies. A notable drawback is that even in the most basic continuous control problem (that of linear quadratic regulators), these methods must solve a non-convex optimization problem, where little is understood about their efficiency from both computational and statistical perspectives. In contrast, system identification and model based planning in opti- : Mal control theory have a much more solid theo- ! retical footing, where much is known with regards to their computational and statistical properties. , This work bridges this gap showing that (model ; free) policy gradient methods globally converge to the optimal solution and are efficient (polynomi- ' ally so in relevant problem dependent quantities) : With regards to their sample and computational complexities.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Adversarial time-to-event modeling",
      "authors": "Chapfuwa, P; Tao, C; Li, C; Page, C; Goldstein, B; Carin, L; Henao, R",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 by the Authors. All rights reserved. Modern health data science applications leverage abundant molecular and electronic health data; providing opportunities for machine learning to build statistical models to support clinical practice. Time-to-event analysis, also called survival analysis, stands as one of the most representative examples of such statistical models. We present a deep-network-based approach that leverages ad-versarial learning to address a key challenge in modern time-to-event modeling: nonparametric estimation of event-time distributions. We also introduce a principled cost function to exploit in-formation from censored events (events that occur subsequent to the observation window). Unlike most time-to-event models, we focus on the estimation of time-to-event distributions, rather than time ordering. We validate our model on both benchmark and real datasets, demonstrating that the proposed formulation yields significant performance gains relative to a parametric alternative, which we also propose.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "DCFNet: Deep Neural Network with Decomposed Convolutional Filters",
      "authors": "Qiu, Q; Cheng, X; Calderbank, R; Sapiro, G",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "©35th International Conference on Machine Learning, ICML 2018.All Rights Reserved. Filters in a Convolutional Neural Network (CNN) contain model parameters learned from enormous amounts of data. In this paper, we suggest to decompose convolutional filters in CNN as a truncated expansion with pre-fixed bases, namely the Decomposed Convolutional Filters network (DCFNet), where the expansion coefficients remain learned from data. Such a structure not only reduces the number of trainable parameters and computation, but also imposes filter regularity by bases truncation. Through extensive experiments, we consistently observe that DCFNet maintains accuracy for image classification tasks with a significant reduction of model parameters, particularly with Fourier-Bessel (FB) bases, and even with random bases. Theoretically, we analyze the representation stability of DCFNet with respect to input variations, and prove representation stability under generic assumptions on the expansion coefficients. The analysis is consistent with the empirical observations.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "https://hdl.handle.net/10161/17837",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Online algorithms for rent-or-buy with expert advice",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "Copyright © 2019 ASME We study the use of predictions by multiple experts (such as machine learning algorithms) to improve the performance of online algorithms. In particular, we consider the classical rcnt-or-buy problem (also called ski rental), and obtain algorithms that provably improve their performance over the adversarial scenario by using these predictions. We also prove matching lower bounds to show that our algorithms are the best possible, and perform experiments to empirically validate their performance in practice.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "ILP: A short look back and a longer look forward",
      "authors": "Page, D; Srinivasan, A",
      "published_date": "May 15, 2004",
      "doi": "10.1162/153244304773936009",
      "abstract": "Inductive logic programming (ILP) is built on a foundation laid by research in machine learning and computational logic. Armed with this strong foundation, ILP has been applied to important and interesting problems in the life sciences, engineering and the arts. This paper begins by briefly reviewing some example applications, in order to illustrate the benefits of ILP. In turn, the applications have brought into focus the need for more research into specific topics. We enumerate and elaborate five of these: (1) novel search methods; (2) incorporation of explicit probabilities; (3) incorporation of special-purpose reasoners; (4) parallel execution using commodity components; and (5) enhanced human interaction. It is our hypothesis that progress in each of these areas can greatly improve the contributions that can be made with ILP; and that, with assistance from research workers in other areas, significant progress in each of these areas is possible.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "http://dx.doi.org/10.1162/153244304773936009",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multiple testing under dependence via semiparametric graphical models",
      "authors": "Liu, J; Zhang, C; Burnside, E; Page, D",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Copyright © (2014) by the International Machine Learning Society (IMLS) All rights reserved. It has been shown that graphical models can be used to leverage the dependence in large- scale multiple testing problems with significantly improved performance (Sun & Cai, 2009; Liu et al., 2012). These graphical models are fully parametric and require that we know the pa-rameterization of f1 - the density function of the test statistic under the alternative hypothesis. However in practice, f1 is often heterogeneous, and cannot be estimated with a simple parametric distribution. We propose a novel semiparametric approach for multiple testing under dependence, which estimates f1 adaptively. This semiparametric approach exactly generalizes the local FDR procedure (Efron et al., 2001) and connects with the BH procedure (Benjamini & Hochberg, 1995). A variety of simulations show that our semiparametric approach outperforms classical procedures which assume independence and the parametric approaches which capture dependence.",
      "publication_location": "31st International Conference on Machine Learning, Icml 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "When samples are strategically selected",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 36th International Conference on Machine Learning, ICML 2019. All rights reserved. In standard classification problems, the assumption is that the entity making the decision (the principal) has access to all the samples. However, in many contexts, she either docs not have direct access to the samples, or can inspect only a limited set of samples and does not know which are the most relevant ones. In such cases, she must rely on another party (the agent) to either provide the samples or point out the most relevant ones. If the agent has a different objective, then the principal cannot trust the submitted samples to be representative. She must set a policy for how she makes decisions, keeping in mind the agent's incentives. In this paper, we introduce a theoretical framework for this problem and provide key structural and computational results.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Understanding and accelerating particle-based variational inference",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 36th International Conference on Machine Learning, ICML 2019. All rights reserved. Particle-based variational inference methods (ParVIs) have gained attention in the Bayesian inference literature, for their capacity to yield flexible and accurate approximations. We explore ParVIs from the perspective of Wasscrstcin gradient flows, and make both theoretical and practical contributions. We unify various finite-particle approximations that existing ParVIs use, and recognize that the approximation is essentially a compulsory smoothing treatment, in either of two equivalent forms. This novel understanding reveals the assumptions and relations of existing ParVIs, and also inspires new ParVIs. We propose an acceleration framework and a principled bandwidth-selection method for general ParVIs; these are based on the developed theory and leverage the geometry of the Wasscrstcin space. Experimental results show the improved convergence by the acceleration framework and enhanced sample accuracy by the bandwidth-selection method.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Characterizing the function space for bayesian kernel models",
      "authors": "Pillai, NS; Wu, Q; Liang, F; Mukherjee, S; Wolpert, RL",
      "published_date": "August 1, 2007",
      "doi": "",
      "abstract": "Kernel methods have been very popular in the machine learning literature in the last ten years, mainly in the context of Tikhonov regularization algorithms. In this paper we study a coherent Bayesian kernel model based on an integral operator defined as the convolution of a kernel with a signed measure. Priors on the random signed measures correspond to prior distributions on the functions mapped by the integral operator. We study several classes of signed measures and their image mapped by the integral operator. In particular, we identify a general class of measures whose image is dense in the reproducing kernel Hilbert space (RKHS) induced by the kernel. A consequence of this result is a function theoretic foundation for using non-parametric prior specifications in Bayesian modeling, such as Gaussian process and Dirichlet process prior distributions. We discuss the construction of priors on spaces of signed measures using Gaussian and Levy processes, with the Dirichlet processes being a special case the latter. Computational issues involved with sampling from the posterior distribution are outlined for a univariate regression and a high dimensional classification problem.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Variational annealing of GANs: A Langevin perspective",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 36th International Conference on Machine Learning, ICML 2019. All rights reserved. The generative adversarial network (GAN) has received considerable attention recently as a model for data synthesis, without an explicit specification of a likelihood function. There has been commensurate interest in leveraging likelihood estimates to improve GAN training. To enrich the understanding of this fast-growing yet almost exclusively heuristic-driven subject, we elucidate the theoretical roots of some of the empirical attempts to stabilize and improve GAN training with the introduction of likelihoods. We highlight new insights from variational theory of diffusion processes to derive a likelihood-based regularizing scheme for GAN training, and present a novel approach to train GANs with an unnormalized distribution instead of empirical samples. To substantiate our claims, we provide experimental evidence on how our theoretically-inspired new algorithms improve upon current practice.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Weighted Classification Cascades for Optimizing Discovery Significance in the HiggsML Challenge",
      "authors": "Mackey, L; Bryan, J; Mo, MY",
      "published_date": "December 13, 2015",
      "doi": "",
      "abstract": "We introduce a minorization-maximization approach to optimizing common measures of discovery significance in high energy physics. The approach alternates between solving a weighted binary classification problem and updating class weights in a simple, closed-form manner. Moreover, an argument based on convex duality shows that an improvement in weighted classification error on any round yields a commensurate improvement in discovery significance. We complement our derivation with experimental results from the 2014 Higgs boson machine learning challenge.",
      "publication_location": "PMLR",
      "link": "http://proceedings.mlr.press/v42/mack14.html",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian watermark attacks",
      "authors": "Shterev, ID; Dunson, DB",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "This paper presents an application of statistical machine learning to the field of water-marking. We propose a new attack model on additive spread-spectrum watermarking systems. The proposed attack is based on Bayesian statistics. We consider the scenario in which a watermark signal is repeatedly embedded in specific, possibly chosen based on a secret message bitstream, segments (signals) of the host data. The host signal can represent a patch of pixels from an image or a video frame. We propose a probabilistic model that infers the embedded message bit-stream and watermark signal, directly from the watermarked data, without access to the decoder. We develop an efficient Markov chain Monte Carlo sampler for updating the model parameters from their conjugate full conditional posteriors. We also provide a variational Bayesian solution, which further increases the convergence speed of the algorithm. Experiments with synthetic and real image signals demonstrate that the attack model is able to correctly infer a large part of the message bitstream and obtain a very accurate estimate of the watermark signal. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Proportionally fair clustering",
      "authors": "Chen, X; Fain, B; Lyu, L; Munagala, K",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 2019 by the Author(S). We extend the fair machine learning literature by considering the problem of proportional centroid clustering in a metric context. For clustering n points with k centers, we define fairness as proportionality to mean that any n/k points are entitled to form their own cluster if there is another center that is closer in distance for all n/k points. We seek clustering solutions to which there are no such justified complaints from any subsets of agents, without assuming any a priori notion of protected subsets. We present and analyze algorithms to efficiently compute, optimize, and audit proportional solutions. We conclude with an empirical examination of the tradeoff between proportional solutions and the k-means objective.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Data-driven components in a model of inner-shelf sorted bedforms: A new hybrid model",
      "authors": "Goldstein, EB; Coco, G; Murray, AB; Green, MO",
      "published_date": "January 28, 2014",
      "doi": "10.5194/esurf-2-67-2014",
      "abstract": "© 2014 Author(s). Numerical models rely on the parameterization of processes that often lack a deterministic description. In this contribution we demonstrate the applicability of using machine learning, a class of optimization tools from the discipline of computer science, to develop parameterizations when extensive data sets exist. We develop a new predictor for near-bed suspended sediment reference concentration under unbroken waves using genetic programming, a machine learning technique. We demonstrate that this newly developed parameterization performs as well or better than existing empirical predictors, depending on the chosen error metric. We add this new predictor into an established model for inner-shelf sorted bedforms. Additionally we incorporate a previously reported machine-learning-derived predictor for oscillatory flow ripples into the sorted bedform model. This new \"hybrid\" sorted bedform model, whereby machine learning components are integrated into a numerical model, demonstrates a method of incorporating observational data (filtered through a machine learning algorithm) directly into a numerical model. Results suggest that the new hybrid model is able to capture dynamics previously absent from the model - specifically, two observed pattern modes of sorted bedforms. Lastly we discuss the challenge of integrating data-driven components into morphodynamic models and the future of hybrid modeling.",
      "publication_location": "Earth Surface Dynamics",
      "link": "http://dx.doi.org/10.5194/esurf-2-67-2014",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Un-regularizing: Approximate proximal point and faster stochastic algorithms for empirical risk minimization",
      "authors": "Frostig, R; Ge, R; Kakade, SM; Sidford, A",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© Copyright 2015 by International Machine Learning Society (IMLS). All rights reserved. We develop a family of accelerated stochastic algorithms that optimize sums of convex functions. Our algorithms improve upon the fastest running time for empirical risk minimization (ERM), and in particular linear least-squares regression, across a wide range of problem settings. To achieve this, we establish a framework, based on the classical proximal point algorithm, useful for accelerating recent fast stochastic algorithms in a black-box fashion. Empirically, we demonstrate that the resulting algorithms exhibit notions of stability that are advantageous in practice. Both in theory and in practice, the provided algorithms reap the computational benefits of adding a large strongly convex regularization term, without incurring a corresponding bias to the original ERM problem.",
      "publication_location": "32nd International Conference on Machine Learning, Icml 2015",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Simple, efficient, and neural algorithms for sparse coding",
      "authors": "Arora, S; Ge, R; Ma, T; Moitra, A",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015 A. Agarwal  &  S. Agarwal. Sparse coding is a basic task in many fields including signal processing, neuroscience and machine learning where the goal is to learn a basis that enables a sparse representation of a given set of data, if one exists. Its standard formulation is as a non-convex optimization problem which is solved in practice by heuristics based on alternating minimization. Re- cent work has resulted in several algorithms for sparse coding with provable guarantees, but somewhat surprisingly these are outperformed by the simple alternating minimization heuristics. Here we give a general framework for understanding alternating minimization which we leverage to analyze existing heuristics and to design new ones also with provable guarantees. Some of these algorithms seem implementable on simple neural architectures, which was the original motivation of Olshausen and Field (1997a) in introducing sparse coding. We also give the first efficient algorithm for sparse coding that works almost up to the information theoretic limit for sparse recovery on incoherent dictionaries. All previous algorithms that approached or surpassed this limit run in time exponential in some natural parameter. Finally, our algorithms improve upon the sample complexity of existing approaches. We believe that our analysis framework will have applications in other settings where simple iterative algorithms are used.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Efficient approaches for escaping higher order saddle points in non-convex optimization",
      "authors": "Anandkumar, A; Ge, R",
      "published_date": "June 6, 2016",
      "doi": "",
      "abstract": "© 2016 A. Anandkumar  &  R. Ge. Local search heuristics for non-convex optimizations are popular in applied machine learning. However, in general it is hard to guarantee that such algorithms even converge to a local minimum, due to the existence of complicated saddle point structures in high dimensions. Many functions have degenerate saddle points such that the first and second order derivatives cannot distinguish them with local optima. In this paper we use higher order derivatives to escape these saddle points: we design the first efficient algorithm guaranteed to converge to a third order local optimum (while existing techniques are at most second order). We also show that it is NP-hard to extend this further to finding fourth order local optima.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Intersecting faces: Non-negative matrix factorization with new guarantees",
      "authors": "Ge, R; Zou, J",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© Copyright 2015 by International Machine Learning Society (IMLS). All rights reserved. Non-negative matrix factorization (NMF) is a natural model of admixture and is widely used in science and engineering. A plethora of algorithms have been developed to tackle NMF, but due to the non-convex nature of the problem, there is little guarantee on how well these methods work. Recently a surge of research have focused on a very restricted class of NMFs, called separable NMF, where provably correct algorithms have been developed. In this paper, we propose the notion of subset-separable NMF, which substantially generalizes the property of separability. We show that subset-separability is a natural necessary condition for the factorization to be unique or to have minimum volume. We developed the Face-Intersect algorithm which provably and efficiently solves subset-separable NMF under natural conditions, and we prove that our algorithm is robust to small noise. We explored the performance of Face-Intersect on simulations and discuss settings where it empirically outperformed the state-of-art methods. Our work is a step towards finding provably correct algorithms that solve large classes of NMF problems.",
      "publication_location": "32nd International Conference on Machine Learning, Icml 2015",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Generalization and equilibrium in generative adversarial nets (GANs)",
      "authors": "Arora, S; Ge, R; Liang, Y; Ma, T; Zhang, Y",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© 2017 International Machine Learning Society (IMLS). All rights reserved. Generalization is defined training of generative adversarial network (GAN), and it's shown that generalization is not guaranteed for the popular distances between distributions such as Jensen-Shannon or Wasserstein. In particular, training may appear to be successful and yet the trained distribution may be arbitrarily far from the target distribution in standard metrics. It is shown that generalization does occur for a much weaker metric we call neural net distance. It is also shown that an approximate pure equilibrium exists in the discriminator/generator game for a natural training objective (Wasserstein) when generator capacity and training set sizes are moderate. Finally, the above theoretical ideas suggest a new training protocol, mix+GAN, which can be combined with any existing method, and empirically is found to improves some existing GAN protocols out of the box.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A process for predicting manhole events in Manhattan",
      "authors": "Rudin, C; Passonneau, RJ; Radeva, A; Dutta, H; Ierome, S; Isaac, D",
      "published_date": "July 1, 2010",
      "doi": "10.1007/s10994-009-5166-y",
      "abstract": "We present a knowledge discovery and data mining process developed as part of the Columbia/Con Edison project on manhole event prediction. This process can assist with real-world prioritization problems that involve raw data in the form of noisy documents requiring significant amounts of pre-processing. The documents are linked to a set of instances to be ranked according to prediction criteria. In the case of manhole event prediction, which is a new application for machine learning, the goal is to rank the electrical grid structures in Manhattan (manholes and service boxes) according to their vulnerability to serious manhole events such as fires, explosions and smoking manholes. Our ranking results are currently being used to help prioritize repair work on the Manhattan electrical grid. © 2010 The Author(s).",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-009-5166-y",
      "citations": 23,
      "readership": 53,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "On equivalence relationships between classification and ranking algorithms",
      "authors": "Ertekin, S; Rudin, C",
      "published_date": "October 1, 2011",
      "doi": "",
      "abstract": "We demonstrate that there are machine learning algorithms that can achieve success for two separate tasks simultaneously, namely the tasks of classification and bipartite ranking. This means that advantages gained from solving one task can be carried over to the other task, such as the ability to obtain conditional density estimates, and an order-of-magnitude reduction in computational time for training the algorithm. It also means that some algorithms are robust to the choice of evaluation metric used; they can theoretically perform well when performance is measured either by a misclassification error or by a statistic of the ROC curve (such as the area under the curve). Specifically, we provide such an equivalence relationship between a generalization of Freund et al.'s RankBoost algorithm, called the \"P-Norm Push,\" and a particular cost-sensitive classification algorithm that generalizes AdaBoost, which we call \"P-Classification.\" We discuss and validate the potential benefits of this equivalence relationship, and perform controlled experiments to understand P-Classification's empirical performance. There is no established equivalence relationship for logistic regression and its ranking counterpart, so we introduce a logistic-regression-style algorithm that aims in between classification and ranking, and has promising experimental performance with respect to both tasks. © 2011 Şeyda Ertekin and Cynthia Rudin.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "How to reverse-engineer quality rankings",
      "authors": "Chang, A; Rudin, C; Cavaretta, M; Robert Thomas, ; Gloria Chou,",
      "published_date": "September 1, 2012",
      "doi": "10.1007/s10994-012-5295-6",
      "abstract": "A good or bad product quality rating can make or break an organization. However, the notion of \"quality\" is often defined by an independent rating company that does not make the formula for determining the rank of a product publicly available. In order to invest wisely in product development, organizations are starting to use intelligent approaches for determining how funding for product development should be allocated. A critical step in this process is to \"reverse-engineer\" a rating company's proprietary model as closely as possible. In this work, we provide a machine learning approach for this task, which optimizes a certain rank statistic that encodes preference information specific to quality rating data. We present experiments on data from a major quality rating company, and provide new methods for evaluating the solution. In addition, we provide an approach to use the reverse-engineered model to achieve a top ranked product in a cost-effective way. © The Author(s) 2012.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-012-5295-6",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Lévy measure decompositions for the beta and gamma processes",
      "authors": "Wang, Y; Carin, L",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "We develop new representations for the Lévy measures of the beta and gamma processes. These representations are manifested in terms of an infinite sum of well-behaved (proper) beta and gamma distributions. Further, we demonstrate how these infinite sums may be truncated in practice, and explicitly characterize truncation errors. We also perform an analysis of the characteristics of posterior distributions, based on the proposed decompositions. The decompositions provide new insights into the beta and gamma processes (and their generalizations), and we demonstrate how the proposed representation unifies some properties of the two. This paper is meant to provide a rigorous foundation for and new perspectives on Lévy processes, as these are of increasing importance in machine learning. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Independently coupled HMM switching classifier for a bimodel brain-machine interface",
      "authors": "Darmanjian, S; Kim, SP; Nechyba, MC; Principe, J; Wessberg, J; Nicolelis, MAL",
      "published_date": "January 1, 2006",
      "doi": "10.1109/MLSP.2006.275579",
      "abstract": "Our initial attempt to develop a switching classifier used vector quantization to compress the multi-dimensional neural data recorded from multiple cortical areas of an owl monkey, into a discrete symbol for use in a single Hidden Markov Model (HMM) or HMM chain. After classification, different neural data is delegated to local linear predictors when the monkey's arm is moving and when it is at rest. This multiple-model approach helped to validate the hypothesis that by switching the neuronal firing data, the performance of the final linear prediction is improved. In this paper, we take the idea of using multiple models a step further and apply the concept to our actual switching classifier. This new structure uses an ensemble of single neural-channel HMM chains to form an Independently Coupled Hidden Markov Model (ICHMM). Consequently, this classifier takes advantage of the neural firing properties and allows for the removal of Vector Quantization while jointly improving the classification performance and the subsequent linear prediction of the trajectory. © 2006 IEEE.",
      "publication_location": "Proceedings of the 2006 16th Ieee Signal Processing Society Workshop on Machine Learning for Signal Processing, Mlsp 2006",
      "link": "http://dx.doi.org/10.1109/MLSP.2006.275579",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning to detect sepsis with a multitask Gaussian process RNN classifier",
      "authors": "Futoma, J; Hariharan, S; Heller, K",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "Copyright 2017 by the author(s). We present a scalable end-to-end classifier that uses streaming physiological and medication data to accurately predict the onset of sepsis, a life-threatening complication from infections that has high mortality and morbidity. Our proposed framework models the multivariate trajectories of continuous-valued physiological time series using multitask Gaussian processes, seamlessly accounting for the high uncertainty, frequent missingness, and irregular sampling rates typically associated with real clinical data. The Gaussian process is directly connected to a black-box classifier that predicts whether a patient will become septic, chosen in our case to be a recurrent neural network to account for the extreme variability in the length of patient encounters. We show how to scale the computations associated with the Gaussian process in a manner so that the entire system can be discriminatively trained end-to-end using backpropagation. In a large cohort of heterogeneous inpatient encounters at our university health system we find that it outperforms several baselines at predicting sepsis, and yields 19.4% and 55.5% improved areas under the Receiver Operating Characteristic and Precision Recall curves as compared to the NEWS score currently used by our hospital.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning gradients: Predictive models that infer geometry and statistical dependence",
      "authors": "",
      "published_date": "August 1, 2010",
      "doi": "",
      "abstract": "The problems of dimension reduction and inference of statistical dependence are addressed by the modeling framework of learning gradients. The models we propose hold for Euclidean spaces as well as the manifold setting. The central quantity in this approach is an estimate of the gradient of the regression or classification function. Two quadratic forms are constructed from gradient estimates: the gradient outer product and gradient based diffusion maps. The first quantity can be used for supervised dimension reduction on manifolds as well as inference of a graphical model encoding dependencies that are predictive of a response variable. The second quantity can be used for nonlinear projections that incorporate both the geometric structure of the manifold as well as variation of the response variable on the manifold. We relate the gradient outer product to standard statistical quantities such as covariances and provide a simple and precise comparison of a variety of supervised dimensionality reduction methods. We provide rates of convergence for both inference of informative directions as well as inference of a graphical model of variable dependencies. © 2010.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "https://hdl.handle.net/10161/4634",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Gromov-Wasserstein learning for graph matching and node embedding",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "Copyright © 2019 ASME A novel Gromov-Wasserstein learning framework is proposed to jointly match (align) graphs and learn embedding vectors for the associated graph nodes. Using Gromov-Wasserstein discrepancy, we measure the dissimilarity between two graphs and find their correspondence, according to the learned optimal transport. The node embeddings associated with the two graphs are learned under the guidance of the optimal transport, the distance of which not only reflects the topological structure of each graph but also yields the correspondence across the graphs. These two learning steps are mutually-beneficial, and are unified here by minimizing the Gromov-Wasserstein discrepancy with structural regularizes. This framework leads to an optimization problem that is solved by a proximal point method. We apply the proposed method to matching problems in real-world networks, and demonstrate its superior performance compared to alternative approaches.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning non-stationary dynamic bayesian networks",
      "authors": "Robinson, JW; Hartemink, AJ",
      "published_date": "December 1, 2010",
      "doi": "",
      "abstract": "Learning dynamic Bayesian network structures provides a principled mechanism for identifying conditional dependencies in time-series data. An important assumption of traditional DBN structure learning is that the data are generated by a stationary process, an assumption that is not true in many important settings. In this paper, we introduce a new class of graphical model called a nonstationary dynamic Bayesian network, in which the conditional dependence structure of the underlying data-generation process is permitted to change over time. Non-stationary dynamic Bayesian networks represent a new framework for studying problems in which the structure of a network is evolving over time. Some examples of evolving networks are transcriptional regulatory networks during an organism's development, neural pathways during learning, and traffic patterns during the day. We define the non-stationary DBN model, present an MCMC sampling algorithm for learning the structure of the model from time-series data under different assumptions, and demonstrate the effectiveness of the algorithm on both simulated and biological data. © 2010 Joshua W. Robinson and Alexander J. Hartemink.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Transfer in reinforcement learning via shared features",
      "authors": "Konidaris, G; Scheidwasser, I; Barto, AG",
      "published_date": "May 1, 2012",
      "doi": "",
      "abstract": "We present a framework for transfer in reinforcement learning based on the idea that related tasks share some common features, and that transfer can be achieved via those shared features. The framework attempts to capture the notion of tasks that are related but distinct, and provides some insight into when transfer can be usefully applied to a problem sequence and when it cannot. We apply the framework to the knowledge transfer problem, and show that an agent can learn a portable shaping function from experience in a sequence of tasks to significantly improve performance in a later related task, even given a very brief training period. We also apply the framework to skill transfer, to show that agents can learn portable skills across a sequence of tasks that significantly improve performance on later related tasks, approaching the performance of agents given perfectly learned problem-specific skills. © 2012 George Konidaris, Ilya Scheidwasser and Andrew Barto.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Autonomous shaping: Knowledge transfer in reinforcement learning",
      "authors": "Konidaris, G; Barto, A",
      "published_date": "October 6, 2006",
      "doi": "",
      "abstract": "We introduce the use of learned shaping rewards in reinforcement learning tasks, where an agent uses prior experience on a sequence of tasks to learn a portable predictor that estimates intermediate rewards, resulting in accelerated learning in later tasks that are related but distinct. Such agents can be trained on a sequence of relatively easy tasks in order to develop a more informative measure of reward that can be transferred to improve performance on more difficult tasks with-out requiring a hand coded shaping function. We use a rod positioning task to show that this significantly improves performance even after a very brief training period.",
      "publication_location": "Icml 2006   Proceedings of the 23rd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Policy and Value Transfer in Lifelong Reinforcement Learning",
      "authors": "Abel, D; Jinnai, Y; Yue, G; Konidaris, G; Littman, ML",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© Copyright 2018 by the Authors. All rights reserved. We consider the problem of how best to use prior experience to bootstrap lifelong learning, where an agent faces a series of task instances drawn from some task distribution. First, we identify the initial policy that optimizes expected performance over the distribution of tasks for increasingly complex classes of policy and task distributions. We empirically demonstrate the relative performance of each policy class' optimal element in a variety of simple task distributions. We then consider value-function initialization methods that preserve PAC guarantees while simultaneously minimizing the learning required in two learning algorithms, yielding MAXQINIT, a practical new method for value-function-based transfer. We show that MAXQINIT performs well in simple lifelong RL experiments.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning overcomplete latent variable models through tensor methods",
      "authors": "Anandkumar, A; Ge, R; Janzamin, M",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015 A. Agarwal  &  S. Agarwal. We provide guarantees for learning latent variable models emphasizing on the overcomplete regime, where the dimensionality of the latent space exceeds the observed dimensionality. In particular, we consider multiview mixtures, ICA, and sparse coding models. Our main tool is a new algorithm for tensor decomposition that works in the overcomplete regime. In the semi-supervised setting, we exploit label information to get a rough estimate of the model parameters, and then refine it using the tensor method on unlabeled samples. We establish learning guarantees when the number of components scales as k = o(dp/2), where d is the observed dimension, and p is the order of the observed moment employed in the tensor method (usually p = 3; 4). In the unsupervised setting, a simple initialization algorithm based on SVD of the tensor slices is proposed, and the guarantees are provided under the stricter condition that k ≤βd (where constant β can be larger than 1). For the learning applications, we provide tight sample complexity bounds through novel covering arguments.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A tensor approach to learning mixed membership community models",
      "authors": "Anandkumar, A; Ge, R; Hsu, D; Kakade, SM",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Community detection is the task of detecting hidden communities from observed interactions. Guaranteed community detection has so far been mostly limited to models with non-overlapping communities such as the stochastic block model. In this paper, we remove this restriction, and provide guaranteed community detection for a family of probabilistic network models with overlapping communities, termed as the mixed membership Dirichlet model, first introduced by Airoldi et al. (2008). This model allows for nodes to have fractional memberships in multiple communities and assumes that the community memberships are drawn from a Dirichlet distribution. Moreover, it contains the stochastic block model as a special case. We propose a unified approach to learning these models via a tensor spectral decomposition method. Our estimator is based on low-order moment tensor of the observed network, consisting of 3-star counts. Our learning method is fast and is based on simple linear algebraic operations, e.g., singular value decomposition and tensor power iterations. We provide guaranteed recovery of community memberships and model parameters and present a careful finite sample analysis of our learning method. As an important special case, our results match the best known scaling requirements for the (homogeneous) stochastic block model. © 2014 Anima Anandkumar, Rong Ge, Daniel Hsu, Sham Kakade.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Tensor decompositions for learning latent variable models",
      "authors": "Anandkumar, A; Ge, R; Hsu, D; Kakade, SM; Telgarsky, M",
      "published_date": "August 1, 2014",
      "doi": "",
      "abstract": "© 2014 Animashree Anandkumar, Rong Ge, Daniel Hsu, Sham M. Kakade, and Matus Telgarsky. This work considers a computationally and statistically efficient parameter estimation method for a wide class of latent variable models-including Gaussian mixture models, hidden Markov models, and latent Dirichlet allocation-which exploits a certain tensor structure in their low-order observable moments (typically, of second- and third-order). Specifically, parameter estimation is reduced to the problem of extracting a certain (orthogonal) decomposition of a symmetric tensor derived from the moments; this decomposition can be viewed as a natural generalization of the singular value decomposition for matrices. Although tensor decompositions are generally intractable to compute, the decomposition of these specially structured tensors can be efficiently obtained by a variety of approaches, including power iterations and maximization approaches (similar to the case of matrices). A detailed analysis of a robust tensor power method is provided, establishing an analogue of Wedin's perturbation theorem for the singular vectors of matrices. This implies a robust and computationally tractable estimation approach for several popular latent variable models.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A tensor spectral approach to learning mixed membership community models",
      "authors": "Anandkumar, A; Ge, R; Hsu, D; Kakade, SM",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "Detecting hidden communities from observed interactions is a classical problem. Theoretical analysis of community detection has so far been mostly limited to models with non-overlapping communities such as the stochastic block model. In this paper, we provide guaranteed community detection for a family of probabilistic network models with overlapping communities, termed as the mixed membership Dirichlet model, first introduced in Airoldi et al. (2008). This model allows for nodes to have fractional memberships in multiple communities and assumes that the community memberships are drawn from a Dirichlet distribution. Moreover, it contains the stochastic block model as a special case. We propose a unified approach to learning communities in these models via a tensor spectral decomposition approach. Our estimator uses low-order moment tensor of the observed network, consisting of 3-star counts. Our learning method is based on simple linear algebraic operations such as singular value decomposition and tensor power iterations. We provide guaranteed recovery of community memberships and model parameters, and present a careful finite sample analysis of our learning method. Additionally, our results match the best known scaling requirements for the special case of the (homogeneous) stochastic block model. © 2013 A. Anandkumar, R. Ge, D. Hsu & S.M. Kakade.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stochastic kernel temporal difference for reinforcement learning",
      "authors": "Bae, J; Giraldo, LS; Chhatbar, P; Francis, J; Sanchez, J; Principe, J",
      "published_date": "December 5, 2011",
      "doi": "10.1109/MLSP.2011.6064634",
      "abstract": "This paper introduces a kernel adaptive filter using the stochastic gradient on temporal differences, kernel TD(λ), to estimate the state-action value function Q in reinforcement learning. Kernel methods are powerful for solving nonlinear problems, but the growing computational complexity and memory size limit their applicability on practical scenarios. To overcome this, the quantization approach introduced in [1] is applied. To help understand the behavior and illustrate the role of the parameters, we apply the algorithm on a 2-dimentional spatial navigation task. Eligibility traces are commonly applied in TD learning to improve data efficiency, so the relations of eligibility trace λ and step size and filter size are observed. Moreover, kernel TD (0) is applied to neural decoding of an 8 target center-out reaching task performed by a monkey. Results show the method can effectively learn the brain-state action mapping for this task. © 2011 IEEE.",
      "publication_location": "Ieee International Workshop on Machine Learning for Signal Processing",
      "link": "http://dx.doi.org/10.1109/MLSP.2011.6064634",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Generalization bounds for learning with linear, polygonal, quadratic and conic side knowledge",
      "authors": "Tulabandhula, T; Rudin, C",
      "published_date": "September 17, 2015",
      "doi": "10.1007/s10994-014-5478-4",
      "abstract": "© 2014, The Author(s). In this paper, we consider a supervised learning setting where side knowledge is provided about the labels of unlabeled examples. The side knowledge has the effect of reducing the hypothesis space, leading to tighter generalization bounds, and thus possibly better generalization. We consider several types of side knowledge, the first leading to linear and polygonal constraints on the hypothesis space, the second leading to quadratic constraints, and the last leading to conic constraints. We show how different types of domain knowledge can lead directly to these kinds of side knowledge. We prove bounds on complexity measures of the hypothesis space for quadratic and conic side knowledge, and show that these bounds are tight in a specific sense for the quadratic case.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-014-5478-4",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning certifiably optimal rule lists for categorical data",
      "authors": "Angelino, E; Larus-Stone, N; Alabi, D; Seltzer, M; Rudin, C",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 Elaine Angelino, Nicholas Larus-Stone, Daniel Alabi, Margo Seltzer, and Cynthia Rudin. We present the design and implementation of a custom discrete optimization technique for building rule lists over a categorical feature space. Our algorithm produces rule lists with optimal training performance, according to the regularized empirical risk, with a certificate of optimality. By leveraging algorithmic bounds, efficient data structures, and computational reuse, we achieve several orders of magnitude speedup in time and a massive reduction of memory consumption. We demonstrate that our approach produces optimal rule lists on practical problems in seconds. Our results indicate that it is possible to construct optimal sparse rule lists that are approximately as accurate as the COMPAS proprietary risk prediction tool on data from Broward County, Florida, but that are completely interpretable. This framework is a novel alternative to CART and other decision tree methods for interpretable modeling.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning deep sigmoid belief networks with data augmentation",
      "authors": "Gan, Z; Henao, R; Carlson, D; Carin, L",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "Copyright 2015 by the authors. Deep directed generative models are developed. The multi-layered model is designed by stacking sigmoid belief networks, with sparsity-encouraging priors placed on the model parameters. Learning and inference of layer-wise model parameters are implemented in a Bayesian setting. By exploring the idea of data augmentation and introducing auxiliary Polya-Gamma variables, simple and efficient Gibbs sampling and mean-field variational Bayes (VB) inference are implemented. To address large-scale datasets, an online version of VB is also developed. Experimental results are presented for three publicly available datasets: MNIST, Caltech 101 Silhouettes and OCR letters.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Locally convex kernel mixtures: Bayesian subspace learning",
      "authors": "Thai, DH; Wu, HT; Dunson, DB",
      "published_date": "December 1, 2019",
      "doi": "10.1109/ICMLA.2019.00051",
      "abstract": "© 2019 IEEE. Kernel mixture models are routinely used for density estimation. However, in multivariate settings, issues arise in efficiently approximating lower-dimensional structure in the data. For example, it is common to suppose that the density is concentrated near a lower-dimensional non-linear subspace or manifold. Typical kernels used to locally approximate such subspaces are inflexible, so that a large number of components are often needed. We propose a novel class of LOcally COnvex (LOCO) kernels that are flexible in adapting to nonlinear local structure. LOCO kernels are induced by introducing random knots within local neighborhoods, and generating data as a random convex combination of these knots with adaptive weights and an additive noise. For identifiability, we constrain all observations from a particular component to have the same mean. For Bayesian inference subject to this constraint, we develop a hybrid Gibbs sampler and optimization algorithm that incorporates a Lagrange multiplier within a splitting method. The resulting LOCO algorithm is shown to dramatically outperform typical Gaussian mixture models in challenging examples.",
      "publication_location": "Proceedings   18th Ieee International Conference on Machine Learning and Applications, Icmla 2019",
      "link": "http://dx.doi.org/10.1109/ICMLA.2019.00051",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multi-task reinforcement learning in partially observable stochastic environments",
      "authors": "Li, H; Liao, X; Carin, L",
      "published_date": "January 1, 2009",
      "doi": "",
      "abstract": "We consider the problem of multi-task reinforcement learning (MTRL) in multiple partially observable stochastic environments. We introduce the regionalized policy representation (RPR) to characterize the agent's behavior in each environment. The RPR is a parametric model of the conditional distribution over current actions given the history of past actions and observations; the agent's choice of actions is directly based on this conditional distribution, without an intervening model to characterize the environment itself. We propose off-policy batch algorithms to learn the parameters of the RPRs, using episodic data collected when following a behavior policy, and show their linkage to policy iteration. We employ the Dirichlet process as a nonparametric prior over the RPRs across multiple environments. The intrinsic clustering property of the Dirichlet process imposes sharing of episodes among similar environments, which effectively reduces the number of episodes required for learning a good policy in each environment, when data sharing is appropriate. The number of distinct RPRs and the associated clusters (the sharing patterns) are automatically discovered by exploiting the episodic data as well as the nonparametric nature of the Dirichlet process. We demonstrate the effectiveness of the proposed RPR as well as the RPR-based MTRL framework on various problems, including grid-world navigation and multi-aspect target classification. The experimental results show that the RPR is a competitive reinforcement learning algorithm in partially observable domains, and the MTRL consistently achieves better performance than single task reinforcement learning. © 2009 Hui Li, Xuejun Liao and Lawrence Carin.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Nonlinear statistical learning with truncated Gaussian graphical models",
      "authors": "Su, Q; Liao, X; Chen, C; Carin, L",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 by the author(s). We introduce the truncated Gaussian graphical model (TGGM) as a novel framework for designing statistical models for nonlinear learning. A TGGM is a Gaussian graphical model (GGM) with a subset of variables truncated to be nonneg- Ative. The truncated variables are assumed latent and integrated out to induce a marginal model. We show that the variables in the marginal model arc non-Gaussian distributed and their expected relations are nonlinear. We use expectation- maximization to break the inference of the nonlinear model into a sequence of TGGM inference problems, each of which is efficiently solved by using the properties and numerical methods of multivariate Gaussian distributions. We use the TGGM to design models for nonlinear regression and classification, with the performances of these models demonstrated on extensive benchmark datasets and compared to state-of-the-art competing results.",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multi-task learning for classification with Dirichlet process priors",
      "authors": "Ya, X; Xuejun, L; Carin, L; Krishnapuram, B",
      "published_date": "January 1, 2007",
      "doi": "",
      "abstract": "Consider the problem of learning logistic-regression models for multiple classification tasks, where the training data set for each task is not drawn from the same statistical distribution. In such a multi-task learning (MTL) scenario, it is necessary to identify groups of similar tasks that should be learned jointly. Relying on a Dirichlet process (DP) based statistical model to learn the extent of similarity between classification tasks, we develop computationally efficient algorithms for two different forms of the MTL problem. First, we consider a symmetric multi-task learning (SMTL) situation in which classifiers for multiple tasks are learned jointly using a variational Bayesian (VB) algorithm. Second, we consider an asymmetric multi-task learning (AMTL) formulation in which the posterior density function from the SMTL model parameters (from previous tasks) is used as a prior for a new task: this approach has the significant advantage of not requiring storage and use of all previous data from prior tasks. The AMTL formulation is solved with a simple Markov Chain Monte Carlo (MCMC) construction. Experimental results on two real life MTL problems indicate that the proposed algorithms: (a) automatically identify subgroups of related tasks whose training data appear to be drawn from similar distributions; and (b) are more accurate than simpler approaches such as single-task learning, pooling of data across all tasks, and simplified approximations to DP.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Cross-domain multitask learning with latent probit models",
      "authors": "Han, S; Liao, X; Carin, L",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "Learning multiple tasks across heterogeneous domains is a challenging problem since the feature space may not be the same for different tasks. We assume the data in multiple tasks are generated from a latent common domain via sparse domain transforms and propose a latent probit model (LPM) to jointly learn the domain transforms, and a probit classifier shared in the common domain. To learn meaningful task relatedness and avoid over-fitting in classification, we introduce sparsity in the domain transforms matrices, as well as in the common classifier parameters. We derive theoretical bounds for the estimation error of the classifier parameters in terms of the sparsity of domain transform matrices. An expectation-maximization algorithm is derived for learning the LPM. The effectiveness of the approach is demonstrated on several real datasets. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "https://hdl.handle.net/10161/8955",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Factored temporal sigmoid belief networks for sequence learning",
      "authors": "Song, J; Gan, Z; Carin, L",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "Deep conditional generative models are developed to simultaneously learn the temporal dependencies of multiple sequences. The model is designed by introducing a three-way weight tensor to capture the multiplicative interactions between side information and sequences. The proposed model builds on the Temporal Sigmoid Belief Network (TSBN), a sequential stack of Sigmoid Belief Networks (SBNs). The transition matrices are further factored to reduce the number of parameters and improve generalization. When side information is not available, a general framework for semi-supervised learning based on the proposed model is constituted, allowing robust sequence classification. Experimental results show that the proposed approach achieves state-of-theart predictive and classification performance on sequential data, and has the capacity to synthesize sequences, with controlled style transitioning and blending.",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The hierarchical beta process for convolutional factor analysis and deep learning",
      "authors": "Chen, B; Polatkan, G; Sapiro, G; Dunson, DB; Carin, L",
      "published_date": "October 7, 2011",
      "doi": "",
      "abstract": "A convolutional factor-analysis model is developed, with the number of filters (factors) inferred via the beta process (BP) and hierarchical BP, for single-task and multi-task learning, respectively. The computation of the model parameters is implemented within a Bayesian setting, employing Gibbs sampling; we explicitly exploit the convolutional nature of the expansion to accelerate computations. The model is used in a multi-level (\"deep\") analysis of general data, with specific results presented for image-processing data sets, e.g., classification. Copyright 2011 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 28th International Conference on Machine Learning, Icml 2011",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "AWESOME: A General Multiagent Learning Algorithm that Converges in Self-Play and Learns a Best Response Against Stationary Opponents",
      "authors": "Conitzer, V; Sandholm, T",
      "published_date": "December 1, 2003",
      "doi": "",
      "abstract": "A satisfactory multiagent learning algorithm should, at a minimum, learn to play optimally against stationary opponents and converge to a Nash equilibrium in self-play. The algorithm that has come closest, WoLF-IGA, has been proven to have these two properties in 2-player 2-action repeated games - assuming that the opponent's (mixed) strategy is observable. In this paper we present AWESOME, the first algorithm that is guaranteed to have these two properties in all repeated (finite) games. It requires only that the other players' actual actions (not their strategies) can be observed at each step. It also learns to play optimally against opponents that eventually become stationary. The basic idea behind AWESOME (Adapt When Everybody is Stationary, Otherwise Move to Equilibrium) is to try to adapt to the others' strategies when they appear stationary, but otherwise to retreat to a precomputed equilibrium strategy. The techniques used to prove the properties of AWESOME are fundamentally different from those used for previous algorithms, and may help in analyzing other multiagent learning algorithms also.",
      "publication_location": "Proceedings, Twentieth International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "AWESOME: A general multiagent learning algorithm that converges in self-play and learns a best response against stationary opponents",
      "authors": "Conitzer, V; Sandholm, T",
      "published_date": "May 1, 2007",
      "doi": "10.1007/s10994-006-0143-1",
      "abstract": "Two minimal requirements for a satisfactory multiagent learning algorithm are that it 1. learns to play optimally against stationary opponents and 2. converges to a Nash equilibrium in self-play. The previous algorithm that has come closest, WoLF-IGA, has been proven to have these two properties in 2-player 2-action (repeated) games-assuming that the opponent's mixed strategy is observable. Another algorithm, ReDVaLeR (which was introduced after the algorithm described in this paper), achieves the two properties in games with arbitrary numbers of actions and players, but still requires that the opponents' mixed strategies are observable. In this paper we present AWESOME, the first algorithm that is guaranteed to have the two properties in games with arbitrary numbers of actions and players. It is still the only algorithm that does so while only relying on observing the other players' actual actions (not their mixed strategies). It also learns to play optimally against opponents that eventually become stationary. The basic idea behind AWESOME (Adapt When Everybody is Stationary, Otherwise Move to Equilibrium) is to try to adapt to the others' strategies when they appear stationary, but otherwise to retreat to a precomputed equilibrium strategy. We provide experimental results that suggest that AWESOME converges fast in practice. The techniques used to prove the properties of AWESOME are fundamentally different from those used for previous algorithms, and may help in analyzing future multiagent learning algorithms as well. © Springer Science + Business Media, LLC 2007.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-006-0143-1",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes",
      "authors": "",
      "published_date": "October 1, 2007",
      "doi": "",
      "abstract": "This paper introduces a novel spectral framework for solving Markov decision processes (MDPs) by jointly learning representations and optimal policies. The major components of the framework described in this paper include: (i) A general scheme for constructing representations or basis functions by diagonalizing symmetric diffusion operators (ii) A specific instantiation of this approach where global basis functions calledproto-value functions (PVFs) are formed using the eigenvectors of the graph Laplacian on an undirected graph formed from state transitions induced by the MDP (iii) A three-phased procedure called representation policy iteration comprising of a sample collection phase, a representation learning phase that constructs basis functions from samples, and a final parameter estimation phase that determines an (approximately) optimal policy within the (linear) subspace spanned by the (current) basis functions. (iv) A specific instantiation of the RPI framework using least-squares policy iteration (LSPI) as the parameter estimation method (v) Several strategies for scaling the proposed approach to large discrete and continuous state spaces, including the Nyström extension for out-of-sample interpolation of eigenfunctions, and the use of Kronecker sum factorization to construct compact eigenfunctions in product spaces such as factored MDPs (vi) Finally, a series of illustrative discrete and continuous control tasks, which both illustrate the concepts and provide a benchmark for evaluating the proposed approach. Many challenges remain to be addressed in scaling the proposed framework to large MDPs, and several elaboration of the proposed framework are briefly summarized at the end.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Why skewing works: Learning difficult boolean functions with greedy tree learners",
      "authors": "Rosell, B; Hellerstein, L; Ray, S; Page, D",
      "published_date": "December 1, 2005",
      "doi": "",
      "abstract": "We analyze skewing, an approach that has been empirically observed to enable greedy decision tree learners to learn \"difficult\" Boolean functions, such as parity, in the presence of irrelevant variables. We prove that, in an idealized setting, for any function and choice of skew parameters, skewing finds relevant variables with probability 1. We present experiments exploring how different parameter choices affect the success of skewing in empirical settings. Finally, we analyze a variant of skewing called Sequential Skewing.",
      "publication_location": "Icml 2005   Proceedings of the 22nd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian and L 1 approaches for sparse unsupervised learning",
      "authors": "Mohamed, S; Heller, KA; Ghahramani, Z",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "The use of L 1 regularisation for sparse learning has generated immense research interest, with many successful applications in diverse areas such as signal acquisition, image coding, genomics and collaborative filtering. While existing work highlights the many advantages of L 1 methods, in this paper we find that L 1 regularisation often dramatically under-performs in terms of predictive performance when compared to other methods for inferring sparsity. We focus on unsupervised latent variable models, and develop L 1 minimising factor models, Bayesian variants of \"L 1\", and Bayesian models with a stronger L 0-like sparsity induced through spike-and-slab distributions. These spike-and-slab Bayesian factor models encourage sparsity while accounting for uncertainty in a principled manner, and avoid unnecessary shrinkage of non-zero values. We demonstrate on a number of data sets that in practice spike-and-slab Bayesian methods outperform L 1 minimisation, even on a computational budget. We thus highlight the need to re-assess the wide use of L 1 methods in sparsity-reliant applications, particularly when we care about generalising to previously unseen data, and provide an alternative that, over many varying conditions, provides improved generalisation performance. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning algorithms for online principal-agent problems (and selling goods online)",
      "authors": "Conitzer, V; Garera, N",
      "published_date": "October 6, 2006",
      "doi": "",
      "abstract": "In a principal-agent problem, a principal seeks to motivate an agent to take a certain action beneficial to the principal, while spending as little as possible on the reward. This is complicated by the fact that the principal does not know the agent's utility function (or type). We study the online setting where at each round, the principal encounters a new agent, and the principal sets the rewards anew. At the end of each round, the principal only finds out the action that the agent took, but not his type. The principal must learn how to set the rewards optimally. We show that this setting generalizes the setting of selling a digital good online. We study and experimentally compare three main approaches to this problem. First, we show how to apply a standard bandit algorithm to this setting. Second, for the case where the distribution of agent types is fixed (but unknown to the principal), we introduce a new gradient ascent algorithm. Third, for the case where the distribution of agents' types is fixed, and the principal has a prior belief (distribution) over a limited class of type distributions, we study a Bayesian approach.",
      "publication_location": "Icml 2006   Proceedings of the 23rd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian learning in sparse graphical factor models via annealed entropy",
      "authors": "Yoshida, R; West, M",
      "published_date": 2010,
      "doi": "",
      "abstract": "",
      "publication_location": "Journal of Machine Learning Research",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2947451\n\ncomment: PMID: 20890391, PMC2947451\nowner: mw\ntimestamp: 2010.03.16",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian Learning in Sparse Graphical Factor Models via Variational Mean-Field Annealing.",
      "authors": "Yoshida, R; West, M",
      "published_date": "May 2010",
      "doi": "",
      "abstract": "We describe a class of sparse latent factor models, called graphical factor models (GFMs), and relevant sparse learning algorithms for posterior mode estimation. Linear, Gaussian GFMs have sparse, orthogonal factor loadings matrices, that, in addition to sparsity of the implied covariance matrices, also induce conditional independence structures via zeros in the implied precision matrices. We describe the models and their use for robust estimation of sparse latent factor structure and data/signal reconstruction. We develop computational algorithms for model exploration and posterior mode search, addressing the hard combinatorial optimization involved in the search over a huge space of potential sparse configurations. A mean-field variational technique coupled with annealing is developed to successively generate \"artificial\" posterior distributions that, at the limiting temperature in the annealing schedule, define required posterior modes in the GFM parameter space. Several detailed empirical studies and comparisons to related approaches are discussed, including analyses of handwritten digit image and cancer gene expression data.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/20890391",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Combining deep learning methods and human knowledge to identify abnormalities in computed tomography (CT) reports",
      "authors": "Benitez, M; Tian, J; Kelly, M; Selvakumaran, V; Phelan, M; Mazurowski, M; Lo, JY; Rubin, GD; Henao, R",
      "published_date": "January 1, 2019",
      "doi": "10.1117/12.2512886",
      "abstract": "© 2019 SPIE. Many researchers in the field of machine learning have addressed the problem of detecting anomalies within Computed Tomography (CT) scans. Training these machine learning algorithms requires a dataset of CT scans with identified anomalies (labels), usually, in specific organs. This represents a problem, since it requires experts to review thousands of images in order to create labels for these data. We aim to decrease human burden at labeling CT scans by developing a model that identifies anomalies within plain-text-based reports that then could be further used as a method to create labels for models based on CT scans. This study contains more than 4800 CT reports from Duke Health System, for which we aim to identify organ specific abnormalities. We propose an iterative active learning approach that consists of building a machine learning model to classify CT reports by abnormalities in different organs and then improving it by actively adding reports sequentially. At each iteration, clinical experts review the report that provides the model with highest expected information gain. This process is done in real time by using a web interface. Then, this datum is used by the model to improve its performance. We evaluated the performance of our method for abnormalities in kidneys and lungs. When starting with a model trained on 99 reports, the results show the model achieves an Area Under the Curve (AUC) score of 0.93 on the test set after adding 130 actively labeled reports to the model from an unlabeled pool of 4,000. This suggests that a set of labeled CT scans can be obtained with significantly reduced human work by combining machine learning techniques and clinical experts' knowledge.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2512886",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning",
      "authors": "",
      "published_date": "November 26, 2008",
      "doi": "",
      "abstract": "We show that linear value-function approximation is equivalent to a form of linear model approximation. We then derive a relationship between the model-approximation error and the Bellman error, and show how this relationship can guide feature selection for model improvement and/or value-function improvement. We also show how these results give insight into the behavior of existing feature-selection algorithms. Copyright 2008 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 25th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "All models are wrong, but many are useful: Learning a variable’s importance by studying an entire class of prediction models simultaneously",
      "authors": "Fisher, A; Rudin, C; Dominici, F",
      "published_date": "December 1, 2019",
      "doi": "",
      "abstract": "©c 2019 Aaron Fisher, Cynthia Rudin, and Francesca Dominici. Variable importance (VI) tools describe how much covariates contribute to a prediction model’s accuracy. However, important variables for one well-performing model (for example, a linear model f(x) = xTβ with a fixed coefficient vector β) may be unimportant for another model. In this paper, we propose model class reliance (MCR) as the range of VI values across all well-performing model in a prespecified class. Thus, MCR gives a more comprehensive description of importance by accounting for the fact that many prediction models, possibly of different parametric forms, may fit the data well. In the process of deriving MCR, we show several informative results for permutation-based VI estimates, based on the VI measures used in Random Forests. Specifically, we derive connections between permutation importance estimates for a single prediction model, U-statistics, conditional variable importance, conditional causal effects, and linear model coefficients. We then give probabilistic bounds for MCR, using a novel, generalizable technique. We apply MCR to a public data set of Broward County criminal records to study the reliance of recidivism prediction models on sex and race. In this application, MCR can be used to help inform VI for unknown, proprietary models.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Least-squares policy iteration",
      "authors": "",
      "published_date": "August 15, 2004",
      "doi": "10.1162/1532443041827907",
      "abstract": "We propose a new approach to reinforcement learning for control problems which combines value-function approximation with linear architectures and approximate policy iteration. This new approach is motivated by the least-squares temporal-difference learning algorithm (LSTD) for prediction problems, which is known for its efficient use of sample experiences compared to pure temporal-difference algorithms. Heretofore, LSTD has not had a straightforward application to control problems mainly because LSTD learns the state value function of a fixed policy which cannot be used for action selection and control without a model of the underlying process. Our new algorithm, least-squares policy iteration (LSPI), learns the state-action value function which allows for action selection without a model and for incremental policy improvement within a policy-iteration framework. LSPI is a model-free, off-policy method which can use efficiently (and reuse in each iteration) sample experiences collected in any manner. By separating the sample collection method, the choice of the linear approximation architecture, and the solution method, LSPI allows for focused attention on the distinct elements that contribute to practical reinforcement learning. LSPI is tested on the simple task of balancing an inverted pendulum and the harder task of balancing and riding a bicycle to a target location. In both cases, LSPI learns to control the pendulum or the bicycle by merely observing a relatively small number of trials where actions are selected randomly. LSPI is also compared against Q-learning (both with and without experience replay) using the same value function architecture. While LSPI achieves good performance fairly consistently on the difficult bicycle task, Q-learning variants were rarely able to balance for more than a small fraction of the time needed to reach the target location.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "http://dx.doi.org/10.1162/1532443041827907",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "BL-WoLF: A Framework For Loss-Bounded Learnability In Zero-Sum Games",
      "authors": "Conitzer, V; Sandholm, T",
      "published_date": "December 1, 2003",
      "doi": "",
      "abstract": "We present BL-WoLF, a framework for learnability in repeated zero-sum games where the cost of learning is measured by the losses the learning agent accrues (rather than the number of rounds). The game is adversarially chosen from some family that the learner knows. The opponent knows the game and the learner's learning strategy. The learner tries to either not accrue losses, or to quickly learn about the game so as to avoid future losses (this is consistent with the Win or Learn Fast (WoLF) principle; BL stands for \"bounded loss\"). Our framework allows for both probabilistic and approximate learning. The resultant notion of BL-WoLF-learnability can be applied to any class of games, and allows us to measure the inherent disadvantage to a player that does not know which game in the class it is in. We present guaranteed BL-WoLF-learnability results for families of games with deterministic payoffs and families of games with stochastic payoffs. We demonstrate that these families are guaranteed approximately BL-WoLF-learnable with lower cost. We then demonstrate families of games (both stochastic and deterministic) that are not guaranteed BL-WoLF-learnable. We show that those families, nevertheless, are BL-WoLF-learnable. To prove these results, we use a key lemma which we derive.",
      "publication_location": "Proceedings, Twentieth International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Scalable and robust Bayesian inference via the median posterior",
      "authors": "Minsker, S; Srivastava, S; Lin, L; Dunson, DB",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Copyright 2014 by the author(s). Many Bayesian learning methods for massive data benefit from working with small subsets of observations. In particular, significant progress has been made in scalable Bayesian learning via stochastic approximation. However, Bayesian learning methods in distributed computing environments are often problem- or distribution-specific and use ad hoc techniques. We propose a novel general approach to Bayesian inference that is scalable and robust to corruption in the data. Our technique is based on the idea of splitting the data into several non-overlapping subgroups, evaluating the posterior distribution given each independent subgroup, and then combining the results. Our main contribution is the proposed aggregation step which is based on finding the geometric median of subset posterior distributions. Presented theoretical and numerical results confirm the advantages of our approach.",
      "publication_location": "31st International Conference on Machine Learning, Icml 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Continuous-time flows for efficient inference and density estimation",
      "authors": "Chen, C; Li, C; Chen, L; Wang, W; Pu, Y; Carin, L",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 by the Authors. All rights reserved. Two fundamental problems in unsupervised learning are efficient inference for latent-variable models and robust density estimation based on large amounts of unlabeled data. Algorithms for the two tasks, such as normalizing flows and generative adversarial networks (GANs), are often developed independently. In this paper, we propose the concept of continuous-time flows (CTFs), a family of diffusion-based methods that are able to asymptotically approach a target distribution. Distinct from normalizing flows and GANs, CTFs can be adopted to achieve the above two goals in one framework, with theoretical guarantees. Our framework includes distilling knowledge from a CTF for efficient inference, and learning an explicit energy-based distribution with CTFs for density estimation. Both tasks rely on a new technique for distribution matching within amortized learning. Experiments on various tasks demonstrate promising performance of the proposed CTF framework, compared to related techniques.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Improving structure MCMC for Bayesian networks through Markov Blanket resampling",
      "authors": "Su, C; Borsuk, ME",
      "published_date": "April 1, 2016",
      "doi": "",
      "abstract": "©2016 Chengwei Su and Mark E. Borsuk. Algorithms for inferring the structure of Bayesian networks from data have become an increasingly popular method for uncovering the direct and indirect influences among variables in complex systems. A Bayesian approach to structure learning uses posterior probabilities to quantify the strength with which the data and prior knowledge jointly support each possible graph feature. Existing Markov Chain Monte Carlo (MCMC) algorithms for estimating these posterior probabilities are slow in mixing and convergence, especially for large networks. We present a novel Markov blanket resampling (MBR) scheme that intermittently reconstructs the Markov blanket of nodes, thus allowing the sampler to more effectively traverse low-probability regions between local maxima. As we can derive the complementary forward and backward directions of the MBR proposal distribution, the Metropolis-Hastings algorithm can be used to account for any asymmetries in these proposals. Experiments across a range of network sizes show that the MBR scheme outperforms other state-of-the-art algorithms, both in terms of learning performance and convergence rate. In particular, MBR achieves better learning performance than the other algorithms when the number of observations is relatively small and faster convergence when the number of variables in the network is large.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Analyzing tensor power method dynamics in overcomplete regime",
      "authors": "Anandkumar, A; Ge, R; Janzamin, M",
      "published_date": "April 1, 2017",
      "doi": "",
      "abstract": "© 2017 Animashree Anandkumar, Rong Ge, and Majid Janzamin. We present a novel analysis of the dynamics of tensor power iterations in the overcomplete regime where the tensor CP rank is larger than the input dimension. Finding the CP decomposition of an overcomplete tensor is NP-hard in general. We consider the case where the tensor components are randomly drawn, and show that the simple power iteration recovers the components with bounded error under mild initialization conditions. We apply our analysis to unsupervised learning of latent variable models, such as multi-view mixture models and spherical Gaussian mixtures. Given the third order moment tensor, we learn the parameters using tensor power iterations. We prove it can correctly learn the model parameters when the number of hidden components k is much larger than the data dimension d, up to k = o(d1:5). We initialize the power iterations with data samples and prove its success under mild conditions on the signal-to-noise ratio of the samples. Our analysis significantly expands the class of latent variable models where spectral methods are applicable. Our analysis also deals with noise in the input tensor leading to sample complexity result in the application to learning latent variable models.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "WASP: Scalable Bayes via barycenters of subset posteriors",
      "authors": "Srivastava, S; Cevher, V; Tran-Dinh, Q; Dunson, DB",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "Copyright 2015 by the authors. The promise of Bayesian methods for big data sets has not fully been realized due to the lack of scalable computational algorithms. For massive data, it is necessary to store and process subsets on different machines in a distributed manner. We propose a simple, general, and highly efficient approach, which first runs a posterior sampling algorithm in parallel on different machines for subsets of a large data set. To combine these subset posteriors, we calculate the Wasserstein barycenter via a highly efficient linear program. The resulting estimate for the Wasserstein posterior (WASP) has an atomic form, facilitating straightforward estimation of posterior summaries of functionals of interest. The WASP approach allows posterior sampling algorithms for smaller data sets to be trivially scaled to huge data. We provide theoretical justification in terms of posterior consistency and algorithm efficiency. Examples are provided in complex settings including Gaussian process regression and nonparametric Bayes mixture models.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A practical algorithm for topic modeling with provable guarantees",
      "authors": "Arora, S; Ge, R; Halpern, Y; Mimno, D; Moitra, A; Sontag, D; Wu, Y; Zhu, M",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "Topic models provide a useful method for dimensionality reduction and exploratory data analysis in large text corpora. Most approaches to topic model learning have been based on a maximum likelihood objective. Efficient algorithms exist that attempt to approximate this objective, but they have no provable guarantees. Recently, algorithms have been introduced that provide provable bounds, but these algorithms are not practical because they are inefficient and not robust to violations of model assumptions. In this paper we present an algorithm for learning topic models that is both provable and practical. The algorithm produces results comparable to the best MCMC implementations while running orders of magnitude faster. Copyright 2013 by the author(s).",
      "publication_location": "30th International Conference on Machine Learning, Icml 2013",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Falling rule lists",
      "authors": "Wang, F; Rudin, C",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "Copyright 2015 by the authors. Falling rule lists are classification models consisting of an ordered list of if-then rules, where (i) the order of rules determines which example should be classified by each rule, and (ii) the estimated probability of success decreases monotonically down the list. These kinds of rule lists are inspired by healthcare applications where patients would be stratified into risk sets and the highest at-risk patients should be considered first. We provide a Bayesian framework for learning falling rule lists that does not rely on traditional greedy decision tree learning methods.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The infinite regionalized policy representation",
      "authors": "Liu, M; Liao, X; Carin, L",
      "published_date": "October 7, 2011",
      "doi": "",
      "abstract": "We introduce the infinite regionalized policy presentation (iRPR), as a nonparametric policy for reinforcement learning in partially observable Markov decision processes (POMDPs). The iRPR assumes an unbounded set of decision states a priori, and infers the number of states to represent the policy given the experiences. We propose algorithms for learning the number of decision states while maintaining a proper balance between exploration and exploitation. Convergence analysis is provided, along with performance evaluations on benchmark problems. Copyright 2011 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 28th International Conference on Machine Learning, Icml 2011",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Logistic regression with an auxiliary data source",
      "authors": "Liao, X; Xue, Y; Carin, L",
      "published_date": "December 1, 2005",
      "doi": "",
      "abstract": "To achieve good generalization in supervised learning, the training and testing examples are usually required to be drawn from the same source distribution. In this paper we propose a method to relax this requirement in the context of logistic regression. Assuming D p and D a are two sets of examples drawn from two mismatched distributions, where D a are fully labeled and D p partially labeled, our objective is to complete the labels of D p. We introduce an auxiliary variable μ for each example in D a to reflect its mismatch with D p. Under an appropriate constraint the μ's are estimated as a byproduct, along with the classifier. We also present an active learning approach for selecting the labeled examples in D p. The proposed algorithm, called \"Migratory-Logit\" or M-Logit, is demonstrated successfully on simulated as well as real data sets.",
      "publication_location": "Icml 2005   Proceedings of the 22nd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Partition functions from rao-blackwellized tempered sampling",
      "authors": "Carlson, DE; Stinson, P; Pakman, A; Paninski, L",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 by the author(s). Partition functions of probability distributions are important quantities for model evaluation and comparisons. We present a new method to compute partition functions of complex and multi-modal distributions. Such distributions are often sampled using simulated tempering, which augments the target space with an auxiliary inverse temperature variable. Our method exploits the multinomial probability law of the inverse temperatures, and provides estimates of the partition function in terms of a simple quotient of Rao-Blackwellized marginal inverse temperature probability estimates, which are updated while sampling. We show that the method has interesting connections with several alternative popular methods, and offers some significant advantages. In particular, we empirically find that the new method provides more accurate estimates than Annealed Importance Sampling when calculating partition functions of large Restricted Boltz-mann Machines (RBM); moreover, the method is sufficiently accurate to track training and validation log-likelihoods during learning of RBMs, at minimal computational cost.",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "https://hdl.handle.net/10161/16067",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Rich component analysis",
      "authors": "Ge, R; Zou, J",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "In many settings, we have multiple data sets (also called views) that capture different and overlapping aspects of the same phenomenon. We are often interested in finding patterns that are unique to one or to a subset of the views. For example, we might have one set of molecular observations and one set of physiological observations on the same group of individuals, and we want to quantify molecular patterns that are uncorrelated with physiology. Despite being a common problem, this is highly challenging when the correlations come from complex distributions. In this paper, we develop the general framework of Rich Component Analysis (RCA) to model settings where the observations from different views are driven by different sets of latent components, and each component can be a complex, high-dimensional distribution. We introduce algorithms based on cumulant extraction that provably learn each of the components without having to model the other components. We show how to integrate RCA with stochastic gradient descent into a meta-algorithm for learning general models, and demonstrate substantial improvement in accuracy on several synthetic and real datasets in both supervised and unsupervised tasks. Our method makes it possible to learn latent variable models when we don't have samples from the true model but only samples after complex perturbations.",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Structure-leveraged methods in breast cancer risk prediction",
      "authors": "Fan, J; Wu, Y; Yuan, M; Page, D; Liu, J; Ong, IM; Peissig, P; Burnside, E",
      "published_date": "May 1, 2016",
      "doi": "",
      "abstract": "©2016 Jun Fan, Yirong Wu, Ming Yuan, David Page, Jie Liu, Irene M. Ong, Peggy Peissig and Elizabeth Burnside. Predicting breast cancer risk has long been a goal of medical research in the pursuit of precision medicine. The goal of this study is to develop novel penalized methods to improve breast cancer risk prediction by leveraging structure information in electronic health records. We conducted a retrospective case-control study, garnering 49 mammography descriptors and 77 high-frequency/low-penetrance single-nucleotide polymorphisms (SNPs) from an existing personalized medicine data repository. Structured mammography reports and breast imaging features have long been part of a standard electronic health record (EHR), and genetic markers likely will be in the near future. Lasso and its variants are widely used approaches to integrated learning and feature selection, and our methodological contribution is to incorporate the dependence structure among the features into these approaches. More specifically, we propose a new methodology by combining group penalty and lp (1 ≤ p ≤ 2) fusion penalty to improve breast cancer risk prediction, taking into account structure information in mammography descriptors and SNPs. We demonstrate that our method provides benefits that are both statistically significant and potentially significant to people's lives.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A nonparametric Bayesian approach to modeling overlapping clusters",
      "authors": "Heller, KA; Ghahramani, Z",
      "published_date": "December 1, 2007",
      "doi": "",
      "abstract": "Although clustering data into mutually exclusive partitions has been an extremely successful approach to unsupervised learning, there are many situations in which a richer model is needed to fully represent the data. This is the case in problems where data points actually simultaneously belong to multiple, overlapping clusters. For example a particular gene may have several functions, therefore belonging to several distinct clusters of genes, and a biologist may want to discover these through unsupervised modeling of gene expression data. We present a new nonparametric Bayesian method, the Infinite Overlapping Mixture Model (IOMM), for modeling overlapping clusters. The IOMM uses exponential family distributions to model each cluster and forms an overlapping mixture by taking products of such distributions, much like products of experts (Hinton, 2002). The IOMM allows an unbounded number of clusters, and assignments of points to (multiple) clusters is modeled using an Indian Buffet Process (IBP), (Griffiths and Ghahramani, 2006). The IOMM has the desirable properties of being able to focus in on overlapping regions while maintaining the ability to model a potentially infinite number of clusters which may overlap. We derive MCMC inference algorithms for the IOMM and show that these can be used to cluster movies into multiple genres.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Quantitative pharmacophore models with inductive logic programming",
      "authors": "Srinivasan, A; Page, D; Camacho, R; King, R",
      "published_date": "September 1, 2006",
      "doi": "10.1007/s10994-006-8262-2",
      "abstract": "Three-dimensional models, or pharmacophores, describing Euclidean constraints on the location on small molecules of functional groups (like hydrophobic groups, hydrogen acceptors and donors, etc.), are often used in drug design to describe the medicinal activity of potential drugs (or 'ligands'). This medicinal activity is produced by interaction of the functional groups on the ligand with a binding site on a target protein. In identifying structure-activity relations of this kind there are three principal issues: (1) It is often difficult to \"align\" the ligands in order to identify common structural properties that may be responsible for activity; (2) Ligands in solution can adopt different shapes (or 'conformations') arising from torsional rotations about bonds. The 3-D molecular substructure is typically sought on one or more low-energy conformers; and (3) Pharmacophore models must, ideally, predict medicinal activity on some quantitative scale. It has been shown that the logical representation adopted by Inductive Logic Programming (ILP) naturally resolves many of the difficulties associated with the alignment and multi-conformation issues. However, the predictions of models constructed by ILP have hitherto only been nominal, predicting medicinal activity to be present or absent. In this paper, we investigate the construction of two kinds of quantitative pharmacophoric models with ILP: (a) Models that predict the probability that a ligand is \"active\"; and (b) Models that predict the actual medicinal activity of a ligand. Quantitative predictions are obtained by the utilising the following statistical procedures as background knowledge: logistic regression and naive Bayes, for probability prediction; linear and kernel regression, for activity prediction. The multi-conformation issue and, more generally, the relational representation used by ILP results in some special difficulties in the use of any statistical procedure. We present the principal issues and some solutions. Specifically, using data on the inhibition of the protease Thermolysin, we demonstrate that it is possible for an ILP program to construct good quantitative structure-activity models. We also comment on the relationship of this work to other recent developments in statistical relational learning.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-006-8262-2",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Statistical models for partial membership",
      "authors": "Heller, KA; Williamson, S; Ghahramani, Z",
      "published_date": "November 26, 2008",
      "doi": "",
      "abstract": "We present a principled Bayesian framework for modeling partial memberships of data points to clusters. Unlike a standard mixture model which assumes that each data point belongs to one and only one mixture component, or cluster, a partial membership model allows data points to have fractional membership in multiple clusters. Algorithms which assign data points partial memberships to clusters can be useful for tasks such as clustering genes based on microarray data (Gasch & Eisen, 2002). Our Bayesian Partial Membership Model (BPM) uses exponential family distributions to model each cluster, and a product of these distibtutions, with weighted parameters, to model each datapoint. Here the weights correspond to the degree to which the datapoint belongs to each cluster. All parameters in the BPM are continuous, so we can use Hybrid Monte Carlo to perform inference and learning. We discuss relationships between the BPM and Latent Dirichlet Allocation, Mixed Membership models, Exponential Family PCA, and fuzzy clustering. Lastly, we show some experimental results and discuss nonparametric extensions to our model. Copyright 2008 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 25th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Exploiting product distributions to identify relevant variables of correlation immune functions",
      "authors": "Hellerstein, L; Roseli, B; Bach, E; Ray, S; Page, D",
      "published_date": "November 30, 2009",
      "doi": "",
      "abstract": "A Boolean function f is correlation immune if each input variable is independent of the output, under the uniform distribution on inputs. For example, the parity function is correlation immune. We consider the problem of identifying relevant variables of a correlation immune function, in the presence of irrelevant variables. We address this problem in two different contexts. First, we analyze Skewing, a heuristic method that was developed to improve the ability of greedy decision tree algorithms to identify relevant variables of correlation immune Boolean functions, given examples drawn from the uniform distribution (Page and Ray, 2003). We present theoretical results revealing both the capabilities and limitations of skewing. Second, we explore the problem of identifying relevant variables in the Product Distribution Choice (PDC) learning model, a model in which the learner can choose product distributions and obtain examples from them. We prove a lemma establishing a property of Boolean functions that may be of independent interest. Using this lemma, we give two new algorithms for finding relevant variables of correlation immune functions in the PDC model. © 2009 Lisa Hellerstein, Bernard Roseli, Eric Bach, Soumya Ray and David Page.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Escaping the local minima via simulated annealing: Optimization of approximately convex functions",
      "authors": "Belloni, A; Liang, T; Narayanan, H; Rakhlin, A",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015 A. Agarwal  &  S. Agarwal. We consider the problem of optimizing an approximately convex function over a bounded convex set in Rn using only function evaluations. The problem is reduced to sampling from an approximately log-concave distribution using the Hit-and-Run method, which is shown to have the same Ω∗ complexity as sampling from log-concave distributions. In addition to extend the analysis for log-concave distributions to approximate log-concave distributions, the implementation of the 1- dimensional sampler of the Hit-and-Run walk requires new methods and analysis. The algorithm then is based on simulated annealing which does not relies on first order conditions which makes it essentially immune to local minima. We then apply the method to different motivating problems. In the context of zeroth order stochastic convex optimization, the proposed method produces an ϵ-minimizer after Ω∗ (n7.5ϵ-2) noisy function evaluations by inducing a Ω(ϵ=n)-approximately log concave distribution. We also consider in detail the case when the \"amount of non-convexity\" decays towards the optimum of the function. Other applications of the method discussed in this work include private computation of empirical risk minimizers, two-stage stochastic programming, and approximate dynamic programming for online learning.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Infinite hierarchical hidden Markov models",
      "authors": "Heller, KA; Teh, YW; Görür, D",
      "published_date": "December 1, 2009",
      "doi": "",
      "abstract": "In this paper we present the Infinite Hierarchical Hidden Markov Model (IHHMM), a nonparametric generalization of Hierarchical Hidden Markov Models (HHMMs). HHMMs have been used for modeling sequential data in applications such as speech recognition, detecting topic transitions in video and extracting information from text. The IHHMM provides more flexible modeling of sequential data by allowing a potentially unbounded number of levels in the hierarchy, instead of requiring the specification of a fixed hierarchy depth. Inference and learning are performed efficiently using Gibbs sampling and a modified forward-backtrack algorithm. We present encouraging results on toy sequences and English text data. © 2009 by the authors.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian hierarchical clustering",
      "authors": "Heller, KA; Ghahramani, Z",
      "published_date": "December 1, 2005",
      "doi": "10.1145/1102351.1102389",
      "abstract": "We present a novel algorithm for agglomer-ative hierarchical clustering based on evaluating marginal likelihoods of a probabilistic model. This algorithm has several advantages over traditional distance-based agglomerative clustering algorithms. (1) It defines a probabilistic model of the data which can be used to compute the predictive distribution of a test point and the probability of it belonging to any of the existing clusters in the tree. (2) It uses a model-based criterion to decide on merging clusters rather than an ad-hoc distance metric. (3) Bayesian hypothesis testing is used to decide which merges are advantageous and to output the recommended depth of the tree. (4) The algorithm can be interpreted as a novel fast bottom-up approximate inference method for a Dirichlet process (i.e. countably infinite) mixture model (DPM). It provides a new lower bound on the marginal likelihood of a DPM by summing over exponentially many clusterings of the data in polynomial time. We describe procedures for learning the model hyperparameters, computing the predictive distribution, and extensions to the algorithm. Experimental results on synthetic and real-world data sets demonstrate useful properties of the algorithm.",
      "publication_location": "Icml 2005   Proceedings of the 22nd International Conference on Machine Learning",
      "link": "http://dx.doi.org/10.1145/1102351.1102389",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Estimation of gradients and coordinate covariation in classification",
      "authors": "",
      "published_date": "November 1, 2006",
      "doi": "",
      "abstract": "We introduce an algorithm that simultaneously estimates a classification function as well as its gradient in the supervised learning framework. The motivation for the algorithm is to find salient variables and estimate how they covary. An efficient implementation with respect to both memory and time is given. The utility of the algorithm is illustrated on simulated data as well as a gene expression data set. An error analysis is given for the convergence of the estimate of the classification function and its gradient to the true classification function and true gradient.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Lossless online Bayesian bagging",
      "authors": "Lee, HKH; Clyde, MA",
      "published_date": 2004,
      "doi": "",
      "abstract": "© 2004 Herbert K. H. Lee and Merlise A. Clyde. Bagging frequently improves the predictive performance of a model. An online version has recently been introduced, which attempts to gain the benefits of an online algorithm while approximating regular bagging. However, regular online bagging is an approximation to its batch counterpart and so is not lossless with respect to the bagging operation. By operating under the Bayesian paradigm, we introduce an online Bayesian version of bagging which is exactly equivalent to the batch Bayesian version, and thus when combined with a lossless learning algorithm gives a completely lossless online bagging algorithm. We also note that the Bayesian formulation resolves a theoretical problem with bagging, produces less variability in its estimates, and can improve predictive performance for smaller data sets.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "https://hdl.handle.net/10161/11774",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian logistic Gaussian process models for dynamic networks",
      "authors": "Durante, D; Dunson, DB",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Time-varying adjacency matrices encoding the presence or absence of a relation among entities are available in many research fields. Motivated by an application to studying dynamic networks among sports teams, we propose a Bayesian nonparametric model. The proposed approach uses a logistic mapping from the probability matrix, encoding link probabilities between each team, to an embedded latent relational space. Within this latent space, we incorporate a dictionary of Gaussian process (GP) latent trajectories characterizing changes over time in each team, while allowing learning of the number of latent dimensions through a specially tailored prior for the GP covariance. The model is provably flexible and borrows strength across the network and over time. We provide simulation experiments and an application to the Italian soccer Championship.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Provable algorithms for inference in topic models",
      "authors": "Arora, S; Ge, R; Koehler, F; Ma, T; Moitra, A",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 by the author(s). Recently, there has been considerable progress on designing algorithms with provable guarantees - typically using linear algebraic methods - for parameter learning in latent variable models. But designing provable algorithms for inference has proven to be more challenging. Here we take a first step towards provable inference in topic models. We leverage a property of topic models that enables us to construct simple linear estimators for the unknown topic proportions that have small variance, and consequently can work with short documents. Our estimators also correspond to finding an estimate around which the posterior is well-concentrated. We show lower bounds that for shorter documents it can be information theoretically impossible to find the hidden topics. Finally, we give empirical results that demonstrate that our algorithm works on realistic topic models. It yields good solutions on synthetic data and runs in time comparable to a single iteration of Gibbs sampling.",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Escaping from saddle points: Online stochastic gradient for tensor decomposition",
      "authors": "Ge, R; Huang, F; Jin, C; Yuan, Y",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015 A. Agarwal  &  S. Agarwal. We analyze stochastic gradient descent for optimizing non-convex functions. In many cases for non-convex functions the goal is to find a reasonable local minimum, and the main concern is that gradient updates are trapped in saddle points. In this paper we identify strict saddle property for non-convex problem that allows for efficient optimization. Using this property we show that from an arbitrary starting point, stochastic gradient descent converges to a local minimum in a polynomial number of iterations. To the best of our knowledge this is the first work that gives global convergence guarantees for stochastic gradient descent on non-convex functions with exponentially many local minima and saddle points. Our analysis can be applied to orthogonal tensor decomposition, which is widely used in learning a rich class of latent variable models. We propose a new optimization formulation for the tensor decomposition problem that has strict saddle property. As a result we get the first online algorithm for orthogonal tensor decomposition with global convergence guarantee.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The rate of convergence of AdaBoost",
      "authors": "Mukherjee, I; Rudin, C; Schapire, RE",
      "published_date": "August 1, 2013",
      "doi": "",
      "abstract": "The AdaBoost algorithm was designed to combine many \"weak\" hypotheses that perform slightly better than random guessing into a \"strong\" hypothesis that has very low error. We study the rate at which AdaBoost iteratively converges to the minimum of the \"exponential loss.\" Unlike previous work, our proofs do not require a weak-learning assumption, nor do they require that minimizers of the exponential loss are finite. Our first result shows that the exponential loss of AdaBoost's computed parameter vector will be at most e more than that of any parameter vector of l1-norm bounded by B in a number of rounds that is at most a polynomial in B and 1/ε. We also provide lower bounds showing that a polynomial dependence is necessary. Our second result is that within C/ε iterations, AdaBoost achieves a value of the exponential loss that is at most e more than the best possible value, where C depends on the data set. We show that this dependence of the rate on ε is optimal up to constant factors, that is, at least Ω(1/ε) rounds are necessary to achieve within e of the optimal exponential loss. © 2013 Indraneel Mukherjee, Cynthia Rudin and Robert E. Schapire.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Margin-based ranking and an equivalence between AdaBoost and RankBoost",
      "authors": "Rudin, C; Schapire, RE",
      "published_date": "November 30, 2009",
      "doi": "",
      "abstract": "We study boosting algorithms for learning to rank. We give a general margin-based bound for ranking based on covering numbers for the hypothesis space. Our bound suggests that algorithms that maximize the ranking margin will generalize well. We then describe a new algorithm, smooth margin ranking, that precisely converges to a maximum ranking-margin solution. The algorithm is a modification of RankBoost, analogous to \"approximate coordinate ascent boosting.\" Finally, we prove that AdaBoost and RankBoost are equally good for the problems of bipartite ranking and classification in terms of their asymptotic behavior on the training set. Under natural conditions, AdaBoost achieves an area under the ROC curve that is equally as good as RankBoost's; furthermore, RankBoost, when given a specific intercept, achieves a misclassification error that is as good as AdaBoost's. This may help to explain the empirical observations made by Cortes and Mohri, and Caruana and Niculescu-Mizil, about the excellent performance of AdaBoost as a bipartite ranking algorithm, as measured by the area under the ROC curve. © 2009 Cynthia Rudin and Robert E. Schapire.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The rate of convergence of AdaBoost",
      "authors": "Mukherjee, I; Rudin, C; Schapire, RE",
      "published_date": "January 1, 2011",
      "doi": "",
      "abstract": "The AdaBoost algorithm of Freund and Schapire (1997) was designed to combine many \"weak\" hypotheses that perform slightly better than a random guess into a \"strong\" hypo-thesis that has very low error. We study the rate at which AdaBoost iteratively converges to the minimum of the \"exponential loss\" with a fast rate of convergence. Our proofs do not require a weak-learning assumption, nor do they require that minimizers of the exponential loss are finite. Specifically, our first result shows that at iteration t, the exponential loss of AdaBoost 's computed parameter vector will be at most ε more than that of any parameter vector of ℓ1- norm bounded by B in a number of rounds that is bounded by a polynomial in B and 1/ε. We also provide rate lower bound examples showing a polynomial dependence on these parameters is necessary. Our second result is that within C/ε iterations, AdaBoost achieves a value of the exponential loss that is at most ε more than the best possible value, where C depends on the dataset. We show that this dependence of the rate on ε is optimal up to constant factors, i.e. at least Ω( 1/ε) rounds are necessary to achieve within ε of the optimal exponential loss. © 2011 I. Mukherjee, C. Rudin & R.E. Schapire.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sparse linear identifiable multivariate modeling",
      "authors": "Henao, R; Winther, O",
      "published_date": "March 1, 2011",
      "doi": "",
      "abstract": "In this paper we consider sparse and identifiable linear latent variable (factor) and linear Bayesian network models for parsimonious analysis of multivariate data. We propose a computationally efficient method for joint parameter and model inference, and model comparison. It consists of a fully Bayesian hierarchy for sparse models using slab and spike priors (two-component δ-function and continuous mixtures), non-Gaussian latent factors and a stochastic search over the ordering of the variables. The framework, which we call SLIM (Sparse Linear Identifiable Multivariate modeling), is validated and bench-marked on artificial and real biological data sets. SLIM is closest in spirit to LiNGAM (Shimizu et al., 2006), but differs substantially in inference, Bayesian network structure learning and model comparison. Experimentally, SLIM performs equally well or better than LiNGAM with comparable computational complexity. We attribute this mainly to the stochastic search strategy used, and to parsimony (sparsity and identifiability), which is an explicit part of the model. We propose two extensions to the basic i.i.d. linear framework: non-linear dependence on observed variables, called SNIM (Sparse Non-linear Identifiable Multivariate modeling) and allowing for correlations between latent variables, called CSLIM (Correlated SLIM), for the temporal and/or spatial data. The source code and scripts are available from http://cogsys.imm.dtu.dk/ slim/. © 2011 Ricardo Henao and Ole Winther.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stochastic Blockmodels meet Graph Neural Networks",
      "authors": "Mehta, N; Carin, L; Rai, P",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 2019 by the author(s). Stochastic blockmodels (SBM) and their variants, e.g., mixed-membership and overlapping stochastic blockmodels, are latent variable based generative models for graphs. They have proven to be successful for various tasks, such as discovering the community structure and link prediction on graph-structured data. Recently, graph neural networks, e.g., graph convolutional networks, have also emerged as a promising approach to learn powerful representations (embeddings) for the nodes in the graph, by exploiting graph properties such as locality and invariance. In this work, we unify these two directions by developing a sparse variational autoencoder for graphs, that retains the interpretability of SBMs, while also enjoying the excellent predictive performance of graph neural nets. Moreover, our framework is accompanied by a fast recognition model that enables fast inference of the node embeddings (which are of independent interest for inference in SBM and its variants). Although we develop this framework for a particular type of SBM, namely the overlapping stochastic blockmodel, the proposed framework can be adapted readily for other types of SBMs. Experimental results on several benchmarks demonstrate encouraging results on link prediction while learning an interpretable latent structure that can be used for community discovery.",
      "publication_location": "36th International Conference on Machine Learning, Icml 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The dynamics of AdaBoost: Cyclic behavior and convergence of margins",
      "authors": "Rudin, C; Daubechies, I; Schapire, RE",
      "published_date": "December 1, 2004",
      "doi": "",
      "abstract": "© 2004 Cynthia Rudin, Ingrid Daubechies and Robert E. Schapire. In order to study the convergence properties of the AdaBoost algorithm, we reduce AdaBoost to a nonlinear iterated map and study the evolution of its weight vectors. This dynamical systems approach allows us to understand AdaBoost's convergence properties completely in certain cases; for these cases we find stable cycles, allowing us to explicitly solve for AdaBoost's output. Using this unusual technique, we are able to show that AdaBoost does not always converge to a maximum margin combined classifier, answering an open question. In addition, we show that \"nonoptimal\" AdaBoost (where the weak learning algorithm does not necessarily choose the best weak classifier at each iteration) may fail to converge to a maximum margin classifier, even if \"optimal\" AdaBoost produces a maximum margin. Also, we show that if AdaBoost cycles, it cycles among \"support vectors\", i.e., examples that achieve the same smallest margin.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Logistic Stick-Breaking Process.",
      "authors": "Ren, L; Du, L; Carin, L; Dunson, DB",
      "published_date": "January 2011",
      "doi": "",
      "abstract": "A logistic stick-breaking process (LSBP) is proposed for non-parametric clustering of general spatially- or temporally-dependent data, imposing the belief that proximate data are more likely to be clustered together. The sticks in the LSBP are realized via multiple logistic regression functions, with shrinkage priors employed to favor contiguous and spatially localized segments. The LSBP is also extended for the simultaneous processing of multiple data sets, yielding a hierarchical logistic stick-breaking process (H-LSBP). The model parameters (atoms) within the H-LSBP are shared across the multiple learning tasks. Efficient variational Bayesian inference is derived, and comparisons are made to related techniques in the literature. Experimental analysis is performed for audio waveforms and images, and it is demonstrated that for segmentation applications the LSBP yields generally homogeneous segments with sharp boundaries.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/25258593",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Classification with Incomplete Data Using Dirichlet Process Priors.",
      "authors": "Wang, C; Liao, X; Carin, L; Dunson, DB",
      "published_date": "March 2010",
      "doi": "",
      "abstract": "A non-parametric hierarchical Bayesian framework is developed for designing a classifier, based on a mixture of simple (linear) classifiers. Each simple classifier is termed a local \"expert\", and the number of experts and their construction are manifested via a Dirichlet process formulation. The simple form of the \"experts\" allows analytical handling of incomplete data. The model is extended to allow simultaneous design of classifiers on multiple data sets, termed multi-task learning, with this also performed non-parametrically via the Dirichlet process. Fast inference is performed using variational Bayesian (VB) analysis, and example results are presented for several data sets. We also perform inference via Gibbs sampling, to which we compare the VB results.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/23990757",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Hierarchical kernel stick-breaking process for multi-task image analysis",
      "authors": "An, Q; Wang, C; Shterev, I; Wang, E; Carin, L; Dunson, DB",
      "published_date": "November 26, 2008",
      "doi": "",
      "abstract": "The kernel stick-breaking process (KSBP) is employed to segment general imagery, imposing the condition that patches (small blocks of pixels) that are spatially proximate are more likely to be associated with the same cluster (segment). The number of clusters is not set a priori and is inferred from the hierarchical Bayesian model. Further, KSBP is integrated with a shared Dirichlet process prior to simultaneously model multiple images, inferring their inter-relationships. This latter application may be useful for sorting and learning relationships between multiple images. The Bayesian inference algorithm is based on a hybrid of variational Bayesian analysis and local sampling. In addition to providing details on the model and associated inference framework, example results are presented for several image-analysis problems. Copyright 2008 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 25th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Policy optimization as wasserstein gradient flows",
      "authors": "Zhang, R; Chen, C; Li, C; Carin, L",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© Copyright 2018 by the author(s). All rights reserved. Policy optimization is a core component of reinforcement learning (RL), and most existing RL methods directly optimize parameters of a policy based on maximizing the expected total reward, or its surrogate. Though often achieving encouraging empirical success, its underlying mathematical principle on policy-distribution optimization is unclear. We place policy optimization into the space of probability measures, and interpret it as Wasserstein gradient flows. On the probability-measure space, under specified circumstances, policy optimization becomes a convex problem in terms of distribution optimization. To make optimization feasible, we develop efficient algorithms by numerically solving the corresponding discrete gradient flows. Our technique is applicable to several RL settings, and is related to many state-of-the-art policy-optimization algorithms. Empirical results verify the effectiveness of our framework, often obtaining better performance compared to related algorithms.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "PASS-GP: Predictive active set selection for Gaussian processes",
      "authors": "Henao, R; Winther, O",
      "published_date": "November 24, 2010",
      "doi": "10.1109/MLSP.2010.5589264",
      "abstract": "We propose a new approximation method for Gaussian process (GP) learning for large data sets that combines inline active set selection with hyperparameter optimization. The predictive probability of the label is used for ranking the data points. We use the leave-one-out predictive probability available in GPs to make a common ranking for both active and inactive points, allowing points to be removed again from the active set. This is important for keeping the complexity down and at the same time focusing on points close to the decision boundary. We lend both theoretical and empirical support to the active set selection strategy and marginal likelihood optimization on the active set. We make extensive tests on the USPS and MNIST digit classification databases with and without incorporating invariances, demonstrating that we can get state-of-the-art results (e.g. 0.86% error on MNIST) with reasonable time complexity. ©2010 IEEE.",
      "publication_location": "Proceedings of the 2010 Ieee International Workshop on Machine Learning for Signal Processing, Mlsp 2010",
      "link": "http://dx.doi.org/10.1109/MLSP.2010.5589264",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Variational inference and model selection with generalized evidence bounds",
      "authors": "Tao, C; Chen, L; Zhang, R; Henao, R; Carin, L",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 by the Authors. All rights reserved. Recent advances on the scalability and flexibility of variational inference have made it successful at unravelling hidden patterns in complex data. In this work we propose a new variational bound formulation, yielding an estimator that extends beyond the conventional variational bound. It naturally subsumes the importance-weighted and Renyi bounds as special cases, and it is provably sharper than these counterparts. We also present an improved estimator for variational learning, and advocate a novel high signal-to-variance ratio update rule for the variational parameters. We discuss model-selection issues associated with existing evidence-lower-bound-based variational inference procedures, and show how to leverage the flexibility of our new formulation to address them. Empirical evidence is provided to validate our claims.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learnability of prosodic boundaries: Is infant-directed speech easier?",
      "authors": "Ludusan, B; Cristia, A; Martin, A; Mazuka, R; Dupoux, E",
      "published_date": "August 2016",
      "doi": "10.1121/1.4960576",
      "abstract": "This study explores the long-standing hypothesis that the acoustic cues to prosodic boundaries in infant-directed speech (IDS) make those boundaries easier to learn than those in adult-directed speech (ADS). Three cues (pause duration, nucleus duration, and pitch change) were investigated, by means of a systematic review of the literature, statistical analyses of a corpus of Japanese, and machine learning experiments. The review of previous work revealed that the effect of register on boundary cues is less well established than previously thought, and that results often vary across studies for certain cues. Statistical analyses run on a large database of mother-child and mother-interviewer interactions showed that the duration of a pause and the duration of the syllable nucleus preceding the boundary are two cues which are enhanced in IDS, while f0 change is actually degraded in IDS. Supervised and unsupervised machine learning techniques applied to these acoustic cues revealed that IDS boundaries were consistently better classified than ADS ones, regardless of the learning method used. The role of the cues examined in this study and the importance of these findings in the more general context of early linguistic structure acquisition is discussed.",
      "publication_location": "The Journal of the Acoustical Society of America",
      "link": "http://dx.doi.org/10.1121/1.4960576",
      "citations": 3,
      "readership": 42,
      "tweets": 7,
      "news_mentions": ""
    },
    {
      "title": "Discriminative k-metrics",
      "authors": "Szlam, A; Sapiro, G",
      "published_date": "December 9, 2009",
      "doi": "",
      "abstract": "The k q-flats algorithm is a generalization of the popular k-means algorithm where q dimensional best fit affine sets replace centroids as the cluster prototypes. In this work, a modification of the k q-flats framework for pattern classification is introduced. The basic idea is to replace the original reconstruction only energy, which is optimized to obtain the k affine spaces, by a new energy that incorporates discriminative terms. This way, the actual classification task is introduced as part of the design and optimization. The presentation of the proposed framework is complemented with experimental results, showing that the method is computationally very efficient and gives excellent results on standard supervised learning benchmarks.",
      "publication_location": "Proceedings of the 26th International Conference on Machine Learning, Icml 2009",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Non-Gaussian discriminative factor models via the max-margin rank-likelihood",
      "authors": "Yuan, X; Henao, R; Tsalik, EL; Langley, RJ; Carin, L",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "Copyright © 2015 by the author(s). We consider the problem of discriminative factor analysis for data that are in general non-Gaussian. A Bayesian model based on the ranks of the data is proposed. We first introduce a new max-margin version of the rank-likelihood. A discriminative factor model is then developed, integrating the max-margin rank-likelihood and (linear) Bayesian support vector machines, which are also built on the max-margin principle. The discriminative factor model is further extended to the nonlinear case through mixtures of local linear classifiers, via Dirichlet processes. Fully local conjugacy of the model yields efficient inference with both Markov Chain Monte Carlo and variational Bayes approaches. Extensive experiments on benchmark and real data demonstrate superior performance of the proposed model and its potential for applications in computational biology.",
      "publication_location": "32nd International Conference on Machine Learning, Icml 2015",
      "link": "https://hdl.handle.net/10161/13121",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Analogical reasoning with relational Bayesian sets",
      "authors": "Silva, R; Heller, KA; Ghahramani, Z",
      "published_date": "December 1, 2007",
      "doi": "",
      "abstract": "Analogical reasoning depends fundamentally on the ability to learn and generalize about relations between objects. There are many ways in which objects can be related, making automated analogical reasoning very challenging. Here we develop an approach which, given a set of pairs of related objects S =A 1:B 1,A 2:B 2,. .. ,A N:B N, measures how well other pairs A:B fit in with the set S. This addresses the question: is the relation between objects A and B analogous to those relations found in S? We recast this classical problem as a problem of Bayesian analysis of relational data. This problem is nontrivial because direct similarity between objects is not a good way of measuring analogies. For instance, the analogy between an lectron around the nucleus of an atom and a planet around the Sun is hardly justified y isolated, non-relational, comparisons of an electron to a planet, and a nucleus to the Sun. We develop a generative model for predicting the existence of relationships and extend the framework of Ghahramani and Heller (2005) to provide a Bayesian measure for how analogous a relation is to other relations. This sheds new light on an old problem, which we motivate and illustrate through practical applications in exploratory data analysis.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Supersparse linear integer models for optimized medical scoring systems",
      "authors": "Ustun, B; Rudin, C",
      "published_date": "March 1, 2016",
      "doi": "10.1007/s10994-015-5528-6",
      "abstract": "© 2015, The Author(s). Scoring systems are linear classification models that only require users to add, subtract and multiply a few small numbers in order to make a prediction. These models are in widespread use by the medical community, but are difficult to learn from data because they need to be accurate and sparse, have coprime integer coefficients, and satisfy multiple operational constraints. We present a new method for creating data-driven scoring systems called a Supersparse Linear Integer Model (SLIM). SLIM scoring systems are built by using an integer programming problem that directly encodes measures of accuracy (the 0–1 loss) and sparsity (the (Formula presented.) -seminorm) while restricting coefficients to coprime integers. SLIM can seamlessly incorporate a wide range of operational constraints related to accuracy and sparsity, and can produce acceptable models without parameter tuning because of the direct control provided over these quantities. We provide bounds on the testing and training accuracy of SLIM scoring systems, and present a new data reduction technique that can improve scalability by eliminating a portion of the training data beforehand. Our paper includes results from a collaboration with the Massachusetts General Hospital Sleep Laboratory, where SLIM is being used to create a highly tailored scoring system for sleep apnea screening.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-015-5528-6",
      "citations": 55,
      "readership": 114,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Sequential event prediction",
      "authors": "Letham, B; Rudin, C; Madigan, D",
      "published_date": "November 1, 2013",
      "doi": "10.1007/s10994-013-5356-5",
      "abstract": "In sequential event prediction, we are given a \"sequence database\" of past event sequences to learn from, and we aim to predict the next event within a current event sequence. We focus on applications where the set of the past events has predictive power and not the specific order of those past events. Such applications arise in recommender systems, equipment maintenance, medical informatics, and in other domains. Our formalization of sequential event prediction draws on ideas from supervised ranking. We show how specific choices within this approach lead to different sequential event prediction problems and algorithms. In recommender system applications, the observed sequence of events depends on user choices, which may be influenced by the recommendations, which are themselves tailored to the user's choices. This leads to sequential event prediction algorithms involving a non-convex optimization problem. We apply our approach to an online grocery store recommender system, email recipient recommendation, and a novel application in the health event prediction domain. © 2013 The Author(s).",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-013-5356-5",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Electronic health record analysis via deep poisson factor models",
      "authors": "Henao, R; Lu, JT; Lucas, JE; Ferranti, J; Carin, L",
      "published_date": "April 1, 2016",
      "doi": "",
      "abstract": "© 2016 Ricardo Henao, James T. Lu, Joseph E. Lucas, Je rey Ferranti and Lawrence Carin. Electronic Health Record (EHR) phenotyping utilizes patient data captured through normal medical practice, to identify features that may represent computational medical phenotypes. These features may be used to identify at-risk patients and improve prediction of patient morbidity and mortality. We present a novel deep multi-modality architecture for EHR analysis (applicable to joint analysis of multiple forms of EHR data), based on Poisson Factor Analysis (PFA) modules. Each modality, composed of observed counts, is represented as a Poisson distribution, parameterized in terms of hidden binary units. Information from different modalities is shared via a deep hierarchy of common hidden units. Activation of these binary units occurs with probability characterized as Bernoulli-Poisson link functions, instead of more traditional logistic link functions. In addition, we demonstrate that PFA modules can be adapted to discriminative modalities. To compute model parameters, we derive efficient Markov Chain Monte Carlo (MCMC) inference that scales efficiently, with significant computational gains when compared to related models based on logistic link functions. To explore the utility of these models, we apply them to a subset of patients from the Duke-Durham patient cohort. We identified a cohort of over 16,000 patients with Type 2 Diabetes Mellitus (T2DM) based on diagnosis codes and laboratory tests out of our patient population of over 240,000. Examining the common hidden units uniting the PFA modules, we identify patient features that represent medical concepts. Experiments indicate that our learned features are better able to predict mortality and morbidity than clinical features identified previously in a large-scale clinical trial.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Dependent hierarchical beta process for image interpolation and denoising",
      "authors": "Zhou, M; Carin, L; Yang, H; Dunson, D; Sapiro, G",
      "published_date": "December 1, 2011",
      "doi": "",
      "abstract": "A dependent hierarchical beta process (dHBP) is developed as a prior for data that may be represented in terms of a sparse set of latent features, with covariate-dependent feature usage. The dHBP is applicable to general covariates and data models, imposing that signals with similar covariates are likely to be manifested in terms of similar features. Coupling the dHBP with the Bernoulli process, and upon marginalizing out the dHBP, the model may be interpreted as a covariate-dependent hierarchical Indian buffet process. As applications, we consider interpolation and denoising of an image, with covariates defined by the location of image patches within an image. Two types of noise models are considered: (i) typical white Gaussian noise; and (ii) spiky noise of arbitrary amplitude, distributed uniformly at random. In these examples, the features correspond to the atoms of a dictionary, learned based upon the data under test (without a priori training data). State-of-the-art performance is demonstrated, with efficient inference using hybrid Gibbs, Metropolis-Hastings and slice sampling. Copyright 2011 by the authors.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Statistical-computational tradeoffs in planted problems and submatrix localization with a growing number of clusters and submatrices",
      "authors": "Xu, J; Chen, Y",
      "published_date": "February 2014",
      "doi": "",
      "abstract": "",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian group factor analysis with structured sparsity",
      "authors": "",
      "published_date": "April 1, 2016",
      "doi": "",
      "abstract": "© 2016 Shiwen Zhao, Chuan Gao, Sayan Mukherjee, and Barbara E. Engelhardt. Latent factor models are the canonical statistical tool for exploratory analyses of lowdimensional linear structure for a matrix of p features across n samples. We develop a structured Bayesian group factor analysis model that extends the factor model to multiple coupled observation matrices; in the case of two observations, this reduces to a Bayesian model of canonical correlation analysis. Here, we carefully de-ne a structured Bayesian prior that encourages both element-wise and column-wise shrinkage and leads to desirable behavior on high-dimensional data. In particular, our model puts a structured prior on the joint factor loading matrix, regularizing at three levels, which enables element-wise sparsity and unsupervised recovery of latent factors corresponding to structured variance across arbitrary subsets of the observations. In addition, our structured prior allows for both dense and sparse latent factors so that covariation among either all features or only a subset of features can be recovered. We use fast parameter-expanded expectation-maximization for parameter estimation in this model. We validate our method on simulated data with substantial structure. We show results of our method applied to three high-dimensional data sets, comparing results against a number of state-of-The-Art approaches. These results illustrate useful properties of our model, including i) recovering sparse signal in the presence of dense effects; ii) the ability to scale naturally to large numbers of observations; iii) exible observation-and factor-specific regularization to recover factors with a wide variety of sparsity levels and percentage of variance explained; and iv) tractable inference that scales to modern genomic and text data sizes.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Adaptive randomized dimension reduction on massive data",
      "authors": "",
      "published_date": "November 1, 2017",
      "doi": "",
      "abstract": "© 2017 Gregory Darnell, Stoyan Georgiev, Sayan Mukherjee, Barbara E Engelhardt. The scalability of statistical estimators is of increasing importance in modern applications. One approach to implementing scalable algorithms is to compress data into a low dimensional latent space using dimension reduction methods. In this paper, we develop an approach for dimension reduction that exploits the assumption of low rank structure in high dimensional data to gain both computational and statistical advantages. We adapt recent randomized low-rank approximation algorithms to provide an efficient solution to principal component analysis (PCA), and we use this efficient solver to improve estimation in large-scale linear mixed models (LMM) for association mapping in statistical genomics. A key observation in this paper is that randomization serves a dual role, improving both computational and statistical performance by implicitly regularizing the covariance matrix estimate of the random effect in an LMM. These statistical and computational advantages are highlighted in our experiments on simulated data and large-scale genomic studies.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A modified combined method for computing termainl-pair reliability in networks with unreliable nodes",
      "authors": "",
      "published_date": "December 1, 2003",
      "doi": "",
      "abstract": "Terminal-pair (node-pair) reliability is the probability that at least one path exists between a specified pair of nodes in a network. The NPR/T (node-pair reliability-Torrieri) method can be used to compensate for unreliable nodes in network reliability computations. This method transforms the original undirected network into a directed network wherein each undirected link is replaced by two directed anti-parallel links. However, such transformation generates s-dependent events in reliability computation and yields incorrect results for some undirected networks. A modified combined method that can evaluate reliability in a network with unreliable nodes is proposed in this paper. The proposed method solves the problem caused by the NPR/T method.",
      "publication_location": "International Conference on Machine Learning and Cybernetics",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Fast direct policy evaluation using multiscale analysis of Markov diffusion processes",
      "authors": "",
      "published_date": "October 6, 2006",
      "doi": "",
      "abstract": "Policy evaluation is a critical step in the approximate solution of large Markov decision processes (MDPs), typically requiring O(|S|3) to directly solve the Bellman system of |S| linear equations (where |S| is the state space size in the discrete case, and the sample size in the continuous case). In this paper we apply a recently introduced multiscale framework for analysis on graphs to design a faster algorithm for policy evaluation. For a fixed policy π, this framework efficiently constructs a multiscale decomposition of the random walk Pπ associated with the policy π. This enables efficiently computing medium and long term state distributions, approximation of value functions, and the direct computation of the potential operator (I - γPπ)-1 needed to solve Bellman's equation. We show that even a preliminary non-optimized version of the solver competes with highly optimized iterative techniques, requiring in many cases a complexity of O(|S|).",
      "publication_location": "Icml 2006   Proceedings of the 23rd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A recognition algorithm of facial image based on wavelet subbands and decision fusion",
      "authors": "",
      "published_date": "December 1, 2003",
      "doi": "",
      "abstract": "A recognition algorithm of facial image based on wavelet subbands and decision fusion is discussed in this paper. In this algorithm, wavelet transform is used to decompose facial image into suitable levels of four subbands and then the traditional principal component analysis (PCA) or 2-D Fourier transform (spectroface algorithm) is performed on these four subbands. At last, a decision fusion method is used to get the last result. By comparing with traditional PCA algorithm, PCA algorithm using single wavelet subband and spectroface algorithm, the conclusion is that the algorithm based on wavelet subbands and decision fusion is effective.",
      "publication_location": "International Conference on Machine Learning and Cybernetics",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The Bayesian echo chamber: Modeling social inuence via linguistic accommodation",
      "authors": "Guo, F; Blundell, C; Wallach, H; Heller, K",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "Copyright 2015 by the authors. We present the Bayesian Echo Chamber, a new Bayesian generative model for social interaction data. By modeling the evolution of people's language usage over time, this model discovers latent influence relationships between them. Unlike previous work on inferring influence, which has primarily focused on simple temporal dynamics evidenced via turn-taking behavior, our model captures more nuanced influence relationships, evidenced via linguistic accommodation patterns in interaction content. The model, which is based on a discrete analog of the multivariate Hawkes process, permits a fully Bayesian inference algorithm. We validate our model's ability to discover latent influence patterns using transcripts of arguments heard by the US Supreme Court and the movie \"12 Angry Men.\" We showcase our model's capabilities by using it to infer latent influence patterns from Federal Open Market Committee meeting transcripts, demonstrating state-of-the-art performance at uncovering social dynamics in group discussions.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Evaluating multiple viewpoint models of tabla sequences",
      "authors": "",
      "published_date": "December 1, 2010",
      "doi": "10.1145/1878003.1878011",
      "abstract": "We describe a realtime tabla generation system based on a variable-length n-gram model trained on a large symbolic tabla database. A novel, parametric smoothing algorithm based on a family of exponential curves is introduced to control the relative weight of high-and low-order models. This technique is shown to lead to improvements over a back-off smoothing for our tabla database. We find that cross-entropy is lowest when the coefficient of the exponential curve is between 1 and 2 and increases for values outside of this optimal range. The basic n-gram model is extended to model dependencies between duration, stroke-type, and meter using cross-products in a Multiple Viewpoints (MV) framework, leading to improvements in most cases when compared with independent stroke and duration models.",
      "publication_location": "Mml'10   Proceedings of the 3rd Acm International Workshop on Machine Learning and Music, Co Located With Acm Multimedia 2010",
      "link": "http://dx.doi.org/10.1145/1878003.1878011",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The IBP compound Dirichlet process and its application to focused topic modeling",
      "authors": "Williamson, S; Wang, C; Heller, KA; Blei, DM",
      "published_date": "September 17, 2010",
      "doi": "",
      "abstract": "The hierarchical Dirichlet process (HDP) is a Bayesian nonparametric mixed membership model-each data point is modeled with a collection of components of different proportions. Though powerful, the HDP makes an assumption that the probability of a component being exhibited by a data point is positively correlated with its proportion within that data point. This might be an undesirable assumption. For example, in topic modeling, a topic (component) might be rare throughout the corpus but dominant within those documents (data points) where it occurs. We develop the IBP compound Dirichlet process (ICD), a Bayesian nonparametric prior that decouples across-data prevalence and within-data proportion in a mixed membership model. The ICD combines properties from the HDP and the Indian buffet process (IBP), a Bayesian nonparametric prior on binary matrices. The ICD assigns a subset of the shared mixture components to each data point. This subset, the data point's \"focus\", is determined independently from the amount that each of its components contribute. We develop an ICD mixture model for text, the focused topic model (FTM), and show superior performance over the HDP-based topic model. Copyright 2010 by the author(s)/owner(s).",
      "publication_location": "Icml 2010   Proceedings, 27th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Tree-based inference for dirichlet process mixtures",
      "authors": "Xu, Y; Heller, KA; Ghahramani, Z",
      "published_date": "December 1, 2009",
      "doi": "",
      "abstract": "The Dirichlet process mixture (DPM) is a widely used model for clustering and for nonparametric Bayesian density estimation. Unfortunately, like in many statistical models, exact inference in a DPM is intractable, and approximate methods are needed to perform efficient inference. While most attention has been placed on Markov chain Monte Carlo (MCMC) (Escobar and West, 1995; Neal, 2000; Rasmussen, 2000), variational Bayesian (VB) (Blei and Jordan, 2005) and collapsed variational methods (Kurihara, Welling and Teh, 2007), Heller and Ghahramani (2005) recently introduced a new class of approximation for DPMs based on Bayesian hierarchical clustering (BHC). These tree-based combinatorial approximations efficiently sum over exponentially many ways of partitioning the data and offer a novel lower bound on the marginal likelihood of DPMs. In this paper we make the following contributions: (1) We show empirically that the BHC lower bounds are substantially tighter than the bounds given by VB and by collapsed variational methods on synthetic and real datasets. (2) We show that BHC offers a better predictive performance on these datasets. (3) We improve the tree-based lower bounds with an algorithm that efficiently sums contributions from alternative trees. (4) We present a fast approximate method for BHC. Our results suggest that our approximate inference methods and lower bounds may be useful not only in DPMs but in other models as well. © 2009 by the authors.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "SMERED: A Bayesian approach to graphical record linkage and de-duplication",
      "authors": "Steorts, RC; Hall, R; Fienberg, SE",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "We propose a novel unsupervised approach for linking records across arbitrarily many files, while simultaneously detecting duplicate records within files. Our key innovation is to represent the pattern of links between records as a bipartite graph, in which records are directly linked to latent true individuals, and only indirectly linked to other records. This flexible new representation of the linkage structure naturally allows us to estimate the attributes of the unique observable people in the population, calculate k-way posterior probabilities of matches across records, and propagate the uncertainty of record linkage into later analyses. Our linkage structure lends itself to an efficient, linear-time, hybrid Markov chain Monte Carlo algorithm, which overcomes many obstacles encountered by previously proposed methods of record linkage, despite the high dimensional parameter space. We assess our results on real and simulated data.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "https://hdl.handle.net/10161/11815",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Special issue on inductive logic programming",
      "authors": "De Raedt, L; Page, CD; Wrobel, S",
      "published_date": "April 1, 2001",
      "doi": "",
      "abstract": "",
      "publication_location": "Machine Learning",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000167814200001&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Submatrix localization via message passing",
      "authors": "Xu, J; Hajek, B; Wu, Y",
      "published_date": "April 15, 2018",
      "doi": "",
      "abstract": "",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Feature selection using regularization in approximate linear programs for markov decision processes",
      "authors": "",
      "published_date": "September 17, 2010",
      "doi": "",
      "abstract": "Approximate dynamic programming has been used successfully in a large variety of domains, but it relies on a small set of provided approximation features to calculate solutions reliably. Large and rich sets of features can cause existing algorithms to overfit because of a limited number of samples. We address this shortcoming using L1 regularization in approximate linear programming. Because the proposed method can automatically select the appropriate richness of features, its performance does not degrade with an increasing number of features. These results rely on new and stronger sampling bounds for regularized approximate linear programs. We also propose a computationally efficient homotopy method. The empirical evaluation of the approach shows that the proposed method performs well on simple MDPs and standard benchmark problems. Copyright 2010 by the author(s)/owner(s).",
      "publication_location": "Icml 2010   Proceedings, 27th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An adaptive acoustic echo cancellation without double-talk detection",
      "authors": "",
      "published_date": "December 1, 2003",
      "doi": "",
      "abstract": "The paper proposes a novel adaptive acoustic echo cancellation (aec) without double-talk detection (dtd) that can work stably under all operating models. This breaks through the restriction that all of the adaptive echo cancellations must have Dtd currently. The novel Aec is accomplished by injecting a low-level broadband random training signal to the far-end signal before transmission into the local room, modeling adaptively the echo path by taking the training signal as the reference signal, removing the speech signal interference of the adaptive algorithm by an adaptive prediction filter (apf), and modifying the distortion of the reference signal due to the Apf by a compensation filter (cpf). The computer simulations confirm the Aec without Dtd can provide excellent echo cancellation effect under all operating models.",
      "publication_location": "International Conference on Machine Learning and Cybernetics",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multiscale strategies for computing optimal transport",
      "authors": "",
      "published_date": "August 1, 2017",
      "doi": "",
      "abstract": "©2017 Samuel Gerber and Mauro Maggioni. This paper presents a multiscale approach to efficiently compute approximate optimal transport plans between point sets. It is particularly well-suited for point sets that are in high-dimensions, but are close to being intrinsically low-dimensional. The approach is based on an adaptive multiscale decomposition of the point sets. The multiscale decomposition yields a sequence of optimal transport problems, that are solved in a top-to-bottom fashion from the coarsest to the finest scale. We provide numerical evidence that this multiscale approach scales approximately linearly, in time and memory, in the number of nodes, instead of quadratically or worse for a direct solution. Empirically, the multiscale approach results in less than one percent relative error in the objective function. Furthermore, the multiscale plans constructed are of interest by themselves as they may be used to introduce novel features and notions of distances between point sets. An analysis of sets of brain MRI based on optimal transport distances illustrates the effectiveness of the proposed method on a real world data set. The application demonstrates that multiscale optimal transport distances have the potential to improve on state-of-the-art metrics currently used in computational anatomy.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sequential skewing: An improved skewing algorithm",
      "authors": "Ray, S; Page, D",
      "published_date": "December 1, 2004",
      "doi": "",
      "abstract": "This paper extends previous work on the Skewing algorithm, a promising approach that allows greedy decision tree induction algorithms to handle problematic functions such as parity functions with a lower run-time penalty than Lookahead. A deficiency of the previously proposed algorithm is its inability to scale up to high dimensional problems. In this paper, we describe a modified algorithm that scales better with increasing numbers of variables. We present experiments with randomly generated Boolean functions that evaluate the algorithm's response to increasing dimensions. We also evaluate the algorithm on a challenging real world biomedical problem, that of SH3 domain binding. Our results indicate that our algorithm almost always outperforms an information gain-based decision tree learner.",
      "publication_location": "Proceedings, Twenty First International Conference on Machine Learning, Icml 2004",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Development and Performance of the Pulmonary Embolism Result Forecast Model (PERFORM) for Computed Tomography Clinical Decision Support.",
      "authors": "Banerjee, I; Sofela, M; Yang, J; Chen, JH; Shah, NH; Ball, R; Mushlin, AI; Desai, M; Bledsoe, J; Amrhein, T; Rubin, DL; Zamanian, R; Lungren, MP",
      "published_date": "August 2, 2019",
      "doi": "10.1001/jamanetworkopen.2019.8719",
      "abstract": "Importance: Pulmonary embolism (PE) is a life-threatening clinical problem, and computed tomographic imaging is the standard for diagnosis. Clinical decision support rules based on PE risk-scoring models have been developed to compute pretest probability but are underused and tend to underperform in practice, leading to persistent overuse of CT imaging for PE. Objective: To develop a machine learning model to generate a patient-specific risk score for PE by analyzing longitudinal clinical data as clinical decision support for patients referred for CT imaging for PE. Design, Setting, and Participants: In this diagnostic study, the proposed workflow for the machine learning model, the Pulmonary Embolism Result Forecast Model (PERFORM), transforms raw electronic medical record (EMR) data into temporal feature vectors and develops a decision analytical model targeted toward adult patients referred for CT imaging for PE. The model was tested on holdout patient EMR data from 2 large, academic medical practices. A total of 3397 annotated CT imaging examinations for PE from 3214 unique patients seen at Stanford University hospitals and clinics were used for training and validation. The models were externally validated on 240 unique patients seen at Duke University Medical Center. The comparison with clinical scoring systems was done on randomly selected 100 outpatient samples from Stanford University hospitals and clinics and 101 outpatient samples from Duke University Medical Center. Main Outcomes and Measures: Prediction performance of diagnosing acute PE was evaluated using ElasticNet, artificial neural networks, and other machine learning approaches on holdout data sets from both institutions, and performance of models was measured by area under the receiver operating characteristic curve (AUROC). Results: Of the 3214 patients included in the study, 1704 (53.0%) were women from Stanford University hospitals and clinics; mean (SD) age was 60.53 (19.43) years. The 240 patients from Duke University Medical Center used for validation included 132 women (55.0%); mean (SD) age was 70.2 (14.2) years. In the samples for clinical scoring system comparisons, the 100 outpatients from Stanford University hospitals and clinics included 67 women (67.0%); mean (SD) age was 57.74 (19.87) years, and the 101 patients from Duke University Medical Center included 59 women (58.4%); mean (SD) age was 73.06 (15.3) years. The best-performing model achieved an AUROC performance of predicting a positive PE study of 0.90 (95% CI, 0.87-0.91) on intrainstitutional holdout data with an AUROC of 0.71 (95% CI, 0.69-0.72) on an external data set from Duke University Medical Center; superior AUROC performance and cross-institutional generalization of the model of 0.81 (95% CI, 0.77-0.87) and 0.81 (95% CI, 0.73-0.82), respectively, were noted on holdout outpatient populations from both intrainstitutional and extrainstitutional data. Conclusions and Relevance: The machine learning model, PERFORM, may consider multitudes of applicable patient-specific risk factors and dependencies to arrive at a PE risk prediction that generalizes to new population distributions. This approach might be used as an automated clinical decision-support tool for patients referred for CT PE imaging to improve CT use.",
      "publication_location": "Jama Network Open",
      "link": "http://dx.doi.org/10.1001/jamanetworkopen.2019.8719",
      "citations": 5,
      "readership": 34,
      "tweets": 73,
      "news_mentions": ""
    },
    {
      "title": "An alternative prior process for nonparametric Bayesian clustering",
      "authors": "Wallach, HM; Jensen, ST; Dicker, L; Heller, KA",
      "published_date": "December 1, 2010",
      "doi": "",
      "abstract": "Prior distributions play a crucial role in Bayesian approaches to clustering. Two commonly-used prior distributions are the Dirichlet and Pitman-Yor processes. In this paper, we investigate the predictive probabilities that underlie these processes, and the implicit \"rich-get-richer\" characteristic of the resulting partitions. We explore an alternative prior for nonparametric Bayesian clustering-the uniform process-for applications where the \"rich-get-richer\" property is undesirable. We also explore the cost of this process: partitions are no longer ex-changeable with respect to the ordering of variables. We present new asymptotic and simulation-based results for the clustering characteristics of the uniform process and compare these with known results for the Dirichlet and Pitman-Yor processes. We compare performance on a real document clustering task, demonstrating the practical advantage of the uniform process despite its lack of exchangeability over orderings. Copyright 2010 by the authors.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Comparison of a distance-based likelihood ratio test and k-nearest neighbor classification methods",
      "authors": "Remus, JJ; Morton, KD; Torrione, PA; Tantum, SL; Collins, LM",
      "published_date": "December 1, 2008",
      "doi": "10.1109/MLSP.2008.4685507",
      "abstract": "Several studies of the k-nearest neighbor (KNN) classifier have proposed the use of non-uniform weighting on the k neighbors. It has been suggested that the distance to each neighbor can be used to calculate the individual weights in a weighted KNN approach; however, a consensus has not yet been reached on the best method or framework for calculating weights using the distances. In this paper, a distance likelihood ratio test will be discussed and evaluated using simulated data. The distance likelihood ratio test (DLRT) shares several characteristics with the distance-weighted k-nearest neighbor methods but approaches the use of distance from a different perspective. Results illustrate the ability of the distance likelihood ratio test to approximate the likelihood ratio and compare the DLRT to two other k-neighborhood classification rules that utilize distance-weighting. The DLRT performs favorably in comparisons of the classification performance using the simulated data and provides an alternative nonparametric classification method for consideration when designing a distance-weighted KNN classification rule. ©2008 IEEE.",
      "publication_location": "Proceedings of the 2008 Ieee Workshop on Machine Learning for Signal Processing, Mlsp 2008",
      "link": "http://dx.doi.org/10.1109/MLSP.2008.4685507",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Generalized skewing for functions with continuous and nominal attributes",
      "authors": "Ray, S; Page, D",
      "published_date": "December 1, 2005",
      "doi": "",
      "abstract": "This paper extends previous work on skewing, an approach to problematic functions in decision tree induction. The previous algorithms were applicable only to functions of binary variables. In this paper, we extend skewing to directly handle functions of continuous and nominal variables. We present experiments with randomly generated functions and a number of real world datasets to evaluate the algorithm's accuracy. Our results indicate that our algorithm almost always outperforms an Information Gain-based decision tree learner.",
      "publication_location": "Icml 2005   Proceedings of the 22nd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Randomised restarted search in ILP",
      "authors": "Železný, F; Srinivasan, A; Page, CD",
      "published_date": "September 1, 2006",
      "doi": "10.1007/s10994-006-7733-9",
      "abstract": "Recent statistical performance studies of search algorithms in difficult combinatorial problems have demonstrated the benefits of randomising and restarting the search procedure. Specifically, it has been found that if the search cost distribution of the non-restarted randomised search exhibits a slower-than-exponential decay (that is, a \"heavy tail\"), restarts can reduce the search cost expectation. We report on an empirical study of randomised restarted search in ILP. Our experiments conducted on a high-performance distributed computing platform provide an extensive statistical performance sample of five search algorithms operating on two principally different classes of ILP problems, one represented by an artificially generated graph problem and the other by three traditional classification benchmarks (mutagenicity, carcinogenicity, finite element mesh design). The sample allows us to (1) estimate the conditional expected value of the search cost (measured by the total number of clauses explored) given the minimum clause score required and a \"cutoff\" value (the number of clauses examined before the search is restarted), (2) estimate the conditional expected clause score given the cutoff value and the invested search cost, and (3) compare the performance of randomised restarted search strategies to a deterministic non-restarted search. Our findings indicate striking similarities across the five search algorithms and the four domains, in terms of the basic trends of both the statistics (1) and (2). Also, we observe that the cutoff value is critical for the performance of the search algorithm, and using its optimal value in a randomised restarted search may decrease the mean search cost (by several orders of magnitude) or increase the mean achieved score significantly with respect to that obtained with a deterministic non-restarted search.",
      "publication_location": "Machine Learning",
      "link": "http://dx.doi.org/10.1007/s10994-006-7733-9",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Dynamical models and tracking regret in online convex programming",
      "authors": "",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "This paper describes a new online convex optimization method which incorporates a family of candidate dynamical models and establishes novel tracking regret bounds that scale with the comparator's deviation from the best dynamical model in this family. Previous online optimization methods are designed to have a total accumulated loss comparable to that of the best comparator sequence, and existing tracking or shifting regret bounds scale with the overall variation of the comparator sequence. In many practical scenarios, however, the environment is non-stationary and comparator sequences with small variation are quite weak, resulting in large losses. The proposed Dynamic Mirror Descent method, in contrast, can yield low regret relative to highly variable comparator sequences by both tracking the best dynamical model and forming predictions based on that model. This concept is demonstrated empirically in the context of sequential compressive observations of a dynamic scene and tracking a dynamic social network. Copyright 2013 by the author(s).",
      "publication_location": "30th International Conference on Machine Learning, Icml 2013",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bias and variance in value function estimation",
      "authors": "Mannor, S; Simester, D; Sun, P; Tsitsiklis, JN",
      "published_date": "December 1, 2004",
      "doi": "",
      "abstract": "We consider the bias and variance of value function estimation that are caused by using an empirical model instead of the true model. We analyze these bias and variance for Markov processes from a classical (frequentist) statistical point of view, and in a Bayesian setting. Using a second order approximation, we provide explicit expressions for the bias and variance in terms of the transition counts and the reward statistics. We present supporting experiments with artificial Markov chains and with a large transactional database provided by a mail-order catalog firm.",
      "publication_location": "Proceedings, Twenty First International Conference on Machine Learning, Icml 2004",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Approximate dynamic programming for storage problems",
      "authors": "Hannah, LA; Dunson, DB",
      "published_date": "October 7, 2011",
      "doi": "",
      "abstract": "Storage problems are an important subclass of stochastic control problems. This paper presents a new method, approximate dynamic programming for storage, to solve storage problems with continuous, convex decision sets. Unlike other solution procedures, ADPS allows math programming to be used to make decisions each time period, even in the presence of large state variables. We test ADPS on the day ahead wind commitment problem with storage. Copyright 2011 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 28th International Conference on Machine Learning, Icml 2011",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Preface to the Proceedings of AISTATS 2011",
      "authors": "Gordon, GJ; Dunson, D",
      "published_date": "December 1, 2010",
      "doi": "",
      "abstract": "",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Preface to the proceedings of AISTATS 2011",
      "authors": "Gordon, GJ; Dunson, D",
      "published_date": "December 1, 2011",
      "doi": "",
      "abstract": "",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian tensor regression",
      "authors": "Guhaniyogi, R; Qamar, S; Dunson, DB",
      "published_date": "August 1, 2017",
      "doi": "",
      "abstract": "©2017 Rajarshi Guhaniyogi and Shaan Qamar and David B. Dunson. We propose a Bayesian approach to regression with a scalar response on vector and tensor covariates. Vectorization of the tensor prior to analysis fails to exploit the structure, often leading to poor estimation and predictive performance. We introduce a novel class of multiway shrinkage priors for tensor coefficients in the regression setting and present posterior consistency results under mild conditions. A computationally efficient Markov chain Monte Carlo algorithm is developed for posterior computation. Simulation studies illustrate substantial gains over existing tensor regression methods in terms of estimation and parameter inference. Our approach is further illustrated in a neuroimaging application.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Compressed Gaussian process for manifold regression",
      "authors": "Guhaniyogi, R; Dunson, DB",
      "published_date": "May 1, 2016",
      "doi": "",
      "abstract": "©2016 Rajarshi Guhaniyogi and David B. Dunson. Nonparametric regression for large numbers of features (p) is an increasingly important problem. If the sample size n is massive, a common strategy is to partition the feature space, and then separately apply simple models to each partition set. This is not ideal when n is modest relative to p, and we propose an alternative approach relying on random compression of the feature vector combined with Gaussian process regression. The proposed approach is particularly motivated by the setting in which the response is conditionally independent of the features given the projection to a low dimensional manifold. Conditionally on the random compression matrix and a smoothness parameter, the posterior distribution for the regression surface and posterior predictive distributions are available analytically. Running the analysis in parallel for many random compression matrices and smoothness parameters, model averaging is used to combine the results. The algorithm can be implemented rapidly even in very large p and moderately large n nonparametric regression, has strong theoretical justification, and is found to yield state of the art predictive performance.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Ensemble methods for convex regression with applications to geometric programming based circuit design",
      "authors": "Hannah, LA; Dunson, DB",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "Convex regression is a promising area for bridging statistical estimation and deterministic convex optimization. New piecewise linear convex regression methods (Hannah and Dunson, 2011; Magnani and Boyd, 2009) are fast and scalable, but can have instability when used to approximate constraints or objective functions for optimization. Ensemble methods, like bagging, smearing and random partitioning, can alleviate this problem and maintain the theoretical properties of the underlying estimator. We empirically examine the performance of ensemble methods for prediction and optimization, and then apply them to device modeling and constraint approximation for geometric programming based circuit design. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Scalable Bayes via barycenter in Wasserstein space",
      "authors": "Srivastava, S; Li, C; Dunson, DB",
      "published_date": "August 1, 2018",
      "doi": "",
      "abstract": "© 2018 Sanvesh Srivastava, Cheng Li and David B. Dunson. Divide-and-conquer based methods for Bayesian inference provide a general approach for tractable posterior inference when the sample size is large. These methods divide the data into smaller subsets, sample from the posterior distribution of parameters in parallel on all the subsets, and combine posterior samples from all the subsets to approximate the full data posterior distribution. The smaller size of any subset compared to the full data implies that posterior sampling on any subset is computationally more efficient than sampling from the true posterior distribution. Since the combination step takes negligible time relative to sampling, posterior computations can be scaled to massive data by dividing the full data into sufficiently large number of data subsets. One such approach relies on the geometry of posterior distributions estimated across different subsets and combines them through their barycenter in a Wasserstein space of probability measures. We provide theoretical guarantees on the accuracy of approximation that are valid in many applications. We show that the geometric method approximates the full data posterior distribution better than its competitors across diverse simulations and reproduces known results when applied to a movie ratings database.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Diagonal orthant multinomial probit models",
      "authors": "Johndrow, JE; Lum, K; Dunson, DB",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "Copyright 2013 by the authors. Bayesian classification commonly relies on probit models, with data augmentation algorithms used for posterior computation. By imputing latent Gaussian variables, one can often trivially adapt computational approaches used in Gaussian models. However, MCMC for multinomial probit (MNP) models can be inefficient in practice due to high posterior dependence between latent variables and parameters, and to difficulties in efficiently sampling latent variables when there are more than two categories. To address these problems, we propose a new class of diagonal orthant (DO) multinomial models. The key characteristics of these models include conditional independence of the latent variables given model parameters, avoidance of arbitrary identifiability restrictions, and simple expressions for category probabilities. We show substantially improved computational efficiency and comparable predictive performance to MNP.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multivariate Convex Regression with Adaptive Partitioning",
      "authors": "Hannah, LA; Dunson, DB",
      "published_date": "November 1, 2013",
      "doi": "",
      "abstract": "",
      "publication_location": "Journal of Machine Learning Research",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000329786900002&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multivariate convex regression with adaptive partitioning",
      "authors": "Hannah, LA; Dunson, DB",
      "published_date": "November 1, 2013",
      "doi": "",
      "abstract": "We propose a new, nonparametric method for multivariate regression subject to convexity or concavity constraints on the response function. Convexity constraints are common in economics, statistics, operations research, financial engineering and optimization, but there is currently no multivariate method that is stable and computationally feasible for more than a few thousand observations. We introduce convex adaptive partitioning (CAP), which creates a globally convex regression model from locally linear estimates fit on adaptively selected covariate partitions. CAP is a computationally efficient, consistent method for convex regression. We demonstrate empirical performance by comparing the performance of CAP to other shape-constrained and unconstrained regression methods for predicting weekly wages and value function approximation for pricing American basket options. © 2013 Lauren A. Hannah and David B. Dunson.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Hierarchical latent dictionaries for models of brain activation",
      "authors": "Fyshe, A; Fox, E; Dunson, D; Mitchell, T",
      "published_date": "January 1, 2012",
      "doi": "",
      "abstract": "In this work, we propose a hierarchical latent dictionary approach to estimate the timevarying mean and covariance of a process for which we have only limited noisy samples. We fully leverage the limited sample size and redundancy in sensor measurements by transferring knowledge through a hierarchy of lower dimensional latent processes. As a case study, we utilize Magnetoencephalography (MEG) recordings of brain activity to identify the word being viewed by a human subject. Specifically, we identify the word category for a single noisy MEG recording, when only given limited noisy samples on which to train.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Robust and scalable bayes via a median of subset posterior measures",
      "authors": "Minsker, S; Srivastava, S; Lin, L; Dunson, DB",
      "published_date": "December 1, 2017",
      "doi": "",
      "abstract": "© 2017 Stanislav Minsker, Sanvesh Srivastava, Lizhen Lin and David B. Dunson. We propose a novel approach to Bayesian analysis that is provably robust to outliers in the data and often has computational advantages over standard methods. Our technique is based on splitting the data into non-overlapping subgroups, evaluating the posterior distribution given each independent subgroup, and then combining the resulting measures. The main novelty of our approach is the proposed aggregation step, which is based on the evaluation of a median in the space of probability measures equipped with a suitable collection of distances that can be quickly and efficiently evaluated in practice. We present both theoretical and numerical evidence illustrating the improvements achieved by our method.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian nonparametric covariance regression",
      "authors": "Fox, EB; Dunson, DB; Airoldi, EM",
      "published_date": "December 1, 2015",
      "doi": "",
      "abstract": "© 2015 Emily B. Fox and David B. Dunson. Capturing predictor-dependent correlations amongst the elements of a multivariate response vector is fundamental to numerous applied domains, including neuroscience, epidemiology, and finance. Although there is a rich literature on methods for allowing the variance in a univariate regression model to vary with predictors, relatively little has been done in the multivariate case. As a motivating example, we consider the Google Flu Trends data set, which provides indirect measurements of influenza incidence at a large set of locations over time (our predictor). To accurately characterize temporally evolving influenza incidence across regions, it is important to develop statistical methods for a time-varying covariance matrix. Importantly, the locations provide a redundant set of measurements and do not yield a sparse nor static spatial dependence structure. We propose to reduce dimensionality and induce a flexible Bayesian nonparametric covariance regression model by relating these location-specific trajectories to a lower-dimensional subspace through a latent factor model with predictor-dependent factor loadings. These loadings are in terms of a collection of basis functions that vary nonparametrically over the predictor space. Such low-rank approximations are in contrast to sparse precision assumptions, and are appropriate in a wide range of applications. Our formulation aims to address three challenges: scaling to large p domains, coping with missing values, and allowing an irregular grid of observations. The model is shown to be highly flexible, while leading to a computationally feasible implementation via Gibbs sampling. The ability to scale to large p domains and cope with missing values is fundamental in analyzing the Google Flu Trends data.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian graphical models for multivariate functional data",
      "authors": "Zhu, H; Strawn, N; Dunson, DB",
      "published_date": "October 1, 2016",
      "doi": "",
      "abstract": "© 2016 Hongxiao Zhu, Nate Strawn, and David B. Dunson. Graphical models express conditional independence relationships among variables. Although methods for vector-valued data are well established, functional data graphical models remain underdeveloped. By functional data, we refer to data that are realizations of random functions varying over a continuum (e.g., images, signals). We introduce a notion of conditional independence between random functions, and construct a framework for Bayesian inference of undirected, decomposable graphs in the multivariate functional data context. This framework is based on extending Markov distributions and hyper Markov laws from random variables to random processes, providing a principled alternative to naive application of multivariate methods to discretized functional data. Markov properties facilitate the composition of likelihoods and priors according to the decomposition of a graph. Our focus is on Gaussian process graphical models using orthogonal basis expansions. We propose a hyper-inverse-Wishart-process prior for the covariance kernels of the infinite coeficient sequences of the basis expansion, and establish its existence and uniqueness. We also prove the strong hyper Markov property and the conjugacy of this prior under a finite rank condition of the prior kernel parameter. Stochastic search Markov chain Monte Carlo algorithms are developed for posterior inference, assessed through simulations, and applied to a study of brain activity and alcoholism.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Locally adaptive factor processes for multivariate time series",
      "authors": "Durante, D; Scarpa, B; Dunson, DB",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "In modeling multivariate time series, it is important to allow time-varying smoothness in the mean and covariance process. In particular, there may be certain time intervals exhibiting rapid changes and others in which changes are slow. If such time-varying smoothness is not accounted for, one can obtain misleading inferences and predictions, with over-smoothing across erratic time intervals and under-smoothing across times exhibiting slow variation. This can lead to mis-calibration of predictive intervals, which can be substantially too narrow or wide depending on the time. We propose a locally adaptive factor process for characterizing multivariate mean-covariance changes in continuous time, allowing locally varying smoothness in both the mean and covariance matrix. This process is constructed utilizing latent dictionary functions evolving in time through nested Gaussian processes and linearly related to the observed data with a sparse mapping. Using a diffential equation representation, we bypass usual computational bottlenecks in obtaining MCMC and online algorithms for approximate Bayesian inference. The performance is assessed in simulations and illustrated in a financial application. © 2014 Daniele Durante, Bruno Scarpa and David B. Dunson.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Scaling up data augmentation MCMC via calibration",
      "authors": "Duan, LL; Johndrow, JE; Dunson, DB",
      "published_date": "October 1, 2018",
      "doi": "",
      "abstract": "© 2018 Leo L. Duan, James E. Johndrow and David B. Dunson. There has been considerable interest in making Bayesian inference more scalable. In big data settings, most of the focus has been on reducing the computing time per iteration rather than reducing the number of iterations needed in Markov chain Monte Carlo (MCMC). This article considers data augmentation MCMC (DA-MCMC), a widely used technique. DA-MCMC samples tend to become highly autocorrelated in large samples, due to a mis-calibration problem in which conditional posterior distributions given augmented data are too concentrated. This makes it necessary to collect very long MCMC paths to obtain acceptably low MC error. To combat this inefficiency, we propose a family of calibrated data augmentation algorithms, which appropriately adjust the variance of conditional posterior distributions. A Metropolis-Hastings step is used to eliminate bias in the stationary distribution of the resulting sampler. Compared to existing alternatives, this approach can dramatically reduce MC error by reducing autocorrelation and increasing the effective number of DA-MCMC samples per unit of computing time. The approach is simple and applicable to a broad variety of existing data augmentation algorithms. We focus on three popular generalized linear models: probit, logistic and Poisson log-linear. Dramatic gains in computational efficiency are shown in applications.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "No penalty no tears: Least squares in high-dimensional linear models",
      "authors": "Wang, X; Dunson, D; Leng, C",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 by the author(s). Ordinary least squares (OI,S) is the default method for fitting linear models, but is not applicable for problems with dimensionality larger than the sample size. For these problems, we advocate the use of a generalized version of OLS motivated by ridge regression, and propose two novel three-step algorithms involving least squares fitting and hard thresholding. The algorithms are methodologically simple to understand intuitively, computationally easy to implement efficiently, and theoretically appealing for choosing models consistently. Numerical exercises comparing our methods with penalization-based approaches in simulations and data analyses illustrate the great potential of the proposed algorithms.",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Improving prediction from dirichlet process mixtures via enrichment",
      "authors": "Wade, S; Dunson, DB; Petrone, S; Trippa, L",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Flexible covariate-dependent density estimation can be achieved by modelling the joint density of the response and covariates as a Dirichlet process mixture. An appealing aspect of this approach is that computations are relatively easy. In this paper, we examine the predictive performance of these models with an increasing number of covariates. Even for a moderate number of covariates, we find that the likelihood for x tends to dominate the posterior of the latent random partition, degrading the predictive performance of the model. To overcome this, we suggest using a different nonparametric prior, namely an enriched Dirichlet process. Our proposal maintains a simple allocation rule, so that computations remain relatively simple. Advantages are shown through both predictive equations and examples, including an application to diagnosis Alzheimer's disease. © 2014 Sara Wade, David B. Dunson, Sonia Petrone and Lorenzo Trippa.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stochastic regret minimization via Thompson Sampling",
      "authors": "Guha, S; Munagala, K",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "© 2014 S. Guha  &  K. Munagala. The Thompson Sampling (TS) policy is a widely implemented algorithm for the stochastic multiarmed bandit (MAB) problem. Given a prior distribution over possible parameter settings of the underlying reward distributions of the arms, at each time instant, the policy plays an arm with probability equal to the probability that this arm has largest mean reward conditioned on the current posterior distributions of the arms. This policy generalizes the celebrated \"probability matching\" heuristic which has been experimentally and widely observed in human decision making. However, despite its ubiquity, the Thompson Sampling policy is poorly understood. Our goal in this paper is to make progress towards understanding the empirical success of this policy. We proceed using the lens of approximation algorithms and problem definitions from stochastic optimization. We focus on an objective function termed stochastic regret that captures the expected number of times the policy plays an arm that is not the eventual best arm, where the expectation is over the prior distribution. Given such a definition, we show that TS is a 2-approximation to the optimal decision policy in two extreme but canonical scenarios. One such scenario is the two-armed bandit problem which is used as a calibration point in all bandit literature. The second scenario is stochastic optimization where the outcome of a random variable is revealed in a single play to a high or low deterministic value. We show that the 2 approximation is tight in both these scenarios. We provide an uniform analysis framework that in theory is capable of proving our conjecture that the TS policy is a 2-approximation to the optimal decision policy for minimizing stochastic regret, for any prior distribution and any time horizon.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Discussion of \"a conditional game for comparing approximations",
      "authors": "Conitzer, V",
      "published_date": "December 1, 2011",
      "doi": "",
      "abstract": "This brief paper discusses the paper by Eaton mentioned in the title [1]. Copyright 2011 by the authors.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Competing with the empirical risk minimizer in a single pass",
      "authors": "Frostig, R; Ge, R; Kakade, SM; Sidford, A",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015 A. Agarwal  &  S. Agarwal. In many estimation problems, e.g. linear and logistic regression, we wish to minimize an unknown objective given only unbiased samples of the objective function. Furthermore, we aim to achieve this using as few samples as possible. In the absence of computational constraints, the minimizer of a sample average of observed data - commonly referred to as either the empirical risk minimizer (ERM) or the M-estimator - is widely regarded as the estimation strategy of choice due to its desirable statistical convergence properties. Our goal in this work is to perform as well as the ERM, on every problem, while minimizing the use of computational resources such as running time and space usage. We provide a simple streaming algorithm which, under standard regularity assumptions on the underlying problem, enjoys the following properties: 1. The algorithm can be implemented in linear time with a single pass of the observed data, using space linear in the size of a single sample. 2. The algorithm achieves the same statistical rate of convergence as the empirical risk minimizer on every problem, even considering constant factors. 3. The algorithm's performance depends on the initial error at a rate that decreases super-polynomially. 4. The algorithm is easily parallelizable. Moreover, we quantify the (finite-sample) rate at which the algorithm becomes competitive with the ERM.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "No spurious local minima in nonconvex low rank problems: A unified geometric analysis",
      "authors": "Ge, R; Jin, C; Zheng, Y",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "Copyright 2017 by the author(s). In this paper we develop a new framework that captures the common landscape underlying the common non-convex low-rank matrix problems including matrix sensing, matrix completion and robust PCA. In particular, we show for all above problems (including asymmetric cases): 1) ail local minima are also globally optimal; 2) no high-order saddle points exists. These results explain why simple algorithms such as stochastic gradient descent have global converge, and efficiently optimize these non-convex objective functions in practice. Our framework connects and simplifies the existing analyses on optimization landscapes for matrix sensing and symmetric matrix completion. The framework naturally leads to new results for asymmetric matrix completion and robust PCA.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Efficient algorithms for large-scale generalized eigenvector computation and canonical correlation analysis",
      "authors": "Ge, R; Jin, C; Kakade, S; Netrapalli, P; Sidford, A",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 by the author(s). This paper considers the problem of canonical- correlation analysis, and more broadly, the generalized eigenvector problem for a pair of symmetric matrices. We consider the setting of finding top-A- canonical/eigen subspace, and solve these problems through a general framework that simply requires black box access to an approximate linear system solver. Instantiating this framework with acceleratcd gradient descent we obtain a running time of O log(l/) log (∗ κ/p)) where z is the total number of nonzero entries, κ is the condition number and p is the relative eigenvalue gap of the appropriate matrices. Our algorithm is linear in the input size and the number of components κup to a iog( κ) factor, which is essential for handling large-scale matrices that appear in practice. To the best of our knowledge this is the first such algorithm with global linear convergence. We hope that our results prompt further research improving the practical running time for performing these important data analysis procedures on large-scale data sets.",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stronger generalization bounds for deep nets via a compression approach",
      "authors": "Arora, S; Ge, R; Neyshabur, B; Zhang, Y",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© Copyright 2018 by the Authors. All rights reserved. Deep nets generalize well despite having more parameters than the number of training samples. Recent works try to give an explanation using PAC-Bayes and Margin-based analyses, but do not as yet result in sample complexity bounds better than naive parameter counting. The current paper shows generalization bounds that are orders of magnitude better in practice. These rely upon new succinct reparametrizations of the trained net - a compression that is explicit and efficient. These yield generalization bounds via a simple compression-based framework introduced here. Our results also provide some theoretical justification for widespread empirical success in compressing deep nets. Analysis of correctness of our compression relies upon some newly identified \"noise stability\"properties of trained deep nets, which are also experimentally verified. The study of these properties and resulting generalization bounds are also extended to convolutional nets, which had eluded earlier attempts on proving generalization.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stochastic bouncy particle sampler",
      "authors": "Pakman, A; Gilboa, D; Carlson, D; Paninski, L",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "Copyright © 2017 by the author(s). We introduce a stochastic version of the nonreversible, rejection-free Bouncy Particle Sampler (BPS), a Markov process whose sample trajectories are piecewise linear, to efficiently sample Bayesian posteriors in big datasets. We prove that in the BPS no bias is introduced by noisy evaluations of the log-likelihood gradient. On the other hand, we argue that efficiency considerations favor a small, controllable bias, in exchange for faster mixing. We introduce a simple method that controls this tradc-off. We illustrate these ideas in several examples which outperform previous approaches.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The factorized self-controlled case series method: An approach for estimating the effects of many drugs on many outcomes",
      "authors": "Moghaddass, R; Rudin, C; Madigan, D",
      "published_date": "June 1, 2016",
      "doi": "",
      "abstract": "© 2016 Moghaddass et al. We provide a hierarchical Bayesian model for estimating the effects of transient drug exposures on a collection of health outcomes, where the effects of all drugs on all outcomes are estimated simultaneously. The method possesses properties that allow it to handle important challenges of dealing with large-scale longitudinal observational databases. In particular, this model is a generalization of the self-controlled case series (SCCS) method, meaning that certain patient specific baseline rates never need to be estimated. Further, this model is formulated with layers of latent factors, which substantially reduces the number of parameters and helps with interpretability by illuminating latent classes of drugs and outcomes. We believe our work is the first to consider multivariate SCCS (in the sense of multiple outcomes) and is the first to couple latent factor analysis with SCCS. We demonstrate the approach by estimating the effects of various time-sensitive insulin treatments for diabetes.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Scalable Bayesian rule lists",
      "authors": "Yang, H; Rudin, C; Seltzer, M",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© Copyright 2017 by the authors(s). We present an algorithm for building probabilistic rule lists that is two orders of magnitude faster than previous work. Rule list algorithms are competitors for decision tree algorithms. They are associative classifiers, in that they are built from pre-mined association rules. They have a logical structure that is a sequence of IF-THEN rules, identical to a decision list or one-sided decision tree. Instead of using greedy splitting and pruning like decision tree algorithms, we aim to fully optimize over rule lists, striking a practical balance between accuracy, inter-pretability, and computational speed. The algorithm presented here uses a mixture of theoretical bounds (tight enough to have practical implications as a screening or bounding procedure), computational reuse, and highly tuned language libraries to achieve computational efficiency. Currently, for many practical problems, this method achieves better accuracy and sparsity than decision trees, with practical running times. The predictions in each leaf are probabilistic.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The P-norm push: A simple convex ranking algorithm that concentrates at the top of the list",
      "authors": "Rudin, C",
      "published_date": "November 30, 2009",
      "doi": "",
      "abstract": "We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufficiently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This \"push\" near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓp-norms to provide a specific type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm's objective is unique in a specific sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. © 2009 Cynthia Rudin.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Data quality assurance and performance measurement of data mining for preventive maintenance of power grid",
      "authors": "Wu, L; Kaiser, G; Rudin, C; Anderson, R",
      "published_date": "September 15, 2011",
      "doi": "10.1145/2018673.2018679",
      "abstract": "Ensuring reliability as the electrical grid morphs into the \"smart grid\" will require innovations in how we assess the state of the grid, for the purpose of proactive maintenance, rather than reactive maintenance; in the future, we will not only react to failures, but also try to anticipate and avoid them using predictive modeling (machine learning and data mining) techniques. To help in meeting this challenge, we present the Neutral Online Visualization-aided Autonomic evaluation framework (NOVA) for evaluating machine learning and data mining algorithms for preventive maintenance on the electrical grid. NOVA has three stages provided through a unified user interface: evaluation of input data quality, evaluation of machine learning and data mining results, and evaluation of the reliability improvement of the power grid. A prototype version of NOVA has been deployed for the power grid in New York City, and it is able to evaluate machine learning and data mining systems effectively and efficiently. Copyright 2011 ACM.",
      "publication_location": "Proceedings of the 1st International Workshop on Data Mining for Service and Maintenance, Kdd4service 2011   Held in Conjunction With Sigkdd'11",
      "link": "http://dx.doi.org/10.1145/2018673.2018679",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Interpretable Almost-Exact Matching for Causal Inference.",
      "authors": "Dieng, A; Liu, Y; Roy, S; Rudin, C; Volfovsky, A",
      "published_date": "April 2019",
      "doi": "",
      "abstract": "Matching methods are heavily used in the social and health sciences due to their interpretability. We aim to create the highest possible quality of treatment-control matches for categorical data in the potential outcomes framework. The method proposed in this work aims to match units on a weighted Hamming distance, taking into account the relative importance of the covariates; the algorithm aims to match units on as many relevant variables as possible. To do this, the algorithm creates a hierarchy of covariate combinations on which to match (similar to downward closure), in the process solving an optimization problem for each unit in order to construct the optimal matches. The algorithm uses a single dynamic program to solve all of the units' optimization problems simultaneously. Notable advantages of our method over existing matching procedures are its high-quality interpretable matches, versatility in handling different data distributions that may have irrelevant variables, and ability to handle missing data by matching on as many available covariates as possible.",
      "publication_location": "Proceedings of Machine Learning Research",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/31198908",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deep generative models for relational data with side information",
      "authors": "Hu, C; Rai, P; Carin, L",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© Copyright 2017 by the author(s). We present a probabilistic framework for overlapping community discovery and link prediction for relational data, given as a graph. The proposed framework has: (1) a deep architecture which enables us to infer multiple layers of latent features/communities for each node, providing superior link prediction performance on more complex networks and better interpretability of the latent features; and (2) a regression model which allows directly conditioning the node latent features on the side information available in form of node attributes. Our framework handles both (1) and (2) via a clean, unified model, which enjoys full local conjugacy via data augmentation, and facilitates efficient inference via closed form Gibbs sampling. Moreover, inference cost scales in the number of edges which is attractive for massive but sparse networks. Our framework is also easily extendable to model weighted networks with count-valued edges. We compare with various state-of-the-art methods and report results, both quantitative and qualitative, on several benchmark data sets.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Beta-negative binomial process and poisson factor analysis",
      "authors": "Zhou, M; Hannah, LA; Dunson, DB; Carin, L",
      "published_date": "January 1, 2012",
      "doi": "",
      "abstract": "© Copyright 2012 by the authors. A beta-negative binomial (BNB) process is proposed, leading to a beta-gamma-Poisson process, which may be viewed as a \"multiscoop\" generalization of the beta-Bernoulli process. The BNB process is augmented into a beta-gamma-gamma-Poisson hierarchical structure, and applied as a nonparametric Bayesian prior for an infinite Poisson factor analysis model. A finite approximation for the beta process Lévy random measure is constructed for convenient implementation. Efficient MCMC computations are performed with data augmentation and marginalization techniques. Encouraging results are shown on document count matrix factorization.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "https://hdl.handle.net/10161/15597",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A stick-breaking construction of the beta process",
      "authors": "Paisley, J; Zaas, A; Woods, CW; Ginsburg, GS; Carin, L",
      "published_date": "September 17, 2010",
      "doi": "",
      "abstract": "We present and derive a new stick-breaking construction of the beta process. The construction is closely related to a special case of the stick-breaking construction of the Dirich-let process (Sethuraman, 1994) applied to the beta distribution. We derive an inference procedure that relies on Monte Carlo integration to reduce the number of parameters to be inferred, and present results on synthetic data, the MNIST handwritten digits data set and a time-evolving gene expression data set. Copyright 2010 by the author(s)/owner(s).",
      "publication_location": "Icml 2010   Proceedings, 27th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Developing an Algorithm to Detect Early Childhood Obesity in Two Tertiary Pediatric Medical Centers.",
      "authors": "Lingren, T; Thaker, V; Brady, C; Namjou, B; Kennebeck, S; Bickel, J; Patibandla, N; Ni, Y; Van Driest, SL; Chen, L; Roach, A; Cobb, B; Kirby, J; Denny, J; Bailey-Davis, L; Williams, MS; Marsolo, K; Solti, I; Holm, IA; Harley, J; Kohane, IS; Savova, G; Crimmins, N",
      "published_date": "July 20, 2016",
      "doi": "10.4338/ACI-2016-01-RA-0015",
      "abstract": "OBJECTIVE: The objective of this study is to develop an algorithm to accurately identify children with severe early onset childhood obesity (ages 1-5.99 years) using structured and unstructured data from the electronic health record (EHR). INTRODUCTION: Childhood obesity increases risk factors for cardiovascular morbidity and vascular disease. Accurate definition of a high precision phenotype through a standardize tool is critical to the success of large-scale genomic studies and validating rare monogenic variants causing severe early onset obesity. DATA AND METHODS: Rule based and machine learning based algorithms were developed using structured and unstructured data from two EHR databases from Boston Children's Hospital (BCH) and Cincinnati Children's Hospital and Medical Center (CCHMC). Exclusion criteria including medications or comorbid diagnoses were defined. Machine learning algorithms were developed using cross-site training and testing in addition to experimenting with natural language processing features. RESULTS: Precision was emphasized for a high fidelity cohort. The rule-based algorithm performed the best overall, 0.895 (CCHMC) and 0.770 (BCH). The best feature set for machine learning employed Unified Medical Language System (UMLS) concept unique identifiers (CUIs), ICD-9 codes, and RxNorm codes. CONCLUSIONS: Detecting severe early childhood obesity is essential for the intervention potential in children at the highest long-term risk of developing comorbidities related to obesity and excluding patients with underlying pathological and non-syndromic causes of obesity assists in developing a high-precision cohort for genetic study. Further such phenotyping efforts inform future practical application in health care environments utilizing clinical decision support.",
      "publication_location": "Applied Clinical Informatics",
      "link": "http://dx.doi.org/10.4338/ACI-2016-01-RA-0015",
      "citations": 13,
      "readership": 79,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "XTALOPT Version r12: An open-source evolutionary algorithm for crystal structure prediction",
      "authors": "Avery, P; Toher, C; Curtarolo, S; Zurek, E",
      "published_date": "April 1, 2019",
      "doi": "10.1016/j.cpc.2018.11.016",
      "abstract": "© 2018 Elsevier B.V. Version 12 of XTALOPT, an evolutionary algorithm for crystal structure prediction, is now available for download from the CPC program library or the XTALOPT website, http://xtalopt.github.io. The new version includes: a method for calculating hardness using a machine learning algorithm within AFLOW-ML (Automatic FLOW for Materials Discovery — Machine Learning), the ability to predict hard materials, a generic optimizer (which allows the user to employ many optimizers that were previously not supported), and the ability to generate simulated XRD (X-ray diffraction) patterns. New version program summary: Program Title: XTALOPT Program Files doi: http://dx.doi.org/10.17632/jt5pvnnm39.3 Licensing provisions: 3-Clause BSD [1] Programming language: C++ External routines/libraries: QT [2], QWT [3], AVOGADRO2 [4,5] (optional), LIBSSH [6], OPEN BABEL [7,8] (separate executable), OBJCRYST++ [9,10] (separate executable), AFLOW-ML [11,12] (through network), and an external program for optimizing the geometries of extended systems. Subprograms used: PUGIXML [13], SPGLIB [14], XTALCOMP [15], RANDSPG [16]. Nature of problem: Computationally predicting stable and/or hard crystal structures given only their stoichiometry. Solution method: Evolutionary algorithms (EAs), which use ideas from biological evolution, are optimization algorithms whose goal is to find the optimal solution for a problem that has many degrees of freedom. For a priori crystal structure prediction (CSP), EAs search to find the lattice parameters and atomic coordinates that, for example, minimize the energy/enthalpy or maximize the hardness. The XTALOPT EA for crystal structure prediction is published under the 3-Clause BSD License, which is an open source license that is officially recognized by the Open Source Initiative [17]. More information is available in the following publications: XTALOPT's original implementation [18], previous version announcements [19–22], manuscripts detailing the subprograms XTALOPT employs: XTALCOMP [23] and RANDSPG [24], and the XtalOpt website [25]. Reasons for new version: Since the release of XTALOPT version r11 in January 2018, the following changes have been made: • Added a hardness calculation via AFLOW-ML (Automatic FLOW for Materials Discovery — Machine Learning). • Added a hardness fitness function, which allows for the prediction of hard structures. • Added a generic optimizer, which allows the user to employ many previously unsupported optimizers for minimizing the geometry of an extended system. • Added the ability to generate a simulated XRD (X-ray Diffraction) pattern. • Added the ability to use different optimizers and queuing interfaces for each optimization step. • Implemented various bug fixes. Summary of revisions: The theoretical hardness of a crystal can now be automatically calculated during an XTALOPT run. The hardness is calculated through a linear relationship with the shear modulus (originally discovered by Teter [26]) as reported by Chen [27]. The shear modulus is obtained via AFLOW-ML [11,12], which employs a machine learning model trained with the AFLOW Automatic Elasticity Library (AEL) [28,29]. As a result, the EA can employ a new fitness function, which attempts to minimize the enthalpy and maximize the hardness of the predicted structures. This facilitates the search for crystals that are both stable and hard. Additionally, a new generic optimizer was added that allows the user to employ optimizers that were previously not supported (ADF BAND [30] and ADF DFTB [31] are examples that we have thoroughly tested). The only caveat is that the rules for the generic optimizer, which are provided in the online tutorial, must be followed. OPEN BABEL [7,8] is used to read the output of the generic optimizer. Because of the addition of an executable that uses OBJCRYST++ [9,10], a simulated XRD pattern of a crystal can now also be generated during a structure search. Finally, different optimizers and different queuing interfaces can now be used for each optimization step.",
      "publication_location": "Computer Physics Communications",
      "link": "http://dx.doi.org/10.1016/j.cpc.2018.11.016",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Adversarial feature matching for text generation",
      "authors": "Zhang, Y; Gan, Z; Fan, K; Chen, Z; Henao, R; Shen, D; Carin, L",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© Copyright 2017 by the authors(s). The Generative Adversarial Network (GAN) has achieved great success in generating realistic (real-valued) synthetic data. However, convergence issues and difficulties dealing with discrete data hinder the applicability of GAN to text. We propose a framework for generating realistic text via adversarial training. We employ a long short-term memory network as generator, and a convolutional network as discriminator. Instead of using the standard objective of GAN, we propose matching the high-dimensional latent feature distributions of real and synthetic sentences, via a kernelized discrepancy metric. This eases adversarial training by alleviating the mode-collapsing problem. Our experiments show superior performance in quantitative evaluation, and demonstrate that our model can generate realistic-looking sentences.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Variational inference for stick-breaking beta process priors",
      "authors": "Paisley, J; Carin, L; Blei, D",
      "published_date": "October 7, 2011",
      "doi": "",
      "abstract": "We present a variational Bayesian inference algorithm for the stick-breaking construction of the beta process. We derive an alternate representation of the beta process that is amenable to variational inference, and present a bound relating the truncated beta process to its infinite counterpart. We assess performance on two matrix factorization problems, using a non-negative factorization model and a linear-Gaussian model. Copyright 2011 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 28th International Conference on Machine Learning, Icml 2011",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Incomplete-data classification using logistic regression",
      "authors": "Williams, D; Liao, X; Xue, Y; Carin, L",
      "published_date": "December 1, 2005",
      "doi": "",
      "abstract": "A logistic regression classification algorithm is developed for problems in which the feature vectors may be missing data (features). Single or multiple imputation for the missing data is avoided by performing analytic integration with an estimated conditional density function (conditioned on the non-missing data). Conditional density functions are estimated using a Gaussian mixture model (GMM), with parameter estimation performed using both expectation maximization (EM) and Variational Bayesian EM (VB-EM). Using widely available real data, we demonstrate the general advantage of the VB-EM GMM estimation for handling incomplete data, vis-à-vis the EM algorithm. Moreover, it is demonstrated that the approach proposed here is generally superior to standard imputation procedures.",
      "publication_location": "Icml 2005   Proceedings of the 22nd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The dynamic hierarchical Dirichlet process",
      "authors": "Ren, L; Dunson, DB; Carin, L",
      "published_date": "November 26, 2008",
      "doi": "",
      "abstract": "The dynamic hierarchical Dirichlet process (dHDP) is developed to model the time-evolving statistical properties of sequential data sets. The data collected at any time point are represented via a mixture associated with an appropriate underlying model, in the framework of HDP. The statistical properties of data collected at consecutive time points are linked via a random parameter that controls their probabilistic similarity. The sharing mechanisms of the time-evolving data are derived, and a relatively simple Markov Chain Monte Carlo sampler is developed. Experimental results are presented to demonstrate the model. Copyright 2008 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 25th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multi-task compressive sensing with dirichlet process priors",
      "authors": "Qi, Y; Liu, D; Dunson, D; Carin, L",
      "published_date": "November 26, 2008",
      "doi": "",
      "abstract": "Compressive sensing (CS) is an emerging £eld that, under appropriate conditions, can signi£cantly reduce the number of measurements required for a given signal. In many applications, one is interested in multiple signals that may be measured in multiple CS-type measurements, where here each signal corresponds to a sensing \"task\". In this paper we propose a novel multitask compressive sensing framework based on a Bayesian formalism, where a Dirichlet process (DP) prior is employed, yielding a principled means of simultaneously inferring the appropriate sharing mechanisms as well as CS inversion for each task. A variational Bayesian (VB) inference algorithm is employed to estimate the full posterior on the model parameters. Copyright 2008 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 25th International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Nonparametric factor analysis with beta process priors",
      "authors": "Paisley, J; Carin, L",
      "published_date": "December 9, 2009",
      "doi": "",
      "abstract": "We propose a nonparametric extension to the factor analysis problem using a beta process prior. This beta process factor analysis (BP-FA) model allows for a dataset to be decomposed into a linear combination of a sparse set of factors, providing information on the underlying structure of the observations. As with the Dirichlet process, the beta process is a fully Bayesian conjugate prior, which allows for analytical posterior calculation and straightforward inference. We derive a variational Bayes inference algorithm and demonstrate the model on the MNIST digits and HGDP-CEPH cell line panel datasets.",
      "publication_location": "Proceedings of the 26th International Conference on Machine Learning, Icml 2009",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Latent Gaussian models for topic modeling",
      "authors": "Hu, C; Ryu, E; Carlson, D; Wang, Y; Carin, L",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "A new approach is proposed for topic modeling, in which the latent matrix factorization employs Gaussian priors, rather than the Dirichlet-class priors widely used in such models. The use of a latent-Gaussian model permits simple and efficient approximate Bayesian posterior inference, via the Laplace approximation. On multiple datasets, the proposed approach is demonstrated to yield results as accurate as state-of-the-art approaches based on Dirichlet constructions, at a small fraction of the computation. The framework is general enough to jointly model text and binary data, here demonstrated to produce accurate and fast results for joint analysis of voting rolls and the associated legislative text. Further, it is demonstrated how the technique may be scaled up to massive data, with encouraging performance relative to alternative methods.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stochastic gradient monomial gamma sampler",
      "authors": "Zhang, Y; Chen, C; Gan, Z; Henao, R; Carin, L",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© Copyright 2017 by the authors(s). Recent advances in stochastic gradient techniques have made it possible to estimate posterior distributions from large datasets via Markov Chain Monte Carlo (MCMC). However, when the target posterior is multimodal, mixing performance is often poor. This results in inadequate exploration of the posterior distribution. A framework is proposed to improve the sampling efficiency of stochastic gradient MCMC, based on Hamiltonian Monte Carlo. A generalized kinetic function is leveraged, delivering superior stationary mixing, especially for multimodal distributions. Techniques are also discussed to overcome the practical issues introduced by this generalization. It is shown that the proposed approach is better at exploring complex multimodal posterior distributions, as demonstrated on multiple applications and in comparison with other stochastic gradient MCMC methods.",
      "publication_location": "34th International Conference on Machine Learning, Icml 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Scalable bayesian low-rank decomposition of incomplete multiway tensors",
      "authors": "Rai, P; Wang, Y; Guo, S; Chen, G; Dunson, D; Carin, L",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "Copyright 2014 by the author(s). We present a scalable Bayesian framework for low-rank decomposition of multiway tensor data with missing observations. The key issue of pre-specifying the rank of the decomposition is sidestepped in a principled manner using a multiplicative gamma process prior. Both continuous and binary data can be analyzed under the framework, in a coherent way using fully conjugate Bayesian analysis. In particular, the analysis in the non-conjugate binary case is facilitated via the use of the Pólya-Gamma sampling strategy which elicits closed-form Gibbs sampling updates. The resulting samplers are efficient and enable us to apply our framework to large-scale problems, with time-complexity that is linear in the number of observed entries in the tensor. This is especially attractive in analyzing very large but sparsely observed tensors with very few known entries. Moreover, our method admits easy extension to the supervised setting where entities in one or more tensor modes have labels. Our method outperforms several state-of-the-art tensor decomposition methods on various synthetic and benchmark real-world datasets.",
      "publication_location": "31st International Conference on Machine Learning, Icml 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Modeling correlated arrival events with latent semi-Markov processes",
      "authors": "Lian, W; Rao, V; Eriksson, B; Carin, L",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "2014 The analysis of correlated point process data has wide applications, ranging from biomedical research to network analysis. In this work, we model such data as generated by a latent collection of continuous-time binary semi-Markov processes,' corresponding to external events appearing and disappearing. A continuous-time modeling framework is more appropriate for multichannel point process data than a binning approach requiring time discretization, and we show connections between our model and recent ideas from the discrete-time literature. We describe an efficient MCMC algorithm for posterior inference, and apply our ideas to both synthetic data and a real-world biometrics application.",
      "publication_location": "31st International Conference on Machine Learning, Icml 2014",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Inferring latent structure from mixed real and categorical relational data",
      "authors": "Salazar, E; Cain, MS; Darling, EF; Mitroff, SR; Carin, L",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "We consider analysis of relational data (a matrix), in which the rows correspond to subjects (e.g., people) and the columns correspond to attributes. The elements of the matrix may be a mix of real and categorical. Each subject and attribute is characterized by a latent binary feature vector, and an inferred matrix maps each row-column pair of binary feature vectors to an observed matrix element. The latent binary features of the rows are modeled via a multivariate Gaussian distribution with low-rank covariance matrix, and the Gaussian random variables are mapped to latent binary features via a probit link. The same type construction is applied jointly to the columns. The model infers latent, low-dimensional binary features associated with each row and each column, as well correlation structure between all rows and between all columns. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "https://hdl.handle.net/10161/8953",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Region-based value iteration for partially observable Markov decision processes",
      "authors": "Li, H; Liao, X; Carin, L",
      "published_date": "October 6, 2006",
      "doi": "",
      "abstract": "An approximate region-based value iteration (RBVI) algorithm is proposed to find the optimal policy for a partially observable Markov decision process (POMDP). The proposed RBVI approximates the true polyhedral partition of the belief simplex with an ellipsoidal partition, such that the optimal value function is linear in each of the ellipsoidal regions. The position and shape of each region, as well as the gradient (alpha-vector) of the optimal value function in the region, are parameterized explicitly, and are estimated via efficient expectation maximization (EM) and variational Bayesian EM (VBEM), based on a set of selected sample belief points. The RBVI maintains a much smaller number of alpha-vectors than point-based methods and yields a more parsimonious representation that approximates the true value function in the maximum likelihood (ML) sense. The results on benchmark problems show that the proposed RBVI is comparable in performance to state-of-the-art algorithms, despite of the small number of alpha-vectors that are used.",
      "publication_location": "Icml 2006   Proceedings of the 23rd International Conference on Machine Learning",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Lognormal and gamma mixed negative binomial regression",
      "authors": "Zhou, M; Li, L; Dunson, D; Carin, L",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "In regression analysis of counts, a lack of simple and efficient algorithms for posterior computation has made Bayesian approaches appear unattractive and thus underdeveloped. We propose a lognormal and gamma mixed negative binomial (NB) regression model for counts, and present efficient closed-form Bayesian inference; unlike conventional Poisson models, the proposed approach has two free parameters to include two different kinds of random effects, and allows the incorporation of prior information, such as sparsity in the regression coefficients. By placing a gamma distribution prior on the NB dispersion parameter r, and connecting a log-normal distribution prior with the logit of the NB probability parameter p, efficient Gibbs sampling and variational Bayes inference are both developed. The closed-form updates are obtained by exploiting conditional conjugacy via both a compound Poisson representation and a Polya-Gamma distribution based data augmentation approach. The proposed Bayesian inference can be implemented routinely, while being easily generalizable to more complex settings involving multivariate dependence structures. The algorithms are illustrated using real examples. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "https://hdl.handle.net/10161/8954",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Supplementary material for \"x",
      "authors": "Tao, C; Chen, L; Henao, R; Feng, J; Carin, L",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Exploring the mind: Integrating questionnaires and fMRI",
      "authors": "Salazar, E; Bogdan, R; Gorka, A; Hariri, AR; Carin, L",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "A new model is developed for joint analysis of ordered, categorical, real and count data. The ordered and categorical data are answers to questionnaires, the (word) count data correspond to the text questions from the questionnaires, and the real data correspond to fMRI responses for each subject. The Bayesian model employs the von Mises distribution in a novel manner to infer sparse graphical models jointly across people, questions, fMRI stimuli and brain region, with this integrated within a new matrix factorization based on latent binary features. The model is compared with simpler alternatives on two real datasets. We also demonstrate the ability to predict the response of the brain to visual stimuli (as measured by fMRI), based on knowledge of how the associated person answered classical questionnaires. Copyright 2013 by the author(s).",
      "publication_location": "30th International Conference on Machine Learning, Icml 2013",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "X",
      "authors": "Tao, C; Chen, L; Henao, R; Feng, J; Carin, L",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 by the Authors All rights reserved. To assess the difference between real and synthetic data, Generative Adversarial Networks (GANs) are trained using a distribution discrepancy measure. Three widely employed measures are information-theoretic divergences, integral probability metrics, and Hilbert space discrepancy metrics. We elucidate the theoretical connections between these three popular GAN training criteria and propose a novel procedure, called x2-GAN, that is conceptually simple, stable at training and resistant to mode collapse. Our procedure naturally generalizes to address the problem of simultaneous matching of multiple distributions. Further, we propose a resampling strategy that significantly improves sample quality, by repurpos-ing the trained critic function via an importance weighting mechanism. Experiments show that the proposed procedure improves stability and convergence, and yields state-of-art results on a wide range of generative modeling tasks.",
      "publication_location": "35th International Conference on Machine Learning, Icml 2018",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "USER AND DEVICE LOCALIZATION USING PROBABILISTIC DEVICE LOG TRILATERATION",
      "authors": "Bouchard, G; Ulloa, LR; Andreoli, J-M; Ciriza, V; Zoeter, O",
      "published_date": "January 1, 2011",
      "doi": "",
      "abstract": "",
      "publication_location": "Ieee International Workshop on Machine Learning for Signal Processing, Mlsp",
      "link": "http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000298259900046&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=47d3190e77e5a3a53558812f597b0b92",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Detecting weak but hierarchically-structured patterns in networks",
      "authors": "Singh, A; Nowak, R; Calderbank, R",
      "published_date": "December 1, 2010",
      "doi": "",
      "abstract": "The ability to detect weak distributed activation patterns in networks is critical to several applications, such as identifying the onset of anomalous activity or incipient congestion in the Internet, or faint traces of a biochemical spread by a sensor network. This is a challenging problem since weak distributed patterns can be invisible in per node statistics as well as a global network-wide aggregate. Most prior work considers situations in which the activation/non-activation of each node is statistically independent, but this is unrealistic in many problems. In this paper, we consider structured patterns arising from statistical dependencies in the activation process. Our contributions are three-fold. First, we propose a sparsifying transform that succinctly represents structured activation patterns that conform to a hierarchical dependency graph. Second, we establish that the proposed transform facilitates detection of very weak activation patterns that cannot be detected with existing methods. Third, we show that the structure of the hierarchical dependency graph governing the activation process, and hence the network transform, can be learnt from very few (logarithmic in network size) independent snapshots of network activity. Copyright 2010 by the authors.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multi-Level Mean-Shift Clustering for Single-Channel Radio Frequency Signal Separation",
      "authors": "Zhou, Y; Feng, Y; Tarokh, V; Gintautas, V; McClelland, J; Garagic, D",
      "published_date": "October 1, 2019",
      "doi": "10.1109/MLSP.2019.8918879",
      "abstract": "© 2019 IEEE. Emerging wireless communication applications have led to a crowded radio frequency (RF) spectrum. Therefore, it is desired to develop signal separation techniques that can extract different RF signals from their mixtures. Existing signal separation approaches typically require multiple observations of the signal mixtures and depend on statistical independence among the signals. In this paper, we consider separating multiple RF wireless signals from their single-channel superposition. These RF signals are transmitted in their corresponding high-frequency pass bands with diverse power spectrum densities, bandwidths, and time durations. We propose a signal separation approach that exploits the mean-shift clustering algorithm with multiple levels of cluster sizes to identify RF signals with different bandwidths in the spectrogram of the superposed signal. We demonstrate the effectiveness of our approach by separating RF signals using real datasets.",
      "publication_location": "Ieee International Workshop on Machine Learning for Signal Processing, Mlsp",
      "link": "http://dx.doi.org/10.1109/MLSP.2019.8918879",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Average case analysis of high-dimensional block-sparse recovery and regression for arbitrary designs",
      "authors": "Bajwa, WU; Duarte, MF; Calderbank, R",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "This paper studies conditions for high-dimensional inference when the set of observations is given by a linear combination of a small number of groups of columns of a design matrix, termed the \"block-sparse\" case. In this regard, it first specifies conditions on the design matrix under which most of its block submatrices are well conditioned. It then leverages this result for average-case analysis of high-dimensional block-sparse recovery and regression. In contrast to earlier works: (i) this paper provides conditions on arbitrary designs that can be explicitly computed in polynomial time, (ii) the provided conditions translate into near-optimal scaling of the number of observations with the number of active blocks of the design matrix, and (iii) the conditions suggest that the spectral norm, rather than the column/block coherences, of the design matrix fundamentally limits the performance of computational methods in high-dimensional settings.",
      "publication_location": "Journal of Machine Learning Research",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Markov-modulated marked poisson processes for check-in data",
      "authors": "Pan, J; Rao, V; Agarwal, PK; Gelfand, AE",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 by the author(s). We develop continuous-time probabilistic models to study trajectory data consisting of times and locations of user 'check-ins'. We model the data as realizations of a marked point process, with intensity and mark-distribution modulated by a latent Markov jump process (MJP). We also include user-heterogeneity in our model by assigning each user a vector of 'preferred locations'. Our model extends latent Dirichlet allocation by dropping the bag-of-words assumption and operating in continuous time. We show how an appropriate choice of priors allows efficient posterior inference. Our experiments demonstrate the usefulness of our approach by comparing with various baselines on a variety of tasks.copyright",
      "publication_location": "33rd International Conference on Machine Learning, Icml 2016",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Communications inspired linear discriminant analysis",
      "authors": "Chen, M; Carson, W; Rodrigues, M; Calderbank, R; Carin, L",
      "published_date": "October 10, 2012",
      "doi": "",
      "abstract": "We study the problem of supervised linear dimensionality reduction, taking an information-theoretic viewpoint. The linear projection matrix is designed by maximizing the mutual information between the projected signal and the class label. By harnessing a recent theoretical result on the gradient of mutual information, the above optimization problem can be solved directly using gradient descent, without requiring simplification of the objective function. Theoretical analysis and empirical comparison are made between the proposed method and two closely related methods, and comparisons are also made with a method in which Rényi entropy is used to define the mutual information (in this case the gradient may be computed simply, under a special parameter setting). Relative to these alternative approaches, the proposed method achieves promising results on real datasets. Copyright 2012 by the author(s)/owner(s).",
      "publication_location": "Proceedings of the 29th International Conference on Machine Learning, Icml 2012",
      "link": "https://hdl.handle.net/10161/8956",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Support Vector Machines for Differential Prediction.",
      "authors": "Kuusisto, F; Santos Costa, V; Nassif, H; Burnside, E; Page, D; Shavlik, J",
      "published_date": 2014,
      "doi": "10.1007/978-3-662-44851-9_4",
      "abstract": "Machine learning is continually being applied to a growing set of fields, including the social sciences, business, and medicine. Some fields present problems that are not easily addressed using standard machine learning approaches and, in particular, there is growing interest in differential prediction. In this type of task we are interested in producing a classifier that specifically characterizes a subgroup of interest by maximizing the difference in predictive performance for some outcome between subgroups in a population. We discuss adapting maximum margin classifiers for differential prediction. We first introduce multiple approaches that do not affect the key properties of maximum margin classifiers, but which also do not directly attempt to optimize a standard measure of differential prediction. We next propose a model that directly optimizes a standard measure in this field, the uplift measure. We evaluate our models on real data from two medical applications and show excellent results.",
      "publication_location": "Mach Learn Knowl Discov Databases",
      "link": "http://dx.doi.org/10.1007/978-3-662-44851-9_4",
      "citations": 4,
      "readership": 26,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Board-level functional fault diagnosis using multikernel support vector machines and incremental learning",
      "authors": "Ye, F; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "February 1, 2014",
      "doi": "10.1109/TCAD.2013.2287184",
      "abstract": "Advanced machine learning techniques offer an unprecedented opportunity to increase the accuracy of board-level functional fault diagnosis and reduce product cost through successful repair. Ambiguous or incorrect diagnosis results lead to long debug times and even wrong repair actions, which significantly increase repair cost. We propose a smart diagnosis method based on multikernel support vector machines (MK-SVMs) and incremental learning. The MK-SVM method leverages a linear combination of single kernels to achieve accurate faulty-component classification based on the errors observed. The MK-SVMs thus generated can also be updated based on incremental learning, which allows the diagnosis system to quickly adapt to new error observations and provide even more accurate fault diagnosis. Two complex boards from industry, currently in volume production, are used to validate the proposed diagnosis approach in terms of diagnosis accuracy (success rate) and quantifiable improvements over previously proposed machine-learning methods based on several single-kernel SVMs and artificial neural networks. © 1982-2012 IEEE.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2013.2287184",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Classifying abnormalities in computed tomography radiology reports with rule-based and natural language processing models",
      "authors": "Han, S; Tian, J; Kelly, M; Selvakumaran, V; Henao, R; Rubin, GD; Lo, JY",
      "published_date": "January 1, 2019",
      "doi": "10.1117/12.2513577",
      "abstract": "© 2019 SPIE. Purpose: When conducting machine learning algorithms on classification and detection of abnormalities for medical imaging, many researchers are faced with the problem that it is hard to get enough labeled data. This is especially difficult for modalities such as computed tomography (CT) with potentially 1000 or more slice images per case. To solve this problem, we plan to use machine learning algorithms to identify abnormalities within existing radiologist reports, thus creating case-level labels that may be used for weakly supervised training on the image data. We used a two-stage procedure to label the CT reports. In the first stage, a rule-based system labeled a smaller set of cases automatically with high accuracy. In the second stage, we developed machine learing algorithms using the labels from the rule-based system and word vectors learned without supervision from unlabeled CT reports. Method: In this study, we used approximately 24,000 CT reports from Duke University Health System. We initially focused on three organs, the lungs, liver/gallbladder, and kidneys. We first developed a rule-based system that can quickly identify certain types of abnormalities within CT reports with high accuracy. For each organ and disease combination, we produced several hundred cases with rule-based labels. These labels were combined with word vectors generated using word2vec from all the unlabeled reports to train two different machine learning algorithms: (a) average of word vectors merged by logistic regression, and (b) recurrent neural network (RNN). Result: Performance was evaluated by receiver operating characteristic (ROC) area under the curve (AUC) over an independent test set of 440 reports for which those organs were manually labeled as normal or abnormal by clinical experts. For lungs, the performance was 0.796 for average word vector and 0.827 for RNN. Liver performance was 0.683 for average word vector and 0.791 for RNN. For kidneys, it was 0.786 for average word vector and 0.928 for RNN. Conclusion: It is possible to label large numbers of cases automatically. These rule-based labels can then be used to build a classification model for large numbers of medical reports. With word2vec and other transfer learning techniques, we can get a good generalization performance.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2513577",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Agonists of G-Protein-Coupled Odorant Receptors Are Predicted from Chemical Features.",
      "authors": "Bushdid, C; de March, CA; Fiorucci, S; Matsunami, H; Golebiowski, J",
      "published_date": "May 3, 2018",
      "doi": "10.1021/acs.jpclett.8b00633",
      "abstract": "Predicting the activity of chemicals for a given odorant receptor is a longstanding challenge. Here the activity of 258 chemicals on the human G-protein-coupled odorant receptor (OR)51E1, also known as prostate-specific G-protein-coupled receptor 2 (PSGR2), was virtually screened by machine learning using 4884 chemical descriptors as input. A systematic control by functional in vitro assays revealed that a support vector machine algorithm accurately predicted the activity of a screened library. It allowed us to identify two novel agonists in vitro for OR51E1. The transferability of the protocol was assessed on OR1A1, OR2W1, and MOR256-3 odorant receptors, and, in each case, novel agonists were identified with a hit rate of 39-50%. We further show how ligands' efficacy is encoded into residues within OR51E1 cavity using a molecular modeling protocol. Our approach allows widening the chemical spaces associated with odorant receptors. This machine-learning protocol based on chemical features thus represents an efficient tool for screening ligands for G-protein-coupled odorant receptors that modulate non-olfactory functions or, upon combinatorial activation, give rise to our sense of smell.",
      "publication_location": "The Journal of Physical Chemistry Letters",
      "link": "http://dx.doi.org/10.1021/acs.jpclett.8b00633",
      "citations": 11,
      "readership": 30,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "A systematic study of the class imbalance problem in convolutional neural networks.",
      "authors": "Buda, M; Maki, A; Mazurowski, MA",
      "published_date": "October 2018",
      "doi": "10.1016/j.neunet.2018.07.011",
      "abstract": "In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.",
      "publication_location": "Neural Netw",
      "link": "http://dx.doi.org/10.1016/j.neunet.2018.07.011",
      "citations": 218,
      "readership": 965,
      "tweets": 222,
      "news_mentions": ""
    },
    {
      "title": "Bayesian compressive sensing and projection optimization",
      "authors": "Ji, S; Carin, L",
      "published_date": "August 23, 2007",
      "doi": "10.1145/1273496.1273544",
      "abstract": "This paper introduces a new problem for which machine-learning tools may make an impact. The problem considered is termed \"compressive sensing\", in which a real signal of dimension N is measured accurately based on K << N real measurements. This is achieved under the assumption that the underlying signal has a sparse representation in some basis (e.g., wavelets). In this paper we demonstrate how techniques developed in machine learning, specifically sparse Bayesian regression and active learning, may be leveraged to this new problem. We also point out future research directions in compressive sensing of interest to the machine-learning community.",
      "publication_location": "Acm International Conference Proceeding Series",
      "link": "http://dx.doi.org/10.1145/1273496.1273544",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Use of Mobile Health Apps and Wearable Technology to Assess Changes and Predict Pain During Treatment of Acute Pain in Sickle Cell Disease: Feasibility Study.",
      "authors": "Johnson, A; Yang, F; Gollarahalli, S; Banerjee, T; Abrams, D; Jonassaint, J; Jonassaint, C; Shah, N",
      "published_date": "December 2, 2019",
      "doi": "10.2196/13671",
      "abstract": "BACKGROUND: Sickle cell disease (SCD) is an inherited red blood cell disorder affecting millions worldwide, and it results in many potential medical complications throughout the life course. The hallmark of SCD is pain. Many patients experience daily chronic pain as well as intermittent, unpredictable acute vaso-occlusive painful episodes called pain crises. These pain crises often require acute medical care through the day hospital or emergency department. Following presentation, a number of these patients are subsequently admitted with continued efforts of treatment focused on palliative pain control and hydration for management. Mitigating pain crises is challenging for both the patients and their providers, given the perceived unpredictability and subjective nature of pain. OBJECTIVE: The objective of this study was to show the feasibility of using objective, physiologic measurements obtained from a wearable device during an acute pain crisis to predict patient-reported pain scores (in an app and to nursing staff) using machine learning techniques. METHODS: For this feasibility study, we enrolled 27 adult patients presenting to the day hospital with acute pain. At the beginning of pain treatment, each participant was given a wearable device (Microsoft Band 2) that collected physiologic measurements. Pain scores from our mobile app, Technology Resources to Understand Pain Assessment in Patients with Pain, and those obtained by nursing staff were both used with wearable signals to complete time stamp matching and feature extraction and selection. Following this, we constructed regression and classification machine learning algorithms to build between-subject pain prediction models. RESULTS: Patients were monitored for an average of 3.79 (SD 2.23) hours, with an average of 5826 (SD 2667) objective data values per patient. As expected, we found that pain scores and heart rate decreased for most patients during the course of their stay. Using the wearable sensor data and pain scores, we were able to create a regression model to predict subjective pain scores with a root mean square error of 1.430 and correlation between observations and predictions of 0.706. Furthermore, we verified the hypothesis that the regression model outperformed the classification model by comparing the performances of the support vector machines (SVM) and the SVM for regression. CONCLUSIONS: The Microsoft Band 2 allowed easy collection of objective, physiologic markers during an acute pain crisis in adults with SCD. Features can be extracted from these data signals and matched with pain scores. Machine learning models can then use these features to feasibly predict patient pain scores.",
      "publication_location": "Jmir Mhealth and Uhealth",
      "link": "http://dx.doi.org/10.2196/13671",
      "citations": 1,
      "readership": "(None,)",
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "In-Depth Characterization and Validation of Human Urine Metabolomes Reveal Novel Metabolic Signatures of Lower Urinary Tract Symptoms.",
      "authors": "Hao, L; Greer, T; Page, D; Shi, Y; Vezina, CM; Macoska, JA; Marker, PC; Bjorling, DE; Bushman, W; Ricke, WA; Li, L",
      "published_date": "August 9, 2016",
      "doi": "10.1038/srep30869",
      "abstract": "Lower urinary tract symptoms (LUTS) are a range of irritative or obstructive symptoms that commonly afflict aging population. The diagnosis is mostly based on patient-reported symptoms, and current medication often fails to completely eliminate these symptoms. There is a pressing need for objective non-invasive approaches to measure symptoms and understand disease mechanisms. We developed an in-depth workflow combining urine metabolomics analysis and machine learning bioinformatics to characterize metabolic alterations and support objective diagnosis of LUTS. Machine learning feature selection and statistical tests were combined to identify candidate biomarkers, which were statistically validated with leave-one-patient-out cross-validation and absolutely quantified by selected reaction monitoring assay. Receiver operating characteristic analysis showed highly-accurate prediction power of candidate biomarkers to stratify patients into disease or non-diseased categories. The key metabolites and pathways may be possibly correlated with smooth muscle tone changes, increased collagen content, and inflammation, which have been identified as potential contributors to urinary dysfunction in humans and rodents. Periurethral tissue staining revealed a significant increase in collagen content and tissue stiffness in men with LUTS. Together, our study provides the first characterization and validation of LUTS urinary metabolites and pathways to support the future development of a urine-based diagnostic test for LUTS.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/srep30869",
      "citations": 16,
      "readership": 30,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Recent developments in pediatric retina.",
      "authors": "Cai, S; Therattil, A; Vajzovic, L",
      "published_date": "May 2020",
      "doi": "10.1097/ICU.0000000000000650",
      "abstract": "PURPOSE OF REVIEW: Pediatric retina is an exciting, but also challenging field, where patient age and cooperation can limit ease of diagnosis of a broad range of congenital and acquired diseases, inherited retinal degenerations are mostly untreatable and surgical outcomes can be quite different from those for adults. This review aims to highlight some recent advances and trends that are improving our ability to care for children with retinal conditions. RECENT FINDINGS: Studies have demonstrated the feasibility of multimodal imaging even in nonsedated infants, with portable optical coherence tomography (OCT) and OCT angiography in particular offering structural insights into diverse pediatric retinal conditions. Encouraging long-term outcomes of subretinal voretigene neparvovec-rzyl injection for RPE65 mutation-associated Leber congenital amaurosis have inspired research on the optimization of subretinal gene delivery and gene therapy for other inherited retinal degenerations. In retinopathy of prematurity, machine learning and smartphone-based imaging can facilitate screening, and studies have highlighted favorable outcomes from intravitreal anti-vascular endothelial growth factor (anti-VEGF) injections. A nomogram for pediatric pars plana sclerotomy site placement may improve safety in complex surgeries. SUMMARY: Multimodal imaging, gene therapy, machine learning and surgical innovation have been and will continue to be important to advances in pediatric retina.",
      "publication_location": "Current Opinion in Ophthalmology: Retina and Vitreous Disorders",
      "link": "http://dx.doi.org/10.1097/ICU.0000000000000650",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Information-theoretic syndrome and root-cause analysis for guiding board-level fault diagnosis",
      "authors": "Ye, F; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "September 9, 2013",
      "doi": "10.1109/ETS.2013.6569364",
      "abstract": "High-volume manufacturing of complex electronic products involves functional test at board level to ensure low defect escapes. Machine-learning techniques have recently been proposed for reasoning-based functional-fault diagnosis system to achieve high diagnosis accuracy. However, machine learning requires a rich set of test items (syndromes) and a sizable database of faulty boards. An insufficient number of failed boards, ambiguous root-cause identification, and redundant or irrelevant syndromes can render machine learning ineffective. We propose an evaluation and enhancement framework based on information theory for guiding diagnosis systems using syndrome and root-cause analysis. Syndrome analysis based on subset selection provides a representative set of syndromes with minimum redundancy and maximum relevance. Root-cause analysis measures the discriminative ability of differentiating a given root cause from others. The metrics obtained from the proposed framework can also provide guidelines for test redesign to enhance diagnosis. A real board from industry, currently in volume production, and an additional synthetic board, based on data extrapolated from another real board, are used to demonstrate the effectiveness of the proposed framework. © 2013 IEEE.",
      "publication_location": "Proceedings   2013 18th Ieee European Test Symposium, Ets 2013",
      "link": "http://dx.doi.org/10.1109/ETS.2013.6569364",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Prediction of wave ripple characteristics using genetic programming",
      "authors": "Goldstein, EB; Coco, G; Murray, AB",
      "published_date": "December 1, 2013",
      "doi": "10.1016/j.csr.2013.09.020",
      "abstract": "We integrate published data sets of field and laboratory experiments of wave ripples and use genetic programming, a machine learning paradigm, in an attempt to develop a universal equilibrium predictor for ripple wavelength, height, and steepness. We train our genetic programming algorithm with data selected using a maximum dissimilarity selection routine. Thanks to this selection algorithm; we use less data to train the genetic programming software, allowing more data to be used as testing (i.e., to compare our predictor vs. common prediction schemes). Our resulting predictor is smooth and physically meaningful, different from other machine learning derived results. Furthermore our predictor incorporates wave orbital ripples that were previously excluded from empirical prediction schemes, notably ripples in coarse sediment and long wavelength, low height ripples ('hummocks'). This new predictor shows ripple length to be a weakly nonlinear function of both bottom orbital excursion and grain size. Ripple height and steepness are both nonlinear functions of grain size and predicted ripple length (i.e., bottom orbital excursion and grain size). We test this new prediction scheme against common (and recent) predictors and the new predictors yield a lower normalized root mean squared error using the testing data. This study further demonstrates the applicability of machine learning techniques to successfully develop well performing predictors if data sets are large in size, extensive in scope, multidimensional, and nonlinear. © 2013 Elsevier Ltd.",
      "publication_location": "Continental Shelf Research",
      "link": "http://dx.doi.org/10.1016/j.csr.2013.09.020",
      "citations": 27,
      "readership": 30,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Human Gut Microbiota Predicts Susceptibility to Vibrio cholerae Infection.",
      "authors": "Midani, FS; Weil, AA; Chowdhury, F; Begum, YA; Khan, AI; Debela, MD; Durand, HK; Reese, AT; Nimmagadda, SN; Silverman, JD; Ellis, CN; Ryan, ET; Calderwood, SB; Harris, JB; Qadri, F; David, LA; LaRocque, RC",
      "published_date": "July 13, 2018",
      "doi": "10.1093/infdis/jiy192",
      "abstract": "Background: Cholera is a public health problem worldwide, and the risk factors for infection are only partially understood. Methods: We prospectively studied household contacts of patients with cholera to compare those who were infected to those who were not. We constructed predictive machine learning models of susceptibility, using baseline gut microbiota data. We identified bacterial taxa associated with susceptibility to Vibrio cholerae infection and tested these taxa for interactions with V. cholerae in vitro. Results: We found that machine learning models based on gut microbiota, as well as models based on known clinical and epidemiological risk factors, predicted V. cholerae infection. A predictive gut microbiota of roughly 100 bacterial taxa discriminated between contacts who developed infection and those who did not. Susceptibility to cholera was associated with depleted levels of microbes from the phylum Bacteroidetes. By contrast, a microbe associated with cholera by our modeling framework, Paracoccus aminovorans, promoted the in vitro growth of V. cholerae. Gut microbiota structure, clinical outcome, and age were also linked. Conclusion: These findings support the hypothesis that abnormal gut microbial communities are a host factor related to V. cholerae susceptibility.",
      "publication_location": "J Infect Dis",
      "link": "http://dx.doi.org/10.1093/infdis/jiy192",
      "citations": 11,
      "readership": 66,
      "tweets": 34,
      "news_mentions": 11
    },
    {
      "title": "Clinical phenotyping in selected national networks: demonstrating the need for high-throughput, portable, and computational methods.",
      "authors": "Richesson, RL; Sun, J; Pathak, J; Kho, AN; Denny, JC",
      "published_date": "July 2016",
      "doi": "10.1016/j.artmed.2016.05.005",
      "abstract": "OBJECTIVE:The combination of phenomic data from electronic health records (EHR) and clinical data repositories with dense biological data has enabled genomic and pharmacogenomic discovery, a first step toward precision medicine. Computational methods for the identification of clinical phenotypes from EHR data will advance our understanding of disease risk and drug response, and support the practice of precision medicine on a national scale. METHODS:Based on our experience within three national research networks, we summarize the broad approaches to clinical phenotyping and highlight the important role of these networks in the progression of high-throughput phenotyping and precision medicine. We provide supporting literature in the form of a non-systematic review. RESULTS:The practice of clinical phenotyping is evolving to meet the growing demand for scalable, portable, and data driven methods and tools. The resources required for traditional phenotyping algorithms from expert defined rules are significant. In contrast, machine learning approaches that rely on data patterns will require fewer clinical domain experts and resources. CONCLUSIONS:Machine learning approaches that generate phenotype definitions from patient features and clinical profiles will result in truly computational phenotypes, derived from data rather than experts. Research networks and phenotype developers should cooperate to develop methods, collaboration platforms, and data standards that will enable computational phenotyping and truly modernize biomedical research and precision medicine.",
      "publication_location": "Artificial Intelligence in Medicine",
      "link": "http://dx.doi.org/10.1016/j.artmed.2016.05.005",
      "citations": 32,
      "readership": 107,
      "tweets": 9,
      "news_mentions": ""
    },
    {
      "title": "Pathway analysis using random forests with bivariate node-split for survival outcomes.",
      "authors": "Pang, H; Datta, D; Zhao, H",
      "published_date": "January 15, 2010",
      "doi": "10.1093/bioinformatics/btp640",
      "abstract": "MOTIVATION: There is great interest in pathway-based methods for genomics data analysis in the research community. Although machine learning methods, such as random forests, have been developed to correlate survival outcomes with a set of genes, no study has assessed the abilities of these methods in incorporating pathway information for analyzing microarray data. In general, genes that are identified without incorporating biological knowledge are more difficult to interpret. Correlating pathway-based gene expression with survival outcomes may lead to biologically more meaningful prognosis biomarkers. Thus, a comprehensive study on how these methods perform in a pathway-based setting is warranted. RESULTS: In this article, we describe a pathway-based method using random forests to correlate gene expression data with survival outcomes and introduce a novel bivariate node-splitting random survival forests. The proposed method allows researchers to identify important pathways for predicting patient prognosis and time to disease progression, and discover important genes within those pathways. We compared different implementations of random forests with different split criteria and found that bivariate node-splitting random survival forests with log-rank test is among the best. We also performed simulation studies that showed random forests outperforms several other machine learning algorithms and has comparable results with a newly developed component-wise Cox boosting model. Thus, pathway-based survival analysis using machine learning tools represents a promising approach in dissecting pathways and for generating new biological hypothesis from microarray studies. AVAILABILITY: R package Pwayrfsurvival is available from URL: http://www.duke.edu/~hp44/pwayrfsurvival.htm. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",
      "publication_location": "Bioinformatics",
      "link": "http://dx.doi.org/10.1093/bioinformatics/btp640",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An application of Random Forests to a genome-wide association dataset: methodological considerations & new findings.",
      "authors": "Goldstein, BA; Hubbard, AE; Cutler, A; Barcellos, LF",
      "published_date": "June 14, 2010",
      "doi": "10.1186/1471-2156-11-49",
      "abstract": "BACKGROUND: As computational power improves, the application of more advanced machine learning techniques to the analysis of large genome-wide association (GWA) datasets becomes possible. While most traditional statistical methods can only elucidate main effects of genetic variants on risk for disease, certain machine learning approaches are particularly suited to discover higher order and non-linear effects. One such approach is the Random Forests (RF) algorithm. The use of RF for SNP discovery related to human disease has grown in recent years; however, most work has focused on small datasets or simulation studies which are limited. RESULTS: Using a multiple sclerosis (MS) case-control dataset comprised of 300 K SNP genotypes across the genome, we outline an approach and some considerations for optimally tuning the RF algorithm based on the empirical dataset. Importantly, results show that typical default parameter values are not appropriate for large GWA datasets. Furthermore, gains can be made by sub-sampling the data, pruning based on linkage disequilibrium (LD), and removing strong effects from RF analyses. The new RF results are compared to findings from the original MS GWA study and demonstrate overlap. In addition, four new interesting candidate MS genes are identified, MPHOSPH9, CTNNA3, PHACTR2 and IL7, by RF analysis and warrant further follow-up in independent studies. CONCLUSIONS: This study presents one of the first illustrations of successfully analyzing GWA data with a machine learning algorithm. It is shown that RF is computationally feasible for GWA data and the results obtained make biologic sense based on previous studies. More importantly, new genes were identified as potentially being associated with MS, suggesting new avenues of investigation for this complex disease.",
      "publication_location": "Bmc Genetics",
      "link": "http://dx.doi.org/10.1186/1471-2156-11-49",
      "citations": 125,
      "readership": 217,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Preparing an annotated gold standard corpus to share with extramural investigators for de-identification research.",
      "authors": "Deleger, L; Lingren, T; Ni, Y; Kaiser, M; Stoutenborough, L; Marsolo, K; Kouril, M; Molnar, K; Solti, I",
      "published_date": "August 2014",
      "doi": "10.1016/j.jbi.2014.01.014",
      "abstract": "OBJECTIVE: The current study aims to fill the gap in available healthcare de-identification resources by creating a new sharable dataset with realistic Protected Health Information (PHI) without reducing the value of the data for de-identification research. By releasing the annotated gold standard corpus with Data Use Agreement we would like to encourage other Computational Linguists to experiment with our data and develop new machine learning models for de-identification. This paper describes: (1) the modifications required by the Institutional Review Board before sharing the de-identification gold standard corpus; (2) our efforts to keep the PHI as realistic as possible; (3) and the tests to show the effectiveness of these efforts in preserving the value of the modified data set for machine learning model development. MATERIALS AND METHODS: In a previous study we built an original de-identification gold standard corpus annotated with true Protected Health Information (PHI) from 3503 randomly selected clinical notes for the 22 most frequent clinical note types of our institution. In the current study we modified the original gold standard corpus to make it suitable for external sharing by replacing HIPAA-specified PHI with newly generated realistic PHI. Finally, we evaluated the research value of this new dataset by comparing the performance of an existing published in-house de-identification system, when trained on the new de-identification gold standard corpus, with the performance of the same system, when trained on the original corpus. We assessed the potential benefits of using the new de-identification gold standard corpus to identify PHI in the i2b2 and PhysioNet datasets that were released by other groups for de-identification research. We also measured the effectiveness of the i2b2 and PhysioNet de-identification gold standard corpora in identifying PHI in our original clinical notes. RESULTS: Performance of the de-identification system using the new gold standard corpus as a training set was very close to training on the original corpus (92.56 vs. 93.48 overall F-measures). Best i2b2/PhysioNet/CCHMC cross-training performances were obtained when training on the new shared CCHMC gold standard corpus, although performances were still lower than corpus-specific trainings. DISCUSSION AND CONCLUSION: We successfully modified a de-identification dataset for external sharing while preserving the de-identification research value of the modified gold standard corpus with limited drop in machine learning de-identification performance.",
      "publication_location": "J Biomed Inform",
      "link": "http://dx.doi.org/10.1016/j.jbi.2014.01.014",
      "citations": 20,
      "readership": 54,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Automated problem list generation and physicians perspective from a pilot study.",
      "authors": "Devarakonda, MV; Mehta, N; Tsou, C-H; Liang, JJ; Nowacki, AS; Jelovsek, JE",
      "published_date": "September 2017",
      "doi": "10.1016/j.ijmedinf.2017.05.015",
      "abstract": "OBJECTIVE: An accurate, comprehensive and up-to-date problem list can help clinicians provide patient-centered care. Unfortunately, problem lists created and maintained in electronic health records by providers tend to be inaccurate, duplicative and out of date. With advances in machine learning and natural language processing, it is possible to automatically generate a problem list from the data in the EHR and keep it current. In this paper, we describe an automated problem list generation method and report on insights from a pilot study of physicians' assessment of the generated problem lists compared to existing providers-curated problem lists in an institution's EHR system. MATERIALS AND METHODS: The natural language processing and machine learning-based Watson1 method models clinical thinking in identifying a patient's problem list using clinical notes and structured data. This pilot study assessed the Watson method and included 15 randomly selected, de-identified patient records from a large healthcare system that were each planned to be reviewed by at least two internal medicine physicians. The physicians created their own problem lists, and then evaluated the overall usefulness of their own problem lists (P), Watson generated problem lists (W), and the existing EHR problem lists (E) on a 10-point scale. The primary outcome was pairwise comparisons of P, W, and E. RESULTS: Six out of the 10 invited physicians completed 27 assessments of P, W, and E, and in process evaluated 732 Watson generated problems and 444 problems in the EHR system. As expected, physicians rated their own lists, P, highest. However, W was rated higher than E. Among 89% of assessments, Watson identified at least one important problem that physicians missed. CONCLUSION: Cognitive computing systems like this Watson system hold the potential for accurate, problem-list-centered summarization of patient records, potentially leading to increased efficiency, better clinical decision support, and improved quality of patient care.",
      "publication_location": "Int J Med Inform",
      "link": "http://dx.doi.org/10.1016/j.ijmedinf.2017.05.015",
      "citations": 10,
      "readership": 83,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Pathway-based identification of SNPs predictive of survival.",
      "authors": "Pang, H; Hauser, M; Minvielle, S",
      "published_date": "June 2011",
      "doi": "10.1038/ejhg.2011.3",
      "abstract": "In recent years, several association analysis methods for case-control studies have been developed. However, as we turn towards the identification of single nucleotide polymorphisms (SNPs) for prognosis, there is a need to develop methods for the identification of SNPs in high dimensional data with survival outcomes. Traditional methods for the identification of SNPs have some drawbacks. First, the majority of the approaches for case-control studies are based on single SNPs. Second, SNPs that are identified without incorporating biological knowledge are more difficult to interpret. Random forests has been found to perform well in gene expression analysis with survival outcomes. In this paper we present the first pathway-based method to correlate SNP with survival outcomes using a machine learning algorithm. We illustrate the application of pathway-based analysis of SNPs predictive of survival with a data set of 192 multiple myeloma patients genotyped for 500,000 SNPs. We also present simulation studies that show that the random forests technique with log-rank score split criterion outperforms several other machine learning algorithms. Thus, pathway-based survival analysis using machine learning tools represents a promising approach for the identification of biologically meaningful SNPs associated with disease.",
      "publication_location": "European Journal of Human Genetics : Ejhg",
      "link": "http://dx.doi.org/10.1038/ejhg.2011.3",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Glaucoma progression detection using structural retinal nerve fiber layer measurements and functional visual field points.",
      "authors": "Yousefi, S; Goldbaum, MH; Balasubramanian, M; Jung, T-P; Weinreb, RN; Medeiros, FA; Zangwill, LM; Liebmann, JM; Girkin, CA; Bowd, C",
      "published_date": "April 2014",
      "doi": "10.1109/TBME.2013.2295605",
      "abstract": "Machine learning classifiers were employed to detect glaucomatous progression using longitudinal series of structural data extracted from retinal nerve fiber layer thickness measurements and visual functional data recorded from standard automated perimetry tests. Using the collected data, a longitudinal feature vector was created for each patient's eye by computing the norm 1 difference vector of the data at the baseline and at each follow-up visit. The longitudinal features from each patient's eye were then fed to the machine learning classifier to classify each eye as stable or progressed over time. This study was performed using several machine learning classifiers including Bayesian, Lazy, Meta, and Tree, composing different families. Combinations of structural and functional features were selected and ranked to determine the relative effectiveness of each feature. Finally, the outcomes of the classifiers were assessed by several performance metrics and the effectiveness of structural and functional features were analyzed.",
      "publication_location": "Ieee Trans Biomed Eng",
      "link": "http://dx.doi.org/10.1109/TBME.2013.2295605",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Vertebral artery fusiform aneurysm geometry in predicting rupture risk.",
      "authors": "Zhao, X; Gold, N; Fang, Y; Xu, S; Zhang, Y; Liu, J; Gupta, A; Huang, H",
      "published_date": "October 31, 2018",
      "doi": "10.1098/rsos.180780",
      "abstract": "Cerebral aneurysms affect a significant portion of the adult population worldwide. Despite significant progress, the development of robust techniques to evaluate the risk of aneurysm rupture remains a critical challenge. We hypothesize that vertebral artery fusiform aneurysm (VAFA) morphology may be predictive of rupture risk and can serve as a deciding factor in clinical management. To investigate the VAFA morphology, we use a combination of image analysis and machine learning techniques to study a geometric feature set computed from a depository of 37 (12 ruptured and 25 un-ruptured) aneurysm images. Of the 571 unique features we compute, we distinguish five features for use by our machine learning classification algorithm by an analysis of statistical significance. These machine learning methods achieve state-of-the-art classification performance (81.43 ± 13.08%) for the VAFA morphology, and identify five features (cross-sectional area change of aneurysm, maximum diameter of nearby distal vessel, solidity of aneurysm, maximum curvature of nearby distal vessel, and ratio of curvature between aneurysm and its nearby proximal vessel) as effective predictors of VAFA rupture risk. These results suggest that the geometric features of VAFA morphology may serve as useful non-invasive indicators for the prediction of aneurysm rupture risk in surgical settings.",
      "publication_location": "Royal Society Open Science",
      "link": "http://dx.doi.org/10.1098/rsos.180780",
      "citations": 2,
      "readership": 7,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Self-learning and adaptive board-level functional fault diagnosis",
      "authors": "Ye, F; Chakrabarty, K; Zhang, Z; Gu, X",
      "published_date": "January 1, 2015",
      "doi": "10.1109/ASPDAC.2015.7059021",
      "abstract": "© 2015 IEEE. Functional fault diagnosis is necessary for board-level product qualification. However, ambiguous diagnosis results can lead to long debug times and wrong repair actions, which significantly increase repair cost and adversely impact yield. A state-of-the-art functional fault diagnosis system involves several key components: (1) design of functional test programs, (2) collection of functional-failure syndromes, (3) building of the diagnosis engine, (4) isolation of root causes, and (5) evaluation of the diagnosis engine. Advances in each of these components can pave the way for a more effective diagnosis system, thus improving diagnosis accuracy and reducing diagnosis time. Machine-learning and data analysis techniques offer an unprecedented opportunity to develop an automated and adaptive diagnosis system to increase diagnosis accuracy and reduce diagnosis time. This paper describes how all the above components of an advanced diagnosis system can benefit from machine learning and information theory. Topics discussed include incremental learning, decision trees, root-cause analysis and evaluation metrics, data acquisition, and knowledge transfer.",
      "publication_location": "20th Asia and South Pacific Design Automation Conference, Asp Dac 2015",
      "link": "http://dx.doi.org/10.1109/ASPDAC.2015.7059021",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Detection of forgery in paintings using supervised learning",
      "authors": "Polatkan, G; Jafarpour, S; Brasoveanu, A; Hughes, S; Daubechies, I",
      "published_date": "January 1, 2009",
      "doi": "10.1109/ICIP.2009.5413338",
      "abstract": "This paper examines whether machine learning and image analysis tools can be used to assist art experts in the authentication of unknown or disputed paintings. Recent work on this topic [1] has presented some promising initial results. Our reexamination of some of these recently successful experiments shows that variations in image clarity in the experimental datasets were correlated with authenticity, and may have acted as a confounding factor, artificially improving the results. To determine the extent of this factor's influence on previous results, we provide a new \"ground truth\" data set in which originals and copies are known and image acquisition conditions are uniform. Multiple previously-successful methods are found ineffective on this new confounding-factor-free dataset, but we demonstrate that supervised machine learning on features derived from Hidden-Markov-Tree-modeling of the paintings' wavelet coefficients has the potential to distinguish copies from originals in the new dataset. ©2009 IEEE.",
      "publication_location": "Proceedings   International Conference on Image Processing, Icip",
      "link": "http://dx.doi.org/10.1109/ICIP.2009.5413338",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Improving Diagnostic Resolution of Failing ICs Through Learning",
      "authors": "Xue, Y; Li, X; Blanton, RD",
      "published_date": "June 1, 2018",
      "doi": "10.1109/TCAD.2016.2611499",
      "abstract": "© 1982-2012 IEEE. Diagnosis is the first analysis step for uncovering the root cause of failure for a defective integrated logic circuit. The conventional objective of identifying failure locations has been augmented with various physically-aware diagnosis techniques that are intended to improve both resolution and accuracy. Despite these advances, it is often the case, however, that resolution, i.e., the number of locations or candidates reported by diagnosis, exceeds the number of actual failing locations. To address this major challenge, a novel, machine-learning-based resolution improvement methodology named physically-aware diagnostic resolution enhancement (PADRE) is described. PADRE uses easily-available tester and simulation data to extract features that uniquely characterize each candidate. PADRE applies machine learning to the features to identify candidates that correspond to the actual failure locations. Through various experiments, PADRE is shown to significantly improve resolution with virtually no negative impact on accuracy. Additional experiments demonstrate that PADRE is robust against data set variation and feature-data availability.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2016.2611499",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Discriminative dictionary learning to learn effective features for detecting buried threats in ground penetrating radar data",
      "authors": "Malof, JM; Reichman, D; Collins, LM",
      "published_date": "January 1, 2017",
      "doi": "10.1117/12.2263111",
      "abstract": "© 2017 SPIE. The ground penetrating radar (GPR) is a popular remote sensing modality for buried threat detection. In this work we focus on the development of supervised machine learning algorithms that automatically identify buried threats in GPR data. An important step in many of these algorithms is feature extraction, where statistics or other measures are computed from the raw GPR data, and then provided to the machine learning algorithms for classification. It is well known that an effective feature can lead to major performance improvements and, as a result, a variety of features have been proposed in the literature. Most of these features have been handcrafted, or designed through trial and error experimentation. Dictionary learning is a class of algorithms that attempt to automatically learn effective features directly from the data (e.g., raw GPR data), with little or no supervision. Dictionary learning methods have yielded state-of-theart performance on many problems, including image recognition, and in this work we adapt them to GPR data in order to learn effective features for buried threat classification. We employ the LC-KSVD algorithm, which is a discriminative dictionary learning approach, as opposed to a purely reconstructive one like the popular K-SVD algorithm. We use a large collection of GPR data to show that LC-KSVD outperforms two other approaches: the popular Histogram of oriented gradient (HOG) with a linear classifier, and HOG with a nonlinear classifier (the Random Forest).",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2263111",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Development and Validation of a Deep Learning System for Diabetic Retinopathy and Related Eye Diseases Using Retinal Images From Multiethnic Populations With Diabetes.",
      "authors": "Ting, DSW; Cheung, CY-L; Lim, G; Tan, GSW; Quang, ND; Gan, A; Hamzah, H; Garcia-Franco, R; San Yeo, IY; Lee, SY; Wong, EYM; Sabanayagam, C; Baskaran, M; Ibrahim, F; Tan, NC; Finkelstein, EA; Lamoureux, EL; Wong, IY; Bressler, NM; Sivaprasad, S; Varma, R; Jonas, JB; He, MG; Cheng, C-Y; Cheung, GCM; Aung, T; Hsu, W; Lee, ML; Wong, TY",
      "published_date": "December 12, 2017",
      "doi": "10.1001/jama.2017.18152",
      "abstract": "Importance: A deep learning system (DLS) is a machine learning technology with potential for screening diabetic retinopathy and related eye diseases. Objective: To evaluate the performance of a DLS in detecting referable diabetic retinopathy, vision-threatening diabetic retinopathy, possible glaucoma, and age-related macular degeneration (AMD) in community and clinic-based multiethnic populations with diabetes. Design, Setting, and Participants: Diagnostic performance of a DLS for diabetic retinopathy and related eye diseases was evaluated using 494 661 retinal images. A DLS was trained for detecting diabetic retinopathy (using 76 370 images), possible glaucoma (125 189 images), and AMD (72 610 images), and performance of DLS was evaluated for detecting diabetic retinopathy (using 112 648 images), possible glaucoma (71 896 images), and AMD (35 948 images). Training of the DLS was completed in May 2016, and validation of the DLS was completed in May 2017 for detection of referable diabetic retinopathy (moderate nonproliferative diabetic retinopathy or worse) and vision-threatening diabetic retinopathy (severe nonproliferative diabetic retinopathy or worse) using a primary validation data set in the Singapore National Diabetic Retinopathy Screening Program and 10 multiethnic cohorts with diabetes. Exposures: Use of a deep learning system. Main Outcomes and Measures: Area under the receiver operating characteristic curve (AUC) and sensitivity and specificity of the DLS with professional graders (retinal specialists, general ophthalmologists, trained graders, or optometrists) as the reference standard. Results: In the primary validation dataset (n = 14 880 patients; 71 896 images; mean [SD] age, 60.2 [2.2] years; 54.6% men), the prevalence of referable diabetic retinopathy was 3.0%; vision-threatening diabetic retinopathy, 0.6%; possible glaucoma, 0.1%; and AMD, 2.5%. The AUC of the DLS for referable diabetic retinopathy was 0.936 (95% CI, 0.925-0.943), sensitivity was 90.5% (95% CI, 87.3%-93.0%), and specificity was 91.6% (95% CI, 91.0%-92.2%). For vision-threatening diabetic retinopathy, AUC was 0.958 (95% CI, 0.956-0.961), sensitivity was 100% (95% CI, 94.1%-100.0%), and specificity was 91.1% (95% CI, 90.7%-91.4%). For possible glaucoma, AUC was 0.942 (95% CI, 0.929-0.954), sensitivity was 96.4% (95% CI, 81.7%-99.9%), and specificity was 87.2% (95% CI, 86.8%-87.5%). For AMD, AUC was 0.931 (95% CI, 0.928-0.935), sensitivity was 93.2% (95% CI, 91.1%-99.8%), and specificity was 88.7% (95% CI, 88.3%-89.0%). For referable diabetic retinopathy in the 10 additional datasets, AUC range was 0.889 to 0.983 (n = 40 752 images). Conclusions and Relevance: In this evaluation of retinal images from multiethnic cohorts of patients with diabetes, the DLS had high sensitivity and specificity for identifying diabetic retinopathy and related eye diseases. Further research is necessary to evaluate the applicability of the DLS in health care settings and the utility of the DLS to improve vision outcomes.",
      "publication_location": "Jama",
      "link": "http://dx.doi.org/10.1001/jama.2017.18152",
      "citations": 336,
      "readership": 503,
      "tweets": 331,
      "news_mentions": 5
    },
    {
      "title": "Board-level functional fault diagnosis using learning based on incremental support-vector machines",
      "authors": "Ye, F; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "December 1, 2012",
      "doi": "10.1109/ATS.2012.49",
      "abstract": "Advanced machine learning techniques offer an unprecedented opportunity to increase the accuracy of board-level functional fault diagnosis based on the historical data of successfully repaired boards. However, the training complexity increases significantly in diagnosis systems due to the increasing amount of the historical data. We propose a smart learning method in the diagnosis system using incremental support-vector machines (SVMs). The SVMs updated using incremental learning allow the diagnosis system to quickly adapt to new error observations and provide more accurate fault diagnosis. Two sets of large-scale synthetic data generated from the log information of two complex industrial boards, in volume production, are used to validate the proposed diagnosis approach in terms of training time and diagnosis accuracy over a previously proposed diagnosis system based on simple support-vector machines. © 2012 IEEE.",
      "publication_location": "Proceedings of the Asian Test Symposium",
      "link": "http://dx.doi.org/10.1109/ATS.2012.49",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Relevance vector machine and support vector machine classifier analysis of scanning laser polarimetry retinal nerve fiber layer measurements.",
      "authors": "Bowd, C; Medeiros, FA; Zhang, Z; Zangwill, LM; Hao, J; Lee, T-W; Sejnowski, TJ; Weinreb, RN; Goldbaum, MH",
      "published_date": "April 2005",
      "doi": "10.1167/iovs.04-1122",
      "abstract": "PURPOSE: To classify healthy and glaucomatous eyes using relevance vector machine (RVM) and support vector machine (SVM) learning classifiers trained on retinal nerve fiber layer (RNFL) thickness measurements obtained by scanning laser polarimetry (SLP). METHODS: Seventy-two eyes of 72 healthy control subjects (average age = 64.3 +/- 8.8 years, visual field mean deviation = -0.71 +/- 1.2 dB) and 92 eyes of 92 patients with glaucoma (average age = 66.9 +/- 8.9 years, visual field mean deviation = -5.32 +/- 4.0 dB) were imaged with SLP with variable corneal compensation (GDx VCC; Laser Diagnostic Technologies, San Diego, CA). RVM and SVM learning classifiers were trained and tested on SLP-determined RNFL thickness measurements from 14 standard parameters and 64 sectors (approximately 5.6 degrees each) obtained in the circumpapillary area under the instrument-defined measurement ellipse (total 78 parameters). Ten-fold cross-validation was used to train and test RVM and SVM classifiers on unique subsets of the full 164-eye data set and areas under the receiver operating characteristic (AUROC) curve for the classification of eyes in the test set were generated. AUROC curve results from RVM and SVM were compared to those for 14 SLP software-generated global and regional RNFL thickness parameters. Also reported was the AUROC curve for the GDx VCC software-generated nerve fiber indicator (NFI). RESULTS: The AUROC curves for RVM and SVM were 0.90 and 0.91, respectively, and increased to 0.93 and 0.94 when the training sets were optimized with sequential forward and backward selection (resulting in reduced dimensional data sets). AUROC curves for optimized RVM and SVM were significantly larger than those for all individual SLP parameters. The AUROC curve for the NFI was 0.87. CONCLUSIONS: Results from RVM and SVM trained on SLP RNFL thickness measurements are similar and provide accurate classification of glaucomatous and healthy eyes. RVM may be preferable to SVM, because it provides a Bayesian-derived probability of glaucoma as an output. These results suggest that these machine learning classifiers show good potential for glaucoma diagnosis.",
      "publication_location": "Investigative Ophthalmology & Visual Science",
      "link": "http://dx.doi.org/10.1167/iovs.04-1122",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Predicting Spatial Visualization Problems' Difficulty Level from Eye-Tracking Data.",
      "authors": "Li, X; Younes, R; Bairaktarova, D; Guo, Q",
      "published_date": "March 31, 2020",
      "doi": "10.3390/s20071949",
      "abstract": "The difficulty level of learning tasks is a concern that often needs to be considered in the teaching process. Teachers usually dynamically adjust the difficulty of exercises according to the prior knowledge and abilities of students to achieve better teaching results. In e-learning, because there is no teacher involvement, it often happens that the difficulty of the tasks is beyond the ability of the students. In attempts to solve this problem, several researchers investigated the problem-solving process by using eye-tracking data. However, although most e-learning exercises use the form of filling in blanks and choosing questions, in previous works, research focused on building cognitive models from eye-tracking data collected from flexible problem forms, which may lead to impractical results. In this paper, we build models to predict the difficulty level of spatial visualization problems from eye-tracking data collected from multiple-choice questions. We use eye-tracking and machine learning to investigate (1) the difference of eye movement among questions from different difficulty levels and (2) the possibility of predicting the difficulty level of problems from eye-tracking data. Our models resulted in an average accuracy of 87.60% on eye-tracking data of questions that the classifier has seen before and an average of 72.87% on questions that the classifier has not yet seen. The results confirmed that eye movement, especially fixation duration, contains essential information on the difficulty of the questions and it is sufficient to build machine-learning-based models to predict difficulty level.",
      "publication_location": "Sensors (Basel, Switzerland)",
      "link": "http://dx.doi.org/10.3390/s20071949",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Board-Level Functional Fault Identification using Streaming Data",
      "authors": "Liu, M; Ye, F; Li, X; Chakrabarty, K; Gu, X",
      "published_date": "April 1, 2019",
      "doi": "10.1109/VTS.2019.8758599",
      "abstract": "© 2019 IEEE. High integration densities and design complexity of printed-circuit boards make board-level functional fault identification extremely difficult. Machine learning provides an opportunity to identify functional faults with high accuracy and thereby reduce repair cost. However, the large volume of manufacturing data comes in a streaming format and exhibits time-dependent concept drift in a production environment. These drawbacks limit the effectiveness of traditional machine-learning algorithms. We propose a diagnosis workflow that utilizes online learning to train classifiers incrementally with a small chunk of data at each step. These online learning algorithms adapt to concept drift quickly with carefully designed update rules. A hybrid algorithm is also proposed to handle the scenario that data for varying numbers of boards are collected at different times. Experimental results using two boards in high-volume production show that, with the help of online learning and the proposed hybrid algorithm, the F1-score for diagnosis can be improved from 57.3% to 78.9%.",
      "publication_location": "Proceedings of the Ieee Vlsi Test Symposium",
      "link": "http://dx.doi.org/10.1109/VTS.2019.8758599",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Studying Aging-Related Bug Prediction Using Cross-Project Models",
      "authors": "Qin, F; Zheng, Z; Qiao, Y; Trivedi, KS",
      "published_date": "August 28, 2018",
      "doi": "10.1109/TR.2018.2864960",
      "abstract": "IEEE In long running systems, software tends to encounter performance degradation and increasing failure rate during execution. This phenomenon has been named software aging, which is caused by aging-related bugs (ARBs). Testing resource allocation can be optimized by identifying ARB-prone modules with ARB prediction. However, due to the low presence and reproducing difficulty of ARBs, it is usually hard to collect sufficient training data to carry out within-project ARB prediction. In this paper, we propose an approach named transfer learning based aging-related bug prediction (TLAP) to perform cross-project ARB prediction. TLAP first takes advantage of transfer learning to reduce distribution difference between training and testing project. Then, class imbalance learning is conducted to mitigate the severe class imbalance between ARB-prone and ARB-free modules. Finally, machine learning methods are used to handle bug prediction tasks. The effectiveness of this approach is validated and evaluated by nine groups of experiments on real software systems. Major conclusions from the experiments include the following: first, TLAP improves cross-project ARB prediction on average compared with traditional machine learning methods; second, utilizing information from multiple-projects can further improve the prediction performance on average. In the best case, it outperforms within-project prediction; third, the number of ARB-prone files and distribution similarity can influence TLAP performance.",
      "publication_location": "Ieee Transactions on Reliability",
      "link": "http://dx.doi.org/10.1109/TR.2018.2864960",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Unachievable Region in Precision-Recall Space and Its Effect on Empirical Evaluation.",
      "authors": "Boyd, K; Santos Costa, V; Davis, J; Page, CD",
      "published_date": "December 1, 2012",
      "doi": "",
      "abstract": "Precision-recall (PR) curves and the areas under them are widely used to summarize machine learning results, especially for data sets exhibiting class skew. They are often used analogously to ROC curves and the area under ROC curves. It is known that PR curves vary as class skew changes. What was not recognized before this paper is that there is a region of PR space that is completely unachievable, and the size of this region depends only on the skew. This paper precisely characterizes the size of that region and discusses its implications for empirical evaluation methodology in machine learning.",
      "publication_location": "Proc Int Conf Mach Learn",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/24350304",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Harmonizing Genetic Ancestry and Self-identified Race/Ethnicity in Genome-wide Association Studies.",
      "authors": "Fang, H; Hui, Q; Lynch, J; Honerlaw, J; Assimes, TL; Huang, J; Vujkovic, M; Damrauer, SM; Pyarajan, S; Gaziano, JM; DuVall, SL; O'Donnell, CJ; Cho, K; Chang, K-M; Wilson, PWF; Tsao, PS; VA Million Veteran Program, ; Sun, YV; Tang, H",
      "published_date": "October 3, 2019",
      "doi": "10.1016/j.ajhg.2019.08.012",
      "abstract": "Large-scale multi-ethnic cohorts offer unprecedented opportunities to elucidate the genetic factors influencing complex traits related to health and disease among minority populations. At the same time, the genetic diversity in these cohorts presents new challenges for analysis and interpretation. We consider the utility of race and/or ethnicity categories in genome-wide association studies (GWASs) of multi-ethnic cohorts. We demonstrate that race/ethnicity information enhances the ability to understand population-specific genetic architecture. To address the practical issue that self-identified racial/ethnic information may be incomplete, we propose a machine learning algorithm that produces a surrogate variable, termed HARE. We use height as a model trait to demonstrate the utility of HARE and ethnicity-specific GWASs.",
      "publication_location": "Am J Hum Genet",
      "link": "http://dx.doi.org/10.1016/j.ajhg.2019.08.012",
      "citations": 4,
      "readership": 38,
      "tweets": 78,
      "news_mentions": ""
    },
    {
      "title": "WE‐C‐213CD‐01: Decision Support for Radiation Therapy",
      "authors": "Yin, F",
      "published_date": "January 1, 2012",
      "doi": "10.1118/1.4736116",
      "abstract": "Informatics in radiation therapy is less understood. Decision support for, or knowledge‐guided, radiation therapy, is a major component of informatics, where the data is mined, modeled and turned into computable knowledge. It is critically important for radiation therapy as it employs highly complex procedures, such as IMRT and IGRT, where radiation related normal tissue/organ damages and clinical outcomes require delicate balance. Decision support can be provided in passive, active, and cooperative modes. The passive mode focuses on improved presentation of available data and knowledge to minimize cognitive burden in decision making. The active mode applies machine learning algorithms, such as support vector machines, to generate decision suggestions based on existing knowledge. The cooperative mode allows users to interact with the decision support system to iteratively reach an optimal decision. Decision support for the execution of Clinical Practice Guidelines (CPG) is another important area in which significant improvement can be achieved by helping physicians following best clinical practices specified in the guidelines. In radiation therapy, significant data, algorithms, knowledge, and guidelines have been developed in the past two decades. Various modes of decision support systems have been proposed in recent years that incorporate different data, optimization algorithms, knowledge representations, and machine learning algorithms. In this session, we will first review concepts and systems of clinical decision support in general; followed by specific applications of decision support in radiation therapy. The basic principles of making decisions when the outcomes of any available actions are uncertain are discussed. Methods for applying these principles in medical environments are described. We will conclude our discussion with a number of state‐of‐the‐art techniques for decision support in radiation treatment planning and quality assurance. Learning Objectives: 1. To discuss the need for decision support in health care and specifically in radiation therapy 2. To review major concepts and approaches in clinical decision support systems 3. To describe example systems for decision support in radiation therapy 4. To present a number of new techniques for decision support in intensity modulated radiation treatment planning. © 2012, American Association of Physicists in Medicine. All rights reserved.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.4736116",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Hardware acceleration for neuromorphic computing: An evolving view",
      "authors": "Liu, B; Liu, X; Liu, C; Wen, W; Meng, M; Li, H; Chen, Y",
      "published_date": "April 20, 2016",
      "doi": "10.1109/NVMTS.2015.7457496",
      "abstract": "© 2015 IEEE. The rapid growth of computing capacity of modern microprocessors enables the wide adoption of machine learning and neural network models. The ever-increasing demand for performance, combining with the concern on power budget, motivated the recent research on hardware acceleration for these learning algorithms. A wide spectrum of hardware platforms have been extensively studied, from conventional heterogeneous computing systems to emerging nanoscale systems. In this paper, we will review the ongoing efforts at Evolutionary Intelligence Laboratory (www.ei-lab.org) about hardware acceleration for neuromorphic computing and ma-chine learning. Realizations on various platforms such as FPGA, on-chip heterogeneous processors, and memristor-based ASIC designs will be explored. An evolving view of the accelerator de-signs for learning algorithms will be also presented.",
      "publication_location": "2015 15th Non Volatile Memory Technology Symposium, Nvmts 2015",
      "link": "http://dx.doi.org/10.1109/NVMTS.2015.7457496",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Security of neuromorphic systems: Challenges and solutions",
      "authors": "Liu, B; Yang, C; Li, H; Chen, Y; Wu, Q; Barnell, M",
      "published_date": "July 29, 2016",
      "doi": "10.1109/ISCAS.2016.7527493",
      "abstract": "© 2016 IEEE. With the rapid growth of big-data applications, advanced data processing technologies, e.g., machine learning, are widely adopted in many industry fields. Although these technologies demonstrate powerful data analyzing and processing capability, there exist some security concerns that may potentially expose the user/owner of the services to information safety risk. In particular, the adoption of neuromorphic computing systems that implement neural network and machine learning algorithms on hardware generates the need for protecting the data security in such systems. In this paper, we introduce the security concerns in the learning-based applications and propose a secured neuromorphic system design that can prevent potential attackers from replicating the learning model. Our results show that the computation accuracy of the designed neuromorphic computing system will quickly degrade when no proper authorization is given, by leveraging the drifting effect of the memristor device.",
      "publication_location": "Proceedings   Ieee International Symposium on Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/ISCAS.2016.7527493",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Human Versus Machine: Comparing a Deep Learning Algorithm to Human Gradings for Detecting Glaucoma on Fundus Photographs.",
      "authors": "",
      "published_date": "March 2020",
      "doi": "10.1016/j.ajo.2019.11.006",
      "abstract": "PURPOSE: To compare the diagnostic performance of human gradings vs predictions provided by a machine-to-machine (M2M) deep learning (DL) algorithm trained to quantify retinal nerve fiber layer (RNFL) damage on fundus photographs. DESIGN: Evaluation of a machine learning algorithm. METHODS: An M2M DL algorithm trained with RNFL thickness parameters from spectral-domain optical coherence tomography was applied to a subset of 490 fundus photos of 490 eyes of 370 subjects graded by 2 glaucoma specialists for the probability of glaucomatous optical neuropathy (GON), and estimates of cup-to-disc (C/D) ratios. Spearman correlations with standard automated perimetry (SAP) global indices were compared between the human gradings vs the M2M DL-predicted RNFL thickness values. The area under the receiver operating characteristic curves (AUC) and partial AUC for the region of clinically meaningful specificity (85%-100%) were used to compare the ability of each output to discriminate eyes with repeatable glaucomatous SAP defects vs eyes with normal fields. RESULTS: The M2M DL-predicted RNFL thickness had a significantly stronger absolute correlation with SAP mean deviation (rho=0.54) than the probability of GON given by human graders (rho=0.48; P < .001). The partial AUC for the M2M DL algorithm was significantly higher than that for the probability of GON by human graders (partial AUC = 0.529 vs 0.411, respectively; P = .016). CONCLUSION: An M2M DL algorithm performed as well as, if not better than, human graders at detecting eyes with repeatable glaucomatous visual field loss. This DL algorithm could potentially replace human graders in population screening efforts for glaucoma.",
      "publication_location": "American Journal of Ophthalmology",
      "link": "http://dx.doi.org/10.1016/j.ajo.2019.11.006",
      "citations": "(None,)",
      "readership": 16,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "A Supervised Approach to Robust Photoplethysmography Quality Assessment.",
      "authors": "Pereira, T; Gadhoumi, K; Ma, M; Liu, X; Xiao, R; Colorado, RA; Keenan, KJ; Meisel, K; Hu, X",
      "published_date": "March 2020",
      "doi": "10.1109/jbhi.2019.2909065",
      "abstract": "Early detection of Atrial Fibrillation (AFib) is crucial to prevent stroke recurrence. New tools for monitoring cardiac rhythm are important for risk stratification and stroke prevention. As many of new approaches to long-term AFib detection are now based on photoplethysmogram (PPG) recordings from wearable devices, ensuring high PPG signal-to-noise ratios is a fundamental requirement for a robust detection of AFib episodes. Traditionally, signal quality assessment is often based on the evaluation of similarity between pulses to derive signal quality indices. There are limitations to using this approach for accurate assessment of PPG quality in the presence of arrhythmia, as in the case of AFib, mainly due to substantial changes in pulse morphology. In this paper, we first tested the performance of algorithms selected from a body of studies on PPG quality assessment using a dataset of PPG recordings from patients with AFib. We then propose machine learning approaches for PPG quality assessment in 30-s segments of PPG recording from 13 stroke patients admitted to the University of California San Francisco (UCSF) neuro intensive care unit and another dataset of 3764 patients from one of the five UCSF general intensive care units. We used data acquired from two systems, fingertip PPG (fPPG) from a bedside monitor system, and radial PPG (rPPG) measured using a wearable commercial wristband. We compared various supervised machine learning techniques including k-nearest neighbors, decisions trees, and a two-class support vector machine (SVM). SVM provided the best performance. fPPG signals were used to build the model and achieved 0.9477 accuracy when tested on the data from the fPPG exclusive to the test set, and 0.9589 accuracy when tested on the rPPG data.",
      "publication_location": "Ieee Journal of Biomedical and Health Informatics",
      "link": "http://dx.doi.org/10.1109/jbhi.2019.2909065",
      "citations": 2,
      "readership": 27,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Transient-evoked otoacoustic emission signals predicting outcomes of acute sensorineural hearing loss in patients with Ménière's disease.",
      "authors": "Liu, Y-W; Kao, S-L; Wu, H-T; Liu, T-C; Fang, T-Y; Wang, P-C",
      "published_date": "March 2020",
      "doi": "10.1080/00016489.2019.1704865",
      "abstract": "Background: Fluctuating hearing loss is characteristic of Ménière's disease (MD) during acute episodes. However, no reliable audiometric hallmarks are available for counselling the hearing recovery possibility.Aims/objectives: To find parameters for predicting MD hearing outcomes.Material and methods: We applied machine learning techniques to analyse transient-evoked otoacoustic emission (TEOAE) signals recorded from patients with MD. Thirty unilateral MD patients were recruited prospectively after onset of acute cochleo-vestibular symptoms. Serial TEOAE and pure-tone audiogram (PTA) data were recorded longitudinally. Denoised TEOAE signals were projected onto the three most prominent principal directions through a linear transformation. Binary classification was performed using a support vector machine (SVM). TEOAE signal parameters, including signal energy and group delay, were compared between improved (PTA improvement: ≥15 dB) and nonimproved groups using Welch's t-test.Results: Signal energy did not differ (p = .64) but a significant difference in 1-kHz (p = .045) group delay was recorded between improved and nonimproved groups. The SVM achieved a cross-validated accuracy of >80% in predicting hearing outcomes.Conclusions and significance: This study revealed that baseline TEOAE parameters obtained during acute MD episodes, when processed through machine learning technology, may provide information on outer hair cell function to predict hearing recovery.",
      "publication_location": "Acta Oto Laryngologica",
      "link": "http://dx.doi.org/10.1080/00016489.2019.1704865",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Mining texts to efficiently generate global data on political regime types",
      "authors": "Minhas, S; Ulfelder, J; Ward, MD",
      "published_date": "July 1, 2015",
      "doi": "10.1177/2053168015589217",
      "abstract": "© The Author(s) 2015. We describe the design and results of an experiment in using text-mining and machine-learning techniques to generate annual measures of national political regime types. Valid and reliable measures of countries’ forms of national government are essential to cross-national and dynamic analysis of many phenomena of great interest to political scientists, including civil war, interstate war, democratization, and coups d’état. Unfortunately, traditional measures of regime type are very expensive to produce, and observations for ambiguous cases are often sharply contested. In this project, we train a series of support vector machine (SVM) classifiers to infer regime type from textual data sources. To train the classifiers, we used vectorized textual reports from Freedom House and the State Department as features for a training set of prelabeled regime type data. To validate our SVM classifiers, we compare their predictions in an out-of-sample context, and the performance results across a variety of metrics (accuracy, precision, recall) are very high. The results of this project highlight the ability of these techniques to contribute to producing real-time data sources for use in political science that can also be routinely updated at much lower cost than human-coded data. To this end, we set up a text-processing pipeline that pulls updated textual data from selected sources, conducts feature extraction, and applies supervised machine learning methods to produce measures of regime type. This pipeline, written in Python, can be pulled from the Github repository associated with this project and easily extended as more data becomes available.",
      "publication_location": "Research & Politics",
      "link": "http://dx.doi.org/10.1177/2053168015589217",
      "citations": 3,
      "readership": 34,
      "tweets": 41,
      "news_mentions": ""
    },
    {
      "title": "Automated algorithms combining structure and function outperform general ophthalmologists in diagnosing glaucoma.",
      "authors": "Shigueoka, LS; Vasconcellos, JPCD; Schimiti, RB; Reis, ASC; Oliveira, GOD; Gomi, ES; Vianna, JAR; Lisboa, RDDR; Medeiros, FA; Costa, VP",
      "published_date": 2018,
      "doi": "10.1371/journal.pone.0207784",
      "abstract": "PURPOSE: To test the ability of machine learning classifiers (MLCs) using optical coherence tomography (OCT) and standard automated perimetry (SAP) parameters to discriminate between healthy and glaucomatous individuals, and to compare it to the diagnostic ability of the combined structure-function index (CSFI), general ophthalmologists and glaucoma specialists. DESIGN: Cross-sectional prospective study. METHODS: Fifty eight eyes of 58 patients with early to moderate glaucoma (median value of the mean deviation = -3.44 dB; interquartile range, -6.0 to -2.4 dB) and 66 eyes of 66 healthy individuals underwent OCT and SAP tests. The diagnostic accuracy (area under the ROC curve-AUC) of 10 MLCs was compared to those obtained with the CSFI, 3 general ophthalmologists and 3 glaucoma specialists exposed to the same OCT and SAP data. RESULTS: The AUCs obtained with MLCs ranged from 0.805 (Classification Tree) to 0.931 (Radial Basis Function Network, RBF). The sensitivity at 90% specificity ranged from 51.6% (Classification Tree) to 82.8% (Bagging, Multilayer Perceptron and Support Vector Machine Gaussian). The CSFI had a sensitivity of 79.3% at 90% specificity, and the highest AUC (0.948). General ophthalmologists and glaucoma specialists' grading had sensitivities of 66.2% and 83.8% at 90% specificity, and AUCs of 0.879 and 0.921, respectively. RBF (the best MLC), the CSFI, and glaucoma specialists showed significantly higher AUCs than that obtained by general ophthalmologists (P<0.05). However, there were no significant differences between the AUCs obtained by RBF, the CSFI, and glaucoma specialists (P>0.25). CONCLUSION: Our findings suggest that both MLCs and the CSFI can be helpful in clinical practice and effectively improve glaucoma diagnosis in the primary eye care setting, when there is no glaucoma specialist available.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0207784",
      "citations": 3,
      "readership": 26,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Predicting atrial fibrillation and flutter using electronic health records.",
      "authors": "Karnik, S; Tan, SL; Berg, B; Glurich, I; Zhang, J; Vidaillet, HJ; Page, CD; Chowdhary, R",
      "published_date": 2012,
      "doi": "10.1109/EMBC.2012.6347254",
      "abstract": "Electronic Health Records (EHR) contain large amounts of useful information that could potentially be used for building models for predicting onset of diseases. In this study, we have investigated the use of free-text and coded data in Marshfield Clinic's EHR, individually and in combination for building machine learning based models to predict the first ever episode of atrial fibrillation and/or atrial flutter (AFF). We trained and evaluated our AFF models on the EHR data across different time intervals (1, 3, 5 and all years) prior to first documented onset of AFF. We applied several machine learning methods, including naïve bayes, support vector machines (SVM), logistic regression and random forests for building AFF prediction models and evaluated these using 10-fold cross-validation approach. On text-based datasets, the best model achieved an F-measure of 60.1%, when applied exclusively to coded data. The combination of textual and coded data achieved comparable performance. The study results attest to the relative merit of utilizing textual data to complement the use of coded data for disease onset prediction modeling.",
      "publication_location": "Conference Proceedings : ... Annual International Conference of the Ieee Engineering in Medicine and Biology Society. Ieee Engineering in Medicine and Biology Society. Annual Conference",
      "link": "http://dx.doi.org/10.1109/EMBC.2012.6347254",
      "citations": 6,
      "readership": 41,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "An improved frequency domain feature with partial least-squares dimensionality reduction for classifying buried threats in forwardlooking ground-penetrating radar data",
      "authors": "Camilo, JA; Crosskey, M; Morton, K; Collins, LM; Malof, JM",
      "published_date": "January 1, 2017",
      "doi": "10.1117/12.2263034",
      "abstract": "© 2017 SPIE. Forward-looking ground penetrating radar (FLGPR) is a remote sensing modality that has been investigated for buried threat detection. The FLGPR considered in this work consists of a sensor array mounted on the front of a vehicle, which inspects an area in front of the vehicle as it moves down a lane. The FLGPR collects data using a stepped frequency approach, and the received radar data is processed by filtered backprojection to create images of the subsurface. A large body of research has focused on developing effective supervised machine learning algorithms to automatically discriminate between imagery associated with target and non-target FLGPR responses. An important component of these automated algorithms is the design of effective features (e.g., image descriptors) that are extracted from the FLGPR imagery and then provided to the machine learning classifiers (e.g., support vector machines). One feature that has recently been proposed is computed from the magnitude of the two-dimensional fast Fourier transform (2DFFT) of the FLGPR imagery. This paper presents a modified version of the 2DFFT feature, termed 2DFFT+, that yields substantial detection performance when compared with several other existing features on a large collection of FLGPR imagery. Further, we show that using partial least-squares discriminative dimensionality reduction, it is possible to dramatically lower the dimensionality of the 2DFFT+ feature from 2652 dimensions down to twenty dimensions (on average), while simultaneously improving its performance.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2263034",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Interpretable classification models for recidivism prediction",
      "authors": "Zeng, J; Ustun, B; Rudin, C",
      "published_date": "June 1, 2017",
      "doi": "10.1111/rssa.12227",
      "abstract": "© 2016 Royal Statistical Society We investigate a long-debated question, which is how to create predictive models of recidivism that are sufficiently accurate, transparent and interpretable to use for decision making. This question is complicated as these models are used to support different decisions, from sentencing, to determining release on probation to allocating preventative social services. Each case might have an objective other than classification accuracy, such as a desired true positive rate TPR or false positive rate FPR. Each (TPR, FPR) pair is a point on the receiver operator characteristic (ROC) curve. We use popular machine learning methods to create models along the full ROC curve on a wide range of recidivism prediction problems. We show that many methods (support vector machines, stochastic gradient boosting and ridge regression) produce equally accurate models along the full ROC curve. However, methods that are designed for interpretability (classification and regression trees and C5.0) cannot be tuned to produce models that are accurate and/or interpretable. To handle this shortcoming, we use a recent method called supersparse linear integer models to produce accurate, transparent and interpretable scoring systems along the full ROC curve. These scoring systems can be used for decision making for many different use cases, since they are just as accurate as the most powerful black box machine learning models for many applications, but completely transparent, and highly interpretable.",
      "publication_location": "Journal of the Royal Statistical Society: Series a (Statistics in Society)",
      "link": "http://dx.doi.org/10.1111/rssa.12227",
      "citations": 36,
      "readership": 123,
      "tweets": 15,
      "news_mentions": 3
    },
    {
      "title": "Knowledge-based planning for intensity-modulated radiation therapy: A review of data-driven approaches.",
      "authors": "Ge, Y; Wu, QJ",
      "published_date": "June 2019",
      "doi": "10.1002/mp.13526",
      "abstract": "PURPOSE: Intensity-Modulated Radiation Therapy (IMRT), including its variations (including IMRT, Volumetric Arc Therapy (VMAT), and Tomotherapy), is a widely used and critically important technology for cancer treatment. It is a knowledge-intensive technology due not only to its own technical complexity, but also to the inherently conflicting nature of maximizing tumor control while minimizing normal organ damage. As IMRT experience and especially the carefully designed clinical plan data are accumulated during the past two decades, a new set of methods commonly termed knowledge-based planning (KBP) have been developed that aim to improve the quality and efficiency of IMRT planning by learning from the database of past clinical plans. Some of this development has led to commercial products recently that allowed the investigation of KBP in numerous clinical applications. In this literature review, we will attempt to present a summary of published methods of knowledge-based approaches in IMRT and recent clinical validation results. METHODS: In March 2018, a literature search was conducted in the NIH Medline database using the PubMed interface to identify publications that describe methods and validations related to KBP in IMRT including variations such as VMAT and Tomotherapy. The search criteria were designed to have a broad scope to capture relevant results with high sensitivity. The authors filtered down the search results according to a predefined selection criteria by reviewing the titles and abstracts first and then by reviewing the full text. A few papers were added to the list based on the references of the reviewed papers. The final set of papers was reviewed and summarized here. RESULTS: The initial search yielded a total of 740 articles. A careful review of the titles, abstracts, and eventually the full text and then adding relevant articles from reviewing the references resulted in a final list of 73 articles published between 2011 and early 2018. These articles described methods for developing knowledge models for predicting such parameters as dosimetric and dose-volume points, voxel-level doses, and objective function weights that improve or automate IMRT planning for various cancer sites, addressing different clinical and quality assurance needs, and using a variety of machine learning approaches. A number of articles reported carefully designed clinical studies that assessed the performance of KBP models in realistic clinical applications. Overwhelming majority of the studies demonstrated the benefits of KBP in achieving comparable and often improved quality of IMRT planning while reducing planning time and plan quality variation. CONCLUSIONS: The number of KBP-related studies has been steadily increasing since 2011 indicating a growing interest in applying this approach to clinical applications. Validation studies have generally shown KBP to produce plans with quality comparable to expert planners while reducing the time and efforts to generate plans. However, current studies are mostly retrospective and leverage relatively small datasets. Larger datasets collected through multi-institutional collaboration will enable the development of more advanced models to further improve the performance of KBP in complex clinical cases. Prospective studies will be an important next step toward widespread adoption of this exciting technology.",
      "publication_location": "Med Phys",
      "link": "http://dx.doi.org/10.1002/mp.13526",
      "citations": 10,
      "readership": 54,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Distributed solar photovoltaic array location and extent dataset for remote sensing object identification",
      "authors": "Bradbury, K; Saboo, R; Johnson, TL; Malof, JM; Devarajan, A; Zhang, W; Collins, LM; Newell, RG",
      "published_date": "December 6, 2016",
      "doi": "10.1038/sdata.2016.106",
      "abstract": "© The Author(s) 2016. Earth-observing remote sensing data, including aerial photography and satellite imagery, offer a snapshot of the world from which we can learn about the state of natural resources and the built environment. The components of energy systems that are visible from above can be automatically assessed with these remote sensing data when processed with machine learning methods. Here, we focus on the information gap in distributed solar photovoltaic (PV) arrays, of which there is limited public data on solar PV deployments at small geographic scales. We created a dataset of solar PV arrays to initiate and develop the process of automatically identifying solar PV locations using remote sensing imagery. This dataset contains the geospatial coordinates and border vertices for over 19,000 solar panels across 601 high-resolution images from four cities in California. Dataset applications include training object detection and other machine learning algorithms that use remote sensing imagery, developing specific algorithms for predictive detection of distributed PV systems, estimating installed PV capacity, and analysis of the socioeconomic correlates of PV deployment.",
      "publication_location": "Scientific Data",
      "link": "http://dx.doi.org/10.1038/sdata.2016.106",
      "citations": 11,
      "readership": 47,
      "tweets": 10,
      "news_mentions": ""
    },
    {
      "title": "Knowledge transfer in board-level functional fault identification using domain adaptation",
      "authors": "Liu, M; Li, X; Chakrabarty, K; Gu, X",
      "published_date": "November 1, 2019",
      "doi": "10.1109/ITC44170.2019.9000172",
      "abstract": "© 2019 IEEE. High integration densities and design complexity make board-level functional fault identification extremely difficult. Machine-learning techniques can identify functional faults with high accuracy, but they require a large volume of data to achieve high prediction accuracy. This drawback limits the effectiveness of traditional machine-learning algorithms for training a model in the early stage of manufacturing, when only a limited amount of fail data and repair records are available. We propose a board-level diagnosis workflow that utilizes domain adaptation to transfer the knowledge learned from a mature board to a new board in the ramp-up phase. First, a metric is designed to evaluate the similarity between products, and based on the calculated value of the similarity, either a homogeneous or a heterogeneous domain adaptation algorithm is selected. Second, these domain adaptation algorithms utilize information from both the mature and the new boards with carefully designed domain-alignment rules and train a functional fault identification classifier. Three complex boards in volume production and one new board in the ramp-up phase are used to validate the proposed domain-adaptation approach in terms of the diagnosis accuracy.",
      "publication_location": "Proceedings   International Test Conference",
      "link": "http://dx.doi.org/10.1109/ITC44170.2019.9000172",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A comparison of optimal MIMO linear and nonlinear models for brain-machine interfaces.",
      "authors": "Kim, S-P; Sanchez, JC; Rao, YN; Erdogmus, D; Carmena, JM; Lebedev, MA; Nicolelis, MAL; Principe, JC",
      "published_date": "June 2006",
      "doi": "10.1088/1741-2560/3/2/009",
      "abstract": "The field of brain-machine interfaces requires the estimation of a mapping from spike trains collected in motor cortex areas to the hand kinematics of the behaving animal. This paper presents a systematic investigation of several linear (Wiener filter, LMS adaptive filters, gamma filter, subspace Wiener filters) and nonlinear models (time-delay neural network and local linear switching models) applied to datasets from two experiments in monkeys performing motor tasks (reaching for food and target hitting). Ensembles of 100-200 cortical neurons were simultaneously recorded in these experiments, and even larger neuronal samples are anticipated in the future. Due to the large size of the models (thousands of parameters), the major issue studied was the generalization performance. Every parameter of the models (not only the weights) was selected optimally using signal processing and machine learning techniques. The models were also compared statistically with respect to the Wiener filter as the baseline. Each of the optimization procedures produced improvements over that baseline for either one of the two datasets or both.",
      "publication_location": "Journal of Neural Engineering",
      "link": "http://dx.doi.org/10.1088/1741-2560/3/2/009",
      "citations": 84,
      "readership": 124,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Learning Efficient Sparse and Low Rank Models.",
      "authors": "Sprechmann, P; Bronstein, AM; Sapiro, G",
      "published_date": "September 2015",
      "doi": "10.1109/tpami.2015.2392779",
      "abstract": "Parsimony, including sparsity and low rank, has been shown to successfully model data in numerous machine learning and signal processing tasks. Traditionally, such modeling approaches rely on an iterative algorithm that minimizes an objective function with parsimony-promoting terms. The inherently sequential structure and data-dependent complexity and latency of iterative optimization constitute a major limitation in many applications requiring real-time performance or involving large-scale data. Another limitation encountered by these modeling techniques is the difficulty of their inclusion in discriminative learning scenarios. In this work, we propose to move the emphasis from the model to the pursuit algorithm, and develop a process-centric view of parsimonious modeling, in which a learned deterministic fixed-complexity pursuit process is used in lieu of iterative optimization. We show a principled way to construct learnable pursuit process architectures for structured sparse and robust low rank models, derived from the iteration of proximal descent algorithms. These architectures learn to approximate the exact parsimonious representation at a fraction of the complexity of the standard optimization methods. We also show that appropriate training regimes allow to naturally extend parsimonious models to discriminative settings. State-of-the-art results are demonstrated on several challenging problems in image and audio processing with several orders of magnitude speed-up compared to the exact optimization algorithms.",
      "publication_location": "Ieee Transactions on Pattern Analysis and Machine Intelligence",
      "link": "http://dx.doi.org/10.1109/tpami.2015.2392779",
      "citations": 53,
      "readership": 154,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "A preliminary investigation into predictive models for adverse drug events",
      "authors": "Davis, J; Costa, VS; Peissig, P; Caldwell, M; Page, D",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "Adverse drug events are a leading cause of danger and cost in health care. We could reduce both the danger and the cost if we had accurate models to predict, at prescription time for each drug, which patients are most at risk for known adverse reactions to that drug, such as myocardial infarction (MI, or \"heart attack\") if given a Cox2 inhibitor, angioedema if given an ACE inhibitor, or bleeding if given an anticoagulant such as Warfarin. We address this task for the specific case of Cox2 inhibitors, a type of non-steroidal anti-inflammatory drug (NSAID) or pain reliever that is easier on the gastrointestinal system than most NSAIDS. Because of the MI adverse drug reaction, some but not all very effective Cox2 inhibitors were removed from the market. Specifically, we use machine learning to predict which patients on a Cox2 inhibitor would suffer an MI. An important issue for machine learning is that we do not know which of these patients might have suffered an MI even without the drug. To begin to make some headway on this important problem, we compare our predictive model for MI for patients on Cox2 inhibitors against a more general model for predicting MI among a broader population not on Cox2 inhibitors. Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved.",
      "publication_location": "Aaai Workshop   Technical Report",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Identifying Parkinson's Patients: A Functional Gradient Boosting Approach.",
      "authors": "Dhami, DS; Soni, A; Page, D; Natarajan, S",
      "published_date": "June 2017",
      "doi": "10.1007/978-3-319-59758-4_39",
      "abstract": "Parkinson's, a progressive neural disorder, is difficult to identify due to the hidden nature of the symptoms associated. We present a machine learning approach that uses a definite set of features obtained from the Parkinsons Progression Markers Initiative(PPMI) study as input and classifies them into one of two classes: PD(Parkinson's disease) and HC(Healthy Control). As far as we know this is the first work in applying machine learning algorithms for classifying patients with Parkinson's disease with the involvement of domain expert during the feature selection process. We evaluate our approach on 1194 patients acquired from Parkinsons Progression Markers Initiative and show that it achieves a state-of-the-art performance with minimal feature engineering.",
      "publication_location": "Artif Intell Med Conf Artif Intell Med (2005 )",
      "link": "http://dx.doi.org/10.1007/978-3-319-59758-4_39",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A protein corona primer for physical chemists.",
      "authors": "Payne, CK",
      "published_date": "October 2019",
      "doi": "10.1063/1.5120178",
      "abstract": "Nanoparticles present in any biological environment are exposed to extracellular proteins. These proteins adsorb on the surface of the nanoparticle forming a \"protein corona.\" These proteins control the interaction of nanoparticles with cells. The interaction of proteins with the nanoparticle surface is governed by physical chemistry. Understanding this process requires spectroscopy, microscopy, and computational tools that are familiar to physical chemists. This perspective provides an overview of the protein corona along with two future directions: first, the need for new computational approaches, including machine learning, to predict corona formation and second, the extension of protein corona studies to more complex environments ranging from lung fluids to waste water treatment.",
      "publication_location": "The Journal of Chemical Physics",
      "link": "http://dx.doi.org/10.1063/1.5120178",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The state of the art in visual analysis approaches for ocean and atmospheric datasets",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "10.1111/cgf.13731",
      "abstract": "© 2019 The Eurographis Assoiation and John Wiley  &  Sons Ltd. Published by John Wiley  &  Sons Ltd. The analysis of ocean and atmospheric datasets offers a unique set of challenges to scientists working in different application areas. These challenges include dealing with extremely large volumes of multidimensional data, supporting interactive visual analysis, ensembles exploration and visualization, exploring model sensitivities to inputs, mesoscale ocean features analysis, predictive analytics, heterogeneity and complexity of observational data, representing uncertainty, and many more. Researchers across disciplines collaborate to address such challenges, which led to significant research and development advances in ocean and atmospheric sciences, and also in several relevant areas such as visualization and visual analytics, big data analytics, machine learning and statistics. In this report, we perform an extensive survey of research advances in the visual analysis of ocean and atmospheric datasets. First, we survey the task requirements by conducting interviews with researchers, domain experts, and end users working with these datasets on a spectrum of analytics problems in the domain of ocean and atmospheric sciences. We then discuss existing models and frameworks related to data analysis, sense-making, and knowledge discovery for visual analytics applications. We categorize the techniques, systems, and tools presented in the literature based on the taxonomies of task requirements, interaction methods, visualization techniques, machine learning and statistical methods, evaluation methods, data types, data dimensions and size, spatial scale and application areas. We then evaluate the task requirements identified based on our interviews with domain experts in the context of categorized research based on our taxonomies, and existing models and frameworks of visual analytics to determine the extent to which they fulfill these task requirements, and identify the gaps in current research. In the last part of this report, we summarize the trends, challenges, and opportunities for future research in this area. (see http://www.acm.org/about/class/class/2012).",
      "publication_location": "Computer Graphics Forum",
      "link": "http://dx.doi.org/10.1111/cgf.13731",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Metabolomics Identifies a Biomarker Revealing In Vivo Loss of Functional β-Cell Mass Before Diabetes Onset.",
      "authors": "Li, L; Krznar, P; Erban, A; Agazzi, A; Martin-Levilain, J; Supale, S; Kopka, J; Zamboni, N; Maechler, P",
      "published_date": "December 2019",
      "doi": "10.2337/db19-0131",
      "abstract": "Identification of individuals with decreased functional β-cell mass is essential for the prevention of diabetes. However, in vivo detection of early asymptomatic β-cell defect remains unsuccessful. Metabolomics has emerged as a powerful tool in providing readouts of early disease states before clinical manifestation. We aimed at identifying novel plasma biomarkers for loss of functional β-cell mass in the asymptomatic prediabetes stage. Nontargeted and targeted metabolomics were applied in both lean β-Phb2-/- (β-cell-specific prohibitin-2 knockout) mice and obese db/db (leptin receptor mutant) mice, two distinct mouse models requiring neither chemical nor dietary treatments to induce spontaneous decline of functional β-cell mass promoting progressive diabetes development. Nontargeted metabolomics on β-Phb2-/- mice identified 48 and 82 significantly affected metabolites in liver and plasma, respectively. Machine learning analysis pointed to deoxyhexose sugars consistently reduced at the asymptomatic prediabetes stage, including in db/db mice, showing strong correlation with the gradual loss of β-cells. Further targeted metabolomics by gas chromatography-mass spectrometry uncovered the identity of the deoxyhexose, with 1,5-anhydroglucitol displaying the most substantial changes. In conclusion, this study identified 1,5-anhydroglucitol as associated with the loss of functional β-cell mass and uncovered metabolic similarities between liver and plasma, providing insights into the systemic effects caused by early decline in β-cells.",
      "publication_location": "Diabetes",
      "link": "http://dx.doi.org/10.2337/db19-0131",
      "citations": 1,
      "readership": 18,
      "tweets": 29,
      "news_mentions": ""
    },
    {
      "title": "Accelerating Markov Random Field Inference Using Molecular Optical Gibbs Sampling Units",
      "authors": "Wang, S; Zhang, X; Li, Y; Bashizade, R; Yang, S; Dwyer, C; Lebeck, AR",
      "published_date": "August 24, 2016",
      "doi": "10.1109/ISCA.2016.55",
      "abstract": "© 2016 IEEE. The increasing use of probabilistic algorithms from statistics and machine learning for data analytics presents new challenges and opportunities for the design of computing systems. One important class of probabilistic machine learning algorithms is Markov Chain Monte Carlo (MCMC) sampling, which can be used on a wide variety of applications in Bayesian Inference. However, this probabilistic iterative algorithm can be inefficient in practice on today's processors, especially for problems with high dimensionality and complex structure. The source of inefficiency is generating samples from parameterized probability distributions. This paper seeks to address this sampling inefficiency and presents a new approach to support probabilistic computing that leverages the native randomness of Resonance Energy Transfer (RET) networks to construct RET-based sampling units (RSU). Although RSUs can be designed for a variety of applications, we focus on the specific class of probabilistic problems described as Markov Random Field Inference. Our proposed RSU uses a RET network to implement a molecular-scale optical Gibbs sampling unit (RSU-G) that can be integrated into a processor /GPU as specialized functional units or organized as a discrete accelerator. We experimentally demonstrate the fundamental operation of an RSU using a macro-scale hardware prototype. Emulation-based evaluation of two computer vision applications for HD images reveal that an RSU augmented GPU provides speedups over a GPU of 3 and 16. Analytic evaluation shows a discrete accelerator that is limited by 336 GB/s DRAM produces speedups of 21 and 54 versus the GPU implementations.",
      "publication_location": "Proceedings   2016 43rd International Symposium on Computer Architecture, Isca 2016",
      "link": "http://dx.doi.org/10.1109/ISCA.2016.55",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Numerical Models and In Vitro Assays to Study Odorant Receptors.",
      "authors": "Bushdid, C; de March, CA; Matsunami, H; Golebiowski, J",
      "published_date": 2018,
      "doi": "10.1007/978-1-4939-8609-5_7",
      "abstract": "Unraveling the sense of smell relies on understanding how odorant receptors recognize odorant molecules. Given the vastness of the odorant chemical space and the complexity of the odorant receptor space, computational methods are in line to propose rules connecting them. We hereby propose an in silico and an in vitro approach, which, when combined are extremely useful for assessing chemogenomic links. In this chapter we mostly focus on the mining of already existing data through machine learning methods. This approach allows establishing predictions that map the chemical space and the receptor space. Then, we describe the method for assessing the activation of odorant receptors and their mutants through luciferase reporter gene functional assays.",
      "publication_location": "Methods Mol Biol",
      "link": "http://dx.doi.org/10.1007/978-1-4939-8609-5_7",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Spatial downscaling of precipitation using adaptable random forests",
      "authors": "He, X; Chaney, NW; Schleiss, M; Sheffield, J",
      "published_date": "October 1, 2016",
      "doi": "10.1002/2016WR019034",
      "abstract": "© 2016. The Authors. This paper introduces Prec-DWARF (Precipitation Downscaling With Adaptable Random Forests), a novel machine-learning based method for statistical downscaling of precipitation. Prec-DWARF sets up a nonlinear relationship between precipitation at fine resolution and covariates at coarse/fine resolution, based on the advanced binary tree method known as Random Forests (RF). In addition to a single RF, we also consider a more advanced implementation based on two independent RFs which yield better results for extreme precipitation. Hourly gauge-radar precipitation data at 0.125° from NLDAS-2 are used to conduct synthetic experiments with different spatial resolutions (0.25°, 0.5°, and 1°). Quantitative evaluation of these experiments demonstrates that Prec-DWARF consistently outperforms the baseline (i.e., bilinear interpolation in this case) and can reasonably reproduce the spatial and temporal patterns, occurrence and distribution of observed precipitation fields. However, Prec-DWARF with a single RF significantly underestimates precipitation extremes and often cannot correctly recover the fine-scale spatial structure, especially for the 1° experiments. Prec-DWARF with a double RF exhibits improvement in the simulation of extreme precipitation as well as its spatial and temporal structures, but variogram analyses show that the spatial and temporal variability of the downscaled fields are still strongly underestimated. Covariate importance analysis shows that the most important predictors for the downscaling are the coarse-scale precipitation values over adjacent grid cells as well as the distance to the closest dry grid cell (i.e., the dry drift). The encouraging results demonstrate the potential of Prec-DWARF and machine-learning based techniques in general for the statistical downscaling of precipitation.",
      "publication_location": "Water Resources Research",
      "link": "http://dx.doi.org/10.1002/2016WR019034",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Markov Chain Based Efficient Defense Against Adversarial Examples in Computer Vision",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "10.1109/ACCESS.2018.2889409",
      "abstract": "© 2013 IEEE. Adversarial examples are the inputs to machine learning models that result in erroneous outputs, which are usually generated from normal inputs via subtle modification and seem to remain unchanged to human observers. They have severely threatened the applications of machine learning, especially in the areas with high-security requirements. Unfortunately, for this issue, there is neither unambiguous interpretation about the causes nor almighty defenses in spite of the increasing attention and discussions. Based on the distinguished statistical feature of Markov chain, an effective defense method is proposed in this paper by exploring the differences in the probability distributions of adjacent pixels between normal images and adversarial examples. Specifically, the concept of overall probability value (OPV) is defined to estimate the modification to an input, which can be used to preliminarily determine whether the input is an adversarial example or not. Furthermore, by calculating the OPV of an input and modifying its pixel value to destroy the potential adversarial characteristics, the proposed method can efficiently purify adversarial examples. A series of experiments demonstrate the effectiveness of the defense method. When facing various attacks, it obtains excellent performance with accuracy over 92% for MNIST and 70% for ImageNet.",
      "publication_location": "Ieee Access",
      "link": "http://dx.doi.org/10.1109/ACCESS.2018.2889409",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Tapprints: Your finger taps have fingerprints",
      "authors": "",
      "published_date": "August 1, 2012",
      "doi": "10.1145/2307636.2307666",
      "abstract": "This paper shows that the location of screen taps on modern smartphones and tablets can be identified from accelerometer and gyroscope readings. Our findings have serious implications, as we demonstrate that an attacker can launch a background process on commodity smartphones and tablets, and silently monitor the user's inputs, such as keyboard presses and icon taps. While precise tap detection is nontrivial, requiring machine learning algorithms to identify fingerprints of closely spaced keys, sensitive sensors on modern devices aid the process. We present TapPrints, a framework for inferring the location of taps on mobile device touch-screens using motion sensor data combined with machine learning analysis. By running tests on two different off-the-shelf smartphones and a tablet computer we show that identifying tap locations on the screen and inferring English letters could be done with up to 90% and 80% accuracy, respectively. By optimizing the core tap detection capability with additional information, such as contextual priors, we are able to further magnify the core threat. © 2012 ACM.",
      "publication_location": "Mobisys'12   Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services",
      "link": "http://dx.doi.org/10.1145/2307636.2307666",
      "citations": 171,
      "readership": 111,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Testing a Bayesian measure of representativeness using a large image database",
      "authors": "Abbott, JT; Heller, KA; Ghahramani, Z; Griffiths, TL",
      "published_date": "December 1, 2011",
      "doi": "",
      "abstract": "How do people determine which elements of a set are most representative of that set? We extend an existing Bayesian measure of representativeness, which indicates the representativeness of a sample from a distribution, to define a measure of the representativeness of an item to a set. We show that this measure is formally related to a machine learning method known as Bayesian Sets. Building on this connection, we derive an analytic expression for the representativeness of objects described by a sparse vector of binary features. We then apply this measure to a large database of images, using it to determine which images are the most representative members of different sets. Comparing the resulting predictions to human judgments of representativeness provides a test of this measure with naturalistic stimuli, and illustrates how databases that are more commonly used in computer vision and machine learning can be used to evaluate psychological theories.",
      "publication_location": "Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, Nips 2011",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "DIADS: Addressing the “my-problem-or-yours” syndrome with integrated SAN and database diagnosis",
      "authors": "",
      "published_date": "January 1, 2009",
      "doi": "",
      "abstract": "© 2009 USENIX Association. All rights reserved. We present DIADS, an integrated DIAgnosis tool for Databases and Storage area networks (SANs). Existing diagnosis tools in this domain have a database-only (e.g., [11]) or SAN-only (e.g., [28]) focus. DIADS is a first-of-a-kind framework based on a careful integration of information from the database and SAN subsystems; and is not a simple concatenation of database-only and SAN-only modules. This approach not only increases the accuracy of diagnosis, but also leads to significant improvements in efficiency. DIADS uses a novel combination of non-intrusive machine learning techniques (e.g., Kernel Density Estimation) and domain knowledge encoded in a new symptoms database design. The machine learning component provides core techniques for problem diagnosis from monitoring data, and domain knowledge acts as checks-and-balances to guide the diagnosis in the right direction. This unique system design enables DIADS to function effectively even in the presence of multiple concurrent problems as well as noisy data prevalent in production environments. We demonstrate the efficacy of our approach through a detailed experimental evaluation of DIADS implemented on a real data center testbed with PostgreSQL databases and an enterprise SAN.",
      "publication_location": "Proceedings of the 7th Usenix Conference on File and Storage Technologies, Fast 2009",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Tumor cell sensitivity to vemurafenib can be predicted from protein expression in a BRAF-V600E basket trial setting.",
      "authors": "Carroll, MJ; Parent, CR; Page, D; Kreeger, PK",
      "published_date": "October 31, 2019",
      "doi": "10.1186/s12885-019-6175-2",
      "abstract": "BACKGROUND: Genetics-based basket trials have emerged to test targeted therapeutics across multiple cancer types. However, while vemurafenib is FDA-approved for BRAF-V600E melanomas, the non-melanoma basket trial was unsuccessful, suggesting mutation status is insufficient to predict response. We hypothesized that proteomic data would complement mutation status to identify vemurafenib-sensitive tumors and effective co-treatments for BRAF-V600E tumors with inherent resistance. METHODS: Reverse Phase Proteomic Array (RPPA, MD Anderson Cell Lines Project), RNAseq (Cancer Cell Line Encyclopedia) and vemurafenib sensitivity (Cancer Therapeutic Response Portal) data for BRAF-V600E cancer cell lines were curated. Linear and nonlinear regression models using RPPA protein or RNAseq were evaluated and compared based on their ability to predict BRAF-V600E cell line sensitivity (area under the dose response curve). Accuracies of all models were evaluated using hold-out testing. CausalPath software was used to identify protein-protein interaction networks that could explain differential protein expression in resistant cells. Human examination of features employed by the model, the identified protein interaction networks, and model simulation suggested anti-ErbB co-therapy would counter intrinsic resistance to vemurafenib. To validate this potential co-therapy, cell lines were treated with vemurafenib and dacomitinib (a pan-ErbB inhibitor) and the number of viable cells was measured. RESULTS: Orthogonal partial least squares (O-PLS) predicted vemurafenib sensitivity with greater accuracy in both melanoma and non-melanoma BRAF-V600E cell lines than other leading machine learning methods, specifically Random Forests, Support Vector Regression (linear and quadratic kernels) and LASSO-penalized regression. Additionally, use of transcriptomic in place of proteomic data weakened model performance. Model analysis revealed that resistant lines had elevated expression and activation of ErbB receptors, suggesting ErbB inhibition could improve vemurafenib response. As predicted, experimental evaluation of vemurafenib plus dacomitinb demonstrated improved efficacy relative to monotherapies. CONCLUSIONS: Combined, our results support that inclusion of proteomics can predict drug response and identify co-therapies in a basket setting.",
      "publication_location": "Bmc Cancer",
      "link": "http://dx.doi.org/10.1186/s12885-019-6175-2",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Analyzing animal behavior via classifying each video frame using convolutional neural networks.",
      "authors": "Stern, U; He, R; Yang, C-H",
      "published_date": "September 23, 2015",
      "doi": "10.1038/srep14351",
      "abstract": "High-throughput analysis of animal behavior requires software to analyze videos. Such software analyzes each frame individually, detecting animals' body parts. But the image analysis rarely attempts to recognize \"behavioral states\"-e.g., actions or facial expressions-directly from the image instead of using the detected body parts. Here, we show that convolutional neural networks (CNNs)-a machine learning approach that recently became the leading technique for object recognition, human pose estimation, and human action recognition-were able to recognize directly from images whether Drosophila were \"on\" (standing or walking) or \"off\" (not in physical contact with) egg-laying substrates for each frame of our videos. We used multiple nets and image transformations to optimize accuracy for our classification task, achieving a surprisingly low error rate of just 0.072%. Classifying one of our 8 h videos took less than 3 h using a fast GPU. The approach enabled uncovering a novel egg-laying-induced behavior modification in Drosophila. Furthermore, it should be readily applicable to other behavior analysis tasks.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/srep14351",
      "citations": 21,
      "readership": 87,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "Accurate analysis and prediction of enterprise service-level performance",
      "authors": "Duan, Q; Koneru, A; Zeng, J; Chakrabarty, K; Dispoto, G",
      "published_date": "January 1, 2015",
      "doi": "10.1145/2757279",
      "abstract": "© 2015 ACM. An enterprise service-level performance time series is a sequence of data points that quantify demand, throughput, average order-delivery time, quality of service, or end-to-end cost. Analytical and predictive models of such time series can be embedded into an enterprise information system (EIS) in order to provide meaningful insights into potential business problems and generate guidance for appropriate solutions. Timeseries analysis includes periodicity detection, decomposition, and correlation analysis. Time-series prediction can be modeled as a regression problem to forecast a sequence of future time-series datapoints based on the given time series. The state-of-the-art (baseline) methods employed in time-series prediction generally apply advanced machine-learning algorithms. In this article, we propose a new univariate method for dealing with midterm time-series prediction. The proposed method first analyzes the hierarchical periodic structure in one time series and decomposes it into trend, season, and noise components. By discarding the noise component, the proposed method only focuses on predicting repetitive season and smoothed trend components. As a result, this method significantly improves upon the performance of baseline methods in midterm timeseries prediction. Moreover, we propose a new multivariate method for dealing with short-term time-series prediction. The proposed method utilizes cross-correlation information derived from multiple time series. The amount of data taken from each time series for training the regression model is determined by results from hierarchical cross-correlation analysis. Such a data-filtering strategy leads to improved algorithm efficiency and prediction accuracy. By combining statistical methods with advanced machine-learning algorithms, we have achieved a significantly superior performance in both short-term and midterm time-series predictions compared to state-of-the-art (baseline) methods.",
      "publication_location": "Acm Transactions on Design Automation of Electronic Systems",
      "link": "http://dx.doi.org/10.1145/2757279",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Efficient Board-Level Functional Fault Diagnosis with Missing Syndromes",
      "authors": "Jin, S; Ye, F; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "June 1, 2016",
      "doi": "10.1109/TCAD.2015.2481859",
      "abstract": "© 1982-2012 IEEE. Functional fault diagnosis is widely used in board manufacturing to ensure product quality and improve product yield. Advanced machine-learning techniques have recently been advocated for reasoning-based diagnosis; these techniques are based on the historical record of successfully repaired boards. However, traditional diagnosis systems fail to provide appropriate repair suggestions when the diagnostic logs are fragmented and some error outcomes, or syndromes, are not available during diagnosis. We describe the design of a diagnosis system that can handle missing syndromes and can be applied to four widely used machine-learning techniques. Several imputation methods are discussed and compared in terms of their effectiveness for addressing missing syndromes. Moreover, a syndrome-selection technique based on the minimum-redundancy-maximum-relevance criteria is also incorporated to further improve the efficiency of the proposed methods. Two large-scale synthetic data sets generated from the log information of complex industrial boards in volume production are used to validate the proposed diagnosis system in terms of diagnosis accuracy and training time.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2015.2481859",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Mind-reading without the scanner: Behavioural decoding of working memory content",
      "authors": "Dowd, EW; Pearson, JM; Egner, T",
      "published_date": "January 1, 2015",
      "doi": "10.1080/13506285.2015.1093244",
      "abstract": "© 2015 Taylor  &  Francis. Sophisticated machine learning algorithms have been successfully applied to functional neuroimaging data in order to characterize internal cognitive states. But is it possible to “mind-read” without the scanner? Capitalizing on the robust finding that the contents of working memory guide visual attention toward memory-matching objects, we trained a multivariate pattern classifier on behavioural indices of attentional guidance. Working memory representations were successfully decoded from behaviour alone, both within and between individuals. The current study provides a proof-of-concept for applying machine learning techniques to simple behavioural outputs (e.g., response times) in order to decode information about specific internal cognitive states.",
      "publication_location": "Visual Cognition",
      "link": "http://dx.doi.org/10.1080/13506285.2015.1093244",
      "citations": 1,
      "readership": 18,
      "tweets": 7,
      "news_mentions": ""
    },
    {
      "title": "Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms.",
      "authors": "Schaffter, T; Buist, DSM; Lee, CI; Nikulin, Y; Ribli, D; Guan, Y; Lotter, W; Jie, Z; Du, H; Wang, S; Feng, J; Feng, M; Kim, H-E; Albiol, F; Albiol, A; Morrell, S; Wojna, Z; Ahsen, ME; Asif, U; Jimeno Yepes, A; Yohanandan, S; Rabinovici-Cohen, S; Yi, D; Hoff, B; Yu, T; Chaibub Neto, E; Rubin, DL; Lindholm, P; Margolies, LR; McBride, RB; Rothstein, JH; Sieh, W; Ben-Ari, R; Harrer, S; Trister, A; Friend, S; Norman, T; Sahiner, B; Strand, F; Guinney, J; Stolovitzky, G; and the DM DREAM Consortium, ; Mackey, L; Cahoon, J; Shen, L; Sohn, JH; Trivedi, H; Shen, Y; Buturovic, L; Pereira, JC; Cardoso, JS; Castro, E; Kalleberg, KT; Pelka, O; Nedjar, I; Geras, KJ; Nensa, F; Goan, E; Koitka, S; Caballero, L; Cox, DD; Krishnaswamy, P; Pandey, G; Friedrich, CM; Perrin, D; Fookes, C; Shi, B; Cardoso Negrie, G; Kawczynski, M; Cho, K; Khoo, CS; Lo, JY; Sorensen, AG; Jung, H",
      "published_date": "March 2, 2020",
      "doi": "10.1001/jamanetworkopen.2020.0265",
      "abstract": "Importance: Mammography screening currently relies on subjective human interpretation. Artificial intelligence (AI) advances could be used to increase mammography screening accuracy by reducing missed cancers and false positives. Objective: To evaluate whether AI can overcome human mammography interpretation limitations with a rigorous, unbiased evaluation of machine learning algorithms. Design, Setting, and Participants: In this diagnostic accuracy study conducted between September 2016 and November 2017, an international, crowdsourced challenge was hosted to foster AI algorithm development focused on interpreting screening mammography. More than 1100 participants comprising 126 teams from 44 countries participated. Analysis began November 18, 2016. Main Outcomes and Measurements: Algorithms used images alone (challenge 1) or combined images, previous examinations (if available), and clinical and demographic risk factor data (challenge 2) and output a score that translated to cancer yes/no within 12 months. Algorithm accuracy for breast cancer detection was evaluated using area under the curve and algorithm specificity compared with radiologists' specificity with radiologists' sensitivity set at 85.9% (United States) and 83.9% (Sweden). An ensemble method aggregating top-performing AI algorithms and radiologists' recall assessment was developed and evaluated. Results: Overall, 144 231 screening mammograms from 85 580 US women (952 cancer positive ≤12 months from screening) were used for algorithm training and validation. A second independent validation cohort included 166 578 examinations from 68 008 Swedish women (780 cancer positive). The top-performing algorithm achieved an area under the curve of 0.858 (United States) and 0.903 (Sweden) and 66.2% (United States) and 81.2% (Sweden) specificity at the radiologists' sensitivity, lower than community-practice radiologists' specificity of 90.5% (United States) and 98.5% (Sweden). Combining top-performing algorithms and US radiologist assessments resulted in a higher area under the curve of 0.942 and achieved a significantly improved specificity (92.0%) at the same sensitivity. Conclusions and Relevance: While no single AI algorithm outperformed radiologists, an ensemble of AI algorithms combined with radiologist assessment in a single-reader screening environment improved overall accuracy. This study underscores the potential of using machine learning methods for enhancing mammography screening interpretation.",
      "publication_location": "Jama Network Open",
      "link": "http://dx.doi.org/10.1001/jamanetworkopen.2020.0265",
      "citations": 2,
      "readership": 32,
      "tweets": 62,
      "news_mentions": 18
    },
    {
      "title": "Evolution patterns and parameter regimes in edge localized modes on the National Spherical Torus Experiment",
      "authors": "Smith, DR; Fonck, RJ; McKee, GR; Diallo, A; Kaye, SM; Leblanc, BP; Sabbagh, SA",
      "published_date": "January 28, 2016",
      "doi": "10.1088/0741-3335/58/4/045003",
      "abstract": "© 2016 IOP Publishing Ltd. We implement unsupervised machine learning techniques to identify characteristic evolution patterns and associated parameter regimes in edge localized mode (ELM) events observed on the National Spherical Torus Experiment. Multi-channel, localized measurements spanning the pedestal region capture the complex evolution patterns of ELM events on Alfvén timescales. Some ELM events are active for less than 100 μs, but others persist for up to 1 ms. Also, some ELM events exhibit a single dominant perturbation, but others are oscillatory. Clustering calculations with time-series similarity metrics indicate the ELM database contains at least two and possibly three groups of ELMs with similar evolution patterns. The identified ELM groups trigger similar stored energy loss, but the groups occupy distinct parameter regimes for ELM-relevant quantities like plasma current, triangularity, and pedestal height. Notably, the pedestal electron pressure gradient is not an effective parameter for distinguishing the ELM groups, but the ELM groups segregate in terms of electron density gradient and electron temperature gradient. The ELM evolution patterns and corresponding parameter regimes can shape the formulation or validation of nonlinear ELM models. Finally, the techniques and results demonstrate an application of unsupervised machine learning at a data-rich fusion facility.",
      "publication_location": "Plasma Physics and Controlled Fusion",
      "link": "http://dx.doi.org/10.1088/0741-3335/58/4/045003",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Adaptive Identification of Cortical and Subcortical Imaging Markers of Early Life Stress and Posttraumatic Stress Disorder.",
      "authors": "Salminen, LE; Morey, RA; Riedel, BC; Jahanshad, N; Dennis, EL; Thompson, PM",
      "published_date": "May 2019",
      "doi": "10.1111/jon.12600",
      "abstract": "BACKGROUND AND PURPOSE: Posttraumatic stress disorder (PTSD) is a heterogeneous condition associated with a range of brain imaging abnormalities. Early life stress (ELS) contributes to this heterogeneity, but we do not know how a history of ELS influences traditionally defined brain signatures of PTSD. Here, we used a novel machine learning method - evolving partitions to improve classification (EPIC) - to identify shared and unique structural neuroimaging markers of ELS and PTSD in 97 combat-exposed military veterans. METHODS: We used EPIC with repeated cross-validation (CV) to determine how combinations of cortical thickness, surface area, and subcortical brain volumes could contribute to classification of PTSD (n = 40) versus controls (n = 57), and classification of ELS within the PTSD (ELS+ n = 16; ELS- n = 24) and control groups (ELS+ n = 16; ELS- n = 41). Additional inputs included intracranial volume, age, sex, adult trauma, and depression. RESULTS: On average, EPIC classified PTSD with 69% accuracy (SD = 5%), and ELS with 64% accuracy in the PTSD group (SD = 10%), and 62% accuracy in controls (SD = 6%). EPIC selected unique sets of individual features that classified each group with 75-85% accuracy in post hoc analyses; combinations of regions marginally improved classification from the individual atlas-defined brain regions. Across analyses, surface area in the right posterior cingulate was the only variable that was repeatedly selected as an important feature for classification of PTSD and ELS. CONCLUSIONS: EPIC revealed unique patterns of features that distinguished PTSD and ELS in this sample of combat-exposed military veterans, which may represent distinct biotypes of stress-related neuropathology.",
      "publication_location": "J Neuroimaging",
      "link": "http://dx.doi.org/10.1111/jon.12600",
      "citations": 2,
      "readership": 15,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Association of an Electroencephalography-Based Risk Score With Seizure Probability in Hospitalized Patients.",
      "authors": "Struck, AF; Ustun, B; Ruiz, AR; Lee, JW; LaRoche, SM; Hirsch, LJ; Gilmore, EJ; Vlachy, J; Haider, HA; Rudin, C; Westover, MB",
      "published_date": "December 2017",
      "doi": "10.1001/jamaneurol.2017.2459",
      "abstract": "Importance:Continuous electroencephalography (EEG) use in critically ill patients is expanding. There is no validated method to combine risk factors and guide clinicians in assessing seizure risk. Objective:To use seizure risk factors from EEG and clinical history to create a simple scoring system associated with the probability of seizures in patients with acute illness. Design, Setting, and Participants:We used a prospective multicenter (Emory University Hospital, Brigham and Women's Hospital, and Yale University Hospital) database containing clinical and electrographic variables on 5427 continuous EEG sessions from eligible patients if they had continuous EEG for clinical indications, excluding epilepsy monitoring unit admissions. We created a scoring system model to estimate seizure risk in acutely ill patients undergoing continuous EEG. The model was built using a new machine learning method (RiskSLIM) that is designed to produce accurate, risk-calibrated scoring systems with a limited number of variables and small integer weights. We validated the accuracy and risk calibration of our model using cross-validation and compared its performance with models built with state-of-the-art logistic regression methods. The database was developed by the Critical Care EEG Research Consortium and used data collected over 3 years. The EEG variables were interpreted using standardized terminology by certified reviewers. Exposures:All patients had more than 6 hours of uninterrupted EEG recordings. Main Outcomes and Measures:The main outcome was the average risk calibration error. Results:There were 5427 continuous EEGs performed on 4772 participants (2868 men, 49.9%; median age, 61 years) performed at 3 institutions, without further demographic stratification. Our final model, 2HELPS2B, had an area under the curve of 0.819 and average calibration error of 2.7% (95% CI, 2.0%-3.6%). It included 6 variables with the following point assignments: (1) brief (ictal) rhythmic discharges (B[I]RDs) (2 points); (2) presence of lateralized periodic discharges, lateralized rhythmic delta activity, or bilateral independent periodic discharges (1 point); (3) prior seizure (1 point); (4) sporadic epileptiform discharges (1 point); (5) frequency greater than 2.0 Hz for any periodic or rhythmic pattern (1 point); and (6) presence of \"plus\" features (superimposed, rhythmic, sharp, or fast activity) (1 point). The probable seizure risk of each score was 5% for a score of 0, 12% for a score of 1, 27% for a score of 2, 50% for a score of 3, 73% for a score of 4, 88% for a score of 5, and greater than 95% for a score of 6 or 7. Conclusions and Relevance:The 2HELPS2B model is a quick accurate tool to aid clinical judgment of the risk of seizures in critically ill patients.",
      "publication_location": "Jama Neurology",
      "link": "http://dx.doi.org/10.1001/jamaneurol.2017.2459",
      "citations": 30,
      "readership": 72,
      "tweets": 67,
      "news_mentions": 4
    },
    {
      "title": "The World Health Organization Adult Attention-Deficit/Hyperactivity Disorder Self-Report Screening Scale for DSM-5.",
      "authors": "Ustun, B; Adler, LA; Rudin, C; Faraone, SV; Spencer, TJ; Berglund, P; Gruber, MJ; Kessler, RC",
      "published_date": "May 2017",
      "doi": "10.1001/jamapsychiatry.2017.0298",
      "abstract": "Importance:Recognition that adult attention-deficit/hyperactivity disorder (ADHD) is common, seriously impairing, and usually undiagnosed has led to the development of adult ADHD screening scales for use in community, workplace, and primary care settings. However, these scales are all calibrated to DSM-IV criteria, which are narrower than the recently developed DSM-5 criteria. Objectives:To update for DSM-5 criteria and improve the operating characteristics of the widely used World Health Organization Adult ADHD Self-Report Scale (ASRS) for screening. Design, Setting, and Participants:Probability subsamples of participants in 2 general population surveys (2001-2003 household survey [n = 119] and 2004-2005 managed care subscriber survey [n = 218]) who completed the full 29-question self-report ASRS, with both subsamples over-sampling ASRS-screened positives, were blindly administered a semistructured research diagnostic interview for DSM-5 adult ADHD. In 2016, the Risk-Calibrated Supersparse Linear Integer Model, a novel machine-learning algorithm designed to create screening scales with optimal integer weights and limited numbers of screening questions, was applied to the pooled data to create a DSM-5 version of the ASRS screening scale. The accuracy of the new scale was then confirmed in an independent 2011-2012 clinical sample of patients seeking evaluation at the New York University Langone Medical Center Adult ADHD Program (NYU Langone) and 2015-2016 primary care controls (n = 300). Data analysis was conducted from April 4, 2016, to September 22, 2016. Main Outcomes and Measures:The sensitivity, specificity, area under the curve (AUC), and positive predictive value (PPV) of the revised ASRS. Results:Of the total 637 participants, 44 (37.0%) household survey respondents, 51 (23.4%) managed care respondents, and 173 (57.7%) NYU Langone respondents met DSM-5 criteria for adult ADHD in the semistructured diagnostic interview. Of the respondents who met DSM-5 criteria for adult ADHD, 123 were male (45.9%); mean (SD) age was 33.1 (11.4) years. A 6-question screening scale was found to be optimal in distinguishing cases from noncases in the first 2 samples. Operating characteristics were excellent at the diagnostic threshold in the weighted (to the 8.2% DSM-5/Adult ADHD Clinical Diagnostic Scale population prevalence) data (sensitivity, 91.4%; specificity, 96.0%; AUC, 0.94; PPV, 67.3%). Operating characteristics were similar despite a much higher prevalence (57.7%) when the scale was applied to the NYU Langone clinical sample (sensitivity, 91.9%; specificity, 74.0%; AUC, 0.83; PPV, 82.8%). Conclusions and Relevance:The new ADHD screening scale is short, easily scored, detects the vast majority of general population cases at a threshold that also has high specificity and PPV, and could be used as a screening tool in specialty treatment settings.",
      "publication_location": "Jama Psychiatry",
      "link": "http://dx.doi.org/10.1001/jamapsychiatry.2017.0298",
      "citations": 55,
      "readership": 232,
      "tweets": 100,
      "news_mentions": 53
    },
    {
      "title": "Turning prediction tools into decision tools",
      "authors": "Rudin, C",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© Springer International Publishing Switzerland 2015. Arguably, the main stumbling block in getting machine learning algorithms used in practice is the fact that people do not trust them. There could be many reasons for this, for instance, perhaps the models are not sparse or transparent, or perhaps the models are not able to be customized to the user’s specifications as to what a decision tool should look like. I will discuss some recent work from the Prediction Analysis Lab on how to build machine learning models that have helpful decision-making properties. I will show how these models are applied to problems in healthcare and criminology.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Reducing noise in labels and features for a real world dataset: Application of NLP corpus annotation methods",
      "authors": "Passonneau, RJ; Rudin, C; Radeva, A; Liu, ZA",
      "published_date": "July 21, 2009",
      "doi": "10.1007/978-3-642-00382-0_7",
      "abstract": "This paper illustrates how a combination of information extraction, machine learning, and NLP corpus annotation practice was applied to a problem of ranking vulnerability of structures (service boxes, manholes) in the Manhattan electrical grid. By adapting NLP corpus annotation methods to the task of knowledge transfer from domain experts, we compensated for the lack of operational definitions of components of the model, such as serious event. The machine learning depended on the ticket classes, but it was not the end goal. Rather, our rule-based document classification determines both the labels of examples and their feature representations. Changes in our classification of events led to improvements in our model, as reflected in the AUC scores for the full ranked list of over 51K structures. The improvements for the very top of the ranked list, which is of most importance for prioritizing work on the electrical grid, affected one in every four or five structures. © Springer-Verlag Berlin Heidelberg 2009.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "http://dx.doi.org/10.1007/978-3-642-00382-0_7",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Interleukin 1 receptor (IL-1R1) activation exacerbates toxin-induced acute kidney injury.",
      "authors": "Privratsky, JR; Zhang, J; Lu, X; Rudemiller, N; Wei, Q; Yu, Y-R; Gunn, MD; Crowley, SD",
      "published_date": "September 1, 2018",
      "doi": "10.1152/ajprenal.00104.2018",
      "abstract": "Acute kidney injury (AKI) is a leading cause of morbidity and mortality. Drug-induced/toxic AKI can be caused by a number of therapeutic agents. Cisplatin is an effective chemotherapeutic agent whose administration is limited by significant nephrotoxicity. Therapies to prevent cisplatin-induced AKI are lacking. Although tumor necrosis factor-α (TNF) plays a key role in the pathogenesis of cisplatin nephrotoxicity, the innate immune signaling pathways that trigger TNF generation in this context require elucidation. In this regard, sterile injury triggers the release and activation of both isoforms of interleukin(IL)-1, IL-1α and IL-1β. In turn, stimulation of the interleukin-1 receptor (IL-1R1) by these ligands engages a proinflammatory signaling cascade that induces TNF induction. We therefore hypothesized that IL-1R1 activation exacerbates cisplatin-induced AKI by inducing TNF production, thereby augmenting inflammatory signals between kidney parenchymal cells and infiltrating myeloid cells. IL-1R1+/+ (WT) and IL-1R1-/- (KO) mice were subjected to cisplatin-induced AKI. Compared with WT mice, IL-1R1 KO mice had attenuated AKI as measured by serum creatinine and BUN, renal NGAL mRNA levels, and blinded histological analysis of kidney pathology. In the cisplatin-injured kidney, IL-1R1 KO mice had diminished levels of whole kidney TNF, and fewer Ly6G-expressing neutrophils. In addition, an unbiased machine learning analysis of intrarenal immune cells revealed a diminished number of CD11bint/CD11cint myeloid cells in IL-1R1 KO injured kidneys compared with IL-1R1 WT kidneys. Following cisplatin, IL-1R1 KO kidneys, compared with WTs, had fewer TNF-producing: macrophages, CD11bint/CD11cint cells, and neutrophils, consistent with an effect of IL-1R1 to polarize intrarenal myeloid cells toward a proinflammatory phenotype. Interruption of IL-1-dependent signaling pathways warrants further evaluation to decrease nephrotoxicity during cisplatin therapy.",
      "publication_location": "Am J Physiol Renal Physiol",
      "link": "http://dx.doi.org/10.1152/ajprenal.00104.2018",
      "citations": 6,
      "readership": 9,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Improved Detection of Invasive Pulmonary Aspergillosis Arising during Leukemia Treatment Using a Panel of Host Response Proteins and Fungal Antigens.",
      "authors": "Brasier, AR; Zhao, Y; Spratt, HM; Wiktorowicz, JE; Ju, H; Wheat, LJ; Baden, L; Stafford, S; Wu, Z; Issa, N; Caliendo, AM; Denning, DW; Soman, K; Clancy, CJ; Nguyen, MH; Sugrue, MW; Alexander, BD; Wingard, JR",
      "published_date": 2015,
      "doi": "10.1371/journal.pone.0143165",
      "abstract": "Invasive pulmonary aspergillosis (IPA) is an opportunistic fungal infection in patients undergoing chemotherapy for hematological malignancy, hematopoietic stem cell transplant, or other forms of immunosuppression. In this group, Aspergillus infections account for the majority of deaths due to mold pathogens. Although early detection is associated with improved outcomes, current diagnostic regimens lack sensitivity and specificity. Patients undergoing chemotherapy, stem cell transplantation and lung transplantation were enrolled in a multi-site prospective observational trial. Proven and probable IPA cases and matched controls were subjected to discovery proteomics analyses using a biofluid analysis platform, fractionating plasma into reproducible protein and peptide pools. From 556 spots identified by 2D gel electrophoresis, 66 differentially expressed post-translationally modified plasma proteins were identified in the leukemic subgroup only. This protein group was rich in complement components, acute-phase reactants and coagulation factors. Low molecular weight peptides corresponding to abundant plasma proteins were identified. A candidate marker panel of host response (9 plasma proteins, 4 peptides), fungal polysaccharides (galactomannan), and cell wall components (β-D glucan) were selected by statistical filtering for patients with leukemia as a primary underlying diagnosis. Quantitative measurements were developed to qualify the differential expression of the candidate host response proteins using selective reaction monitoring mass spectrometry assays, and then applied to a separate cohort of 57 patients with leukemia. In this verification cohort, a machine learning ensemble-based algorithm, generalized pathseeker (GPS) produced a greater case classification accuracy than galactomannan (GM) or host proteins alone. In conclusion, Integration of host response proteins with GM improves the diagnostic detection of probable IPA in patients undergoing treatment for hematologic malignancy. Upon further validation, early detection of probable IPA in leukemia treatment will provide opportunities for earlier interventions and interventional clinical trials.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0143165",
      "citations": 17,
      "readership": 45,
      "tweets": 4,
      "news_mentions": 11
    },
    {
      "title": "FIST: A Feature-Importance Sampling and Tree-Based Method for Automatic Design Flow Parameter Tuning",
      "authors": "Xie, Z; Fang, GQ; Huang, YH; Ren, H; Zhang, Y; Khailany, B; Fang, SY; Hu, J; Chen, Y; Barboza, EC",
      "published_date": "January 1, 2020",
      "doi": "10.1109/ASP-DAC47756.2020.9045201",
      "abstract": "© 2020 IEEE. Design flow parameters are of utmost importance to chip design quality and require a painfully long time to evaluate their effects. In reality, flow parameter tuning is usually performed manually based on designers' experience in an ad hoc manner. In this work, we introduce a machine learning-based automatic parameter tuning methodology that aims to find the best design quality with a limited number of trials. Instead of merely plugging in machine learning engines, we develop clustering and approximate sampling techniques for improving tuning efficiency. The feature extraction in this method can reuse knowledge from prior designs. Furthermore, we leverage a state-of-the-art XGBoost model and propose a novel dynamic tree technique to overcome overfitting. Experimental results on benchmark circuits show that our approach achieves 25% improvement in design quality or 37% reduction in sampling cost compared to random forest method, which is the kernel of a highly cited previous work. Our approach is further validated on two industrial designs. By sampling less than 0.02% of possible parameter sets, it reduces area by 1.83% and 1.43% compared to the best solutions hand-tuned by experienced designers.",
      "publication_location": "Proceedings of the Asia and South Pacific Design Automation Conference, Asp Dac",
      "link": "http://dx.doi.org/10.1109/ASP-DAC47756.2020.9045201",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Utilizing knowledge from prior plans in the evaluation of quality assurance.",
      "authors": "Stanhope, C; Wu, QJ; Yuan, L; Liu, J; Hood, R; Yin, F-F; Adamson, J",
      "published_date": "June 21, 2015",
      "doi": "10.1088/0031-9155/60/12/4873",
      "abstract": "Increased interest regarding sensitivity of pre-treatment intensity modulated radiotherapy and volumetric modulated arc radiotherapy (VMAT) quality assurance (QA) to delivery errors has led to the development of dose-volume histogram (DVH) based analysis. This paradigm shift necessitates a change in the acceptance criteria and action tolerance for QA. Here we present a knowledge based technique to objectively quantify degradations in DVH for prostate radiotherapy. Using machine learning, organ-at-risk (OAR) DVHs from a population of 198 prior patients' plans were adapted to a test patient's anatomy to establish patient-specific DVH ranges. This technique was applied to single arc prostate VMAT plans to evaluate various simulated delivery errors: systematic single leaf offsets, systematic leaf bank offsets, random normally distributed leaf fluctuations, systematic lag in gantry angle of the mutli-leaf collimators (MLCs), fluctuations in dose rate, and delivery of each VMAT arc with a constant rather than variable dose rate.Quantitative Analyses of Normal Tissue Effects in the Clinic suggests V75Gy dose limits of 15% for the rectum and 25% for the bladder, however the knowledge based constraints were more stringent: 8.48 ± 2.65% for the rectum and 4.90 ± 1.98% for the bladder. 19 ± 10 mm single leaf and 1.9 ± 0.7 mm single bank offsets resulted in rectum DVHs worse than 97.7% (2σ) of clinically accepted plans. PTV degradations fell outside of the acceptable range for 0.6 ± 0.3 mm leaf offsets, 0.11 ± 0.06 mm bank offsets, 0.6 ± 1.3 mm of random noise, and 1.0 ± 0.7° of gantry-MLC lag.Utilizing a training set comprised of prior treatment plans, machine learning is used to predict a range of achievable DVHs for the test patient's anatomy. Consequently, degradations leading to statistical outliers may be identified. A knowledge based QA evaluation enables customized QA criteria per treatment site, institution and/or physician and can often be more sensitive to errors than criteria based on organ complication rates.",
      "publication_location": "Phys Med Biol",
      "link": "http://dx.doi.org/10.1088/0031-9155/60/12/4873",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "SU‐FF‐T‐498: Improving Normal Tissue Complication Probability Fits Using Non‐Binary Outcomes",
      "authors": "Das, S; Chen, S; Yin, F; Marks, L",
      "published_date": "January 1, 2009",
      "doi": "10.1118/1.3181996",
      "abstract": "Purpose: Binary outcomes (toxicity=1, no‐toxicity=0) are frequently used as inputs to fit parametric models. However, in reality, outcomes span the range in‐between these extremes; binary values are used for lack of more precise quantification. We propose a method to estimate non‐binary outcomes, which can then be used to more accurately fit conventional parametric models (e.g., Lyman‐probit, relative‐seriality). Methods and Materials: The non‐binary outcomes were estimated using 4 machine learning algorithms. The algorithms used variables selected from the available data to best‐fit binary outcomes. Based on the fitting, each algorithm outputted binary estimates of whether or not the patient suffered toxicity. By fitting each algorithm to randomly selected subsets of the patient data, multiple binary toxicity estimates were generated for each patient. Averaging these estimates for each algorithm produced a non‐binary estimate. Furthermore, averaging these non‐binary estimates over all algorithms reduced prediction bias. This final algorithm‐averaged non‐binary patient estimate was then used as input to conventional parametric algorithms. This method is demonstrated in the context of radiotherapy‐induced pneumonitis. Results: One‐hundred estimates from each algorithm × 4 algorithms were averaged to produce a non‐binary toxicity estimate for each patient. Both the original binary toxicity outcome and the non‐binary estimate were fitted to the parametric Lyman‐probit and relative‐seriality models. Both parametric models had large confidence interval limits when fitted to the original binary outcomes. The fits improved when using the non‐binary estimates. The improvement was substantially better for the Lyman‐probit model, but only marginally so for the relative‐seriality model. Thus, the Lyman‐probit model is better suited to modeling radiation‐induced pneumonitis, a conclusion that would not have been possible from the original binary outcomes. Conclusions: Non‐binary estimates from machine learning algorithms can be used to not only generate better fits to conventional parametric models, but also to deduce which model is methodologically better suited. © 2009, American Association of Physicists in Medicine. All rights reserved.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3181996",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Random forests for genetic association studies.",
      "authors": "Goldstein, BA; Polley, EC; Briggs, FBS",
      "published_date": 2011,
      "doi": "10.2202/1544-6115.1691",
      "abstract": "The Random Forests (RF) algorithm has become a commonly used machine learning algorithm for genetic association studies. It is well suited for genetic applications since it is both computationally efficient and models genetic causal mechanisms well. With its growing ubiquity, there has been inconsistent and less than optimal use of RF in the literature. The purpose of this review is to breakdown the theoretical and statistical basis of RF so that practitioners are able to apply it in their work. An emphasis is placed on showing how the various components contribute to bias and variance, as well as discussing variable importance measures. Applications specific to genetic studies are highlighted. To provide context, RF is compared to other commonly used machine learning algorithms.",
      "publication_location": "Statistical Applications in Genetics and Molecular Biology",
      "link": "http://dx.doi.org/10.2202/1544-6115.1691",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Genomic and Molecular Landscape of DNA Damage Repair Deficiency across The Cancer Genome Atlas.",
      "authors": "Knijnenburg, TA; Wang, L; Zimmermann, MT; Chambwe, N; Gao, GF; Cherniack, AD; Fan, H; Shen, H; Way, GP; Greene, CS; Liu, Y; Akbani, R; Feng, B; Donehower, LA; Miller, C; Shen, Y; Karimi, M; Chen, H; Kim, P; Jia, P; Shinbrot, E; Zhang, S; Liu, J; Hu, H; Bailey, MH; Yau, C; Wolf, D; Zhao, Z; Weinstein, JN; Li, L; Ding, L; Mills, GB; Laird, PW; Wheeler, DA; Shmulevich, I; Cancer Genome Atlas Research Network, ; Monnat, RJ; Xiao, Y; Wang, C",
      "published_date": "April 3, 2018",
      "doi": "10.1016/j.celrep.2018.03.076",
      "abstract": "DNA damage repair (DDR) pathways modulate cancer risk, progression, and therapeutic response. We systematically analyzed somatic alterations to provide a comprehensive view of DDR deficiency across 33 cancer types. Mutations with accompanying loss of heterozygosity were observed in over 1/3 of DDR genes, including TP53 and BRCA1/2. Other prevalent alterations included epigenetic silencing of the direct repair genes EXO5, MGMT, and ALKBH3 in ∼20% of samples. Homologous recombination deficiency (HRD) was present at varying frequency in many cancer types, most notably ovarian cancer. However, in contrast to ovarian cancer, HRD was associated with worse outcomes in several other cancers. Protein structure-based analyses allowed us to predict functional consequences of rare, recurrent DDR mutations. A new machine-learning-based classifier developed from gene expression data allowed us to identify alterations that phenocopy deleterious TP53 mutations. These frequent DDR gene alterations in many human cancers have functional consequences that may determine cancer progression and guide therapy.",
      "publication_location": "Cell Reports",
      "link": "http://dx.doi.org/10.1016/j.celrep.2018.03.076",
      "citations": 152,
      "readership": 695,
      "tweets": 110,
      "news_mentions": ""
    },
    {
      "title": "Block basis factorization for scalable kernel evaluation",
      "authors": "Wang, R; Li, Y; Mahoney, MW; Darve, E",
      "published_date": "January 1, 2019",
      "doi": "10.1137/18M1212586",
      "abstract": "© 2019 Society for Industrial and Applied Mathematics Kernel methods are widespread in machine learning; however, they are limited by the quadratic complexity of the construction, application, and storage of kernel matrices. Low-rank matrix approximation algorithms are widely used to address this problem and reduce the arithmetic and storage cost. However, we observed that for some datasets with wide intraclass variability, the optimal kernel parameter for smaller classes yields a matrix that is less well-approximated by low-rank methods. In this paper, we propose an efficient structured low-rank approximation method-the block basis factorization (BBF)-and its fast construction algorithm to approximate radial basis function kernel matrices. Our approach has linear memory cost and floating point operations for many machine learning kernels. BBF works for a wide range of kernel bandwidth parameters and extends the domain of applicability of low-rank approximation methods significantly. Our empirical results demonstrate the stability and superiority over the state-of-the-art kernel approximation algorithms.",
      "publication_location": "Siam Journal on Matrix Analysis and Applications",
      "link": "http://dx.doi.org/10.1137/18M1212586",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Human genetic and metabolite variation reveals that methylthioadenosine is a prognostic biomarker and an inflammatory regulator in sepsis.",
      "authors": "Wang, L; Ko, ER; Gilchrist, JJ; Pittman, KJ; Rautanen, A; Pirinen, M; Thompson, JW; Dubois, LG; Langley, RJ; Jaslow, SL; Salinas, RE; Rouse, DC; Moseley, MA; Mwarumba, S; Njuguna, P; Mturi, N; Wellcome Trust Case Control Consortium 2, ; Kenyan Bacteraemia Study Group, ; Williams, TN; Scott, JAG; Hill, AVS; Woods, CW; Ginsburg, GS; Tsalik, EL; Ko, DC",
      "published_date": "March 2017",
      "doi": "10.1126/sciadv.1602096",
      "abstract": "Sepsis is a deleterious inflammatory response to infection with high mortality. Reliable sepsis biomarkers could improve diagnosis, prognosis, and treatment. Integration of human genetics, patient metabolite and cytokine measurements, and testing in a mouse model demonstrate that the methionine salvage pathway is a regulator of sepsis that can accurately predict prognosis in patients. Pathway-based genome-wide association analysis of nontyphoidal Salmonella bacteremia showed a strong enrichment for single-nucleotide polymorphisms near the components of the methionine salvage pathway. Measurement of the pathway's substrate, methylthioadenosine (MTA), in two cohorts of sepsis patients demonstrated increased plasma MTA in nonsurvivors. Plasma MTA was correlated with levels of inflammatory cytokines, indicating that elevated MTA marks a subset of patients with excessive inflammation. A machine-learning model combining MTA and other variables yielded approximately 80% accuracy (area under the curve) in predicting death. Furthermore, mice infected with Salmonella had prolonged survival when MTA was administered before infection, suggesting that manipulating MTA levels could regulate the severity of the inflammatory response. Our results demonstrate how combining genetic data, biomolecule measurements, and animal models can shape our understanding of disease and lead to new biomarkers for patient stratification and potential therapeutic targeting.",
      "publication_location": "Science Advances",
      "link": "http://dx.doi.org/10.1126/sciadv.1602096",
      "citations": 23,
      "readership": 52,
      "tweets": 27,
      "news_mentions": 9
    },
    {
      "title": "MSIseq: Software for Assessing Microsatellite Instability from Catalogs of Somatic Mutations.",
      "authors": "Huang, MN; McPherson, JR; Cutcutache, I; Teh, BT; Tan, P; Rozen, SG",
      "published_date": "August 26, 2015",
      "doi": "10.1038/srep13321",
      "abstract": "Microsatellite instability (MSI) is a form of hypermutation that occurs in some tumors due to defects in cellular DNA mismatch repair. MSI is characterized by frequent somatic mutations (i.e., cancer-specific mutations) that change the length of simple repeats (e.g., AAAAA…., GATAGATAGATA...). Clinical MSI tests evaluate the lengths of a handful of simple repeat sites, while next-generation sequencing can assay many more sites and offers a much more complete view of their somatic mutation frequencies. Using somatic mutation data from the exomes of a 361-tumor training set, we developed classifiers to determine MSI status based on four machine-learning frameworks. All frameworks had high accuracy, and after choosing one we determined that it had >98% concordance with clinical tests in a separate 163-tumor test set. Furthermore, this classifier retained high concordance even when classifying tumors based on subsets of whole-exome data. We have released a CRAN R package, MSIseq, based on this classifier. MSIseq is faster and simpler to use than software that requires large files of aligned sequenced reads. MSIseq will be useful for genomic studies in which clinical MSI test results are unavailable and for detecting possible misclassifications by clinical tests.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/srep13321",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "TCR Repertoires of Thymic Conventional and Regulatory T Cells: Identification and Characterization of Both Unique and Shared TCR Sequences.",
      "authors": "Ko, A; Watanabe, M; Nguyen, T; Shi, A; Achour, A; Zhang, B; Sun, X; Wang, Q; Zhuang, Y; Weng, N-P; Hodes, RJ",
      "published_date": "February 15, 2020",
      "doi": "10.4049/jimmunol.1901006",
      "abstract": "Thymic regulatory T cells (tTreg) are critical in the maintenance of normal T cell immunity and tolerance. The role of TCR in tTreg selection remains incompletely understood. In this study, we assessed TCRα and TCRβ sequences of mouse tTreg and thymic conventional CD4+ T cells (Tconv) by high-throughput sequencing. We identified αβ TCR sequences that were unique to either tTreg or Tconv and found that these were distinct as recognized by machine learning algorithm and by preferentially used amino acid trimers in αβ CDR3 of tTreg. In addition, a proportion of αβ TCR sequences expressed by tTreg were also found in Tconv, and machine learning classified the great majority of these shared αβ TCR sequences as characteristic of Tconv and not tTreg. These findings identify two populations of tTreg, one in which the regulatory T cell fate is associated with unique properties of the TCR and another with TCR properties characteristic of Tconv for which tTreg fate is determined by factors beyond TCR sequence.",
      "publication_location": "J Immunol",
      "link": "http://dx.doi.org/10.4049/jimmunol.1901006",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Expression of socially sensitive genes: The multi-ethnic study of atherosclerosis.",
      "authors": "Brown, KM; Diez-Roux, AV; Smith, JA; Needham, BL; Mukherjee, B; Ware, EB; Liu, Y; Cole, SW; Seeman, TE; Kardia, SLR",
      "published_date": 2019,
      "doi": "10.1371/journal.pone.0214061",
      "abstract": "BACKGROUND: Gene expression may be an important biological mediator in associations between social factors and health. However, previous studies were limited by small sample sizes and use of differing cell types with heterogeneous expression patterns. We use a large population-based cohort with gene expression measured solely in monocytes to investigate associations between seven social factors and expression of genes previously found to be sensitive to social factors. METHODS: We employ three methodological approaches: 1) omnibus test for the entire gene set (Global ANCOVA), 2) assessment of each association individually (linear regression), and 3) machine learning method that performs variable selection with correlated predictors (elastic net). RESULTS: In global analyses, significant associations with the a priori defined socially sensitive gene set were detected for major or lifetime discrimination and chronic burden (p = 0.019 and p = 0.047, respectively). Marginally significant associations were detected for loneliness and adult socioeconomic status (p = 0.066, p = 0.093, respectively). No associations were significant in linear regression analyses after accounting for multiple testing. However, a small percentage of gene expressions (up to 11%) were associated with at least one social factor using elastic net. CONCLUSION: The Global ANCOVA and elastic net findings suggest that a small percentage of genes may be \"socially sensitive,\" (i.e. demonstrate differential expression by social factor), yet single gene approaches such as linear regression may be ill powered to capture this relationship. Future research should further investigate the biological mechanisms through which social factors act to influence gene expression and how systemic changes in gene expression affect overall health.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0214061",
      "citations": 2,
      "readership": 10,
      "tweets": 7,
      "news_mentions": ""
    },
    {
      "title": "A risk calculator to predict adult attention-deficit/hyperactivity disorder: generation and external validation in three birth cohorts and one clinical sample.",
      "authors": "Caye, A; Agnew-Blais, J; Arseneault, L; Gonçalves, H; Kieling, C; Langley, K; Menezes, AMB; Moffitt, TE; Passos, IC; Rocha, TB; Sibley, MH; Swanson, JM; Thapar, A; Wehrmeister, F; Rohde, LA",
      "published_date": "May 15, 2019",
      "doi": "10.1017/s2045796019000283",
      "abstract": "AIM:Few personalised medicine investigations have been conducted for mental health. We aimed to generate and validate a risk tool that predicts adult attention-deficit/hyperactivity disorder (ADHD). METHODS:Using logistic regression models, we generated a risk tool in a representative population cohort (ALSPAC - UK, 5113 participants, followed from birth to age 17) using childhood clinical and sociodemographic data with internal validation. Predictors included sex, socioeconomic status, single-parent family, ADHD symptoms, comorbid disruptive disorders, childhood maltreatment, ADHD symptoms, depressive symptoms, mother's depression and intelligence quotient. The outcome was defined as a categorical diagnosis of ADHD in young adulthood without requiring age at onset criteria. We also tested Machine Learning approaches for developing the risk models: Random Forest, Stochastic Gradient Boosting and Artificial Neural Network. The risk tool was externally validated in the E-Risk cohort (UK, 2040 participants, birth to age 18), the 1993 Pelotas Birth Cohort (Brazil, 3911 participants, birth to age 18) and the MTA clinical sample (USA, 476 children with ADHD and 241 controls followed for 16 years from a minimum of 8 and a maximum of 26 years old). RESULTS:The overall prevalence of adult ADHD ranged from 8.1 to 12% in the population-based samples, and was 28.6% in the clinical sample. The internal performance of the model in the generating sample was good, with an area under the curve (AUC) for predicting adult ADHD of 0.82 (95% confidence interval (CI) 0.79-0.83). Calibration plots showed good agreement between predicted and observed event frequencies from 0 to 60% probability. In the UK birth cohort test sample, the AUC was 0.75 (95% CI 0.71-0.78). In the Brazilian birth cohort test sample, the AUC was significantly lower -0.57 (95% CI 0.54-0.60). In the clinical trial test sample, the AUC was 0.76 (95% CI 0.73-0.80). The risk model did not predict adult anxiety or major depressive disorder. Machine Learning approaches did not outperform logistic regression models. An open-source and free risk calculator was generated for clinical use and is available online at https://ufrgs.br/prodah/adhd-calculator/. CONCLUSIONS:The risk tool based on childhood characteristics specifically predicts adult ADHD in European and North-American population-based and clinical samples with comparable discrimination to commonly used clinical tools in internal medicine and higher than most previous attempts for mental and neurological disorders. However, its use in middle-income settings requires caution.",
      "publication_location": "Epidemiology and Psychiatric Sciences",
      "link": "http://dx.doi.org/10.1017/s2045796019000283",
      "citations": 2,
      "readership": 25,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "A Predictive Model for Selective Targeting of the Warburg Effect through GAPDH Inhibition with a Natural Product.",
      "authors": "Liberti, MV; Dai, Z; Wardell, SE; Baccile, JA; Liu, X; Gao, X; Baldi, R; Mehrmohamadi, M; Johnson, MO; Madhukar, NS; Shestov, AA; Chio, IIC; Elemento, O; Rathmell, JC; Schroeder, FC; McDonnell, DP; Locasale, JW",
      "published_date": "October 3, 2017",
      "doi": "10.1016/j.cmet.2017.08.017",
      "abstract": "Targeted cancer therapies that use genetics are successful, but principles for selectively targeting tumor metabolism that is also dependent on the environment remain unknown. We now show that differences in rate-controlling enzymes during the Warburg effect (WE), the most prominent hallmark of cancer cell metabolism, can be used to predict a response to targeting glucose metabolism. We establish a natural product, koningic acid (KA), to be a selective inhibitor of GAPDH, an enzyme we characterize to have differential control properties over metabolism during the WE. With machine learning and integrated pharmacogenomics and metabolomics, we demonstrate that KA efficacy is not determined by the status of individual genes, but by the quantitative extent of the WE, leading to a therapeutic window in vivo. Thus, the basis of targeting the WE can be encoded by molecular principles that extend beyond the status of individual genes.",
      "publication_location": "Cell Metab",
      "link": "http://dx.doi.org/10.1016/j.cmet.2017.08.017",
      "citations": 49,
      "readership": 157,
      "tweets": 31,
      "news_mentions": 11
    },
    {
      "title": "Towards precision medicine: Accurate predictive modeling of infectious complications in combat casualties.",
      "authors": "Dente, CJ; Bradley, M; Schobel, S; Gaucher, B; Buchman, T; Kirk, AD; Elster, E",
      "published_date": "October 2017",
      "doi": "10.1097/TA.0000000000001596",
      "abstract": "BACKGROUND: The biomarker profile of trauma patients may allow for the creation of models to assist bedside decision making and prediction of complications. We sought to determine the utility of modeling in the prediction of bacteremia and pneumonia in combat casualties. METHODS: This is a prospective, observational trial of patients with complex wounds treated at Walter Reed National Military Medical Center (2007-2012). Tissue, serum, and wound effluent samples were collected during operative interventions until wound closure. Clinical, biomarker, and outcome data were used in machine learning algorithms to develop models predicting bacteremia or pneumonia. Modeling was performed on the first operative washout to maximize predictive benefit. Variable selection of dataset variables was performed and the best-fitting Bayesian belief network (BBN), using Bayesian information criterion (BIC), was selected for predictive modeling. Random forest was performed using variables from BBN step. Model performance was evaluated using area under the receiver operating characteristic curve (AUC) analysis. RESULTS: Seventy-three patients (mean age 23, mean Injury Severity Score 25) were enrolled. Patients required a median of 3 (2-13) operations. The incidence of bacteremia and pneumonia was 22% and 12%, respectively. Best-fitting variable selected BBNs were maximum-minimum parents and children (MMPC) for both bacteremia (BIC-24948) and pneumonia (BIC-17886). Full variable and MMPC random forest models AUC were 0.721 and 0.834, respectively, for bacteremia and 0.809 and 0.856, respectively, for pneumonia. CONCLUSIONS: We identified a profile predictive of bacteremia and pneumonia in combat casualties. This has important clinical implications and should be validated in the civilian trauma population. This and similar tools will allow for increasing precision in the management of critically ill and injured patients. LEVEL OF EVIDENCE: Prognostic, level III.",
      "publication_location": "J Trauma Acute Care Surg",
      "link": "http://dx.doi.org/10.1097/TA.0000000000001596",
      "citations": 12,
      "readership": 52,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "A blood-based signature of cerebrospinal fluid Aβ1-42 status.",
      "authors": "Goudey, B; Fung, BJ; Schieber, C; Faux, NG; Alzheimer’s Disease Metabolomics Consortium, ; Alzheimer’s Disease Neuroimaging Initiative,",
      "published_date": "March 11, 2019",
      "doi": "10.1038/s41598-018-37149-7",
      "abstract": "It is increasingly recognized that Alzheimer's disease (AD) exists before dementia is present and that shifts in amyloid beta occur long before clinical symptoms can be detected. Early detection of these molecular changes is a key aspect for the success of interventions aimed at slowing down rates of cognitive decline. Recent evidence indicates that of the two established methods for measuring amyloid, a decrease in cerebrospinal fluid (CSF) amyloid β1-42 (Aβ1-42) may be an earlier indicator of Alzheimer's disease risk than measures of amyloid obtained from Positron Emission Tomography (PET). However, CSF collection is highly invasive and expensive. In contrast, blood collection is routinely performed, minimally invasive and cheap. In this work, we develop a blood-based signature that can provide a cheap and minimally invasive estimation of an individual's CSF amyloid status using a machine learning approach. We show that a Random Forest model derived from plasma analytes can accurately predict subjects as having abnormal (low) CSF Aβ1-42 levels indicative of AD risk (0.84 AUC, 0.78 sensitivity, and 0.73 specificity). Refinement of the modeling indicates that only APOEε4 carrier status and four plasma analytes (CGA, Aβ1-42, Eotaxin 3, APOE) are required to achieve a high level of accuracy. Furthermore, we show across an independent validation cohort that individuals with predicted abnormal CSF Aβ1-42 levels transitioned to an AD diagnosis over 120 months significantly faster than those with predicted normal CSF Aβ1-42 levels and that the resulting model also validates reasonably across PET Aβ1-42 status (0.78 AUC). This is the first study to show that a machine learning approach, using plasma protein levels, age and APOEε4 carrier status, is able to predict CSF Aβ1-42 status, the earliest risk indicator for AD, with high accuracy.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/s41598-018-37149-7",
      "citations": 4,
      "readership": 60,
      "tweets": 47,
      "news_mentions": 5
    },
    {
      "title": "Brain-wide Electrical Spatiotemporal Dynamics Encode Depression Vulnerability.",
      "authors": "Hultman, R; Ulrich, K; Sachs, BD; Blount, C; Carlson, DE; Ndubuizu, N; Bagot, RC; Parise, EM; Vu, M-AT; Gallagher, NM; Wang, J; Silva, AJ; Deisseroth, K; Mague, SD; Caron, MG; Nestler, EJ; Carin, L; Dzirasa, K",
      "published_date": "March 22, 2018",
      "doi": "10.1016/j.cell.2018.02.012",
      "abstract": "Brain-wide fluctuations in local field potential oscillations reflect emergent network-level signals that mediate behavior. Cracking the code whereby these oscillations coordinate in time and space (spatiotemporal dynamics) to represent complex behaviors would provide fundamental insights into how the brain signals emotional pathology. Using machine learning, we discover a spatiotemporal dynamic network that predicts the emergence of major depressive disorder (MDD)-related behavioral dysfunction in mice subjected to chronic social defeat stress. Activity patterns in this network originate in prefrontal cortex and ventral striatum, relay through amygdala and ventral tegmental area, and converge in ventral hippocampus. This network is increased by acute threat, and it is also enhanced in three independent models of MDD vulnerability. Finally, we demonstrate that this vulnerability network is biologically distinct from the networks that encode dysfunction after stress. Thus, these findings reveal a convergent mechanism through which MDD vulnerability is mediated in the brain.",
      "publication_location": "Cell",
      "link": "http://dx.doi.org/10.1016/j.cell.2018.02.012",
      "citations": 28,
      "readership": 273,
      "tweets": 51,
      "news_mentions": 6
    },
    {
      "title": "Scaling Support Vector Machines on modern HPC platforms",
      "authors": "You, Y; Fu, H; Song, SL; Randles, A; Kerbyson, D; Marquez, A; Yang, G; Hoisie, A",
      "published_date": "January 1, 2015",
      "doi": "10.1016/j.jpdc.2014.09.005",
      "abstract": "© 2014 Elsevier Inc. All rights reserved. Support Vector Machines (SVM) have been widely used in data-mining and Big Data applications as modern commercial databases start to attach an increasing importance to the analytic capabilities. In recent years, SVM was adapted to the field of High Performance Computing for power/performance prediction, auto-tuning, and runtime scheduling. However, even at the risk of losing prediction accuracy due to insufficient runtime information, researchers can only afford to apply offline model training to avoid significant runtime training overhead. Advanced multi- and many-core architectures offer massive parallelism with complex memory hierarchies which can make runtime training possible, but form a barrier to efficient parallel SVM design. To address the challenges above, we designed and implemented MIC-SVM, a highly efficient parallel SVM for x86 based multi-core and many-core architectures, such as the Intel Ivy Bridge CPUs and Intel Xeon Phi co-processor (MIC). We propose various novel analysis methods and optimization techniques to fully utilize the multilevel parallelism provided by these architectures and serve as general optimization methods for other machine learning tools. MIC-SVM achieves 4.4-84× and 18-47× speedups against the popular LIBSVM, on MIC and Ivy Bridge CPUs respectively, for several real-world data-mining datasets. Even compared with GPUSVM, running on the NVIDIA k20x GPU, the performance of our MIC-SVM is competitive. We also conduct a cross-platform performance comparison analysis, focusing on Ivy Bridge CPUs, MIC and GPUs, and provide insights on how to select the most suitable advanced architectures for specific algorithms and input data patterns.",
      "publication_location": "Journal of Parallel and Distributed Computing",
      "link": "http://dx.doi.org/10.1016/j.jpdc.2014.09.005",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sequence information for the splicing of human pre-mRNA identified by support vector machine classification.",
      "authors": "Zhang, XH-F; Heller, KA; Hefter, I; Leslie, CS; Chasin, LA",
      "published_date": "December 2003",
      "doi": "10.1101/gr.1679003",
      "abstract": "Vertebrate pre-mRNA transcripts contain many sequences that resemble splice sites on the basis of agreement to the consensus,yet these more numerous false splice sites are usually completely ignored by the cellular splicing machinery. Even at the level of exon definition,pseudo exons defined by such false splices sites outnumber real exons by an order of magnitude. We used a support vector machine to discover sequence information that could be used to distinguish real exons from pseudo exons. This machine learning tool led to the definition of potential branch points,an extended polypyrimidine tract,and C-rich and TG-rich motifs in a region limited to 50 nt upstream of constitutively spliced exons. C-rich sequences were also found in a region extending to 80 nt downstream of exons,along with G-triplet motifs. In addition,it was shown that combinations of three bases within the splice donor consensus sequence were more effective than consensus values in distinguishing real from pseudo splice sites; two-way base combinations were optimal for distinguishing 3' splice sites. These data also suggest that interactions between two or more of these elements may contribute to exon recognition,and provide candidate sequences for assessment as intronic splicing enhancers.",
      "publication_location": "Genome Research",
      "link": "http://dx.doi.org/10.1101/gr.1679003",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Prediction of the severity of obstructive sleep apnea by anthropometric features via support vector machine.",
      "authors": "Liu, W-T; Wu, H-T; Juang, J-N; Wisniewski, A; Lee, H-C; Wu, D; Lo, Y-L",
      "published_date": "January 2017",
      "doi": "10.1371/journal.pone.0176991",
      "abstract": "To develop an applicable prediction for obstructive sleep apnea (OSA) is still a challenge in clinical practice. We apply a modern machine learning method, the support vector machine to establish a predicting model for the severity of OSA. The support vector machine was applied to build up a prediction model based on three anthropometric features (neck circumference, waist circumference, and body mass index) and age on the first database. The established model was then valided independently on the second database. The anthropometric features and age were combined to generate powerful predictors for OSA. Following the common practice, we predict if a subject has the apnea-hypopnea index greater then 15 or not as well as 30 or not. Dividing by genders and age, for the AHI threhosld 15 (respectively 30), the cross validation and testing accuracy for the prediction were 85.3% and 76.7% (respectively 83.7% and 75.5%) in young female, while the negative likelihood ratio for the AHI threhosld 15 (respectively 30) for the cross validation and testing were 0.2 and 0.32 (respectively 0.06 and 0.1) in young female. The more accurate results with lower negative likelihood ratio in the younger patients, especially the female subgroup, reflect the potential of the proposed model for the screening purpose and the importance of approaching by different genders and the effects of aging.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0176991",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "PATTERN: Pain Assessment for paTients who can't TEll using Restricted Boltzmann machiNe.",
      "authors": "Yang, L; Wang, S; Jiang, X; Cheng, S; Kim, H-E",
      "published_date": "July 25, 2016",
      "doi": "10.1186/s12911-016-0317-0",
      "abstract": "Accurately assessing pain for those who cannot make self-report of pain, such as minimally responsive or severely brain-injured patients, is challenging. In this paper, we attempted to address this challenge by answering the following questions: (1) if the pain has dependency structures in electronic signals and if so, (2) how to apply this pattern in predicting the state of pain. To this end, we have been investigating and comparing the performance of several machine learning techniques.We first adopted different strategies, in which the collected original n-dimensional numerical data were converted into binary data. Pain states are represented in binary format and bound with above binary features to construct (n + 1) -dimensional data. We then modeled the joint distribution over all variables in this data using the Restricted Boltzmann Machine (RBM).Seventy-eight pain data items were collected. Four individuals with the number of recorded labels larger than 1000 were used in the experiment. Number of avaliable data items for the four patients varied from 22 to 28. Discriminant RBM achieved better accuracy in all four experiments.The experimental results show that RBM models the distribution of our binary pain data well. We showed that discriminant RBM can be used in a classification task, and the initial result is advantageous over other classifiers such as support vector machine (SVM) using PCA representation and the LDA discriminant method.",
      "publication_location": "Bmc Medical Informatics and Decision Making",
      "link": "http://dx.doi.org/10.1186/s12911-016-0317-0",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Boosting evolutionary support vector machine for designing tumor classifiers from microarray data",
      "authors": "Huang, HL; Chen, YH; Koeberl, DD; Ho, SY",
      "published_date": "December 1, 2007",
      "doi": "",
      "abstract": "Since there are multiple sets of relevant genes having the same high accuracy in fitting training data called model uncertainty, to identify a small set of informative genes from microarray data for designing an accurate tumor classifier for unknown samples is intractable. Support vector machine (SVM), a supervised machine learning technique, is one of the methods successfully applied to cancer diagnosis problems. This study proposes an SVM-based classifier with automatic feature selection associated with a boosting strategy. The proposed boosting evolutionary support vector machine (named BESVM) hybridizes the advantages of SVM, boosting using a majority-voting ensemble and an intelligent genetic algorithm for gene selection. The merits of the BESVM-based classifier are threefold: 1) a small set of used genes, 2) accurate test classification using leave-one-out cross-validation, and 3) robust performance by avoiding overfitting training data. Five benchmark datasets were used to evaluate the BESVM-based classifier. Simulation results reveal that BESVM performs well having a mean accuracy 94.26% using only 10.1 genes averagely, compared with the existing SVM and non-SVM based classifiers. © 2007 IEEE.",
      "publication_location": "2007 Ieee Symposium on Computational Intelligence and Bioinformatics and Computational Biology, Cibcb 2007",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Progression of patterns (POP): a machine classifier algorithm to identify glaucoma progression in visual fields.",
      "authors": "Goldbaum, MH; Lee, I; Jang, G; Balasubramanian, M; Sample, PA; Weinreb, RN; Liebmann, JM; Girkin, CA; Anderson, DR; Zangwill, LM; Fredette, M-J; Jung, T-P; Medeiros, FA; Bowd, C",
      "published_date": "September 25, 2012",
      "doi": "10.1167/iovs.11-8363",
      "abstract": "PURPOSE: We evaluated Progression of Patterns (POP) for its ability to identify progression of glaucomatous visual field (VF) defects. METHODS: POP uses variational Bayesian independent component mixture model (VIM), a machine learning classifier (MLC) developed previously. VIM separated Swedish Interactive Thresholding Algorithm (SITA) VFs from a set of 2,085 normal and glaucomatous eyes into nine axes (VF patterns): seven glaucomatous. Stable glaucoma was simulated in a second set of 55 patient eyes with five VFs each, collected within four weeks. A third set of 628 eyes with 4,186 VFs (mean ± SD of 6.7 ± 1.7 VFs over 4.0 ± 1.4 years) was tested for progression. Tested eyes were placed into suspect and glaucoma categories at baseline, based on VFs and disk stereoscopic photographs; a subset of eyes had stereophotographic evidence of progressive glaucomatous optic neuropathy (PGON). Each sequence of fields was projected along seven VIM glaucoma axes. Linear regression (LR) slopes generated from projections onto each axis yielded a degree of confidence (DOC) that there was progression. At 95% specificity, progression cutoffs were established for POP, visual field index (VFI), and mean deviation (MD). Guided progression analysis (GPA) was also compared. RESULTS: POP identified a statistically similar number of eyes (P > 0.05) as progressing compared with VFI, MD, and GPA in suspects (3.8%, 2.7%, 5.6%, and 2.9%, respectively), and more eyes than GPA (P = 0.01) in glaucoma (16.0%, 15.3%, 12.0%, and 7.3%, respectively), and more eyes than GPA (P = 0.05) in PGON eyes (26.3%, 23.7%, 27.6%, and 14.5%, respectively). CONCLUSIONS: POP, with its display of DOC of progression and its identification of progressing VF defect pattern, adds to the information available to the clinician for detecting VF progression.",
      "publication_location": "Investigative Opthalmology & Visual Science",
      "link": "http://dx.doi.org/10.1167/iovs.11-8363",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning to Simplify Distributed Systems Management",
      "authors": "",
      "published_date": "January 22, 2019",
      "doi": "10.1109/BigData.2018.8622058",
      "abstract": "© 2018 IEEE. Managing large-scale distributed systems is a difficult task. System administrators are responsible for the upkeep and maintenance of numerous components with complex dependencies. With the shift to microservices-based architectures, these systems can consist of 100s to 1000s of interconnected nodes. To combat this difficulty, administrators rely on analyzing logs and metrics collected from the different services. However, the number of available metrics for large systems presents complexity and scaling issues. To combat these issues, we present Minerva, an unsupervised Machine Learning (ML) framework for performing network diagnosis analysis. Minerva is composed of a multi-stage pipeline, where each component can act individually or cohesively to perform various management tasks. Our system offers a unified and extensible framework for managing the complexity of large networks, and presents administrators with a swiss-army knife for diagnosing the overall health of their systems. To demonstrate the feasibility of Minerva, we evaluate its performance on a production-scale system. We present use cases for the various management tools made available by Minerva, and show how these tools can be used to make strong inferences about the system using unsupervised techniques.",
      "publication_location": "Proceedings   2018 Ieee International Conference on Big Data, Big Data 2018",
      "link": "http://dx.doi.org/10.1109/BigData.2018.8622058",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning when to reject an importance sample",
      "authors": "Weiss, JC; Natarajan, S; Page, CD",
      "published_date": "January 1, 2013",
      "doi": "",
      "abstract": "When observations are incomplete or data are missing, approximate inference methods based on importance sampling are often used. Unfortunately, when the target and proposal distributions are dissimilar, the sampling procedure leads to biased estimates or requires a prohibitive number of samples. Our method approximates a multivariate target distribution by sampling from an existing, sequential importance sampler and accepting or rejecting the proposals. We develop the rejection-sampler framework and show we can learn the acceptance probabilities from local samples. In a continuous-time domain, we show our method improves upon previous importance samplers by transforming a sequential importance sampling problem into a machine learning one. Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved.",
      "publication_location": "Aaai Workshop   Technical Report",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning-assisted multi-step planning",
      "authors": "Hauser, K; Bretl, T; Latombe, JC",
      "published_date": "December 1, 2005",
      "doi": "10.1109/ROBOT.2005.1570825",
      "abstract": "Probabilistic sampling-based motion planners are unable to detect when no feasible path exists. A common heuristic is to declare a query infeasible if a path is not found in a fixed amount of time. In applications where many queries must be processed - for instance, robotic manipulation, multi-limbed locomotion, and contact motion - a critical question arises: what should this time limit be? This paper presents a machine-learning approach to deal with this question. In an off-line learning phase, a classifier is trained to quickly predict the feasibility of a query. Then, an improved multi-step motion planning algorithm uses this classifier to avoid wasting time on infeasible queries. This approach has been successfully demonstrated in simulation on a four-limbed, free-climbing robot. ©2005 IEEE.",
      "publication_location": "Proceedings   Ieee International Conference on Robotics and Automation",
      "link": "http://dx.doi.org/10.1109/ROBOT.2005.1570825",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "New algorithms for learning in presence of errors",
      "authors": "Arora, S; Ge, R",
      "published_date": "July 11, 2011",
      "doi": "10.1007/978-3-642-22006-7_34",
      "abstract": "We give new algorithms for a variety of randomly-generated instances of computational problems using a linearization technique that reduces to solving a system of linear equations. These algorithms are derived in the context of learning with structured noise, a notion introduced in this paper. This notion is best illustrated with the learning parities with noise (LPN) problem -well-studied in learning theory and cryptography. In the standard version, we have access to an oracle that, each time we press a button, returns a random vector together with a bit that was computed as a•u+η, where is a secret vector, and is a noise bit that is 1 with some probability p. Say p = 1/3. The goal is to recover u. This task is conjectured to be intractable. In the structured noise setting we introduce a slight (?) variation of the model: upon pressing a button, we receive (say) 10 random vectors , and corresponding bits b 1, b 2, ..., b 10, of which at most 3 are noisy. The oracle may arbitrarily decide which of the 10 bits to make noisy. We exhibit a polynomial-time algorithm to recover the secret vector u given such an oracle. We think this structured noise model may be of independent interest in machine learning. We discuss generalizations of our result, including learning with more general noise patterns. We also give the first nontrivial algorithms for two problems, which we show fit in our structured noise framework. We give a slightly subexponential algorithm for the well-known learning with errors (LWE) problem over introduced by Regev for cryptographic uses. Our algorithm works for the case when the gaussian noise is small; which was an open problem. Our result also clarifies why existing hardness results fail at this particular noise rate. We also give polynomial-time algorithms for learning the MAJORITY OF PARITIES function of Applebaum et al. for certain parameter values. This function is a special case of Goldreich's pseudorandom generator. The full version is available at http://www.eccc.uni-trier.de/report/ 2010/066/ . © 2011 Springer-Verlag.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "http://dx.doi.org/10.1007/978-3-642-22006-7_34",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning mixtures of gaussians in high dimensions",
      "authors": "Ge, R; Huang, Q; Kakade, SM",
      "published_date": "June 14, 2015",
      "doi": "10.1145/2746539.2746616",
      "abstract": "© Copyright 2015 ACM. Efficiently learning mixture of Gaussians is a fundamental problem in statistics and learning theory. Given samples coming from a random one out of k Gaussian distributions in Rn, the learning problem asks to estimate the means and the covariance matrices of these Gaussians. This learning problem arises in many areas ranging from the natural sciences to the social sciences, and has also found many machine learning applications. Unfortunately, learning mixture of Gaussians is an information theoretically hard problem: in order to learn the parameters up to a reasonable accuracy, the number of samples required is exponential in the number of Gaussian components in the worst case. In this work, we show that provided we are in high enough dimensions, the class of Gaussian mixtures is learnable in its most general form under a smoothed analysis framework, where the parameters are randomly perturbed from an adversarial starting point. In particular, given samples from a mixture of Gaussians with randomly perturbed parameters, when n ≥ ?(k2), we give an algorithm that learns the parameters with polynomial running time and using polynomial number of samples. The central algorithmic ideas consist of new ways to decompose the moment tensor of the Gaussian mixture by exploiting its structural properties. The symmetries of this tensor are derived from the combinatorial structure of higher order moments of Gaussian distributions (sometimes referred to as Isserlis' theorem or Wick's theorem). We also develop new tools for bounding smallest singular values of structured random matrices, which could be useful in other smoothed analysis settings.",
      "publication_location": "Proceedings of the Annual Acm Symposium on Theory of Computing",
      "link": "http://dx.doi.org/10.1145/2746539.2746616",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Provable learning of noisy-or networks",
      "authors": "Arora, S; Ge, R; Ma, T; Risteski, A",
      "published_date": "June 19, 2017",
      "doi": "10.1145/3055399.3055482",
      "abstract": "© 2017 ACM. Many machine learning applications use latent variable models to explain structure in data, whereby visible variables (= coordinates of the given datapoint) are explained as a probabilistic function of some hidden variables. Finding parameters with the maximum likelihood is NP-hard even in very simple settings. In recent years, provably efficient algorithms were nevertheless developed for models with linear structures: topic models, mixture models, hidden Markov models, etc. These algorithms use matrix or tensor decomposition, and make some reasonable assumptions about the parameters of the underlying model. But matrix or tensor decomposition seems of little use when the latent variable model has nonlinearities. The current paper shows how to make progress: tensor decomposition is applied for learning the single-layer noisy or network, which is a textbook example of a Bayes net, and used for example in the classic QMR-DT software for diagnosing which disease(s) a patient may have by observing the symptoms he/she exhibits. The technical novelty here, which should be useful in other settings in future, is analysis of tensor decomposition in presence of systematic error (i.e., where the noise/error is correlated with the signal, and doesn't decrease as number of samples goes to infinity). This requires rethinking all steps of tensor decomposition methods from the ground up. For simplicity our analysis is stated assuming that the network parameters were chosen from a probability distribution but the method seems more generally applicable.",
      "publication_location": "Proceedings of the Annual Acm Symposium on Theory of Computing",
      "link": "http://dx.doi.org/10.1145/3055399.3055482",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Neuroprosthetic Decoder Training as Imitation Learning.",
      "authors": "Merel, J; Carlson, D; Paninski, L; Cunningham, JP",
      "published_date": "May 18, 2016",
      "doi": "10.1371/journal.pcbi.1004948",
      "abstract": "Neuroprosthetic brain-computer interfaces function via an algorithm which decodes neural activity of the user into movements of an end effector, such as a cursor or robotic arm. In practice, the decoder is often learned by updating its parameters while the user performs a task. When the user's intention is not directly observable, recent methods have demonstrated value in training the decoder against a surrogate for the user's intended movement. Here we show that training a decoder in this way is a novel variant of an imitation learning problem, where an oracle or expert is employed for supervised training in lieu of direct observations, which are not available. Specifically, we describe how a generic imitation learning meta-algorithm, dataset aggregation (DAgger), can be adapted to train a generic brain-computer interface. By deriving existing learning algorithms for brain-computer interfaces in this framework, we provide a novel analysis of regret (an important metric of learning efficacy) for brain-computer interfaces. This analysis allows us to characterize the space of algorithmic variants and bounds on their regret rates. Existing approaches for decoder learning have been performed in the cursor control setting, but the available design principles for these decoders are such that it has been impossible to scale them to naturalistic settings. Leveraging our findings, we then offer an algorithm that combines imitation learning with optimal control, which should allow for training of arbitrary effectors for which optimal control can generate goal-oriented control. We demonstrate this novel and general BCI algorithm with simulated neuroprosthetic control of a 26 degree-of-freedom model of an arm, a sophisticated and realistic end effector.",
      "publication_location": "Plos Computational Biology",
      "link": "http://dx.doi.org/10.1371/journal.pcbi.1004948",
      "citations": 4,
      "readership": 56,
      "tweets": 22,
      "news_mentions": ""
    },
    {
      "title": "Box drawings for learning with imbalanced data",
      "authors": "Goh, ST; Rudin, C",
      "published_date": "January 1, 2014",
      "doi": "10.1145/2623330.2623648",
      "abstract": "The vast majority of real world classification problems are imbalanced, meaning there are far fewer data from the class of interest (the positive class) than from other classes. We propose two machine learning algorithms to handle highly imbalanced classification problems. The classifiers are disjunctions of conjunctions, and are created as unions of parallel axis rectangles around the positive examples, and thus have the benefit of being interpretable. The first algorithm uses mixed integer programming to optimize a weighted balance between positive and negative class accuracies. Regularization is introduced to improve generalization performance. The second method uses an approximation in order to assist with scalability. Specifically, it follows a \\textit{characterize then discriminate} approach, where the positive class is characterized first by boxes, and then each box boundary becomes a separate discriminative classifier. This method has the computational advantages that it can be easily parallelized, and considers only the relevant regions of feature space. © 2014 ACM.",
      "publication_location": "Proceedings of the Acm Sigkdd International Conference on Knowledge Discovery and Data Mining",
      "link": "http://dx.doi.org/10.1145/2623330.2623648",
      "citations": 15,
      "readership": 68,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "On Deep Learning for Medical Image Analysis.",
      "authors": "Carin, L; Pencina, MJ",
      "published_date": "September 18, 2018",
      "doi": "10.1001/jama.2018.13316",
      "abstract": "",
      "publication_location": "Jama",
      "link": "http://dx.doi.org/10.1001/jama.2018.13316",
      "citations": 9,
      "readership": 230,
      "tweets": 48,
      "news_mentions": ""
    },
    {
      "title": "Variational learning of individual survival distributions",
      "authors": "Xiu, Z; Tao, C; University, D; Henao, R",
      "published_date": "February 4, 2020",
      "doi": "10.1145/3368555.3384454",
      "abstract": "© 2020 ACM. The abundance of modern health data provides many opportunities for the use of machine learning techniques to build better statistical models to improve clinical decision making. Predicting time-to-event distributions, also known as survival analysis, plays a key role in many clinical applications. We introduce a variational time-to-event prediction model, named Variational Survival Inference (VSI), which builds upon recent advances in distribution learning techniques and deep neural networks. VSI addresses the challenges of non-parametric distribution estimation by ($i$) relaxing the restrictive modeling assumptions made in classical models, and ($ii$) efficiently handling the censored observations, i.e. events that occur outside the observation window, all within the variational framework. To validate the effectiveness of our approach, an extensive set of experiments on both synthetic and real-world datasets is carried out, showing improved performance relative to competing solutions.",
      "publication_location": "Acm Chil 2020   Proceedings of the 2020 Acm Conference on Health, Inference, and Learning",
      "link": "http://dx.doi.org/10.1145/3368555.3384454",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 7,
      "news_mentions": ""
    },
    {
      "title": "Deep learning in ophthalmology: The technical and clinical considerations.",
      "authors": "Ting, DSW; Peng, L; Varadarajan, AV; Keane, PA; Burlina, PM; Chiang, MF; Schmetterer, L; Pasquale, LR; Bressler, NM; Webster, DR; Abramoff, M; Wong, TY",
      "published_date": "September 2019",
      "doi": "10.1016/j.preteyeres.2019.04.003",
      "abstract": "The advent of computer graphic processing units, improvement in mathematical models and availability of big data has allowed artificial intelligence (AI) using machine learning (ML) and deep learning (DL) techniques to achieve robust performance for broad applications in social-media, the internet of things, the automotive industry and healthcare. DL systems in particular provide improved capability in image, speech and motion recognition as well as in natural language processing. In medicine, significant progress of AI and DL systems has been demonstrated in image-centric specialties such as radiology, dermatology, pathology and ophthalmology. New studies, including pre-registered prospective clinical trials, have shown DL systems are accurate and effective in detecting diabetic retinopathy (DR), glaucoma, age-related macular degeneration (AMD), retinopathy of prematurity, refractive error and in identifying cardiovascular risk factors and diseases, from digital fundus photographs. There is also increasing attention on the use of AI and DL systems in identifying disease features, progression and treatment response for retinal diseases such as neovascular AMD and diabetic macular edema using optical coherence tomography (OCT). Additionally, the application of ML to visual fields may be useful in detecting glaucoma progression. There are limited studies that incorporate clinical data including electronic health records, in AL and DL algorithms, and no prospective studies to demonstrate that AI and DL algorithms can predict the development of clinical eye disease. This article describes global eye disease burden, unmet needs and common conditions of public health importance for which AI and DL systems may be applicable. Technical and clinical aspects to build a DL system to address those needs, and the potential challenges for clinical adoption are discussed. AI, ML and DL will likely play a crucial role in clinical ophthalmology practice, with implications for screening, diagnosis and follow up of the major causes of vision impairment in the setting of ageing populations globally.",
      "publication_location": "Prog Retin Eye Res",
      "link": "http://dx.doi.org/10.1016/j.preteyeres.2019.04.003",
      "citations": 32,
      "readership": 153,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "A Penalized Method for the Predictive Limit of Learning",
      "authors": "Ding, J; Diao, E; Zhou, J; Tarokh, V",
      "published_date": "September 10, 2018",
      "doi": "10.1109/ICASSP.2018.8461832",
      "abstract": "© 2018 IEEE. Machine learning systems learn from and make predictions by building models from observed data. Because large models tend to overfit while small models tend to underfit for a given fixed dataset, a critical challenge is to select an appropriate model (e.g. set of variables/features). Model selection aims to strike a balance between the goodness of fit and model complexity, and thus to gain reliable predictive power. In this paper, we study a penalized model selection technique that asymptotically achieves the optimal expected prediction loss (referred to as the limit of learning) offered by a set of candidate models. We prove that the proposed procedure is both statistically efficient in the sense that it asymptotically approaches the limit of learning, and computationally efficient in the sense that it can be much faster than cross validation methods. Our theory applies for a wide variety of model classes, loss functions, and high dimensions (in the sense that the models' complexity can grow with data size). We released a python package with our proposed method for general usage like logistic regression and neural networks.",
      "publication_location": "2015 Ieee International Conference on Acoustics, Speech, and Signal Processing (Icassp)",
      "link": "http://dx.doi.org/10.1109/ICASSP.2018.8461832",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Hierarchical dictionary learning for invariant classification",
      "authors": "Bar, L; Sapiro, G",
      "published_date": "November 8, 2010",
      "doi": "10.1109/ICASSP.2010.5495916",
      "abstract": "Sparse representation theory has been increasingly used in the fields of signal processing and machine learning. The standard sparse models are not invariant to spatial transformations such as image rotations, and the representation is very sensitive even under small such distortions. Most studies addressing this problem proposed algorithms which either use transformed data as part of the training set, or are invariant or robust only under minor transformations. In this paper we suggest a framework which extracts sparse features invariant under significant rotations and scalings. The algorithm is based on a hierarchical architecture of dictionary learning for sparse coding in a cortical (log-polar) space. The proposed model is tested in supervised classification applications and proved to be robust under transformed data. ©2010 IEEE.",
      "publication_location": "2015 Ieee International Conference on Acoustics, Speech, and Signal Processing (Icassp)",
      "link": "http://dx.doi.org/10.1109/ICASSP.2010.5495916",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Online dictionary learning for sparse coding",
      "authors": "Mairal, J; Bach, F; Ponce, J; Sapiro, G",
      "published_date": "September 15, 2009",
      "doi": "10.1145/1553374.1553463",
      "abstract": "Sparse coding - that is, modelling data vectors as sparse linear combinations of basis elements - is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on learning the basis set, also called dictionary, to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations, which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets. Copyright 2009.",
      "publication_location": "Acm International Conference Proceeding Series",
      "link": "http://dx.doi.org/10.1145/1553374.1553463",
      "citations": 1093,
      "readership": 1124,
      "tweets": 15,
      "news_mentions": ""
    },
    {
      "title": "The cerebellum: a neuronal learning machine?",
      "authors": "Raymond, JL; Lisberger, SG; Mauk, MD",
      "published_date": "May 24, 1996",
      "doi": "10.1126/science.272.5265.1126",
      "abstract": "Comparison of two seemingly quite different behaviors yields a surprisingly consistent picture of the role of the cerebellum in motor learning. Behavioral and physiological data about classical conditioning of the eyelid response and motor learning in the vestibulo-ocular reflex suggests that (i) plasticity is distributed between the cerebellar cortex and the deep cerebellar nuclei; (ii) the cerebellar cortex plays a special role in learning the timing of movement; and (iii) the cerebellar cortex guides learning in the deep nuclei, which may allow learning to be transferred from the cortex to the deep nuclei. Because many of the similarities in the data from the two systems typify general features of cerebellar organization, the cerebellar mechanisms of learning in these two systems may represent principles that apply to many motor systems.",
      "publication_location": "Science (New York, N.Y.)",
      "link": "http://dx.doi.org/10.1126/science.272.5265.1126",
      "citations": 472,
      "readership": 376,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Board-level functional fault diagnosis using artificial neural networks, support-vector machines, and weighted-majority voting",
      "authors": "Ye, F; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "May 1, 2013",
      "doi": "10.1109/TCAD.2012.2234827",
      "abstract": "Increasing integration densities and high operating speeds lead to subtle manifestation of defects at the board level. Functional fault diagnosis is, therefore, necessary for board-level product qualification. However, ambiguous diagnosis results lead to long debug times and even wrong repair actions, which significantly increase repair cost and adversely impact yield. Advanced machine-learning (ML) techniques offer an unprecedented opportunity to increase the accuracy of board-level functional diagnosis and reduce high-volume manufacturing cost through successful repair. We propose a smart diagnosis method based on two ML classification models, namely, artificial neural networks (ANNs) and support-vector machines (SVMs) that can learn from repair history and accurately localize the root cause of a failure. Fine-grained fault syndromes extracted from failure logs and corresponding repair actions are used to train the classification models. We also propose a decision machine based on weighted-majority voting, which combines the benefits of ANNs and SVMs. Three complex boards from the industry, currently in volume production, and additional synthetic data, are used to validate the proposed methods in terms of diagnostic accuracy, resolution, and quantifiable improvement over current diagnostic software. © 1982-2012 IEEE.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2012.2234827",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "MIC-SVM: Designing a highly efficient support vector machine for advanced modern multi-core and many-core architectures",
      "authors": "You, Y; Song, SL; Fu, H; Marquez, A; Dehnavi, MM; Barker, K; Cameron, KW; Randles, AP; Yang, G",
      "published_date": "January 1, 2014",
      "doi": "10.1109/IPDPS.2014.88",
      "abstract": "Support Vector Machine (SVM) has been widely used in data-mining and Big Data applications as modern commercial databases start to attach an increasing importance to the analytic capabilities. In recent years, SVM was adapted to the field of High Performance Computing for power/performance prediction, auto-tuning, and runtime scheduling. However, even at the risk of losing prediction accuracy due to insufficient runtime information, researchers can only afford to apply offline model training to avoid significant runtime training overhead. Advanced multi- and many-core architectures offer massive parallelism with complex memory hierarchies which can make runtime training possible, but form a barrier to efficient parallel SVM design. To address the challenges above, we designed and implemented MIC-SVM, a highly efficient parallel SVM for x86 based multi-core and many-core architectures, such as the Intel Ivy Bridge CPUs and Intel Xeon Phi co-processor (MIC). We propose various novel analysis methods and optimization techniques to fully utilize the multilevel parallelism provided by these architectures and serve as general optimization methods for other machine learning tools. MIC-SVM achieves 4.4-84x and 18-47x speedups against the popular LIBSVM, on MIC and Ivy Bridge CPUs respectively, for several real-world data-mining datasets. Even compared with GPUSVM, run on a top of the line NVIDIA k20x GPU, the performance of our MIC-SVM is competitive. We also conduct a cross-platform performance comparison analysis, focusing on Ivy Bridge CPUs, MIC and GPUs, and provide insights on how to select the most suitable advanced architectures for specific algorithms and input data patterns. © 2014 IEEE.",
      "publication_location": "2008 Ieee International Symposium on Parallel and Distributed Processing",
      "link": "http://dx.doi.org/10.1109/IPDPS.2014.88",
      "citations": 27,
      "readership": 36,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Propensity score estimation: neural networks, support vector machines, decision trees (CART), and meta-classifiers as alternatives to logistic regression.",
      "authors": "",
      "published_date": "August 2010",
      "doi": "10.1016/j.jclinepi.2009.11.020",
      "abstract": "Propensity scores for the analysis of observational data are typically estimated using logistic regression. Our objective in this review was to assess machine learning alternatives to logistic regression, which may accomplish the same goals but with fewer assumptions or greater accuracy.We identified alternative methods for propensity score estimation and/or classification from the public health, biostatistics, discrete mathematics, and computer science literature, and evaluated these algorithms for applicability to the problem of propensity score estimation, potential advantages over logistic regression, and ease of use.We identified four techniques as alternatives to logistic regression: neural networks, support vector machines, decision trees (classification and regression trees [CART]), and meta-classifiers (in particular, boosting).Although the assumptions of logistic regression are well understood, those assumptions are frequently ignored. All four alternatives have advantages and disadvantages compared with logistic regression. Boosting (meta-classifiers) and, to a lesser extent, decision trees (particularly CART), appear to be most promising for use in the context of propensity score analysis, but extensive simulation studies are needed to establish their utility in practice.",
      "publication_location": "Journal of Clinical Epidemiology",
      "link": "http://dx.doi.org/10.1016/j.jclinepi.2009.11.020",
      "citations": 161,
      "readership": 244,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Multiscale dictionaries, transforms, and learning in high-dimensions",
      "authors": "",
      "published_date": "December 9, 2013",
      "doi": "10.1117/12.2021984",
      "abstract": "Mapping images to a high-dimensional feature space, either by considering patches of images or other features, has lead to state-of-art results in signal processing tasks such as image denoising and imprinting, and in various machine learning and computer vision tasks on images. Understanding the geometry of the embedding of images into high-dimensional feature space is a challenging problem. Finding efficient representations and learning dictionaries for such embeddings is also problematic, often leading to expensive optimization algorithms. Many such algorithms scale poorly with the dimension of the feature space, for example with the size of patches of images if these are chosen as features. This is in contrast with the crucial needs of using a multi-scale approach in the analysis of images, as details at multiple scales are crucial in image understanding, as well as in many signal processing tasks. Here we exploit a recent dictionary learning algorithm based on Geometric Wavelets, and we extend it to perform multi-scale dictionary learning on image patches, with efficient algorithms for both the learning of the dictionary, and the computation of coefficients onto that dictionary. We also discuss how invariances in images may be introduced in the dictionary learning phase, by generalizing the construction of such dictionaries to non-Euclidean spaces. © 2013 SPIE.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2021984",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deep Learning of the Nonlinear Schrödinger Equation in Fiber-Optic Communications",
      "authors": "Hager, C; Pfister, HD",
      "published_date": "August 15, 2018",
      "doi": "10.1109/ISIT.2018.8437734",
      "abstract": "© 2018 IEEE. An important problem in fiber-optic communications is to invert the nonlinear Schrödinger equation in real time to reverse the deterministic effects of the channel. Interestingly, the popular split-step Fourier method (SSFM) leads to a computation graph that is reminiscent of a deep neural network. This observation allows one to leverage tools from machine learning to reduce complexity. In particular, the main disadvantage of the SSFM is that its complexity using M steps is at least M times larger than a linear equalizer. This is because the linear SSFM operator is a dense matrix. In previous work, truncation methods such as frequency sampling, wavelets, or least-squares have been used to obtain 'cheaper' operators that can be implemented using filters. However, a large number of filter taps are typically required to limit truncation errors. For example, Ip and Kahn showed that for a 10 Gbaud signal and 2000 km optical link, a truncated SSFM with 25 steps would require 70-tap filters in each step and 100 times more operations than linear equalization. We find that, by jointly optimizing all filters with deep learning, the complexity can be reduced significantly for similar accuracy. Using optimized 5-tap and 3-tap filters in an alternating fashion, one requires only around 2-6 times the complexity of linear equalization, depending on the implementation.",
      "publication_location": "Ieee International Symposium on Information Theory   Proceedings",
      "link": "http://dx.doi.org/10.1109/ISIT.2018.8437734",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A probabilistic learning approach to whole-genome operon prediction.",
      "authors": "Craven, M; Page, D; Shavlik, J; Bockhorst, J; Glasner, J",
      "published_date": 2000,
      "doi": "",
      "abstract": "We present a computational approach to predicting operons in the genomes of prokaryotic organisms. Our approach uses machine learning methods to induce predictive models for this task from a rich variety of data types including sequence data, gene expression data, and functional annotations associated with genes. We use multiple learned models that individually predict promoters, terminators and operons themselves. A key part of our approach is a dynamic programming method that uses our predictions to map every known and putative gene in a given genome into its most probable operon. We evaluate our approach using data from the E. coli K-12 genome.",
      "publication_location": "Proceedings. International Conference on Intelligent Systems for Molecular Biology",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/10977072",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "DarNet: A deep learning solution for distracted driving detection",
      "authors": "",
      "published_date": "December 11, 2017",
      "doi": "10.1145/3154448.3154452",
      "abstract": "© 2017 ACM. Distracted driving is known to be the leading cause of motor vehicle accidents. With the increase in the number of IoT devices available within vehicles, there exists an abundance of data for monitoring driver behavior. However, designing a system around this goal presents two key challenges - how to concurrently collect data spanning multiple IoT devices, and how to jointly analyze this multimodal input. To that end, we present a unified data collection and analysis framework, DarNet, capable of detecting and classifying distracted driving behavior. DarNet consists of two primary components: A data collection system and an analytics engine. Our system takes advantage of advances in machine learning (ML) to classify driving behavior based on input sensor data. In our system implementation, we collect image data from an inward facing camera, and Inertial Measurement Unit (IMU) data from a mobile device, both located within the vehicle. Using deep learning techniques, we show that DarNet achieves a Top-1 classification percentage of 87.02% on our collected dataset, significantly outperforming our baseline model of 73.88%. Additionally, we address the privacy concerns associated with collecting image data by presenting an alternative framework designed to operate on down-sampled data which produces a Top-1 classification percentage of 80.00%.",
      "publication_location": "Middleware 2017   Proceedings of the 2017 International Middleware Conference (Industrial Track)",
      "link": "http://dx.doi.org/10.1145/3154448.3154452",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deep Learning to Classify Radiology Free-Text Reports.",
      "authors": "Chen, MC; Ball, RL; Yang, L; Moradzadeh, N; Chapman, BE; Larson, DB; Langlotz, CP; Amrhein, TJ; Lungren, MP",
      "published_date": "March 2018",
      "doi": "10.1148/radiol.2017171115",
      "abstract": "Purpose To evaluate the performance of a deep learning convolutional neural network (CNN) model compared with a traditional natural language processing (NLP) model in extracting pulmonary embolism (PE) findings from thoracic computed tomography (CT) reports from two institutions. Materials and Methods Contrast material-enhanced CT examinations of the chest performed between January 1, 1998, and January 1, 2016, were selected. Annotations by two human radiologists were made for three categories: the presence, chronicity, and location of PE. Classification of performance of a CNN model with an unsupervised learning algorithm for obtaining vector representations of words was compared with the open-source application PeFinder. Sensitivity, specificity, accuracy, and F1 scores for both the CNN model and PeFinder in the internal and external validation sets were determined. Results The CNN model demonstrated an accuracy of 99% and an area under the curve value of 0.97. For internal validation report data, the CNN model had a statistically significant larger F1 score (0.938) than did PeFinder (0.867) when classifying findings as either PE positive or PE negative, but no significant difference in sensitivity, specificity, or accuracy was found. For external validation report data, no statistical difference between the performance of the CNN model and PeFinder was found. Conclusion A deep learning CNN model can classify radiology free-text reports with accuracy equivalent to or beyond that of an existing traditional NLP model. © RSNA, 2017 Online supplemental material is available for this article.",
      "publication_location": "Radiology",
      "link": "http://dx.doi.org/10.1148/radiol.2017171115",
      "citations": 49,
      "readership": 113,
      "tweets": 44,
      "news_mentions": ""
    },
    {
      "title": "Integrating knowledge capture and supervised learning through a human-computer interface",
      "authors": "Walker, T; Kunapuli, G; Larsen, N; Page, D; Shavlik, J",
      "published_date": "July 18, 2011",
      "doi": "10.1145/1999676.1999693",
      "abstract": "Some supervised-learning algorithms can make effective use of domain knowledge in addition to the input-output pairs commonly used in machine learning. However, formulating this additional information often requires an in-depth understanding of the specific knowledge representation used by a given learning algorithm. The requirement to use a formal knowledge-representation language means that most domain experts will not be able to articulate their expertise, even when a learning algorithm is capable of exploiting such valuable information. We investigate a method to ease this knowledge acquisition through the use of a graphical, human-computer interface. Our interface allows users to easily provide advice about specific examples, rather than requiring them to provide general rules; we leave the task of properly generalizing such advice to the learning algorithms. We demonstrate the effectiveness of our approach using the Wargus real-time strategy game, comparing learning with no advice to learning with concrete advice provided through our interface, as well as comparing to using generalized advice written by an AI expert. Our results show that our approach of combining a GUI-based advice language with an advice-taking learning algorithm is an effective way to capture domain knowledge. © 2011 ACM.",
      "publication_location": "Kcap 2011   Proceedings of the 2011 Knowledge Capture Conference",
      "link": "http://dx.doi.org/10.1145/1999676.1999693",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multiple instance and context dependent learning in hyperspectral data",
      "authors": "Torrione, P; Ratto, C; Collins, LM",
      "published_date": "December 21, 2009",
      "doi": "10.1109/WHISPERS.2009.5289021",
      "abstract": "Hyperspectral imaging (HSI) is a powerful tool for various remote sensing tasks including agricultural modeling and land-mine/unexploded ordnance clearance. Although the application of standard supervised learning techniques to HSI data has previously been explored, several aspects of hyperspectral data collection and ground truth labeling make some of the assumptions underlying standard machine learning techniques invalid. For example, HSI is highly dependent upon local environmental conditions, and pixel-by-pixel labels for HSI data are often not available. As a result, data from hyper-spectral sensing under various scenarios is not typically i.i.d., and correct data labels must be inferred from training data while learning decision boundaries. In this work we explore two possible solutions to these problems: context-dependent learning for overcoming variations between collections, and multiple instance learning for simultaneously inferring local target labels and global target decision boundaries. Results are compared to standard logistic discriminant classification approaches. © 2009 IEEE.",
      "publication_location": "Whispers '09   1st Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing",
      "link": "http://dx.doi.org/10.1109/WHISPERS.2009.5289021",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Identifying adverse drug events by relational learning",
      "authors": "Page, D; Costa, VS; Natarajan, S; Barnard, A; Peissig, P; Caldwell, M",
      "published_date": "November 7, 2012",
      "doi": "",
      "abstract": "The pharmaceutical industry, consumer protection groups, users of medications and government oversight agencies are all strongly interested in identifying adverse reactions to drugs. While a clinical trial of a drug may use only a thousand patients, once a drug is released on the market it may be taken by millions of patients. As a result, in many cases adverse drug events (ADEs) are observed in the broader population that were not identified during clinical trials. Therefore, there is a need for continued, post-marketing surveillance of drugs to identify previously-unanticipated ADEs. This paper casts this problem as a reverse machine learning task, related to relational subgroup discovery and provides an initial evaluation of this approach based on experiments with an actual EMR/EHR and known adverse drug events. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.",
      "publication_location": "Proceedings of the National Conference on Artificial Intelligence",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning High-Dimensional Generalized Linear Autoregressive Models",
      "authors": "",
      "published_date": "April 1, 2019",
      "doi": "10.1109/TIT.2018.2884673",
      "abstract": "© 2019 IEEE. Vector autoregressive models characterize a variety of time series in which linear combinations of current and past observations can be used to accurately predict future observations. For instance, each element of an observation vector could correspond to a different node in a network, and the parameters of an autoregressive model would correspond to the impact of the network structure on the time series evolution. Often, these models are used successfully in practice to learn the structure of social, epidemiological, financial, or biological neural networks. However, little is known about statistical guarantees on the estimates of such models in non-Gaussian settings. This paper addresses the inference of the autoregressive parameters and associated network structure within a generalized linear model framework that includes Poisson and Bernoulli autoregressive processes. At the heart of this analysis is a sparsity-regularized maximum likelihood estimator. While sparsity-regularization is well-studied in the statistics and machine learning communities, those analysis methods cannot be applied to autoregressive generalized linear models because of the correlations and potential heteroscedasticity inherent in the observations. Sample complexity bounds are derived using a combination of martingale concentration inequalities and modern empirical process techniques for dependent random variables. These bounds, which are supported by several simulation studies, characterize the impact of various network parameters on the estimator performance.",
      "publication_location": "Ieee Transactions on Information Theory",
      "link": "http://dx.doi.org/10.1109/TIT.2018.2884673",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Kernelized value function approximation for reinforcement learning",
      "authors": "",
      "published_date": "September 15, 2009",
      "doi": "10.1145/1553374.1553504",
      "abstract": "A recent surge in research in kernelized approaches to reinforcement learning has sought to bring the benefits of kernelized machine learning techniques to reinforcement learning. Kernelized reinforcement learning techniques are fairly new and different authors have approached the topic with different assumptions and goals. Neither a unifying view nor an understanding of the pros and cons of different approaches has yet emerged. In this paper, we offer a unifying view of the different approaches to kernelized value function approximation for reinforcement learning. We show that, except for different approaches to regularization, Kernelized LSTD (KLSTD) is equivalent to a modelbased approach that uses kernelized regression to find an approximate reward and transition model, and that Gaussian Process Temporal Difference learning (GPTD) returns a mean value function that is equivalent to these other approaches. We also discuss the relationship between our modelbased approach and the earlier Gaussian Processes in Reinforcement Learning (GPRL). Finally, we decompose the Bellman error into the sum of transition error and reward error terms, and demonstrate through experiments that this decomposition can be helpful in choosing regularization parameters. Copyright 2009.",
      "publication_location": "Acm International Conference Proceeding Series",
      "link": "http://dx.doi.org/10.1145/1553374.1553504",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Towards decentralized deep learning with differential privacy",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "10.1007/978-3-030-23502-4_10",
      "abstract": "© Springer Nature Switzerland AG 2019. In distributed machine learning, while a great deal of attention has been paid on centralized systems that include a central parameter server, decentralized systems have not been fully explored. Decentralized systems have great potentials in the future practical use as they have multiple useful attributes such as less vulnerable to privacy and security issues, better scalability, and less prone to single point of bottleneck and failure. In this paper, we focus on decentralized learning systems and aim to achieve differential privacy with good convergence rate and low communication cost. To achieve this goal, we propose a new algorithm, Leader-Follower Elastic Averaging Stochastic Gradient Descent (LEASGD), driven by a novel Leader-Follower topology and differential privacy model. We also provide a theoretical analysis of the convergence rate of LEASGD and the trade-off between the performance and privacy in the private setting. We evaluate LEASGD in real distributed testbed with poplar deep neural network models MNIST-CNN, MNIST-RNN, and CIFAR-10. Extensive experimental results show that LEASGD outperforms state-of-the-art decentralized learning algorithm DPSGD by achieving nearly 40% lower loss function within same iterations and by 30% reduction of communication cost. Moreover, it spends less differential privacy budget and has final higher accuracy result than DPSGD under private setting.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "http://dx.doi.org/10.1007/978-3-030-23502-4_10",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Probabilistic curve learning: Coulomb repulsion and the electrostatic Gaussian process",
      "authors": "Wang, Y; Dunson, D",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "Learning of low dimensional structure in multidimensional data is a canonical problem in machine learning. One common approach is to suppose that the observed data are close to a lower-dimensional smooth manifold. There are a rich variety of manifold learning methods available, which allow mapping of data points to the manifold. However, there is a clear lack of probabilistic methods that allow learning of the manifold along with the generative distribution of the observed data. The best attempt is the Gaussian process latent variable model (GP-LVM), but identifiability issues lead to poor performance. We solve these issues by proposing a novel Coulomb repulsive process (Corp) for locations of points on the manifold, inspired by physical models of electrostatic interactions among particles. Combining this process with a GP prior for the mapping function yields a novel electrostatic GP (electroGP) process. Focusing on the simple case of a one-dimensional manifold, we develop efficient inference algorithms, and illustrate substantially improved performance in a variety of experiments including filling in missing frames in video.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning topic models - Going beyond SVD",
      "authors": "Arora, S; Ge, R; Moitra, A",
      "published_date": "December 1, 2012",
      "doi": "10.1109/FOCS.2012.49",
      "abstract": "Topic Modeling is an approach used for automatic comprehension and classification of data in a variety of settings, and perhaps the canonical application is in uncovering thematic structure in a corpus of documents. A number of foundational works both in machine learning and in theory have suggested a probabilistic model for documents, whereby documents arise as a convex combination of (i.e. distribution on) a small number of topic vectors, each topic vector being a distribution on words (i.e. a vector of word-frequencies). Similar models have since been used in a variety of application areas, the Latent Dirichlet Allocation or LDA model of Blei et al. is especially popular. Theoretical studies of topic modeling focus on learning the model's parameters assuming the data is actually generated from it. Existing approaches for the most part rely on Singular Value Decomposition (SVD), and consequently have one of two limitations: these works need to either assume that each document contains only one topic, or else can only recover the {\\em span} of the topic vectors instead of the topic vectors themselves. This paper formally justifies Nonnegative Matrix Factorization (NMF) as a main tool in this context, which is an analog of SVD where all vectors are nonnegative. Using this tool we give the first polynomial-time algorithm for learning topic models without the above two limitations. The algorithm uses a fairly mild assumption about the underlying topic matrix called separability, which is usually found to hold in real-life data. Perhaps the most attractive feature of our algorithm is that it generalizes to yet more realistic models that incorporate topic-topic correlations, such as the Correlated Topic Model (CTM) and the Pachinko Allocation Model (PAM). We hope that this paper will motivate further theoretical results that use NMF as a replacement for SVD - just as NMF has come to replace SVD in many applications. © 2012 IEEE.",
      "publication_location": "Annual Symposium on Foundations of Computer Science (Proceedings)",
      "link": "http://dx.doi.org/10.1109/FOCS.2012.49",
      "citations": 96,
      "readership": 256,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Learning customized and optimized lists of rules with mathematical programming",
      "authors": "Rudin, C; Ertekin, Ş",
      "published_date": "December 1, 2018",
      "doi": "10.1007/s12532-018-0143-8",
      "abstract": "© 2018, Springer-Verlag GmbH Germany, part of Springer Nature and The Mathematical Programming Society. We introduce a mathematical programming approach to building rule lists, which are a type of interpretable, nonlinear, and logical machine learning classifier involving IF-THEN rules. Unlike traditional decision tree algorithms like CART and C5.0, this method does not use greedy splitting and pruning. Instead, it aims to fully optimize a combination of accuracy and sparsity, obeying user-defined constraints. This method is useful for producing non-black-box predictive models, and has the benefit of a clear user-defined tradeoff between training accuracy and sparsity. The flexible framework of mathematical programming allows users to create customized models with a provable guarantee of optimality. The software reviewed as part of this submission was given the DOI (Digital Object Identifier) https://doi.org/10.5281/zenodo.1344142.",
      "publication_location": "Mathematical Programming Computation",
      "link": "http://dx.doi.org/10.1007/s12532-018-0143-8",
      "citations": 3,
      "readership": 17,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "AutoAudio: Deep Learning for Automatic Audiogram Interpretation",
      "authors": "Crowson, MG; Lee, JW; Hamour, A; Mahmood, R; Babier, A; Lin, V; Tucci, DL; Chan, TCY",
      "published_date": "",
      "doi": "10.1101/2020.04.30.20086637",
      "abstract": "Objectives: Hearing loss is the leading human sensory system loss, and one of the leading causes for years lived with disability with significant effects on quality of life, social isolation, and overall health. Coupled with a forecast of increased hearing loss burden worldwide, national and international health organizations have urgently recommended that access to hearing evaluation be expanded to meet demand. \n\nMethods:  The objective of this study was to develop, AutoAudio,a novel deep learning proof-of-concept model that accurately and quickly interprets diagnostic audiograms. Adult audiogram reports representing normal, conductive, mixed and sensorineural morphologies were used to train different neural network architectures. Image augmentation techniques were used to increase the training image set size. Classification accuracy on a separate test set was used to assess model performance.\n\nResults:  The architecture with the highest out-of-training set accuracy was ResNet-101 at 97.5%. Neural network training time varied between 2 to 7 hours depending on the depth of the neural network architecture. Each neural network architecture produced misclassifications that arose from failures of the model to correctly label the audiogram with the appropriate hearing loss type. The most commonly misclassified hearing loss type were mixed losses.\n\nConclusion:  Re engineering the process of hearing testing with a machine learning innovation may help enhance access to the growing worldwide population that is expected to require audiologist services. Our results suggest that deep learning may be a transformative technology that enables automatic and accurate audiogram interpretation.",
      "publication_location": "",
      "link": "http://dx.doi.org/10.1101/2020.04.30.20086637",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Learning structured weight uncertainty in Bayesian neural networks",
      "authors": "Sun, S; Chen, C; Carin, L",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© 2017 PMLR. All rights reserved. Deep neural networks (DNNs) are increasingly popular in modern machine learning. Bayesian learning affords the opportunity to quantify posterior uncertainty on DNN model parameters. Most existing work adopts independent Gaussian priors on the model weights, ignoring possible structural information. In this paper, we consider the matrix variate Gaussian (MVG) distribution to model structured correlations within the weights of a DNN. To make posterior inference feasible, a reparametrization is proposed for the MVG prior, simplifying the complex MVG-based model to an equivalent yet simpler model with independent Gaussian priors on the transformed weights. Consequently, we develop a scalable Bayesian online inference algorithm by adopting the recently proposed probabilistic backpropagation framework. Experiments on several synthetic and real datasets indicate the superiority of our model, achieving competitive performance in terms of model likelihood and predictive root mean square error. Importantly, it also yields faster convergence speed compared to related Bayesian DNN models.",
      "publication_location": "Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, Aistats 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Variational Bayesian learning of sparse representations and its application in functional neuroimaging",
      "authors": "Roussos, E; Roberts, S; Daubechies, I",
      "published_date": "November 30, 2012",
      "doi": "10.1007/978-3-642-34713-9_28",
      "abstract": "Recent theoretical and experimental work in imaging neuroscience reveals that activations inferred from functional MRI data have sparse structure. We view sparse representation as a problem in Bayesian inference, following a machine learning approach, and construct a structured generative latent-variable model employing adaptive sparsity-inducing priors. The construction allows for automatic complexity control and regularization as well as denoising. Experimental results with benchmark datasets show that the proposed algorithm outperforms standard tools for model-free decompositions such as independent component analysis. © 2012 Springer-Verlag.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "http://dx.doi.org/10.1007/978-3-642-34713-9_28",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning-Based Control Design for Deep Brain Stimulation",
      "authors": "Jovanov, I; Nauman, M; Kumaravelu, K; Lesi, V; Zutshi, A; Grill, WM; Pajic, M",
      "published_date": "August 21, 2018",
      "doi": "10.1109/ICCPS.2018.00048",
      "abstract": "© 2018 IEEE. By employing low-voltage electrical stimulation of the basal ganglia (BG) regions of the brain, deep brain stimulation (DBS) devices are used to alleviate the symptoms of several neurological disorders, including Parkinson's disease (PD). Recently, we have developed a Basal Ganglia Model (BGM) that can be utilized for design and evaluation of DBS devices. In this work, we focus on the use of a hardware (FPGA) implementation of the BGM platform to facilitate development of new control policies. Specifically, we introduce a design-time framework that allows for development of suitable control policies, in the form of electrical pulses with variable temporal patterns, while supporting tradeoffs between energy efficiency and efficacy (i.e., Quality-of-Control) of the therapy. The developed framework exploits machine learning and optimization based methods for design-space exploration where predictive behavior for any control configuration (i.e., temporal pattern) is obtained using the BGM platform that simulates physiological response to the considered control in real-time. To illustrate the use of the developed framework, in our demonstration we present how the BGM can be utilized for physiologically relevant BG modeling and design-state exploration for DBS controllers, as well as show the effectiveness of obtained controllers that significantly outperform conventional DBS controllers.",
      "publication_location": "Proceedings   9th Acm/Ieee International Conference on Cyber Physical Systems, Iccps 2018",
      "link": "http://dx.doi.org/10.1109/ICCPS.2018.00048",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning structured weight uncertainty in Bayesian neural networks",
      "authors": "Sun, S; Chen, C; Carin, L",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© 2017 PMLR. All rights reserved. Deep neural networks (DNNs) are increasingly popular in modern machine learning. Bayesian learning affords the opportunity to quantify posterior uncertainty on DNN model parameters. Most existing work adopts independent Gaussian priors on the model weights, ignoring possible structural information. In this paper, we consider the matrix variate Gaussian (MVG) distribution to model structured correlations within the weights of a DNN. To make posterior inference feasible, a reparametrization is proposed for the MVG prior, simplifying the complex MVG-based model to an equivalent yet simpler model with independent Gaussian priors on the transformed weights. Consequently, we develop a scalable Bayesian online inference algorithm by adopting the recently proposed probabilistic backpropagation framework. Experiments on several synthetic and real datasets indicate the superiority of our model, achieving competitive performance in terms of model likelihood and predictive root mean square error. Importantly, it also yields faster convergence speed compared to related Bayesian DNN models.",
      "publication_location": "Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, Aistats 2017",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Diagnostic resolution improvement through learning-guided physical failure analysis",
      "authors": "Lim, C; Xue, Y; Li, X; Blanton, RD; Amyeen, ME",
      "published_date": "January 4, 2017",
      "doi": "10.1109/TEST.2016.7805824",
      "abstract": "© 2016 IEEE. An accurate and high-resolution diagnosis enables physical failure analysis (PFA) to identify and understand the root-cause of integrated-circuit failure. Despite many existing techniques for improving diagnosis, resolution is still far from ideal, which hinders PFA and other analyses. To address this challenge, we extend the capability of PADRE (physically-Aware diagnostic resolution enhancement), a powerful machine learning based diagnosis resolution improvement technique, with a novel, active learning (AL) based PFA selection approach. An active-learning based PADRE (AL PADRE) selects the most useful defects for PFA in order to improve diagnostic resolution. AL PADRE provides an alternative to the normal PFA selection procedure, it improves the the accuracy of PADRE, and thus enables a more accurately improved resolution. AL PADRE is validated by both simulation-based experiment and silicon experiment. Simulation-based experiments show that by using AL PADRE, the number of PFAs required for increasing the accuracy to a stable level of 90% is reduced by more than 60% on average compared to baseline approach, and AL PADRE consistently outperforms the baseline approach for accuracy improvement in various scenarios. In the silicon experiment, by using AL PADRE, the number of chips needed to undergo PFA was reduced by more than 6x in order to increase diagnosis accuracy by more than 20%.",
      "publication_location": "Proceedings   International Test Conference",
      "link": "http://dx.doi.org/10.1109/TEST.2016.7805824",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "AdaLearner: An adaptive distributed mobile learning system for neural networks",
      "authors": "Mao, J; Qin, Z; Xu, Z; Nixon, KW; Chen, X; Li, H; Chen, Y",
      "published_date": "December 13, 2017",
      "doi": "10.1109/ICCAD.2017.8203791",
      "abstract": "© 2017 IEEE. Neural networks hold a critical domain in machine learning algorithms because of their self-adaptiveness and state-of-the-art performance. Before the testing (inference) phases in practical use, sophisticated training (learning) phases are required, calling for efficient training methods with higher accuracy and shorter converging time. Many existing studies focus on the training optimization on high-performance servers or computing clusters, e.g. GPU clusters. However, training neural networks on resource-constrained devices, e.g. mobile platforms, is an important research topic barely touched. In this paper, we implement AdaLearner-an adaptive distributed mobile learning system for neural networks that trains a single network with heterogenous mobile resources under the same local network in parallel. To exploit the potential of our system, we adapt neural networks training phase to mobile device-wise resources and fiercely decrease the transmission overhead for better system scalability. On three representative neural network structures trained from two image classification datasets, AdaLearner boosts the training phase significantly. For example, on LeNet, 1.75-3.37X speedup is achieved when increasing the worker nodes from 2 to 8, thanks to the achieved high execution parallelism and excellent scalability.",
      "publication_location": "Ieee/Acm International Conference on Computer Aided Design, Digest of Technical Papers, Iccad",
      "link": "http://dx.doi.org/10.1109/ICCAD.2017.8203791",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sparse coding and dictionary learning based on the MDL principle",
      "authors": "Ramírez, I; Sapiro, G",
      "published_date": "August 18, 2011",
      "doi": "10.1109/ICASSP.2011.5946755",
      "abstract": "The power of sparse signal coding with learned overcomplete dictionaries has been demonstrated in a variety of applications and fields, from signal processing to statistical inference and machine learning. However, the statistical properties of these models, such as underfitting or overfitting given sets of data, are still not well characterized in the literature. This work aims at filling this gap by means of the Minimum Description Length (MDL) principle - a well established information-theoretic approach to statistical inference. The resulting framework derives a family of efficient sparse coding and modeling (dictionary learning) algorithms, which by virtue of the MDL principle, are completely parameter free. Furthermore, such framework allows to incorporate additional prior information in the model, such as Markovian dependencies, in a natural way. We demonstrate the performance of the proposed framework with results for image denoising and classification tasks. © 2011 IEEE.",
      "publication_location": "2015 Ieee International Conference on Acoustics, Speech, and Signal Processing (Icassp)",
      "link": "http://dx.doi.org/10.1109/ICASSP.2011.5946755",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An MDL framework for sparse coding and dictionary learning",
      "authors": "Ramirez, I; Sapiro, G",
      "published_date": "June 1, 2012",
      "doi": "10.1109/TSP.2012.2187203",
      "abstract": "The power of sparse signal modeling with learned overcomplete dictionaries has been demonstrated in a variety of applications and fields, from signal processing to statistical inference and machine learning. However, the statistical properties of these models, such as underfitting or overfitting given sets of data, are still not well characterized in the literature. As a result, the success of sparse modeling depends on hand-tuning critical parameters for each data and application. This work aims at addressing this by providing a practical and objective characterization of sparse models by means of the minimum description length (MDL) principlea well-established information-theoretic approach to model selection in statistical inference. The resulting framework derives a family of efficient sparse coding and dictionary learning algorithms which, by virtue of the MDL principle, are completely parameter free. Furthermore, such framework allows to incorporate additional prior information to existing models, such as Markovian dependencies, or to define completely new problem formulations, including in the matrix analysis area, in a natural way. These virtues will be demonstrated with parameter-free algorithms for the classic image denoising and classification problems, and for low-rank matrix recovery in video applications. However, the framework is not limited to this imaging data, and can be applied to a wide range of signal and data types and tasks. © 2012 IEEE.",
      "publication_location": "Ieee Transactions on Signal Processing",
      "link": "http://dx.doi.org/10.1109/TSP.2012.2187203",
      "citations": 35,
      "readership": 67,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Learned Belief-Propagation Decoding with Simple Scaling and SNR Adaptation",
      "authors": "Lian, M; Carpi, F; Hager, C; Pfister, HD",
      "published_date": "July 1, 2019",
      "doi": "10.1109/ISIT.2019.8849419",
      "abstract": "© 2019 IEEE. We consider the weighted belief-propagation (WBP) decoder recently proposed by Nachmani et al. where different weights are introduced for each Tanner graph edge and optimized using machine learning techniques. Our focus is on simple-scaling models that use the same weights across certain edges to reduce the storage and computational burden. The main contribution is to show that simple scaling with few parameters often achieves the same gain as the full parameterization. Moreover, several training improvements for WBP are proposed. For example, it is shown that minimizing average binary cross-entropy is suboptimal in general in terms of bit error rate (BER) and a new \"soft-BER\" loss is proposed which can lead to better performance. We also investigate parameter adapter networks (PANs) that learn the relation between the signal-to-noise ratio and the WBP parameters. As an example, for the (32, 16) Reed-Muller code with a highly redundant parity-check matrix, training a PAN with soft-BER loss gives near-maximum-likelihood performance assuming simple scaling with only three parameters.",
      "publication_location": "Ieee International Symposium on Information Theory   Proceedings",
      "link": "http://dx.doi.org/10.1109/ISIT.2019.8849419",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A Machine-Based Approach to Preoperatively Identify Patients with the Most and Least Benefit Associated with Resection for Intrahepatic Cholangiocarcinoma: An International Multi-institutional Analysis of 1146 Patients.",
      "authors": "Tsilimigras, DI; Mehta, R; Moris, D; Sahara, K; Bagante, F; Paredes, AZ; Moro, A; Guglielmi, A; Aldrighetti, L; Weiss, M; Bauer, TW; Alexandrescu, S; Poultsides, GA; Maithel, SK; Marques, HP; Martel, G; Pulitano, C; Shen, F; Soubrane, O; Koerkamp, BG; Endo, I; Pawlik, TM",
      "published_date": "April 2020",
      "doi": "10.1245/s10434-019-08067-3",
      "abstract": "BACKGROUND:Accurate risk stratification and patient selection is necessary to identify patients who will benefit the most from surgery or be better treated with other non-surgical treatment strategies. We sought to identify which patients in the preoperative setting would likely derive the most or least benefit from resection of intrahepatic cholangiocarcinoma (ICC). METHODS:Patients who underwent curative-intent resection for ICC between 1990 and 2017 were identified from an international multi-institutional database. A machine-based classification and regression tree (CART) was used to generate homogeneous groups of patients relative to overall survival (OS) based on preoperative factors. RESULTS:Among 1146 patients, CART analysis revealed tumor number and size, albumin-bilirubin (ALBI) grade and preoperative lymph node (LN) status as the strongest prognostic factors associated with OS among patients undergoing resection for ICC. In turn, four groups of patients with distinct outcomes were generated through machine learning: Group 1 (n = 228): single ICC, size ≤ 5 cm, ALBI grade I, negative preoperative LN status; Group 2 (n = 708): (1) single tumor > 5 cm, (2) single tumor ≤ 5 cm, ALBI grade 2/3, and (3) single tumor ≤ 5 cm, ALBI grade 1, metastatic/suspicious LNs; Group 3 (n = 150): 2-3 tumors; Group 4 (n = 60): ≥ 4 tumors. 5-year OS among Group 1, 2, 3, and 4 patients was 60.5%, 35.8%, 27.5%, and 3.8%, respectively (p < 0.001). Similarly, 5-year disease-free survival (DFS) among Group 1, 2, 3, and 4 patients was 47%, 27.2%, 6.8%, and 0%, respectively (p < 0.001). CONCLUSIONS:The machine-based CART model identified distinct prognostic groups of patients with distinct outcomes based on preoperative factors. Survival decision trees may be useful as guides in preoperative patient selection and risk stratification.",
      "publication_location": "Annals of Surgical Oncology",
      "link": "http://dx.doi.org/10.1245/s10434-019-08067-3",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deep learning approaches for plethysmography signal quality assessment in the presence of atrial fibrillation.",
      "authors": "Pereira, T; Ding, C; Gadhoumi, K; Tran, N; Colorado, RA; Meisel, K; Hu, X",
      "published_date": "December 27, 2019",
      "doi": "10.1088/1361-6579/ab5b84",
      "abstract": "OBJECTIVE:Photoplethysmography (PPG) monitoring has been implemented in many portable and wearable devices we use daily for health and fitness tracking. Its simplicity and cost-effectiveness has enabled a variety of biomedical applications, such as continuous long-term monitoring of heart arrhythmias, fitness, and sleep tracking, and hydration monitoring. One major issue that can hinder PPG-based applications is movement artifacts, which can lead to false interpretations. In many implementations, noisy PPG signals are discarded. Misinterpreted or discarded PPG signals pose a problem in applications where the goal is to increase the yield of detecting physiological events, such as in the case of paroxysmal atrial fibrillation (AF)-a common episodic heart arrhythmia and a leading risk factor for stroke. In this work, we compared a traditional machine learning and deep learning approaches for PPG quality assessment in the presence of AF, in order to find the most robust method for PPG quality assessment. APPROACH:The training data set was composed of 78 278 30 s long PPG recordings from 3764 patients using bedside patient monitors. Two different representations of PPG signals were employed-a time-series based (1D) one and an image-based (2D) one. Trained models were tested on an independent set of 2683 30 s PPG signals from 13 stroke patients. MAIN RESULTS:ResNet18 showed a higher performance (0.985 accuracy, 0.979 specificity, and 0.988 sensitivity) than SVM and other deep learning approaches. 2D-based models were generally more accurate than 1D-based models. SIGNIFICANCE:2D representation of PPG signal enhances the accuracy of PPG signal quality assessment.",
      "publication_location": "Physiological Measurement",
      "link": "http://dx.doi.org/10.1088/1361-6579/ab5b84",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning to reject sequential importance steps for continuous-time Bayesian networks",
      "authors": "Weiss, JC; Natarajan, S; Page, CD",
      "published_date": "June 1, 2015",
      "doi": "",
      "abstract": "© Copyright 2015, Association tor the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Applications of graphical models often require the use of approximate inference, such as sequential importance sampling (SIS), for estimation of the model distribution given partial evidence, i.e., the target distribution. However, when SIS proposal and target distributions are dissimilar, such procedures lead to biased estimates or require a prohibitive number of samples. We introduce ReBaSIS, a method that better approximates the target distribution by sampling variable by variable from existing importance samplers and accepting or rejecting each proposed assignment in the sequence: a choice made based on anticipating upcoming evidence. We relate the per-variable proposal and model distributions by expected weight ratios of sequence completions and show that we can learn accurate models of optimal acceptance probabilities from local samples. In a continuous-time domain, our method improves upon previous importance samplers by transforming an SIS problem into a machine learning one.",
      "publication_location": "Proceedings of the National Conference on Artificial Intelligence",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multiple instance learning framework for landmine detection using ground penetrating radar",
      "authors": "Manandhar, A; Morton, KD; Collins, LM; Torrione, PA",
      "published_date": "July 13, 2011",
      "doi": "10.1117/12.884869",
      "abstract": "Ground Penetrating Radar (GPR) data provides a powerful technique to identify subsurface buried threats. Although GPR data contains a three-dimensional representation of the subsurface, object truth (i.e. labels and positions of true threat objects in training lanes) is often provided in only two dimensions (GPS coordinates along the earth's surface). To mitigate uncertainty in an object's location in depth, many successful feature extraction/ object recognition techniques in GPR extract feature vectors from several depth regions, and attempt to combine information across these feature vectors to make final decisions. However, many machine learning techniques are not well suited for learning under these conditions. Multiple Instance Learning (MIL) is a type of supervised learning method in which labels are available for sets of samples, but not for individual samples. The goal of learning in MIL is to classify new sets of samples as they become available. This set-based framework is useful in processing GPR responses since features are often extracted independently from multiple un-labeled depth bins, and thus a set of features is produced at each potential threat location. In this work, a comparison of several previous approaches to MlL applied to landmine detection in GPR data is presented. One recent algorithm, the p-Posterior Mixture Model approach (pPMM) is given special attention, and several slight modifications to the pPMM approach are presented and compared. © 2011 SPIE.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.884869",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A feature learning approach for classifying buried threats in forward looking ground penetrating radar data",
      "authors": "Camilo, JA; Malof, JM; Collins, LM",
      "published_date": "January 1, 2016",
      "doi": "10.1117/12.2223117",
      "abstract": "© 2016 SPIE. The forward-looking ground penetrating radar (FLGPR) is a remote sensing modality that has recently been investigated for buried threat detection. The FLGPR considered in this work uses stepped frequency sensing followed by filtered backprojection to create images of the ground, where each image pixel corresponds to the radar energy reflected from the subsurface at that location. Typical target detection processing begins with a prescreening operation where a small subset of spatial locations are chosen to consider for further processing. Image statistics, or features, are then extracted around each selected location and used for training a machine learning classification algorithm. A variety of features have been proposed in the literature for use in classification. Thus far, however, predominantly hand-crafted or manually designed features from the computer vision literature have been employed (e.g., HOG, Gabor filtering, etc.). Recently, it has been shown that image features learned directly from data can obtain state-of-the-art performance on a variety of problems. In this work we employ a feature learning scheme using k-means and a bag-of-visual-words model to learn effective features for target and non-target discrimination in FLGPR data. Experiments are conducted using several lanes of FLGPR data and learned features are compared with several previously proposed static features. The results suggest that learned features perform comparably, or better, than existing static features. Similar to other feature learning results, the features consist of edges or texture primitives, revealing which structures in the data are most useful for discrimination.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2223117",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deep learning for segmentation of brain tumors: Impact of cross-institutional training and testing.",
      "authors": "AlBadawy, EA; Saha, A; Mazurowski, MA",
      "published_date": "March 2018",
      "doi": "10.1002/mp.12752",
      "abstract": "BACKGROUND AND PURPOSE: Convolutional neural networks (CNNs) are commonly used for segmentation of brain tumors. In this work, we assess the effect of cross-institutional training on the performance of CNNs. METHODS: We selected 44 glioblastoma (GBM) patients from two institutions in The Cancer Imaging Archive dataset. The images were manually annotated by outlining each tumor component to form ground truth. To automatically segment the tumors in each patient, we trained three CNNs: (a) one using data for patients from the same institution as the test data, (b) one using data for the patients from the other institution and (c) one using data for the patients from both of the institutions. The performance of the trained models was evaluated using Dice similarity coefficients as well as Average Hausdorff Distance between the ground truth and automatic segmentations. The 10-fold cross-validation scheme was used to compare the performance of different approaches. RESULTS: Performance of the model significantly decreased (P < 0.0001) when it was trained on data from a different institution (dice coefficients: 0.68 ± 0.19 and 0.59 ± 0.19) as compared to training with data from the same institution (dice coefficients: 0.72 ± 0.17 and 0.76 ± 0.12). This trend persisted for segmentation of the entire tumor as well as its individual components. CONCLUSIONS: There is a very strong effect of selecting data for training on performance of CNNs in a multi-institutional setting. Determination of the reasons behind this effect requires additional comprehensive investigation.",
      "publication_location": "Med Phys",
      "link": "http://dx.doi.org/10.1002/mp.12752",
      "citations": 22,
      "readership": 88,
      "tweets": 92,
      "news_mentions": ""
    },
    {
      "title": "Multiple ocular diseases detection based on joint sparse multi-task learning.",
      "authors": "Chen, X; Xu, Y; Yin, F; Zhang, Z; Wong, DWK; Wong, TY; Liu, J",
      "published_date": 2015,
      "doi": "10.1109/EMBC.2015.7319578",
      "abstract": "In this paper, we present a multiple ocular diseases detection scheme based on joint sparse multi-task learning. Glaucoma, Pathological Myopia (PM), and Age-related Macular Degeneration (AMD) are three major causes of vision impairment and blindness worldwide. The proposed joint sparse multitask learning framework aims to reconstruct a test fundus image with multiple features from as few training subjects as possible. The linear version of this problem could be casted into a multi-task joint covariate selection model, which can be very efficiently optimized via kernelizable accelerated proximal gradient method. Extensive experiments are conducted in order to validate the proposed framework on the SiMES dataset. From the Area Under Curve (AUC) results in multiple ocular diseases classification, our method is shown to outperform the state-of-the-art algorithms.",
      "publication_location": "Conference Proceedings : ... Annual International Conference of the Ieee Engineering in Medicine and Biology Society. Ieee Engineering in Medicine and Biology Society. Annual Conference",
      "link": "http://dx.doi.org/10.1109/EMBC.2015.7319578",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Principal component reconstruction (PCR) for cine CBCT with motion learning from 2D fluoroscopy.",
      "authors": "Gao, H; Zhang, Y; Ren, L; Yin, F-F",
      "published_date": "January 2018",
      "doi": "10.1002/mp.12671",
      "abstract": "PURPOSE: This work aims to generate cine CT images (i.e., 4D images with high-temporal resolution) based on a novel principal component reconstruction (PCR) technique with motion learning from 2D fluoroscopic training images. METHODS: In the proposed PCR method, the matrix factorization is utilized as an explicit low-rank regularization of 4D images that are represented as a product of spatial principal components and temporal motion coefficients. The key hypothesis of PCR is that temporal coefficients from 4D images can be reasonably approximated by temporal coefficients learned from 2D fluoroscopic training projections. For this purpose, we can acquire fluoroscopic training projections for a few breathing periods at fixed gantry angles that are free from geometric distortion due to gantry rotation, that is, fluoroscopy-based motion learning. Such training projections can provide an effective characterization of the breathing motion. The temporal coefficients can be extracted from these training projections and used as priors for PCR, even though principal components from training projections are certainly not the same for these 4D images to be reconstructed. For this purpose, training data are synchronized with reconstruction data using identical real-time breathing position intervals for projection binning. In terms of image reconstruction, with a priori temporal coefficients, the data fidelity for PCR changes from nonlinear to linear, and consequently, the PCR method is robust and can be solved efficiently. PCR is formulated as a convex optimization problem with the sum of linear data fidelity with respect to spatial principal components and spatiotemporal total variation regularization imposed on 4D image phases. The solution algorithm of PCR is developed based on alternating direction method of multipliers. RESULTS: The implementation is fully parallelized on GPU with NVIDIA CUDA toolbox and each reconstruction takes about a few minutes. The proposed PCR method is validated and compared with a state-of-art method, that is, PICCS, using both simulation and experimental data with the on-board cone-beam CT setting. The results demonstrated the feasibility of PCR for cine CBCT and significantly improved reconstruction quality of PCR from PICCS for cine CBCT. CONCLUSION: With a priori estimated temporal motion coefficients using fluoroscopic training projections, the PCR method can accurately reconstruct spatial principal components, and then generate cine CT images as a product of temporal motion coefficients and spatial principal components.",
      "publication_location": "Med Phys",
      "link": "http://dx.doi.org/10.1002/mp.12671",
      "citations": 6,
      "readership": 22,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "ASIC Implementation of Time-Domain Digital Backpropagation with Deep-Learned Chromatic Dispersion Filters",
      "authors": "Fougstedt, C; Häger, C; Svensson, L; Pfister, HD; Larsson-Edefors, P",
      "published_date": "November 14, 2018",
      "doi": "10.1109/ECOC.2018.8535430",
      "abstract": "© 2018 IEEE. We consider time-domain digital backpropagation with chromatic dispersion filters jointly optimized and quantized using machine-learning techniques. Compared to the baseline implementations, we show improved BER performance and >40% power dissipation reductions in 28-nm CMOS.",
      "publication_location": "European Conference on Optical Communication, Ecoc",
      "link": "http://dx.doi.org/10.1109/ECOC.2018.8535430",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Unsupervised Learning of Spike Patterns for Seizure Detection and Wavefront Estimation of High Resolution Micro Electrocorticographic ( $\\mu $ ECoG) Data.",
      "authors": "Song, Y; Wang, Y; Viventi, J",
      "published_date": "September 2017",
      "doi": "10.1109/tnb.2017.2714460",
      "abstract": "For the past few years, we have developed flexible, active, and multiplexed recording devices for high resolution recording over large, clinically relevant areas in the brain. While this technology has enabled a much higher-resolution view of the electrical activity of the brain, the analytical methods to process, categorize, and respond to the huge volumes of seizure data produced by these devices have not yet been developed. In this paper, we proposed an unsupervised learning framework for spike analysis, which by itself reveals spike pattern. By applying advanced video processing techniques for separating a multi-channel recording into individual spike segments, unfolding the spike segments manifold, and identifying natural clusters for spike patterns, we are able to find the common spike motion patterns. And we further explored using these patterns for more interesting and practical problems as seizure prediction and spike wavefront prediction. These methods have been applied to in vivo feline seizure recordings and yielded promising results.",
      "publication_location": "Ieee Transactions on Nanobioscience",
      "link": "http://dx.doi.org/10.1109/tnb.2017.2714460",
      "citations": 1,
      "readership": 24,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Automated feature learning using deep convolutional auto-encoder neural network for clustering electroencephalograms into sleep stages",
      "authors": "Prabhudesai, KS; Collins, LM; Mainsah, BO",
      "published_date": "May 16, 2019",
      "doi": "10.1109/NER.2019.8716996",
      "abstract": "© 2019 IEEE. Deep neural networks have emerged as popular machine learning tools due to their ability to automatically learn feature representations from raw input data. An auto-encoder neural network is a special network that can be trained in an unsupervised manner for automated feature learning. Unsupervised analysis of EEG signals is highly desirable since supervised analysis requires manual labeling of EEG signals which can be labor intensive and time consuming given the large amount of EEG data collected. We present a deep convolutional auto-encoder neural network to automatically learn feature representations from raw EEG signals in an unsupervised manner. We use the features extracted from the auto-encoder neural network for clustering EEG signals into sleep stages. For clustering, we test two algorithms: K-means - which is a single-membership model, and the latent Dirichlet allocation (LDA) topic model - which is a mixed membership model. Results are presented demonstrating an improvement in clustering performance using auto-encoder features compared to standard manually extracted features.",
      "publication_location": "International Ieee/Embs Conference on Neural Engineering, Ner",
      "link": "http://dx.doi.org/10.1109/NER.2019.8716996",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Automatic threat recognition of prohibited items at aviation checkpoint with x-ray imaging: A deep learning approach",
      "authors": "Liang, KJ; Heilmann, G; Gregory, C; Diallo, SO; Carlson, D; Spell, GP; Sigman, JB; Roe, K; Carin, L",
      "published_date": "January 1, 2018",
      "doi": "10.1117/12.2309484",
      "abstract": "© Copyright 2018 SPIE. The Transportation Security Administration safeguards all United States air travel. To do so, they employ human inspectors to screen x-ray images of carry-on baggage for threats and other prohibited items, which can be challenging. On the other hand, recent research applying deep learning techniques to computer-aided security screening to assist operators has yielded encouraging results. Deep learning is a subfield of machine learning based on learning abstractions from data, as opposed to engineering features by hand. These techniques have proven to be quite effective in many domains, including computer vision, natural language processing, speech recognition, self-driving cars, and geographical mapping technology. In this paper, we present initial results of a collaboration between Smiths Detection and Duke University funded by the Transportation Security Administration. Using convolutional object detection algorithms trained on annotated x-ray images, we show real-time detection of prohibited items in carry-on luggage. Results of the work so far indicate that this approach can detect selected prohibited items with high accuracy and minimal impact on operational false alarm rates.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2309484",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The optimal number of lymph nodes to evaluate among patients undergoing surgery for gallbladder cancer: Correlating the number of nodes removed with survival in 6531 patients.",
      "authors": "Tsilimigras, DI; Hyer, JM; Paredes, AZ; Moris, D; Beal, EW; Merath, K; Mehta, R; Ejaz, A; Cloyd, JM; Pawlik, TM",
      "published_date": "June 2019",
      "doi": "10.1002/jso.25450",
      "abstract": "BACKGROUND:The aim of the current study was to identify the minimum number and the optimal range of lymph nodes (LNs) to be examined among patients with gallbladder cancer (GBC). METHODS:Between January 1, 2004, and December 31, 2015, patients with a diagnosis of GBC were identified in the National Cancer Database. A machine-based learning approach was used to identify the minimum number and range of LNs to evaluate relative to long-term outcomes. RESULTS:Among 6531 patients with GBC, median number of LNs evaluated was 2 (IQR:1-5); only 21.1% (n = 1376) of patients had 6 or more LNs evaluated. The median number of metastatic LNs was 0 (IQR: 0-1). On multivariable analysis, evaluation of < 4 LNs was associated with a higher hazard of death (referent 4-7 LNs: < 4 LNs, HR = 1.27, 95% CI, 1.16-1.40; P < 0.001), whereas, patients who had 4 to 7 LNs and > 7 LNs evaluated had comparable long-term mortality risk (HR = 1.10, 95%CI, 0.98-1.24; P = 0.11). There was no difference in the proportion of patients who had at least one metastatic LN identified per T category based on total number of nodes resected (all P > 0.05). CONCLUSION:The overwhelming majority of patients did not have the American Joint Committee on Cancer (AJCC) recommended 6 total LN count . A machine-based learning approach identified evaluation of 4 to 7 LNs as the LN number associated with optimal staging and survival. While obtaining 6 LNs may be challenging, evaluation of at least 4 LNs may be a more appropriate threshold as this cut-off value was associated with optimal patient outcomes and staging.",
      "publication_location": "Journal of Surgical Oncology",
      "link": "http://dx.doi.org/10.1002/jso.25450",
      "citations": 5,
      "readership": 8,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Comparative effectiveness of convolutional neural network (CNN) and recurrent neural network (RNN) architectures for radiology text report classification.",
      "authors": "Banerjee, I; Ling, Y; Chen, MC; Hasan, SA; Langlotz, CP; Moradzadeh, N; Chapman, B; Amrhein, T; Mong, D; Rubin, DL; Farri, O; Lungren, MP",
      "published_date": "June 2019",
      "doi": "10.1016/j.artmed.2018.11.004",
      "abstract": "This paper explores cutting-edge deep learning methods for information extraction from medical imaging free text reports at a multi-institutional scale and compares them to the state-of-the-art domain-specific rule-based system - PEFinder and traditional machine learning methods - SVM and Adaboost. We proposed two distinct deep learning models - (i) CNN Word - Glove, and (ii) Domain phrase attention-based hierarchical recurrent neural network (DPA-HNN), for synthesizing information on pulmonary emboli (PE) from over 7370 clinical thoracic computed tomography (CT) free-text radiology reports collected from four major healthcare centers. Our proposed DPA-HNN model encodes domain-dependent phrases into an attention mechanism and represents a radiology report through a hierarchical RNN structure composed of word-level, sentence-level and document-level representations. Experimental results suggest that the performance of the deep learning models that are trained on a single institutional dataset, are better than rule-based PEFinder on our multi-institutional test sets. The best F1 score for the presence of PE in an adult patient population was 0.99 (DPA-HNN) and for a pediatrics population was 0.99 (HNN) which shows that the deep learning models being trained on adult data, demonstrated generalizability to pediatrics population with comparable accuracy. Our work suggests feasibility of broader usage of neural network models in automated classification of multi-institutional imaging text reports for a variety of applications including evaluation of imaging utilization, imaging yield, clinical decision support tools, and as part of automated classification of large corpus for medical imaging deep learning work.",
      "publication_location": "Artif Intell Med",
      "link": "http://dx.doi.org/10.1016/j.artmed.2018.11.004",
      "citations": 17,
      "readership": 66,
      "tweets": 15,
      "news_mentions": ""
    },
    {
      "title": "Go gradient for expectation-based objectives",
      "authors": "Cong, Y; Zhao, M; Bai, K; Carin, L",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved. Within many machine learning algorithms, a fundamental problem concerns efficient calculation of an unbiased gradient wrt parameters γ for expectation-based objectives Eqγ(y)[f(y)]. Most existing methods either (i) suffer from high variance, seeking help from (often) complicated variance-reduction techniques; or (ii) they only apply to reparameterizable continuous random variables and employ a reparameterization trick. To address these limitations, we propose a General and One-sample (GO) gradient that (i) applies to many distributions associated with non-reparameterizable continuous or discrete random variables, and (ii) has the same low-variance as the reparameterization trick. We find that the GO gradient often works well in practice based on only one Monte Carlo sample (although one can of course use more samples if desired). Alongside the GO gradient, we develop a means of propagating the chain rule through distributions, yielding statistical back-propagation, coupling neural networks to common random variables.",
      "publication_location": "7th International Conference on Learning Representations, Iclr 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Go gradient for expectation-based objectives",
      "authors": "Cong, Y; Zhao, M; Bai, K; Carin, L",
      "published_date": "January 1, 2019",
      "doi": "",
      "abstract": "© 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved. Within many machine learning algorithms, a fundamental problem concerns efficient calculation of an unbiased gradient wrt parameters γ for expectation-based objectives Eqγ(y)[f(y)]. Most existing methods either (i) suffer from high variance, seeking help from (often) complicated variance-reduction techniques; or (ii) they only apply to reparameterizable continuous random variables and employ a reparameterization trick. To address these limitations, we propose a General and One-sample (GO) gradient that (i) applies to many distributions associated with non-reparameterizable continuous or discrete random variables, and (ii) has the same low-variance as the reparameterization trick. We find that the GO gradient often works well in practice based on only one Monte Carlo sample (although one can of course use more samples if desired). Alongside the GO gradient, we develop a means of propagating the chain rule through distributions, yielding statistical back-propagation, coupling neural networks to common random variables.",
      "publication_location": "7th International Conference on Learning Representations, Iclr 2019",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Artificial intelligence for teleophthalmology-based diabetic retinopathy screening in a national programme: an economic analysis modelling study",
      "authors": "Xie, Y; Nguyen, QD; Hamzah, H; Lim, G; Bellemo, V; Gunasekeran, DV; Yip, MYT; Qi Lee, X; Hsu, W; Li Lee, M; Tan, CS; Tym Wong, H; Lamoureux, EL; Tan, GSW; Wong, TY; Finkelstein, EA; Ting, DSW",
      "published_date": "May 1, 2020",
      "doi": "10.1016/S2589-7500(20)30060-1",
      "abstract": "© 2020 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY-NC-ND 4.0 license Background: Deep learning is a novel machine learning technique that has been shown to be as effective as human graders in detecting diabetic retinopathy from fundus photographs. We used a cost-minimisation analysis to evaluate the potential savings of two deep learning approaches as compared with the current human assessment: a semi-automated deep learning model as a triage filter before secondary human assessment; and a fully automated deep learning model without human assessment. Methods: In this economic analysis modelling study, using 39 006 consecutive patients with diabetes in a national diabetic retinopathy screening programme in Singapore in 2015, we used a decision tree model and TreeAge Pro to compare the actual cost of screening this cohort with human graders against the simulated cost for semi-automated and fully automated screening models. Model parameters included diabetic retinopathy prevalence rates, diabetic retinopathy screening costs under each screening model, cost of medical consultation, and diagnostic performance (ie, sensitivity and specificity). The primary outcome was total cost for each screening model. Deterministic sensitivity analyses were done to gauge the sensitivity of the results to key model assumptions. Findings: From the health system perspective, the semi-automated screening model was the least expensive of the three models, at US$62 per patient per year. The fully automated model was $66 per patient per year, and the human assessment model was $77 per patient per year. The savings to the Singapore health system associated with switching to the semi-automated model are estimated to be $489 000, which is roughly 20% of the current annual screening cost. By 2050, Singapore is projected to have 1 million people with diabetes; at this time, the estimated annual savings would be $15 million. Interpretation: This study provides a strong economic rationale for using deep learning systems as an assistive tool to screen for diabetic retinopathy. Funding: Ministry of Health, Singapore.",
      "publication_location": "The Lancet Digital Health",
      "link": "http://dx.doi.org/10.1016/S2589-7500(20)30060-1",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 22,
      "news_mentions": 2
    },
    {
      "title": "A Self-Learning Machine Vision System",
      "authors": "",
      "published_date": "May 10, 2004",
      "doi": "10.1117/12.518547",
      "abstract": "Reliable and productive manufacturing operations have depended on people to quickly detect and solve problems whenever they appear. Over the last 20 years, more and more manufacturing operations have embraced machine vision systems to increase productivity, reliability and cost-effectiveness, including reducing the number of human operators required. Because of these two key factors, increased technical complexity and an fewer resources, the people who continue to work in the factory are finding it ever more difficult to deal with issues that involve the production line's sophisticated machine vision equipment. An image processing technology is now available that enables a system to match an operator's subjectivity. A hardware-based implementation of a neural network system enables a vision system to \"think\" and \"inspect\" like a human, with the speed and reliability of a machine.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.518547",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Convolutional regularization methods for 4D, x-ray CT reconstruction",
      "authors": "Clark, DP; Badea, CT",
      "published_date": "January 1, 2019",
      "doi": "10.1117/12.2512816",
      "abstract": "© SPIE. Downloading of the abstract is permitted for personal use only. Deep learning methods have shown great promise in tackling challenging medical imaging tasks. Within the field of x-ray CT, deep learning for image denoising is of interest because of the fundamental link between ionizing radiation dose and diagnostic image quality, the limited availability of clinical projection data, and the computational expense of iterative reconstruction methods. Here, we work with 3D, temporal CT data (4D, cardiac CT), where redundancies in spatial sampling necessitate careful control of imaging dose. Specifically, using custom extensions to the Tensorflow and Keras machine learning packages, we construct and train a 4D, convolutional neural network (CNN) to denoise helical, cardiac CT data acquired in a mouse model of atherosclerosis. With the objective of accelerating iterative reconstruction, we train the CNN to map undersampled algebraic reconstructions of the 4D data to fully-sampled and regularized iterative reconstructions under mean-squared-error, perceptual loss, and low rank cost terms. Using phantom data for quantitative validation, we verify that the CNN robustly denoises static potions of the image without compromising temporal fidelity and that the CNN performs similarly to regularized, iterative reconstruction with the split Bregman method (CNN temporal RMSE: 142 HU; iterative temporal RMSE: 136 HU). Using in vivo validation and testing data excluded from CNN training, we verify that the CNN generalizes well, approximately reproducing the noise power spectrum of the iteratively reconstructed data (noise std. in water vial near heart, CNN: 62-73 HU, depending on cardiac phase; iterative: 94-100 HU), without degradation of spatial resolution (axial MTF, 10% cutoff, CNN: 2.69 lp/mm; iterative: 2.63 lp/mm). Overall, the results presented in this work represent a positive step toward realizing the promises of deep learning methods in medical imaging.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2512816",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A unifying framework for interpreting and predicting mutualistic systems.",
      "authors": "Wu, F; Lopatkin, AJ; Needs, DA; Lee, CT; Mukherjee, S; You, L",
      "published_date": "January 16, 2019",
      "doi": "10.1038/s41467-018-08188-5",
      "abstract": "Coarse-grained rules are widely used in chemistry, physics and engineering. In biology, however, such rules are less common and under-appreciated. This gap can be attributed to the difficulty in establishing general rules to encompass the immense diversity and complexity of biological systems. Furthermore, even when a rule is established, it is often challenging to map it to mechanistic details and to quantify these details. Here we report a framework that addresses these challenges for mutualistic systems. We first deduce a general rule that predicts the various outcomes of mutualistic systems, including coexistence and productivity. We further develop a standardized machine-learning-based calibration procedure to use the rule without the need to fully elucidate or characterize their mechanistic underpinnings. Our approach consistently provides explanatory and predictive power with various simulated and experimental mutualistic systems. Our strategy can pave the way for establishing and implementing other simple rules for biological systems.",
      "publication_location": "Nature Communications",
      "link": "http://dx.doi.org/10.1038/s41467-018-08188-5",
      "citations": 7,
      "readership": 58,
      "tweets": 9,
      "news_mentions": 5
    },
    {
      "title": "Big data: More than big data sets.",
      "authors": "Cobb, AN; Benjamin, AJ; Huang, ES; Kuo, PC",
      "published_date": "October 2018",
      "doi": "10.1016/j.surg.2018.06.022",
      "abstract": "The term big data has been popularized over the past decade and is often used to refer to data sets that are too large or complex to be analyzed by traditional means. Although the term has been utilized for some time in business and engineering, the concept of big data is relatively new to medicine. The reception from the medical community has been mixed; however, the widespread utilization of electronic health records in the United States, the creation of large clinical data sets and national registries that capture information on numerous vectors affecting healthcare delivery and patient outcomes, and the sequencing of the human genome are all opportunities to leverage big data. This review was inspired by a lively panel discussion on big data that took place at the 75th Central Surgical Association Annual Meeting. The authors' aim was to describe big data, the methodologies used to analyze big data, and their practical clinical application.",
      "publication_location": "Surgery",
      "link": "http://dx.doi.org/10.1016/j.surg.2018.06.022",
      "citations": 9,
      "readership": 67,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Reinforcement learning with hierarchies of machines",
      "authors": "",
      "published_date": "January 1, 1998",
      "doi": "",
      "abstract": "We present a new approach to reinforcement learning in which the policies considered by the learning process are constrained by hierarchies of partially specified machines. This allows for the use of prior knowledge to reduce the search space and provides a framework in which knowledge can be transferred across problems and in which component solutions can be recombined to solve larger and more complicated problems. Our approach can be seen as providing a link between reinforcement learning and \"behavior-based\" or \"teleo-reactive\" approaches to control. We present provably convergent algorithms for problem-solving and learning with hierarchical machines and demonstrate their effectiveness on a problem with several thousand states.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Automated identification of protein-ligand interaction features using Inductive Logic Programming: a hexose binding case study.",
      "authors": "A Santos, JC; Nassif, H; Page, D; Muggleton, SH; E Sternberg, MJ",
      "published_date": "July 11, 2012",
      "doi": "10.1186/1471-2105-13-162",
      "abstract": "BACKGROUND: There is a need for automated methods to learn general features of the interactions of a ligand class with its diverse set of protein receptors. An appropriate machine learning approach is Inductive Logic Programming (ILP), which automatically generates comprehensible rules in addition to prediction. The development of ILP systems which can learn rules of the complexity required for studies on protein structure remains a challenge. In this work we use a new ILP system, ProGolem, and demonstrate its performance on learning features of hexose-protein interactions. RESULTS: The rules induced by ProGolem detect interactions mediated by aromatics and by planar-polar residues, in addition to less common features such as the aromatic sandwich. The rules also reveal a previously unreported dependency for residues cys and leu. They also specify interactions involving aromatic and hydrogen bonding residues. This paper shows that Inductive Logic Programming implemented in ProGolem can derive rules giving structural features of protein/ligand interactions. Several of these rules are consistent with descriptions in the literature. CONCLUSIONS: In addition to confirming literature results, ProGolem's model has a 10-fold cross-validated predictive accuracy that is superior, at the 95% confidence level, to another ILP system previously used to study protein/hexose interactions and is comparable with state-of-the-art statistical learners.",
      "publication_location": "Bmc Bioinformatics",
      "link": "http://dx.doi.org/10.1186/1471-2105-13-162",
      "citations": 11,
      "readership": 41,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Open online platforms advancing DSP education",
      "authors": "Slavinsky, JP; Davenport, KJ; Butler, AC; Marsh, EJ; Baraniuk, RG",
      "published_date": "October 18, 2013",
      "doi": "10.1109/ICASSP.2013.6639379",
      "abstract": "Two open, online educational platforms, OpenStax Exercises and OpenStax Tutor, are working to revolutionize the way in which students learn concepts in diverse subject areas. Born and tested in the area of signal processing education, these tools bring to bear cutting-edge ideas in cognitive science and machine learning to automatically build personalized learning pathways for today's students and to advance the field of learning science. These platforms are introduced and initial results discussed. © 2013 IEEE.",
      "publication_location": "2015 Ieee International Conference on Acoustics, Speech, and Signal Processing (Icassp)",
      "link": "http://dx.doi.org/10.1109/ICASSP.2013.6639379",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An integrated approach to feature invention and model construction for drug activity prediction",
      "authors": "Davis, J; Costa, VS; Ray, S; Page, D",
      "published_date": "August 23, 2007",
      "doi": "10.1145/1273496.1273524",
      "abstract": "We present a new machine learning approach for 3D-QSAR, the task of predicting binding affinities of molecules to target proteins based on 3D structure. Our approach predicts binding affinity by using regression on substructures discovered by relational learning. We make two contributions to the state-of-the-art. First, we use multiple-instance (MI) regression, which represents a molecule as a set of 3D conformations, to model activity. Second, the relational learning component employs the \"Score As You Use\" (SAYU) method to select substructures for their ability to improve the regression model. This is the first application of SAYU to multiple-instance, real-valued prediction. We evaluate our approach on three tasks and demonstrate that (i) SAYU outperforms standard coverage measures when selecting features for regression, (ii) the MI representation improves accuracy over standard single feature-vector encodings and (iii) combining SAYU with MI regression is more accurate for 3D-QSAR than either approach by itself.",
      "publication_location": "Acm International Conference Proceeding Series",
      "link": "http://dx.doi.org/10.1145/1273496.1273524",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Special session paper: Data analytics enables energy-efficiency and robustness: From mobile to manycores, datacenters, and networks",
      "authors": "Pasricha, S; Doppa, JR; Chakrabarty, K; Tiku, S; Dauwe, D; Jin, S; Pande, PP",
      "published_date": "November 7, 2017",
      "doi": "10.1145/3125502.3125560",
      "abstract": "© 2017 ACM. The amount of data generated and collected across computing platforms every day is not only enormous, but growing at an exponential rate. Advanced data analytics and machinelearning techniques have become increasingly essential to analyze and extract meaning from such Big Data. These techniques can be very useful to detect patterns and trends to improve the operational behavior of computing platforms, but they also introduce a number of outstanding challenges: (1) How can we design and deploy data analytics and learning mechanisms to improve energy-efficiency in IoT and mobile devices, without introducing significant software overheads' (2) How to use machine learning and analytics techniques for effective designspace exploration during manycore chip design' (3) How can data analytics and learning improve the reliability and energyefficiency of large-scale cloud datacenters, to cost-effectively support connected embedded and IoT platforms? (4) How can data analytics detect anomalies and increase robustness in the network backbone of emerging cloud datacenter networks' In this paper, we discuss these outstanding problems and describe far-reaching solutions applicable across the interconnected ecosystem of IoT and mobile devices, manycore chips, datacenters, and networks.",
      "publication_location": "2017 International Conference on Hardware/Software Codesign and System Synthesis, Codes+Isss 2017",
      "link": "http://dx.doi.org/10.1145/3125502.3125560",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "ZARA: A novel zero-free dataflow accelerator for generative adversarial networks in 3D ReRAM",
      "authors": "",
      "published_date": "June 2, 2019",
      "doi": "10.1145/3316781.3317936",
      "abstract": "© 2019 Association for Computing Machinery. Generative Adversarial Networks (GANs) recently demonstrated a great opportunity toward unsupervised learning with the intention to mitigate the massive human efforts on data labeling in supervised learning algorithms. GAN combines a generative model and a discriminative model to oppose each other in an adversarial situation to refine their abilities. Existing nonvolatile memory based machine learning accelerators, however, could not support the computational needs required by GAN training. Specifically, the generator utilizes a new operator, called transposed convolution, which introduces significant resource underutilization when executed on conventional neural network accelerators as it inserts massive zeros in its input before a convolution operation. In this work, we propose a novel computational deformation technique that synergistically optimizes the forward and backward functions in transposed convolution to eliminate the large resource underutilization. In addition, we present dedicated control units - a dataflow mapper and an operation scheduler, to support the proposed execution model with high parallelism and low energy consumption. ZARA is implemented with commodity ReRAM chips, and experimental results show that our design can improve GAN's training performance by averagely 1.6×∼23× over CMOS-based GAN accelerators. Compared to stateof- the-art ReRAM-based accelerator designs, ZARA also provides 1.15 × ∼2.1× performance improvement.",
      "publication_location": "Proceedings   Design Automation Conference",
      "link": "http://dx.doi.org/10.1145/3316781.3317936",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "On the local minima of the empirical risk",
      "authors": "Jin, C; Ge, R; Liu, LT; Jordan, MI",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 Curran Associates Inc..All rights reserved. Population risk is always of primary interest in machine learning; however, learning algorithms only have access to the empirical risk. Even for applications with nonconvex nonsmooth losses (such as modern deep networks), the population risk is generally significantly more well-behaved from an optimization point of view than the empirical risk. In particular, sampling can create many spurious local minima. We consider a general framework which aims to optimize a smooth nonconvex function F (population risk) given only access to an approximation f (empirical risk) that is pointwise close to F (i.e., kF − fk∞ ≤ ν). Our objective is to find the -approximate local minima of the underlying function F while avoiding the shallow local minima-arising because of the tolerance ν-which exist only in f. We propose a simple algorithm based on stochastic gradient descent (SGD) on a smoothed version of f that is guaranteed to achieve our goal as long as ν ≤ O(1.5/d). We also provide an almost matching lower bound showing that our algorithm achieves optimal error tolerance ν among all algorithms making a polynomial number of queries of f. As a concrete example, we show that our results can be directly used to give sample complexities for learning a ReLU unit.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "On the optimization landscape of tensor decompositions",
      "authors": "Ge, R; Ma, T",
      "published_date": "January 1, 2017",
      "doi": "",
      "abstract": "© 2017 Neural information processing systems foundation. All rights reserved. Non-convex optimization with local search heuristics has been widely used in machine learning, achieving many state-of-art results. It becomes increasingly important to understand why they can work for these NP-hard problems on typical data. The landscape of many objective functions in learning has been conjectured to have the geometric property that \"all local optima are (approximately) global optima\", and thus they can be solved efficiently by local search algorithms. However, establishing such property can be very difficult. In this paper, we analyze the optimization landscape of the random over-complete tensor decomposition problem, which has many applications in unsupervised leaning, especially in learning latent variable models. In practice, it can be efficiently solved by gradient ascent on a non-convex objective. We show that for any small constant ϵ > 0, among the set of points with function values (1 + ϵ)-factor larger than the expectation of the function, all the local maxima are approximate global maxima. Previously, the best-known result only characterizes the geometry in small neighborhoods around the true components. Our result implies that even with an initialization that is barely better than the random guess, the gradient ascent algorithm is guaranteed to solve this problem. Our main technique uses Kac-Rice formula and random matrix theory. To our best knowledge, this is the first time when Kac-Rice formula is successfully applied to counting the number of local optima of a highly-structured random polynomial with dependent coefficients.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Familiarity Detection is an Intrinsic Property of Cortical Microcircuits with Bidirectional Synaptic Plasticity.",
      "authors": "Zhang, X; Ju, H; Penney, TB; VanDongen, AMJ",
      "published_date": "May 2017",
      "doi": "10.1523/ENEURO.0361-16.2017",
      "abstract": "Humans instantly recognize a previously seen face as \"familiar.\" To deepen our understanding of familiarity-novelty detection, we simulated biologically plausible neural network models of generic cortical microcircuits consisting of spiking neurons with random recurrent synaptic connections. NMDA receptor (NMDAR)-dependent synaptic plasticity was implemented to allow for unsupervised learning and bidirectional modifications. Network spiking activity evoked by sensory inputs consisting of face images altered synaptic efficacy, which resulted in the network responding more strongly to a previously seen face than a novel face. Network size determined how many faces could be accurately recognized as familiar. When the simulated model became sufficiently complex in structure, multiple familiarity traces could be retained in the same network by forming partially-overlapping subnetworks that differ slightly from each other, thereby resulting in a high storage capacity. Fisher's discriminant analysis was applied to identify critical neurons whose spiking activity predicted familiar input patterns. Intriguingly, as sensory exposure was prolonged, the selected critical neurons tended to appear at deeper layers of the network model, suggesting recruitment of additional circuits in the network for incremental information storage. We conclude that generic cortical microcircuits with bidirectional synaptic plasticity have an intrinsic ability to detect familiar inputs. This ability does not require a specialized wiring diagram or supervision and can therefore be expected to emerge naturally in developing cortical circuits.",
      "publication_location": "Eneuro",
      "link": "http://dx.doi.org/10.1523/ENEURO.0361-16.2017",
      "citations": 1,
      "readership": 19,
      "tweets": 20,
      "news_mentions": ""
    },
    {
      "title": "Deep mining heterogeneous networks of biomedical linked data to predict novel drug-target associations.",
      "authors": "Zong, N; Kim, H; Ngo, V; Harismendy, O",
      "published_date": "August 2017",
      "doi": "10.1093/bioinformatics/btx160",
      "abstract": "Motivation:A heterogeneous network topology possessing abundant interactions between biomedical entities has yet to be utilized in similarity-based methods for predicting drug-target associations based on the array of varying features of drugs and their targets. Deep learning reveals features of vertices of a large network that can be adapted in accommodating the similarity-based solutions to provide a flexible method of drug-target prediction. Results:We propose a similarity-based drug-target prediction method that enhances existing association discovery methods by using a topology-based similarity measure. DeepWalk, a deep learning method, is adopted in this study to calculate the similarities within Linked Tripartite Network (LTN), a heterogeneous network generated from biomedical linked datasets. This proposed method shows promising results for drug-target association prediction: 98.96% AUC ROC score with a 10-fold cross-validation and 99.25% AUC ROC score with a Monte Carlo cross-validation with LTN. By utilizing DeepWalk, we demonstrate that: (i) this method outperforms other existing topology-based similarity computation methods, (ii) the performance is better for tripartite than with bipartite networks and (iii) the measure of similarity using network topology outperforms the ones derived from chemical structure (drugs) or genomic sequence (targets). Our proposed methodology proves to be capable of providing a promising solution for drug-target prediction based on topological similarity with a heterogeneous network, and may be readily re-purposed and adapted in the existing of similarity-based methodologies. Availability and Implementation:The proposed method has been developed in JAVA and it is available, along with the data at the following URL: https://github.com/zongnansu1982/drug-target-prediction . Contact:nazong@ucsd.edu. Supplementary information:Supplementary data are available at Bioinformatics online.",
      "publication_location": "Bioinformatics (Oxford, England)",
      "link": "http://dx.doi.org/10.1093/bioinformatics/btx160",
      "citations": 51,
      "readership": 66,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Identifying systematic spatial failure patterns through wafer clustering",
      "authors": "Alawieh, MB; Wang, F; Li, X",
      "published_date": "July 29, 2016",
      "doi": "10.1109/ISCAS.2016.7527389",
      "abstract": "© 2016 IEEE. In this paper, we propose a novel methodology for detecting systematic spatial failure patterns at wafer level for yield learning. Our proposed methodology takes the testing results (i.e., pass or fail) of a number of dies over different wafers, cluster all these wafers according to their failures, and eventually identify the underlying spatial failure patterns. Several novel machine learning algorithms, including singular value decomposition, hierarchical clustering, dictionary learning, etc., are developed in order to make the proposed methodology robust to random failures. The efficacy of our proposed approach is demonstrated by an industrial data set.",
      "publication_location": "Proceedings   Ieee International Symposium on Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/ISCAS.2016.7527389",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Comparative Evaluation of MS-based Metabolomics Software and Its Application to Preclinical Alzheimer's Disease.",
      "authors": "Hao, L; Wang, J; Page, D; Asthana, S; Zetterberg, H; Carlsson, C; Okonkwo, OC; Li, L",
      "published_date": "June 18, 2018",
      "doi": "10.1038/s41598-018-27031-x",
      "abstract": "Mass spectrometry-based metabolomics has undergone significant progresses in the past decade, with a variety of software packages being developed for data analysis. However, systematic comparison of different metabolomics software tools has rarely been conducted. In this study, several representative software packages were comparatively evaluated throughout the entire pipeline of metabolomics data analysis, including data processing, statistical analysis, feature selection, metabolite identification, pathway analysis, and classification model construction. LC-MS-based metabolomics was applied to preclinical Alzheimer's disease (AD) using a small cohort of human cerebrospinal fluid (CSF) samples (N = 30). All three software packages, XCMS Online, SIEVE, and Compound Discoverer, provided consistent and reproducible data processing results. A hybrid method combining statistical test and support vector machine feature selection was employed to screen key metabolites, achieving a complementary selection of candidate biomarkers from three software packages. Machine learning classification using candidate biomarkers generated highly accurate and predictive models to classify patients into preclinical AD or control category. Overall, our study demonstrated a systematic evaluation of different MS-based metabolomics software packages for the entire data analysis pipeline which was applied to the candidate biomarker discovery of preclinical AD.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/s41598-018-27031-x",
      "citations": 2,
      "readership": 72,
      "tweets": 13,
      "news_mentions": ""
    },
    {
      "title": "Massively parallel C. elegans tracking provides multi-dimensional fingerprints for phenotypic discovery.",
      "authors": "",
      "published_date": "August 2018",
      "doi": "10.1016/j.jneumeth.2018.02.005",
      "abstract": "BACKGROUND:The nematode worm C. elegans is a model organism widely used for studies of genetics and of human disease. The health and fitness of the worms can be quantified in different ways, such as by measuring their bending frequency, speed or lifespan. Manual assays, however, are time consuming and limited in their scope providing a strong motivation for automation. NEW METHOD:We describe the development and application of an advanced machine vision system for characterising the behaviour of C. elegans, the Wide Field-of-View Nematode Tracking Platform (WF-NTP), which enables massively parallel data acquisition and automated multi-parameter behavioural profiling of thousands of worms simultaneously. RESULTS:We screened more than a million worms from several established models of neurodegenerative disorders and characterised the effects of potential therapeutic molecules for Alzheimer's and Parkinson's diseases. By using very large numbers of animals we show that the sensitivity and reproducibility of behavioural assays is very greatly increased. The results reveal the ability of this platform to detect even subtle phenotypes. COMPARISON WITH EXISTING METHODS:The WF-NTP method has substantially greater capacity compared to current automated platforms that typically either focus on characterising single worms at high resolution or tracking the properties of populations of less than 50 animals. CONCLUSIONS:The WF-NTP extends significantly the power of existing automated platforms by combining enhanced optical imaging techniques with an advanced software platform. We anticipate that this approach will further extend the scope and utility of C. elegans as a model organism.",
      "publication_location": "Journal of Neuroscience Methods",
      "link": "http://dx.doi.org/10.1016/j.jneumeth.2018.02.005",
      "citations": 15,
      "readership": 48,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "3D OCT imaging in clinical settings: Toward quantitative measurements of retinal structures",
      "authors": "Zawadzki, RJ; Fuller, AR; Zhao, M; Wiley, DF; Choi, SS; Bower, BA; Hamann, B; Izatt, JA; Werner, JS",
      "published_date": "June 30, 2006",
      "doi": "10.1117/12.647567",
      "abstract": "The acquisition speed of current FD-OCT (Fourier Domain - Optical Coherence Tomography) instruments allows rapid screening of three-dimensional (3D) volumes of human retinas in clinical settings. To take advantage of this ability requires software used by physicians to be capable of displaying and accessing volumetric data as well as supporting post processing in order to access important quantitative information such as thickness maps and segmented volumes. We describe our clinical FD-OCT system used to acquire 3D data from the human retina over the macula and optic nerve head. B-scans are registered to remove motion artifacts and post-processed with customized 3D visualization and analysis software. Our analysis software includes standard 3D visualization techniques along with a machine learning support vector machine (SVM) algorithm that allows a user to semi-automatically segment different retinal structures and layers. Our program makes possible measurements of the retinal layer thickness as well as volumes of structures of interest, despite the presence of noise and structural deformations associated with retinal pathology. Our software has been tested successfully in clinical settings for its efficacy in assessing 3D retinal structures in healthy as well as diseased cases. Our tool facilitates diagnosis and treatment monitoring of retinal diseases.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.647567",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Relational representation for improved decisions with an information-theoretic CADe system: Initial experience",
      "authors": "Mazurowski, MA; Tourassi, GD",
      "published_date": "June 15, 2009",
      "doi": "10.1117/12.812965",
      "abstract": "Our previously presented information-theoretic computer-aided detection (IT-CADe) system for distinguishing masses and normal parenchyma in mammograms is an example of a case-based system. IT-CAD makes decisions by evaluating the querys average similarity with known mass and normal examples stored in the systems case base. Pairwise case similarity is measured in terms of their normalized mutual information. The purpose of this study was to evaluate whether incorporating a new machine learning concept of relational representation to IT-CAD is a more effective strategy than the decision algorithm that is currently in place. A trainable relational representation classifier builds a decision rule using the relational representation of cases. Instead of describing a case by a vector of intrinsic features, the case is described by its NMI-based similarity to a set of known examples. For this study, we first applied random mutation hill climbing algorithm to select the concise set of knowledge cases and then we applied a support vector machine to derive a decision rule using the relational representation of cases. We performed the study with a database of 600 mammographic regions of interest (300 with masses and 300 with normal parenchyma). Our experiments indicate that incorporating the concept of relational representation with a trainable classifier to IT-CAD provides an improvement in performance as compared with the original decision rule. Therefore, relational representation is a promising strategy for IT-CADe. © 2009 SPIE.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.812965",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "RouteNet: Routability prediction for mixed-size designs using convolutional neural network",
      "authors": "Xie, Z; Huang, YH; Fang, GQ; Ren, H; Fang, SY; Chen, Y; Hu, J",
      "published_date": "November 5, 2018",
      "doi": "10.1145/3240765.3240843",
      "abstract": "© 2018 ACM. Early routability prediction helps designers and tools perform preventive measures so that design rule violations can be avoided in a proactive manner. However, it is a huge challenge to have a predictor that is both accurate and fast. In this work, we study how to leverage convolutional neural network to address this challenge. The proposed method, called RouteNet, can either evaluate the overall routability of cell placement solutions without global routing or predict the locations of DRC (Design Rule Checking) hotspots. In both cases, large macros in mixed-size designs are taken into consideration. Experiments on benchmark circuits show that RouteNet can forecast overall routability with accuracy similar to that of global router while using substantially less runtime. For DRC hotspot prediction, RouteNet improves accuracy by 50% compared to global routing. It also significantly outperforms other machine learning approaches such as support vector machine and logistic regression.",
      "publication_location": "Ieee/Acm International Conference on Computer Aided Design, Digest of Technical Papers, Iccad",
      "link": "http://dx.doi.org/10.1145/3240765.3240843",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Using Artificial Intelligence to Improve the Quality and Safety of Radiation Therapy.",
      "authors": "Pillai, M; Adapa, K; Das, SK; Mazur, L; Dooley, J; Marks, LB; Thompson, RF; Chera, BS",
      "published_date": "September 2019",
      "doi": "10.1016/j.jacr.2019.06.001",
      "abstract": "Within artificial intelligence, machine learning (ML) efforts in radiation oncology have augmented the transition from generalized to personalized treatment delivery. Although their impact on quality and safety of radiation therapy has been limited, they are increasingly being used throughout radiation therapy workflows. Various data-driven approaches have been used for outcome prediction, CT simulation, clinical decision support, knowledge-based planning, adaptive radiation therapy, plan validation, machine quality assurance, and process quality assurance; however, there are many challenges that need to be addressed with the creation and usage of ML algorithms as well as the interpretation and dissemination of findings. In this review, the authors present current applications of ML in radiation oncology quality and safety initiatives, discuss challenges faced by the radiation oncology community, and suggest future directions.",
      "publication_location": "Journal of the American College of Radiology : Jacr",
      "link": "http://dx.doi.org/10.1016/j.jacr.2019.06.001",
      "citations": 2,
      "readership": 26,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Classification of crystallization outcomes using deep convolutional neural networks.",
      "authors": "Bruno, AE; Charbonneau, P; Newman, J; Snell, EH; So, DR; Vanhoucke, V; Watkins, CJ; Williams, S; Wilson, J",
      "published_date": "January 2018",
      "doi": "10.1371/journal.pone.0198883",
      "abstract": "The Machine Recognition of Crystallization Outcomes (MARCO) initiative has assembled roughly half a million annotated images of macromolecular crystallization experiments from various sources and setups. Here, state-of-the-art machine learning algorithms are trained and tested on different parts of this data set. We find that more than 94% of the test images can be correctly labeled, irrespective of their experimental origin. Because crystal recognition is key to high-density screening and the systematic analysis of crystallization experiments, this approach opens the door to both industrial and fundamental research applications.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0198883",
      "citations": 15,
      "readership": 57,
      "tweets": 27,
      "news_mentions": 3
    },
    {
      "title": "Managing Multi-center Flow Cytometry Data for Immune Monitoring.",
      "authors": "White, S; Laske, K; Welters, MJ; Bidmon, N; van der Burg, SH; Britten, CM; Enzor, J; Staats, J; Weinhold, KJ; Gouttefangeas, C; Chan, C",
      "published_date": 2014,
      "doi": "10.4137/CIN.S16346",
      "abstract": "With the recent results of promising cancer vaccines and immunotherapy1-5, immune monitoring has become increasingly relevant for measuring treatment-induced effects on T cells, and an essential tool for shedding light on the mechanisms responsible for a successful treatment. Flow cytometry is the canonical multi-parameter assay for the fine characterization of single cells in solution, and is ubiquitously used in pre-clinical tumor immunology and in cancer immunotherapy trials. Current state-of-the-art polychromatic flow cytometry involves multi-step, multi-reagent assays followed by sample acquisition on sophisticated instruments capable of capturing up to 20 parameters per cell at a rate of tens of thousands of cells per second. Given the complexity of flow cytometry assays, reproducibility is a major concern, especially for multi-center studies. A promising approach for improving reproducibility is the use of automated analysis borrowing from statistics, machine learning and information visualization21-23, as these methods directly address the subjectivity, operator-dependence, labor-intensive and low fidelity of manual analysis. However, it is quite time-consuming to investigate and test new automated analysis techniques on large data sets without some centralized information management system. For large-scale automated analysis to be practical, the presence of consistent and high-quality data linked to the raw FCS files is indispensable. In particular, the use of machine-readable standard vocabularies to characterize channel metadata is essential when constructing analytic pipelines to avoid errors in processing, analysis and interpretation of results. For automation, this high-quality metadata needs to be programmatically accessible, implying the need for a consistent Application Programming Interface (API). In this manuscript, we propose that upfront time spent normalizing flow cytometry data to conform to carefully designed data models enables automated analysis, potentially saving time in the long run. The ReFlow informatics framework was developed to address these data management challenges.",
      "publication_location": "Cancer Informatics",
      "link": "http://dx.doi.org/10.4137/CIN.S16346",
      "citations": 7,
      "readership": 28,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Development of Algorithms for Automated Detection of Cervical Pre-Cancers With a Low-Cost, Point-of-Care, Pocket Colposcope.",
      "authors": "Asiedu, MN; Simhal, A; Chaudhary, U; Mueller, JL; Lam, CT; Schmitt, JW; Venegas, G; Sapiro, G; Ramanujam, N",
      "published_date": "August 2019",
      "doi": "10.1109/TBME.2018.2887208",
      "abstract": "GOAL: In this paper, we propose methods for (1) automatic feature extraction and classification for acetic acid and Lugol's iodine cervigrams and (2) methods for combining features/diagnosis of different contrasts in cervigrams for improved performance. METHODS: We developed algorithms to pre-process pathology-labeled cervigrams and extract simple but powerful color and textural-based features. The features were used to train a support vector machine model to classify cervigrams based on corresponding pathology for visual inspection with acetic acid, visual inspection with Lugol's iodine, and a combination of the two contrasts. RESULTS: The proposed framework achieved a sensitivity, specificity, and accuracy of 81.3%, 78.6%, and 80.0%, respectively, when used to distinguish cervical intraepithelial neoplasia (CIN+) relative to normal and benign tissues. This is superior to the average values achieved by three expert physicians on the same data set for discriminating normal/benign cases from CIN+ (77% sensitivity, 51% specificity, and 63% accuracy). CONCLUSION: The results suggest that utilizing simple color- and textural-based features from visual inspection with acetic acid and visual inspection with Lugol's iodine images may provide unbiased automation of cervigrams. SIGNIFICANCE: This would enable automated, expert-level diagnosis of cervical pre-cancer at the point of care.",
      "publication_location": "Ieee Trans Biomed Eng",
      "link": "http://dx.doi.org/10.1109/TBME.2018.2887208",
      "citations": 5,
      "readership": 20,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Privacy-Preserving Collaborative Prediction using Random Forests",
      "authors": "Giacomelli, I; Jha, S; Kleiman, R; Page, D; Yoon, K",
      "published_date": "",
      "doi": "",
      "abstract": "We study the problem of privacy-preserving machine learning (PPML) for\nensemble methods, focusing our effort on random forests. In collaborative\nanalysis, PPML attempts to solve the conflict between the need for data sharing\nand privacy. This is especially important in privacy sensitive applications\nsuch as learning predictive models for clinical decision support from EHR data\nfrom different clinics, where each clinic has a responsibility for its\npatients' privacy. We propose a new approach for ensemble methods: each entity\nlearns a model, from its own data, and then when a client asks the prediction\nfor a new private instance, the answers from all the locally trained models are\nused to compute the prediction in such a way that no extra information is\nrevealed. We implement this approach for random forests and we demonstrate its\nhigh efficiency and potential accuracy benefit via experiments on real-world\ndatasets, including actual EHR data.",
      "publication_location": "",
      "link": "https://hdl.handle.net/10161/19038",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Toward automatic management of embarrassingly parallel applications",
      "authors": "Dutra, I; Page, D; Costa, VS; Shavlik, J; Waddell, M",
      "published_date": "December 1, 2004",
      "doi": "",
      "abstract": "Large-scale applications that require executing very large numbers of tasks are only feasible through parallelism. In this work we present a system that automatically handles large numbers of experiments and data in the context of machine learning. Our system controls all experiments, including re-submission of failed jobs and relies on available resource managers to spawn jobs through pools of machines. Our results show that we can manage a very large number of experiments, using a reasonable amount of idle CPU cycles, with very little user intervention. © Springer-Verlag 2003.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Combining gene expression, demographic and clinical data in modeling disease: a case study of bipolar disorder and schizophrenia.",
      "authors": "Struyf, J; Dobrin, S; Page, D",
      "published_date": "November 7, 2008",
      "doi": "10.1186/1471-2164-9-531",
      "abstract": "BACKGROUND: This paper presents a retrospective statistical study on the newly-released data set by the Stanley Neuropathology Consortium on gene expression in bipolar disorder and schizophrenia. This data set contains gene expression data as well as limited demographic and clinical data for each subject. Previous studies using statistical classification or machine learning algorithms have focused on gene expression data only. The present paper investigates if such techniques can benefit from including demographic and clinical data. RESULTS: We compare six classification algorithms: support vector machines (SVMs), nearest shrunken centroids, decision trees, ensemble of voters, naïve Bayes, and nearest neighbor. SVMs outperform the other algorithms. Using expression data only, they yield an area under the ROC curve of 0.92 for bipolar disorder versus control, and 0.91 for schizophrenia versus control. By including demographic and clinical data, classification performance improves to 0.97 and 0.94 respectively. CONCLUSION: This paper demonstrates that SVMs can distinguish bipolar disorder and schizophrenia from normal control at a very high rate. Moreover, it shows that classification performance improves by including demographic and clinical data. We also found that some variables in this data set, such as alcohol and drug use, are strongly associated to the diseases. These variables may affect gene expression and make it more difficult to identify genes that are directly associated to the diseases. Stratification can correct for such variables, but we show that this reduces the power of the statistical methods.",
      "publication_location": "Bmc Genomics",
      "link": "http://dx.doi.org/10.1186/1471-2164-9-531",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Handling missing syndromes in board-level functional-fault diagnosis",
      "authors": "Ye, F; Jin, S; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "January 1, 2013",
      "doi": "10.1109/ATS.2013.22",
      "abstract": "Functional fault diagnosis is widely used in board manufacturing to ensure product quality and improve product yield. Advanced machine-learning techniques have recently been advocated for reasoning-based diagnosis; these technologies are based on historical data of successfully repaired boards. However, traditional diagnosis systems fail to provide appropriate repair suggestions when the diagnostic logs are fragmented and some error outcomes, or syndromes, are not available during diagnosis. We describe the design of a diagnosis system, based on supportvector machines, that can handle missing syndromes by using the method of imputation. Several imputation methods are discussed and compared in terms of their efficiency in handling missing syndromes. Two large-scale synthetic data sets generated from the log information of complex industrial boards in volume production are used to validate the proposed diagnosis system in terms of diagnosis accuracy and training time. Copyright © 2013 by The Institute of Electrical and Electronics Engineers, Inc.",
      "publication_location": "Proceedings of the Asian Test Symposium",
      "link": "http://dx.doi.org/10.1109/ATS.2013.22",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Hepatic R2* is more strongly associated with proton density fat fraction than histologic liver iron scores in patients with nonalcoholic fatty liver disease.",
      "authors": "Bashir, MR; Wolfson, T; Gamst, AC; Fowler, KJ; Ohliger, M; Shah, SN; Alazraki, A; Trout, AT; Behling, C; Allende, DS; Loomba, R; Sanyal, A; Schwimmer, J; Lavine, JE; Shen, W; Tonascia, J; Van Natta, ML; Mamidipalli, A; Hooker, J; Kowdley, KV; Middleton, MS; Sirlin, CB; NASH Clinical Research Network (NASH CRN),",
      "published_date": "May 2019",
      "doi": "10.1002/jmri.26312",
      "abstract": "BACKGROUND: The liver R2* value is widely used as a measure of liver iron but may be confounded by the presence of hepatic steatosis and other covariates. PURPOSE: To identify the most influential covariates for liver R2* values in patients with nonalcoholic fatty liver disease (NAFLD). STUDY TYPE: Retrospective analysis of prospectively acquired data. POPULATION: Baseline data from 204 subjects enrolled in NAFLD/NASH (nonalcoholic steatohepatitis) treatment trials. FIELD STRENGTH: 1.5T and 3T; chemical-shift encoded multiecho gradient echo. ASSESSMENT: Correlation between liver proton density fat fraction and R2*; assessment for demographic, metabolic, laboratory, MRI-derived, and histological covariates of liver R2*. STATISTICAL TESTS: Pearson's and Spearman's correlations; univariate analysis; gradient boosting machines (GBM) multivariable machine-learning method. RESULTS: Hepatic proton density fat fraction (PDFF) was the most strongly correlated covariate for R2* at both 1.5T (r = 0.652, P < 0.0001) and at 3T (r = 0.586, P < 0.0001). In the GBM analysis, hepatic PDFF was the most influential covariate for hepatic R2*, with relative influences (RIs) of 61.3% at 1.5T and 47.5% at 3T; less influential covariates had RIs of up to 11.5% at 1.5T and 16.7% at 3T. Nonhepatocellular iron was weakly associated with R2* at 3T only (RI 6.7%), and hepatocellular iron was not associated with R2* at either field strength. DATA CONCLUSION: Hepatic PDFF is the most influential covariate for R2* at both 1.5T and 3T; nonhepatocellular iron deposition is weakly associated with liver R2* at 3T only. LEVEL OF EVIDENCE: 4 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2019;49:1456-1466.",
      "publication_location": "J Magn Reson Imaging",
      "link": "http://dx.doi.org/10.1002/jmri.26312",
      "citations": 2,
      "readership": 20,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Local pattern classification differentiates processes of economic valuation.",
      "authors": "Clithero, JA; Carter, RM; Huettel, SA",
      "published_date": "May 2009",
      "doi": "10.1016/j.neuroimage.2008.12.074",
      "abstract": "For effective decision making, individuals must be able to form subjective values from many types of information. Yet, the neural mechanisms that underlie potential differences in value computation across different decision scenarios are incompletely understood. Here, we used functional magnetic resonance imaging (fMRI), in conjunction with the machine learning technique of support vector machines (SVM), to identify brain regions that contain unique local information associated with different types of valuation. We used a combinatoric approach that evaluated the unique contributions of different brain regions to model generalization strength. Local voxel patterns in left posterior parietal cortex contained unique information differentiating probabilistic and intertemporal valuation, a result that was not accessible using standard fMRI analyses. We conclude that the early valuation phases for these reward types differ on a fine spatial scale, suggesting the existence of computational topographies along the value construction pathway.",
      "publication_location": "Neuroimage",
      "link": "http://dx.doi.org/10.1016/j.neuroimage.2008.12.074",
      "citations": 37,
      "readership": 125,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "An efficient approximation to lookahead in relational learners",
      "authors": "Struyf, J; Davis, J; Page, D",
      "published_date": "January 1, 2006",
      "doi": "",
      "abstract": "Greedy machine learning algorithms suffer from shortsightedness, potentially returning suboptimal models due to limited exploration of the search space. Greedy search misses useful refinements that yield a significant gain only in conjunction with other conditions. Relational learners, such as inductive logic programming algorithms, are especially susceptible to this problem. Lookahead helps greedy search overcome myopia; unfortunately it causes an exponential increase in execution time. Furthermore, it may lead to overfitting. We propose a heuristic for greedy relational learning algorithms that can be seen as an efficient, limited form of lookahead. Our experimental evaluation shows that the proposed heuristic yields models that are as accurate as models generated using lookahead. It is also considerably faster than lookahead. © Springer-Verlag Berlin Heidelberg 2006.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Knowledge discovery and knowledge transfer in board-level functional fault diagnosis",
      "authors": "Ye, F; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "February 6, 2015",
      "doi": "10.1109/TEST.2014.7035335",
      "abstract": "© 2014 IEEE. Diagnosis of functional failures at the board level is critical for improving product yield and reducing manufacturing cost. Reasoning techniques increase the accuracy of functional-fault diagnosis based on the history of successfully repaired boards. However, depending on the complexity of the product, it usually takes several months to accumulate an adequate database for training a reasoning-based diagnosis system. During the initial product ramp-up phase, reasoning-based diagnosis is not feasible for yield learning, since the required database is not available due to lack of volume. We propose a knowledge-discovery method and a knowledge-transfer method for facilitating board-level functional fault diagnosis. First, an analysis technique based on machine learning is used to discover knowledge from syndromes, which can be used for training a diagnosis engine. Second, knowledge from diagnosis engines used for earlier-generation products can be automatically transferred through root-cause mapping and syndrome mapping based on keywords and board-structure similarities. Two complex boards in volume production and with a mature diagnosis system, and three new boards in the ramp-up phase, are used to validate the proposed knowledge-discovery and knowledge-transfer approach in terms of the diagnosis accuracy obtained using the new diagnosis systems.",
      "publication_location": "Proceedings   International Test Conference",
      "link": "http://dx.doi.org/10.1109/TEST.2014.7035335",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Accurate predictions of process-execution time and process status based on support-vector regression for enterprise information systems",
      "authors": "Duan, Q; Zeng, J; Chakrabarty, K; Dispoto, G",
      "published_date": "March 1, 2015",
      "doi": "10.1109/TCAD.2014.2387831",
      "abstract": "© 1982-2012 IEEE. Accurate predictions of both process-execution time and process status are crucial for the development of an intelligent enterprise information system (EIS). We have developed new automated learning-based process-execution time-prediction and process status-prediction methods that can be embedded into an EIS. Process-execution time prediction is a regression problem and state-of-the-art (baseline) time-prediction methods use a machine-learning regression model. Process status prediction is a binary classification problem in which a class labeled \"completed\" or \"in-progress\" is assigned to a process with respect to an arbitrary predictive horizon (i.e., the future time given by the method user). The methods proposed in this paper integrate statistical methods with support-vector regression. Comparison results obtained from the real data of a digital-print enterprise show that the proposed time-prediction method reduces both the relative mean error and the root-mean-squared error of the regression model. Furthermore, the proposed status-prediction method not only achieves higher classification accuracy than state-of-the-art methods, it also estimates the probability of the predicted status. In addition, algorithm development and training phases of the proposed methods do not rely on any arbitrary predictive horizon. Therefore, a single time-prediction model as proposed is sufficient for status prediction as opposed to a baseline status-prediction method that requires classification models for all potential predictive horizons.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2014.2387831",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "New results in breast cancer classification obtained from an evolutionary computation/adaptive boosting hybrid using mammogram and history data",
      "authors": "Land, WH; Masters, T; Lo, JY; McKee, DW; Anderson, FR",
      "published_date": "January 1, 2001",
      "doi": "10.1109/SMCIA.2001.936727",
      "abstract": "© 2001 IEEE. A new neural network technology was developed to improve the diagnosis of breast cancer using mammogram findings. The paradigm, adaptive boosting (AB), uses a markedly different theory in solving the computational intelligence (CI) problem. AB, a new machine learning paradigm, focuses on finding weak learning algorithm(s) that initially need to provide slightly better than \"random\" performance (i.e., approximately 55%) when processing a mammogram training set. By successive development of additional architectures (using the mammogram training set), the adaptive boosting process improves performance of the basic evolutionary programming derived neural network architectures. The results of these several EP-derived hybrid architectures are then intelligently combined and tested using a similar validation mammogram data set. Optimization, focused on improving specificity and positive predictive value at very high sensitivities, with an analysis of the performance of the hybrid would be most meaningful. Using the DUKE mammogram database of 500 biopsy proven samples, this hybrid, on average, was able to achieve (under statistical 5-fold cross-validation) a specificity of 48.3% and a positive predictive value (PPV) of 51.8% while maintaining 100% sensitivity. At 97% sensitivity, a specificity of 56.6% and a PPV of 55.8% were obtained.",
      "publication_location": "Smcia 2001   Proceedings of the 2001 Ieee Mountain Workshop on Soft Computing in Industrial Applications",
      "link": "http://dx.doi.org/10.1109/SMCIA.2001.936727",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Application of adaptive boosting to EP-derived multi-layer feedforward neural networks (MLFN) to improve benign/malignant breast cancer classification",
      "authors": "Land, J; Masters, T; Lo, JY; McKee, DW",
      "published_date": "January 1, 2001",
      "doi": "10.1117/12.431058",
      "abstract": "A new neural network technology was developed for improving the benign/malignant diagnosis of breast cancer using mammogram findings. A new paradigm, Adaptive Boosting (AB), uses a markedly different theory in solutioning Computational Intelligence (CI) problems. AB, a new machine learning paradigm, focuses on finding weak learning algorithm(s) that initially need to provide slightly better than \"random\" performance (i.e., approximately 55%) when processing a mammogram training set. Then, by successive development of additional architectures (using the mammogram training set), the adaptive boosting process improves the performance of the basic Evolutionary Programming derived neural network architectures. The results of these several EP-derived hybrid architectures are then intelligently combined and tested using a similar validation mammogram data set. Optimization focused on improving specificity and positive predictive value at very high sensitivities, where an analysis of the performance of the hybrid would be most meaningful. Using the DUKE mammogram database of 500 biopsy proven samples, on average this hybrid was able to achieve (under statistical 5-fold cross-validation) a specificity of 48.3% and a positive predictive value (PPV) of 51.8% while maintaining 100% sensitivity. At 97% sensitivity, a specificity of 56.6% and a PPV of 55.8% were obtained.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.431058",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Reports of the 2013 AAAI Spring Symposium Series",
      "authors": "Markman, V; Stojanov, G; Indurkhya, B; Kido, T; Takadama, K; Konidaris, G; Eaton, E; Matsumura, N; Fruchter, R; Sofge, D; Lawless, WF; Madani, O; Sukthankar, R",
      "published_date": "January 1, 2013",
      "doi": "10.1609/aimag.v34i3.2493",
      "abstract": "The Association for the Advancement of Artificial Intelligence was pleased to present the AAAI 2013 Spring Symposium Series, held Monday through Wednesday, March 25-27, 2013. The titles of the eight symposia were Analyzing Microtext; Creativity and (Early) Cognitive Development; Data-Driven Wellness: From Self-Tracking to Behavior Change; Designing Intelligent Robots: Reintegrating AI II; Lifelong Machine Learning; Shikakeology: Designing Triggers for Behavior Change; Trust and Autonomous Systems; and Weakly Supervised Learning from Multimedia. This report contains summaries of the symposia, written, in most cases, by the cochairs of the symposium. Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved.",
      "publication_location": "Ai Magazine",
      "link": "http://dx.doi.org/10.1609/aimag.v34i3.2493",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Cloning your mind: Security challenges in cognitive system designs and their solutions",
      "authors": "Liu, B; Wu, C; Li, H; Chen, Y; Wu, Q; Barnell, M; Qiu, Q",
      "published_date": "January 1, 2015",
      "doi": "10.1145/2744769.2747915",
      "abstract": "© 2015 ACM. With the booming of big-data applications, cognitive information processing systems that leverage advanced data processing technologies, e.g., machine learning and data mining, are widely used in many industry fields. Although these technologies demonstrate great processing capability and accuracy in the relevant applications, several security and safety challenges are also emerging against these learning based technologies. In this paper, we will first introduce several security concerns in cognitive system designs. Some real examples are then used to demonstrate how the attackers can potentially access the confidential user data, replicate a sensitive data processing model without being granted the access to the details of the model, and obtain some key features of the training data by using the services publically accessible to a normal user. Based on the analysis of these security challenges, we also discuss several possible solutions that can protect the information privacy and security of cognitive systems during different stages of the usage.",
      "publication_location": "Proceedings   Design Automation Conference",
      "link": "http://dx.doi.org/10.1145/2744769.2747915",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Development of a neuro-fuzzy technique for automated parameter optimization of inverse treatment planning.",
      "authors": "Stieler, F; Yan, H; Lohr, F; Wenz, F; Yin, F-F",
      "published_date": "September 25, 2009",
      "doi": "10.1186/1748-717X-4-39",
      "abstract": "BACKGROUND: Parameter optimization in the process of inverse treatment planning for intensity modulated radiation therapy (IMRT) is mainly conducted by human planners in order to create a plan with the desired dose distribution. To automate this tedious process, an artificial intelligence (AI) guided system was developed and examined. METHODS: The AI system can automatically accomplish the optimization process based on prior knowledge operated by several fuzzy inference systems (FIS). Prior knowledge, which was collected from human planners during their routine trial-and-error process of inverse planning, has first to be \"translated\" to a set of \"if-then rules\" for driving the FISs. To minimize subjective error which could be costly during this knowledge acquisition process, it is necessary to find a quantitative method to automatically accomplish this task. A well-developed machine learning technique, based on an adaptive neuro fuzzy inference system (ANFIS), was introduced in this study. Based on this approach, prior knowledge of a fuzzy inference system can be quickly collected from observation data (clinically used constraints). The learning capability and the accuracy of such a system were analyzed by generating multiple FIS from data collected from an AI system with known settings and rules. RESULTS: Multiple analyses showed good agreements of FIS and ANFIS according to rules (error of the output values of ANFIS based on the training data from FIS of 7.77 +/- 0.02%) and membership functions (3.9%), thus suggesting that the \"behavior\" of an FIS can be propagated to another, based on this process. The initial experimental results on a clinical case showed that ANFIS is an effective way to build FIS from practical data, and analysis of ANFIS and FIS with clinical cases showed good planning results provided by ANFIS. OAR volumes encompassed by characteristic percentages of isodoses were reduced by a mean of between 0 and 28%. CONCLUSION: The study demonstrated a feasible way to automatically perform parameter optimization of inverse treatment planning under guidance of prior knowledge without human intervention other than providing a set of constraints that have proven clinically useful in a given setting.",
      "publication_location": "Radiation Oncology",
      "link": "http://dx.doi.org/10.1186/1748-717X-4-39",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Fine-Grained Adaptive Testing Based on Quality Prediction",
      "authors": "Liu, M; Pan, R; Ye, F; Li, X; Chakrabarty, K; Gu, X",
      "published_date": "January 23, 2019",
      "doi": "10.1109/TEST.2018.8624891",
      "abstract": "© 2018 IEEE. The ever-increasing complexity of integrated circuits inevitably leads to high test cost. Adaptive testing provides an effective solution for test-cost reduction; this testing framework selects the important test items for each set of chips. However, adaptive testing methods designed for digital circuits are coarse-grained, and they are targeted only at systematic defects. In order to incorporate fabrication variations and random defects in the testing framework, we propose a fine-grained adaptive testing method based on machine learning. We use the parametric test results from the previous stages of test to train a quality-prediction model for use in subsequent test stages. Next, we partition a given lot of chips into two groups based on their predicted quality. A test-selection method based on statistical learning is applied to the chips with high predicted quality. An ad hoc test-selection method is proposed and applied to the chips with low predicted quality. Experimental results using a large number of fabricated chips and the associated test data show that to achieve the same defect level as in prior work on adaptive testing, the fine-grained adaptive testing method reduces test cost by 90% for low-quality chips, and up to 7% for all the chips in a lot.",
      "publication_location": "Proceedings   International Test Conference",
      "link": "http://dx.doi.org/10.1109/TEST.2018.8624891",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Shedding light to sleep studies",
      "authors": "Dieffenderfer, J; Krystal, A; Bozkurt, A",
      "published_date": "January 1, 2017",
      "doi": "10.1117/12.2275625",
      "abstract": "© 2107 SPIE. This paper presents our efforts in the development of a small wireless, flexible bandage sized near-infrared spectroscopy (NIRS) system for sleep analysis. The current size of the system is 2.8 cm × 1.7 cm × 0.6 cm. It is capable of performing NIRS with 660nm, 940nm and 850nm wavelengths for up to 11 hours continuously. The device is placed on the forehead to measure from the prefrontal cortex and the raw data is continuously streamed over Bluetooth to a nearby data aggregator such as a smartphone for post processing and cloud connection. In this study, we performed traditional polysomnography simultaneously with NIRS to evaluate agreement with traditional measures of sleep and to provide labelled data for future work involving learning algorithms. Ultimately, we expect a machine learning algorithm to be able to generate characterization of sleep states comparable to traditional methods based on this biophotonics data. The system also includes an inertial measurement unit and the features that can be extracted from the presented system include sleep posture, heart rate, respiratory rate, relative change in oxy and deoxy hemoglobin concentrations and tissue oxygenation and cerebral arterial oxygen extracted from these. Preliminary proof of concept results are promising and demonstrate the capability to measure heart rate, respiratory rate and slow-wave-sleep stages. This system serves as a prototype to evaluate the potential of a small bandage-size continuous-wave NIRS device to be a useful means of studying sleep.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2275625",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Augmentation of Physician Assessments with Multi-Omics Enhances Predictability of Drug Response: A Case Study of Major Depressive Disorder.",
      "authors": "Athreya, A; Iyer, R; Neavin, D; Wang, L; Weinshilboum, R; Kaddurah-Daouk, R; Rush, J; Frye, M; Bobo, W",
      "published_date": "August 2018",
      "doi": "10.1109/MCI.2018.2840660",
      "abstract": "This work proposes a \"learning-augmented clinical assessment\" workflow to sequentially augment physician assessments of patients' symptoms and their socio-demographic measures with heterogeneous biological measures to accurately predict treatment outcomes using machine learning. Across many psychiatric illnesses, ranging from major depressive disorder to schizophrenia, symptom severity assessments are subjective and do not include biological measures, making predictability in eventual treatment outcomes a challenge. Using data from the Mayo Clinic PGRN-AMPS SSRI trial as a case study, this work demonstrates a significant improvement in the prediction accuracy for antidepressant treatment outcomes in patients with major depressive disorder from 35% to 80% individualized by patient, compared to using only a physician's assessment as the predictors. This improvement is achieved through an iterative overlay of biological measures, starting with metabolites (blood measures modulated by drug action) associated with symptom severity, and then adding in genes associated with metabolomic concentrations. Hence, therapeutic efficacy for a new patient can be assessed prior to treatment, using prediction models that take as inputs, selected biological measures and physician's assessments of depression severity. Of broader significance extending beyond psychiatry, the approach presented in this work can potentially be applied to predicting treatment outcomes for other medical conditions, such as migraine headaches or rheumatoid arthritis, for which patients are treated according to subject-reported assessments of symptom severity.",
      "publication_location": "Ieee Computational Intelligence Magazine",
      "link": "http://dx.doi.org/10.1109/MCI.2018.2840660",
      "citations": 9,
      "readership": 27,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Prediction of VRC01 neutralization sensitivity by HIV-1 gp160 sequence features.",
      "authors": "Magaret, CA; Benkeser, DC; Williamson, BD; Borate, BR; Carpp, LN; Georgiev, IS; Setliff, I; Dingens, AS; Simon, N; Carone, M; Simpkins, C; Montefiori, D; Alter, G; Yu, W-H; Juraska, M; Edlefsen, PT; Karuna, S; Mgodi, NM; Edugupanti, S; Gilbert, PB",
      "published_date": "April 2019",
      "doi": "10.1371/journal.pcbi.1006952",
      "abstract": "The broadly neutralizing antibody (bnAb) VRC01 is being evaluated for its efficacy to prevent HIV-1 infection in the Antibody Mediated Prevention (AMP) trials. A secondary objective of AMP utilizes sieve analysis to investigate how VRC01 prevention efficacy (PE) varies with HIV-1 envelope (Env) amino acid (AA) sequence features. An exhaustive analysis that tests how PE depends on every AA feature with sufficient variation would have low statistical power. To design an adequately powered primary sieve analysis for AMP, we modeled VRC01 neutralization as a function of Env AA sequence features of 611 HIV-1 gp160 pseudoviruses from the CATNAP database, with objectives: (1) to develop models that best predict the neutralization readouts; and (2) to rank AA features by their predictive importance with classification and regression methods. The dataset was split in half, and machine learning algorithms were applied to each half, each analyzed separately using cross-validation and hold-out validation. We selected Super Learner, a nonparametric ensemble-based cross-validated learning method, for advancement to the primary sieve analysis. This method predicted the dichotomous resistance outcome of whether the IC50 neutralization titer of VRC01 for a given Env pseudovirus is right-censored (indicating resistance) with an average validated AUC of 0.868 across the two hold-out datasets. Quantitative log IC50 was predicted with an average validated R2 of 0.355. Features predicting neutralization sensitivity or resistance included 26 surface-accessible residues in the VRC01 and CD4 binding footprints, the length of gp120, the length of Env, the number of cysteines in gp120, the number of cysteines in Env, and 4 potential N-linked glycosylation sites; the top features will be advanced to the primary sieve analysis. This modeling framework may also inform the study of VRC01 in the treatment of HIV-infected persons.",
      "publication_location": "Plos Computational Biology",
      "link": "http://dx.doi.org/10.1371/journal.pcbi.1006952",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Hierarchical invariant sparse modeling for image analysis",
      "authors": "Bar, L; Sapiro, G",
      "published_date": "December 1, 2011",
      "doi": "10.1109/ICIP.2011.6116125",
      "abstract": "Sparse representation theory has been increasingly used in signal processing and machine learning. In this paper we introduce a hierarchical sparse modeling approach which integrates information from the image patch level to derive a mid-level invariant image and pattern representation. The proposed framework is based on a hierarchical architecture of dictionary learning for sparse coding in a cortical (log-polar) space, combined with a novel pooling operator which incorporates the Rapid transform and max pooling to attain rotation and scale invariance. The invariant sparse representation of patterns here presented - can be used in different object recognition tasks. Promising results are obtained for three applications - 2D shapes classification, texture recognition and object detection. © 2011 IEEE.",
      "publication_location": "Proceedings   International Conference on Image Processing, Icip",
      "link": "http://dx.doi.org/10.1109/ICIP.2011.6116125",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Logical Differential Prediction Bayes Net, improving breast cancer diagnosis for older women.",
      "authors": "Nassif, H; Wu, Y; Page, D; Burnside, E",
      "published_date": 2012,
      "doi": "",
      "abstract": "Overdiagnosis is a phenomenon in which screening identities cancer which may not go on to cause symptoms or death. Women over 65 who develop breast cancer bear the heaviest burden of overdiagnosis. This work introduces novel machine learning algorithms to improve diagnostic accuracy of breast cancer in aging populations. At the same time, we aim at minimizing unnecessary invasive procedures (thus decreasing false positives) and concomitantly addressing overdiagnosis. We develop a novel algorithm. Logical Differential Prediction Bayes Net (LDP-BN), that calculates the risk of breast disease based on mammography findings. LDP-BN uses Inductive Logic Programming (ILP) to learn relational rules, selects older-specific differentially predictive rules, and incorporates them into a Bayes Net, significantly improving its performance. In addition, LDP-BN offers valuable insight into the classification process, revealing novel older-specific rules that link mass presence to invasive, and calcification presence and lack of detectable mass to DCIS.",
      "publication_location": "Amia ... Annual Symposium Proceedings. Amia Symposium",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/23304412",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Artificial intelligence framework for simulating clinical decision-making: a Markov decision process approach.",
      "authors": "Bennett, CC; Hauser, K",
      "published_date": "January 2013",
      "doi": "10.1016/j.artmed.2012.12.003",
      "abstract": "OBJECTIVE: In the modern healthcare system, rapidly expanding costs/complexity, the growing myriad of treatment options, and exploding information streams that often do not effectively reach the front lines hinder the ability to choose optimal treatment decisions over time. The goal in this paper is to develop a general purpose (non-disease-specific) computational/artificial intelligence (AI) framework to address these challenges. This framework serves two potential functions: (1) a simulation environment for exploring various healthcare policies, payment methodologies, etc., and (2) the basis for clinical artificial intelligence - an AI that can \"think like a doctor\". METHODS: This approach combines Markov decision processes and dynamic decision networks to learn from clinical data and develop complex plans via simulation of alternative sequential decision paths while capturing the sometimes conflicting, sometimes synergistic interactions of various components in the healthcare system. It can operate in partially observable environments (in the case of missing observations or data) by maintaining belief states about patient health status and functions as an online agent that plans and re-plans as actions are performed and new observations are obtained. This framework was evaluated using real patient data from an electronic health record. RESULTS: The results demonstrate the feasibility of this approach; such an AI framework easily outperforms the current treatment-as-usual (TAU) case-rate/fee-for-service models of healthcare. The cost per unit of outcome change (CPUC) was $189 vs. $497 for AI vs. TAU (where lower is considered optimal) - while at the same time the AI approach could obtain a 30-35% increase in patient outcomes. Tweaking certain AI model parameters could further enhance this advantage, obtaining approximately 50% more improvement (outcome change) for roughly half the costs. CONCLUSION: Given careful design and problem formulation, an AI simulation framework can approximate optimal decisions even in complex and uncertain environments. Future work is described that outlines potential lines of research and integration of machine learning algorithms for personalized medicine.",
      "publication_location": "Artificial Intelligence in Medicine",
      "link": "http://dx.doi.org/10.1016/j.artmed.2012.12.003",
      "citations": 98,
      "readership": 555,
      "tweets": 18,
      "news_mentions": 4
    },
    {
      "title": "Program Evaluation and Causal Inference With High-Dimensional Data",
      "authors": "Belloni, A; Chernozhukov, V; Fernández-Val, I; Hansen, C",
      "published_date": "January 1, 2017",
      "doi": "10.3982/ECTA12723",
      "abstract": "© 2017 The Econometric Society In this paper, we provide efficient estimators and honest confidence bands for a variety of treatment effects including local average (LATE) and local quantile treatment effects (LQTE) in data-rich environments. We can handle very many control variables, endogenous receipt of treatment, heterogeneous treatment effects, and function-valued outcomes. Our framework covers the special case of exogenous receipt of treatment, either conditional on controls or unconditionally as in randomized control trials. In the latter case, our approach produces efficient estimators and honest bands for (functional) average treatment effects (ATE) and quantile treatment effects (QTE). To make informative inference possible, we assume that key reduced-form predictive relationships are approximately sparse. This assumption allows the use of regularization and selection methods to estimate those relations, and we provide methods for post-regularization and post-selection inference that are uniformly valid (honest) across a wide range of models. We show that a key ingredient enabling honest inference is the use of orthogonal or doubly robust moment conditions in estimating certain reduced-form functional parameters. We illustrate the use of the proposed methods with an application to estimating the effect of 401(k) eligibility and participation on accumulated assets. The results on program evaluation are obtained as a consequence of more general results on honest inference in a general moment-condition framework, which arises from structural equation models in econometrics. Here, too, the crucial ingredient is the use of orthogonal moment conditions, which can be constructed from the initial moment conditions. We provide results on honest inference for (function-valued) parameters within this general framework where any high-quality, machine learning methods (e.g., boosted trees, deep neural networks, random forest, and their aggregated and hybrid versions) can be used to learn the nonparametric/high-dimensional components of the model. These include a number of supporting auxiliary results that are of major independent interest: namely, we (1) prove uniform validity of a multiplier bootstrap, (2) offer a uniformly valid functional delta method, and (3) provide results for sparsity-based estimation of regression functions for function-valued outcomes.",
      "publication_location": "Econometrica",
      "link": "http://dx.doi.org/10.3982/ECTA12723",
      "citations": 47,
      "readership": 224,
      "tweets": 11,
      "news_mentions": ""
    },
    {
      "title": "Signal representations in modern signal processing",
      "authors": "",
      "published_date": "June 16, 2017",
      "doi": "10.1109/ICASSP.2017.7953399",
      "abstract": "© 2017 IEEE. The last decade of John Cozzens's tenure at the NSF witnessed the advent of theory and methods at the heart of modern data science. These advances include (but are not limited to) compressed sensing, sparse coding, inference methods robust to outliers and missing data, and convex optimization tools that facilitate a host of novel inference methods. This paper describes how these methods evolved from classical basis representations of signals to alternative, flexible representations of signal structure. These new representations facilitate more accurate and robust inference in many contexts, and research at the intersection of signal processing, machine learning, and optimization make it possible to learn new representations from complex sensor data. This paper explores several key representations that have emerged in the past decade and their impact on the signal processing community.",
      "publication_location": "2015 Ieee International Conference on Acoustics, Speech, and Signal Processing (Icassp)",
      "link": "http://dx.doi.org/10.1109/ICASSP.2017.7953399",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Forest-based point process for event prediction from electronic health records",
      "authors": "Weiss, JC; Page, D",
      "published_date": "October 31, 2013",
      "doi": "10.1007/978-3-642-40994-3_35",
      "abstract": "Accurate prediction of future onset of disease from Electronic Health Records (EHRs) has important clinical and economic implications. In this domain the arrival of data comes at semi-irregular intervals and makes the prediction task challenging. We propose a method called multiplicative-forest point processes (MFPPs) that learns the rate of future events based on an event history. MFPPs join previous theory in multiplicative forest continuous-time Bayesian networks and piecewise-continuous conditional intensity models. We analyze the advantages of using MFPPs over previous methods and show that on synthetic and real EHR forecasting of heart attacks, MFPPs outperform earlier methods and augment off-the-shelf machine learning algorithms. © 2013 Springer-Verlag.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "http://dx.doi.org/10.1007/978-3-642-40994-3_35",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An empirical evaluation of bagging in inductive logic programming",
      "authors": "De Castro Dutra, I; Page, D; Costa, VS; Shavlik, J",
      "published_date": "January 1, 2003",
      "doi": "",
      "abstract": "© Springer-Verlag Berlin Heidelberg 2003. Ensembles have proven useful for a variety of applications, with a variety of machine learning approaches. While Quinlan has applied boosting to FOIL, the widely-used approach of bagging has never been employed in ILP. Bagging has the advantage over boosting that the different members of the ensemble can be learned and used in parallel. This advantage is especially important for ILP where run-times often are high. We evaluate bagging on three different application domains using the complete-search ILP system, Aleph. We contrast bagging with an approach where we take advantage of the non-determinism in ILP search, by simply allowing Aleph to run multiple times, each time choosing \"seed\" examples at random.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An integer optimization approach to associative classification",
      "authors": "Bertsimas, D; Chang, A; Rudin, C",
      "published_date": "December 1, 2012",
      "doi": "",
      "abstract": "We aim to design classifiers that have the interpretability of association rules yet have predictive power on par with the top machine learning algorithms for classification. We propose a novel mixed integer optimization (MIO) approach called Ordered Rules for Classification (ORC) for this task. Our method has two parts. The first part mines a particular frontier of solutions in the space of rules, and we show that this frontier contains the best rules according to a variety of interestingness measures. The second part learns an optimal ranking for the rules to build a decision list classifier that is simple and insightful. We report empirical evidence using several different datasets to demonstrate the performance of this method.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "TH‐E‐BRB‐05: Modeling the Correlation Between OAR Dose Sparing and Patient's Anatomy in Head and Neck IMRT",
      "authors": "Yuan, L; ge, Y; li, T; Zhu, X; Yin, F; wu, Q",
      "published_date": "January 1, 2011",
      "doi": "10.1118/1.3613562",
      "abstract": "Purpose: To summarize the knowledge of the dependence of organ‐at‐risk (OAR) dose‐volume distribution on patient's anatomy by machine learning techniques from a database of previous expert plans. Methods: 35 head‐and‐ neck IMRT plans were studied retrospectively. The OAR‐PTV geometry was modeled by the distance‐to‐target histogram (DTH). Principal Component Analysis (PCA) was applied to DVH and DTH to capture their salient features. The PCs of the DVH and DTH were then mapped to the parameter space of patient anatomy and dose distribution using correlation analysis. A polynomial model of the correlation between OAR DVH and patient anatomy was constructed and trained by a stepwise regression method. Two major OARs, the right/left parotids, were modeled in the regression analysis. Results: (1) PCA characterizes two salient features of the DTH and DVH, the first as the mean of the histogram, the second as the average gradient of the histogram within a range. (2) The regression analysis shows that the main factors contributing to the first component of the principal component score (PC1) of OAR DVH are the PC1 of DTH and the fractional volume in the overlap region, and the main factor affecting the PC2 of OAR DVH is the PC2 of DTH. (3) In terms of patient anatomy and dose‐volume distribution parameters, these correlations indicate the influences of the mean and gradient of DTH on the mean and gradient of DVH by the patient plan. In addition, the fractional volume outside treatment field with co‐planar beam setting also plays a role in determining OAR DVH. The determination coefficients by the polynomial models are: R,2=0.89 and R,2=0.47 for PC1 and PC2 of right parotid, respectively; R,2=0.64 and R,2=0.41 for PC1 and PC2 of left parotid, respectively. Conclusions: The model learned from the database quantifies the influence of geometrical complexity on the OAR dose sparing. Duke University has a master reaserch agreement with VARIAN Medical Systems, Inc. © 2011, American Association of Physicists in Medicine. All rights reserved.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3613562",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Random forest prediction of Alzheimer's disease using pairwise selection from time series data.",
      "authors": "Moore, PJ; Lyons, TJ; Gallacher, J; Alzheimer’s Disease Neuroimaging Initiative,",
      "published_date": 2019,
      "doi": "10.1371/journal.pone.0211558",
      "abstract": "Time-dependent data collected in studies of Alzheimer's disease usually has missing and irregularly sampled data points. For this reason time series methods which assume regular sampling cannot be applied directly to the data without a pre-processing step. In this paper we use a random forest to learn the relationship between pairs of data points at different time separations. The input vector is a summary of the time series history and it includes both demographic and non-time varying variables such as genetic data. To test the method we use data from the TADPOLE grand challenge, an initiative which aims to predict the evolution of subjects at risk of Alzheimer's disease using demographic, physical and cognitive input data. The task is to predict diagnosis, ADAS-13 score and normalised ventricles volume. While the competition proceeds, forecasting methods may be compared using a leaderboard dataset selected from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and with standard metrics for measuring accuracy. For diagnosis, we find an mAUC of 0.82, and a classification accuracy of 0.73 compared with a benchmark SVM predictor which gives mAUC = 0.62 and BCA = 0.52. The results show that the method is effective and comparable with other methods.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0211558",
      "citations": "(None,)",
      "readership": 32,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Detecting glaucomatous change in visual fields: Analysis with an optimization framework.",
      "authors": "Yousefi, S; Goldbaum, MH; Varnousfaderani, ES; Belghith, A; Jung, T-P; Medeiros, FA; Zangwill, LM; Weinreb, RN; Liebmann, JM; Girkin, CA; Bowd, C",
      "published_date": "December 2015",
      "doi": "10.1016/j.jbi.2015.09.019",
      "abstract": "Detecting glaucomatous progression is an important aspect of glaucoma management. The assessment of longitudinal series of visual fields, measured using Standard Automated Perimetry (SAP), is considered the reference standard for this effort. We seek efficient techniques for determining progression from longitudinal visual fields by formulating the problem as an optimization framework, learned from a population of glaucoma data. The longitudinal data from each patient's eye were used in a convex optimization framework to find a vector that is representative of the progression direction of the sample population, as a whole. Post-hoc analysis of longitudinal visual fields across the derived vector led to optimal progression (change) detection. The proposed method was compared to recently described progression detection methods and to linear regression of instrument-defined global indices, and showed slightly higher sensitivities at the highest specificities than other methods (a clinically desirable result). The proposed approach is simpler, faster, and more efficient for detecting glaucomatous changes, compared to our previously proposed machine learning-based methods, although it provides somewhat less information. This approach has potential application in glaucoma clinics for patient monitoring and in research centers for classification of study participants.",
      "publication_location": "J Biomed Inform",
      "link": "http://dx.doi.org/10.1016/j.jbi.2015.09.019",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sampling the spatial patterns of cancer: optimized biopsy procedures for estimating prostate cancer volume and Gleason Score.",
      "authors": "Ou, Y; Shen, D; Zeng, J; Sun, L; Moul, J; Davatzikos, C",
      "published_date": "August 2009",
      "doi": "10.1016/j.media.2009.05.002",
      "abstract": "Prostate biopsy is the current gold-standard procedure for prostate cancer diagnosis. Existing prostate biopsy procedures have been mostly focusing on detecting cancer presence. However, they often ignore the potential use of biopsy to estimate cancer volume (CV) and Gleason Score (GS, a cancer grade descriptor), the two surrogate markers for cancer aggressiveness and the two crucial factors for treatment planning. To fill up this vacancy, this paper assumes and demonstrates that, by optimally sampling the spatial patterns of cancer, biopsy procedures can be specifically designed for estimating CV and GS. Our approach combines image analysis and machine learning tools in an atlas-based population study that consists of three steps. First, the spatial distributions of cancer in a patient population are learned, by constructing statistical atlases from histological images of prostate specimens with known cancer ground truths. Then, the optimal biopsy locations are determined in a feature selection formulation, so that biopsy outcomes (either cancer presence or absence) at those locations could be used to differentiate, at the best rate, between the existing specimens having different (high vs. low) CV/GS values. Finally, the optimized biopsy locations are utilized to estimate whether a new-coming prostate cancer patient has high or low CV/GS values, based on a binary classification formulation. The estimation accuracy and the generalization ability are evaluated by the classification rates and the associated receiver-operating-characteristic (ROC) curves in cross validations. The optimized biopsy procedures are also designed to be robust to the almost inevitable needle displacement errors in clinical practice, and are found to be robust to variations in the optimization parameters as well as the training populations.",
      "publication_location": "Med Image Anal",
      "link": "http://dx.doi.org/10.1016/j.media.2009.05.002",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sliding window and regression based cup detection in digital fundus images for glaucoma diagnosis.",
      "authors": "Xu, Y; Xu, D; Lin, S; Liu, J; Cheng, J; Cheung, CY; Aung, T; Wong, TY",
      "published_date": 2011,
      "doi": "10.1007/978-3-642-23626-6_1",
      "abstract": "We propose a machine learning framework based on sliding windows for glaucoma diagnosis. In digital fundus photographs, our method automatically localizes the optic cup, which is the primary structural image cue for clinically identifying glaucoma. This localization uses a bundle of sliding windows of different sizes to obtain cup candidates in each disc image, then extracts from each sliding window a new histogram based feature that is learned using a group sparsity constraint. An epsilon-SVR (support vector regression) model based on non-linear radial basis function (RBF) kernels is used to rank each candidate, and final decisions are made with a non-maximal suppression (NMS) method. Tested on the large ORIGA(-light) clinical dataset, the proposed method achieves a 73.2% overlap ratio with manually-labeled ground-truth and a 0.091 absolute cup-to-disc ratio (CDR) error, a simple yet widely used diagnostic measure. The high accuracy of this framework on images from low-cost and widespread digital fundus cameras indicates much promise for developing practical automated/assisted glaucoma diagnosis systems.",
      "publication_location": "Med Image Comput Comput Assist Interv",
      "link": "http://dx.doi.org/10.1007/978-3-642-23626-6_1",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Experiments with compressively sampled images and a new debluring-denoising algorithm",
      "authors": "Jafarpour, S; Pezeshki, A; Calderbank, R",
      "published_date": "December 1, 2008",
      "doi": "10.1109/ISM.2008.119",
      "abstract": "In this paper we will examine the effect of different parameters in the quality of real compressively sampled images in the compressed sensing framework. We will select a variety of different real images of different types and test the quality of the recovered images, the recovery time, and required resources when different measurement methods with different parameters are used or when different recovering methods are applied. Then we will propose an algorithm to reduce the noise in the recovered images and sharpen them simultaneously. The algorithm exploits a well-known bilateral filtering in order to increase the confidence in margins and edges, and then uses an adaptive unsharp mask method to sharpen the images. The adaptive unsharp mask method extends the ordinary unsharp mask method and uses machine learning square loss minimization and regression in order to learn the optimal unsharping parameters. We will argue why both bilateral filtering and unsharp mask methods should be used in the algorithm simultaneously. Finally, we will show the results of applying the algorithm on real images that are recovered using the compressed sensing method and we will interpret the experimental results. © 2008 IEEE.",
      "publication_location": "Proceedings   10th Ieee International Symposium on Multimedia, Ism 2008",
      "link": "http://dx.doi.org/10.1109/ISM.2008.119",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Belief propagation for min-cost network flow: Convergence and correctness",
      "authors": "",
      "published_date": "March 1, 2012",
      "doi": "10.1287/opre.1110.1025",
      "abstract": "Distributed, iterative algorithms operating with minimal data structure while performing little computation per iteration are popularly known as message passing in the recent literature. Belief propagation (BP), a prototypical message-passing algorithm, has gained a lot of attention across disciplines, including communications, statistics, signal processing, and machine learning as an attractive, scalable, general-purpose heuristic for a wide class of optimization and statistical inference problems. Despite its empirical success, the theoretical understanding of BP is far from complete. With the goal of advancing the state of art of our understanding of BP, we study the performance of BP in the context of the capacitated minimum-cost network flow problem-a cornerstone in the development of the theory of polynomial-time algorithms for optimization problems and widely used in the practice of operations research. As the main result of this paper, we prove that BP converges to the optimal solution in pseudopolynomial time, provided that the optimal solution of the underlying network flow problem instance is unique and the problem parameters are integral. We further provide a simple modification of the BP to obtain a fully polynomial-time randomized approximation scheme (FPRAS) without requiring uniqueness of the optimal solution. This is the first instance where BP is proved to have fully polynomial running time. Our results thus provide a theoretical justification for the viability of BP as an attractive method to solve an important class of optimization problems. © 2012 INFORMS.",
      "publication_location": "Operations Research",
      "link": "http://dx.doi.org/10.1287/opre.1110.1025",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Computer-aided detection of exophytic renal lesions on non-contrast CT images.",
      "authors": "",
      "published_date": "January 2015",
      "doi": "10.1016/j.media.2014.07.005",
      "abstract": "Renal lesions are important extracolonic findings on computed tomographic colonography (CTC). They are difficult to detect on non-contrast CTC images due to low image contrast with surrounding objects. In this paper, we developed a novel computer-aided diagnosis system to detect a subset of renal lesions, exophytic lesions, by (1) exploiting efficient belief propagation to segment kidneys, (2) establishing an intrinsic manifold diffusion on kidney surface, (3) searching for potential lesion-caused protrusions with local maximum diffusion response, and (4) exploring novel shape descriptors, including multi-scale diffusion response, with machine learning to classify exophytic renal lesions. Experimental results on the validation dataset with 167 patients revealed that manifold diffusion significantly outperformed conventional shape features (p<1e-3) and resulted in 95% sensitivity with 15 false positives per patient for detecting exophytic renal lesions. Fivefold cross-validation also demonstrated that our method could stably detect exophytic renal lesions. These encouraging results demonstrated that manifold diffusion is a key means to enable accurate computer-aided diagnosis of renal lesions.",
      "publication_location": "Medical Image Analysis",
      "link": "http://dx.doi.org/10.1016/j.media.2014.07.005",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Gaussian Mixture Models for Stochastic Block Models with Non-Vanishing Noise",
      "authors": "Mathews, H; Mayya, V; Volfovsky, A; Reeves, G",
      "published_date": "December 1, 2019",
      "doi": "10.1109/CAMSAP45676.2019.9022612",
      "abstract": "© 2019 IEEE. Community detection tasks have received a lot of attention across statistics, machine learning, and information theory with work concentrating on providing theoretical guarantees for different methodological approaches to the stochastic block model. Recent work on community detection has focused on modeling the spectral embedding of a network using Gaussian mixture models (GMMs) in scaling regimes where the ability to detect community memberships improves with the size of the network. However, these regimes are not very realistic. This paper provides tractable methodology motivated by new theoretical results for networks with non-vanishing noise. We present a procedure for community detection using novel GMMs that incorporate truncation and shrinkage effects. We provide empirical validation of this new representation as well as experimental results using a large email dataset.",
      "publication_location": "2019 Ieee 8th International Workshop on Computational Advances in Multi Sensor Adaptive Processing, Camsap 2019   Proceedings",
      "link": "http://dx.doi.org/10.1109/CAMSAP45676.2019.9022612",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Finding unprecedentedly low-thermal-conductivity half-heusler semiconductors via high-throughput materials modeling",
      "authors": "",
      "published_date": "January 1, 2014",
      "doi": "10.1103/PhysRevX.4.011019",
      "abstract": "The lattice thermal conductivity (κω) is a key property for many potential applications of compounds. Discovery of materials with very low or high κω remains an experimental challenge due to high costs and time-consuming synthesis procedures. High-throughput computational prescreening is a valuable approach for significantly reducing the set of candidate compounds. In this article, we introduce efficient methods for reliably estimating the bulk κω for a large number of compounds. The algorithms are based on a combination of machine-learning algorithms, physical insights, and automatic ab initio calculations. We scanned approximately 79,000 half-Heusler entries in the AFLOWLIB.org database. Among the 450 mechanically stable ordered semiconductors identified, we find that κω spans more than 2 orders of magnitude-a much larger range than that previously thought. κω is lowest for compounds whose elements in equivalent positions have large atomic radii. We then perform a thorough screening of thermodynamical stability that allows us to reduce the list to 75 systems.We then provide a quantitative estimate of κω for this selected range of systems. Three semiconductors having κω < 5 Wm-1 K-1 are proposed for further experimental study.",
      "publication_location": "Physical Review X",
      "link": "http://dx.doi.org/10.1103/PhysRevX.4.011019",
      "citations": 183,
      "readership": 224,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "K-means clustering for high-resolution, realistic acoustic maps",
      "authors": "",
      "published_date": "January 1, 2018",
      "doi": "10.1117/12.2293990",
      "abstract": "© 2018 SPIE. In this work, we describe a method for converting fat-water-separated magnetic resonance imaging (MRI) volumes to acoustic maps for ultrasound simulations. An acoustic map is a mapping of acoustic imaging parameters such as speed of sound and density to grid points in the ultrasound simulations. Tissues are segmented into five primary classes of tissue in the human abdominal wall (skin, fat, muscle, connective tissue, and non-tissue). This segmentation is achieved using an unsupervised machine learning algorithm, called soft k-means clustering, on a multi-scale feature representation of the MRI volumes. We describe an automated method for utilizing soft k-means weights to produce an acoustic map that achieves approximately 90% agreement with manual segmentation. Two-dimensional (2D) and three-dimensional (3D) nonlinear ultrasound simulations are conducted, demonstrating the utility of realistic 3D maps over previously-available 2D acoustic maps.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2293990",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "GraphSC: Parallel secure computation made easy",
      "authors": "Nayak, K; Wang, XS; Ioannidis, S; Weinsberg, U; Taft, N; Shi, E",
      "published_date": "January 1, 2015",
      "doi": "10.1109/SP.2015.30",
      "abstract": "© 2015 IEEE. We propose introducing modern parallel programming paradigms to secure computation, enabling their secure execution on large datasets. To address this challenge, we present Graph SC, a framework that (i) provides a programming paradigm that allows non-cryptography experts to write secure code, (ii) brings parallelism to such secure implementations, and (iii) meets the need for obliviousness, thereby not leaking any private information. Using Graph SC, developers can efficiently implement an oblivious version of graph-based algorithms (including sophisticated data mining and machine learning algorithms) that execute in parallel with minimal communication overhead. Importantly, our secure version of graph-based algorithms incurs a small logarithmic overhead in comparison with the non-secure parallel version. We build Graph SC and demonstrate, using several algorithms as examples, that secure computation can be brought into the realm of practicality for big data analysis. Our secure matrix factorization implementation can process 1 million ratings in 13 hours, which is a multiple order-of-magnitude improvement over the only other existing attempt, which requires 3 hours to process 16K ratings.",
      "publication_location": "Proceedings   Ieee Symposium on Security and Privacy",
      "link": "http://dx.doi.org/10.1109/SP.2015.30",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Monthly gridded data product of northern wetland methane emissions based on upscaling eddy covariance observations",
      "authors": "",
      "published_date": "January 1, 2019",
      "doi": "10.5194/essd-11-1263-2019",
      "abstract": "© 2019 The Author(s). Natural wetlands constitute the largest and most uncertain source of methane (CH4) to the atmosphere and a large fraction of them are found in the northern latitudes. These emissions are typically estimated using process (\"bottom-up\") or inversion (\"top-down\") models. However, estimates from these two types of models are not independent of each other since the top-down estimates usually rely on the a priori estimation of these emissions obtained with process models. Hence, independent spatially explicit validation data are needed. Here we utilize a random forest (RF) machine-learning technique to upscale CH4 eddy covariance flux measurements from 25 sites to estimate CH4 wetland emissions from the northern latitudes (north of 45° N). Eddy covariance data from 2005 to 2016 are used for model development. The model is then used to predict emissions during 2013 and 2014. The predictive performance of the RF model is evaluated using a leave-one-site-out cross-validation scheme. The performance (Nash-Sutcliffe model efficiency D 0:47) is comparable to previous studies upscaling net ecosystem exchange of carbon dioxide and studies comparing process model output against site-level CH4 emission data. The global distribution of wetlands is one major source of uncertainty for upscaling CH4. Thus, three wetland distribution maps are utilized in the upscaling. Depending on the wetland distribution map, the annual emissions for the northern wetlands yield 32 (22.3-41.2, 95 % confidence interval calculated from a RF model ensemble), 31 (21.4-39.9) or 38 (25.9-49.5) Tg(CH4) yr-1. To further evaluate the uncertainties of the upscaled CH4 flux data products we also compared them against output from two process models (LPX-Bern and WetCHARTs), and methodological issues related to CH4 flux upscaling are discussed. The monthly upscaled CH4 flux data products are available at https://doi.org/10.5281/zenodo.2560163 (Peltola et al., 2019).",
      "publication_location": "Earth System Science Data",
      "link": "http://dx.doi.org/10.5194/essd-11-1263-2019",
      "citations": 6,
      "readership": 25,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Entity resolution: Theory, practice & open challenges",
      "authors": "",
      "published_date": "January 1, 2012",
      "doi": "10.14778/2367502.2367564",
      "abstract": "This tutorial brings together perspectives on ER from a variety of fields, including databases, machine learning, natural language processing and information retrieval, to provide, in one setting, a survey of a large body of work. We discuss both the practical aspects and theoretical underpinnings of ER. We describe existing solutions, current challenges, and open research problems. © 2012 VLDB Endowment.",
      "publication_location": "Proceedings of the Vldb Endowment",
      "link": "http://dx.doi.org/10.14778/2367502.2367564",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Calibrate: Frequency Estimation and Heavy Hitter Identification with Local Differential Privacy via Incorporating Prior Knowledge",
      "authors": "Jia, J; Gong, NZ",
      "published_date": 2019,
      "doi": "",
      "abstract": "Estimating frequencies of certain items among a\npopulation is a basic step in data analytics, which enables more\nadvanced data analytics (e.g., heavy hitter identification, frequent\npattern mining), client software optimization, and detecting\nunwanted or malicious hijacking of user settings in browsers.\nFrequency estimation and heavy hitter identification with local\ndifferential privacy (LDP) protect user privacy as well as the\ndata collector. Existing LDP algorithms cannot leverage 1) prior\nknowledge about the noise in the estimated item frequencies and\n2) prior knowledge about the true item frequencies. As a result,\nthey achieve suboptimal performance in practice.\nIn this work, we aim to design LDP algorithms that can\nleverage such prior knowledge. Specifically, we design Calibrate\nto incorporate the prior knowledge via statistical inference.\nCalibrate can be appended to an existing LDP algorithm to\nreduce its estimation errors. We model the prior knowledge about\nthe noise and the true item frequencies as two probability distributions, respectively. Given the two probability distributions and\nan estimated frequency of an item produced by an existing LDP\nalgorithm, our Calibrate computes the conditional probability\ndistribution of the item’s frequency and uses the mean of the\nconditional probability distribution as the calibrated frequency\nfor the item. It is challenging to estimate the two probability\ndistributions due to data sparsity. We address the challenge via\nintegrating techniques from statistics and machine learning. Our\nempirical results on two real-world datasets show that Calibrate\nsignificantly outperforms state-of-the-art LDP algorithms for\nfrequency estimation and heavy hitter identification.",
      "publication_location": "Ieee International Conference on Computer Communications (Infocom)",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An electroencephalographic signature predicts antidepressant response in major depression.",
      "authors": "",
      "published_date": "April 2020",
      "doi": "10.1038/s41587-019-0397-3",
      "abstract": "Antidepressants are widely prescribed, but their efficacy relative to placebo is modest, in part because the clinical diagnosis of major depression encompasses biologically heterogeneous conditions. Here, we sought to identify a neurobiological signature of response to antidepressant treatment as compared to placebo. We designed a latent-space machine-learning algorithm tailored for resting-state electroencephalography (EEG) and applied it to data from the largest imaging-coupled, placebo-controlled antidepressant study (n = 309). Symptom improvement was robustly predicted in a manner both specific for the antidepressant sertraline (versus placebo) and generalizable across different study sites and EEG equipment. This sertraline-predictive EEG signature generalized to two depression samples, wherein it reflected general antidepressant medication responsivity and related differentially to a repetitive transcranial magnetic stimulation treatment outcome. Furthermore, we found that the sertraline resting-state EEG signature indexed prefrontal neural responsivity, as measured by concurrent transcranial magnetic stimulation and EEG. Our findings advance the neurobiological understanding of antidepressant treatment through an EEG-tailored computational model and provide a clinical avenue for personalized treatment of depression.",
      "publication_location": "Nature Biotechnology",
      "link": "http://dx.doi.org/10.1038/s41587-019-0397-3",
      "citations": 1,
      "readership": "(None,)",
      "tweets": 552,
      "news_mentions": 93
    },
    {
      "title": "Parallel data mining for pharmacophore discovery",
      "authors": "Graham, J; Page, CD; Wild, A",
      "published_date": "January 1, 2000",
      "doi": "10.1109/ICSMC.2000.886389",
      "abstract": "Rapid and effective design of new drugs to combat new strains of antibiotic resistant organisms, more effectively treat chronic conditions, and provide other life sustaining treatment is a key challenge for the medical industry. Current drug design methodologies can take several years just in the initial chemical evaluation stages before compounds can be created for animal and human testing. This paper presents some recent research results in a new parallel machine learning approach that can expedite the drug design cycle. An inductive logic programming search has been reformulated and parallelized to run on an eight node Beowulf cluster. Initial testing with several data sets indicate almost linear speedup using the cluster.",
      "publication_location": "Proceedings of the Ieee International Conference on Systems, Man and Cybernetics",
      "link": "http://dx.doi.org/10.1109/ICSMC.2000.886389",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Information Extraction for Clinical Data Mining: A Mammography Case Study.",
      "authors": "Nassif, H; Woods, R; Burnside, E; Ayvaci, M; Shavlik, J; Page, D",
      "published_date": 2009,
      "doi": "10.1109/icdmw.2009.63",
      "abstract": "Breast cancer is the leading cause of cancer mortality in women between the ages of 15 and 54. During mammography screening, radiologists use a strict lexicon (BI-RADS) to describe and report their findings. Mammography records are then stored in a well-defined database format (NMD). Lately, researchers have applied data mining and machine learning techniques to these databases. They successfully built breast cancer classifiers that can help in early detection of malignancy. However, the validity of these models depends on the quality of the underlying databases. Unfortunately, most databases suffer from inconsistencies, missing data, inter-observer variability and inappropriate term usage. In addition, many databases are not compliant with the NMD format and/or solely consist of text reports. BI-RADS feature extraction from free text and consistency checks between recorded predictive variables and text reports are crucial to addressing this problem. We describe a general scheme for concept information retrieval from free text given a lexicon, and present a BI-RADS features extraction algorithm for clinical data mining. It consists of a syntax analyzer, a concept finder and a negation detector. The syntax analyzer preprocesses the input into individual sentences. The concept finder uses a semantic grammar based on the BI-RADS lexicon and the experts' input. It parses sentences detecting BI-RADS concepts. Once a concept is located, a lexical scanner checks for negation. Our method can handle multiple latent concepts within the text, filtering out ultrasound concepts. On our dataset, our algorithm achieves 97.7% precision, 95.5% recall and an F1-score of 0.97. It outperforms manual feature extraction at the 5% statistical significance level.",
      "publication_location": "Proceedings   Ieee International Conference on Data Mining, Icdm",
      "link": "http://dx.doi.org/10.1109/icdmw.2009.63",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Differential privacy in the wild: A tutorial on current practices & open challenges",
      "authors": "",
      "published_date": "May 9, 2017",
      "doi": "10.1145/3035918.3054779",
      "abstract": "© 2017 ACM. Differential privacy has emerged as an important standard for privacy preserving computation over databases containing sensitive information about individuals. Research on differential privacy spanning a number of research areas, including theory, security, database, networks, machine learning, and statistics, over the last decade has resulted in a variety of privacy preserving algorithms for a number of analysis tasks. Despite maturing research efforts, the adoption of differential privacy by practitioners in industry, academia, or government agencies has so far been rare. Hence, in this tutorial, we will first describe the foundations of differentially private algorithm design that cover the state of the art in private computation on tabular data. In the second half of the tutorial we will highlight real world applications on complex data types, and identify research challenges in applying differential privacy to real world applications.",
      "publication_location": "Proceedings of the Acm Sigmod International Conference on Management of Data",
      "link": "http://dx.doi.org/10.1145/3035918.3054779",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A clinical and proteomics approach to predict the presence of obstructive peripheral arterial disease: From the Catheter Sampled Blood Archive in Cardiovascular Diseases (CASABLANCA) Study.",
      "authors": "",
      "published_date": "July 2018",
      "doi": "10.1002/clc.22939",
      "abstract": "BACKGROUND: Peripheral arterial disease (PAD) is a global health problem that is frequently underdiagnosed and undertreated. Noninvasive tools to predict the presence and severity of PAD have limitations including inaccuracy, cost, or need for intravenous contrast and ionizing radiation. HYPOTHESIS: A clinical/biomarker score may offer an attractive alternative diagnostic method for PAD. METHODS: In a prospective cohort of 354 patients referred for diagnostic peripheral and/or coronary angiography, predictors of ≥50% stenosis in ≥1 peripheral vessel (carotid/subclavian, renal, or lower extremity arteries) were identified from >50 clinical variables and 109 biomarkers. Machine learning identified variables predictive of obstructive PAD; a score derived from the final model was developed. RESULTS: The score consisted of 1 clinical variable (history of hypertension) and 6 biomarkers (midkine, kidney injury molecule-1, interleukin-23, follicle-stimulating hormone, angiopoietin-1, and eotaxin-1). The model had an in-sample area under the receiver operating characteristic curve of 0.85 for obstructive PAD and a cross-validated area under the curve of 0.84; higher scores were associated with greater severity of angiographic stenosis. At optimal cutoff, the score had 65% sensitivity, 88% specificity, 76% positive predictive value (PPV), and 81% negative predictive value (NPV) for obstructive PAD and performed consistently across vascular territories. Partitioning the score into 5 levels resulted in a PPV of 86% and NPV of 98% in the highest and lowest levels, respectively. Elevated score was associated with shorter time to revascularization during 4.3 years of follow-up. CONCLUSIONS: A clinical/biomarker score demonstrates high accuracy for predicting the presence of PAD.",
      "publication_location": "Clinical Cardiology",
      "link": "http://dx.doi.org/10.1002/clc.22939",
      "citations": 1,
      "readership": 18,
      "tweets": 5,
      "news_mentions": 8
    },
    {
      "title": "Graph-based regularization for regression problems with highly-correlated designs",
      "authors": "",
      "published_date": "February 20, 2019",
      "doi": "10.1109/GlobalSIP.2018.8646615",
      "abstract": "© 2018 IEEE. Sparse models for high-dimensional linear regression and machine learning have received substantial attention over the past two decades. Much of the current literature assumes that covariates are only mildly correlated, however, in modern applications ranging from functional MRI to genome-wide association studies, covariates are highly correlated. We consider a high-dimensional regression setting in which a graph governs both correlations among the covariates and the similarity among regression coefficients. This graph is used to define a graph total variation regularizer that promotes similar weights for highly correlated features. Our proposed graph-based regularization yields mean-squared error guarantees for a broad range of covariance graph structures by imposing additional structure on the parameter which encourages alignment with the covariance graph.",
      "publication_location": "2018 Ieee Global Conference on Signal and Information Processing, Globalsip 2018   Proceedings",
      "link": "http://dx.doi.org/10.1109/GlobalSIP.2018.8646615",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "DIADS: A problem diagnosis tool for databases and storage area networks",
      "authors": "",
      "published_date": "January 1, 2009",
      "doi": "10.14778/1687553.1687587",
      "abstract": "Many enterprise environments have databases running on network-attached storage infrastructure (referred toas Storage Area Networks or SANs). Both the database and the SAN are complex subsystems that are managed by separate teams of administrators. As often as not, database administrators have limited understanding of SAN conguration and behavior, and limited visibility into the SAN's run-timeperformance; and vice versa for the SAN administrators. Diagnosing the cause of performance problems is a challenging exercise in these environments. We propose to remedy thesituation through a novel tool, called Diads, for database and SAN problem diagnosis. This demonstration proposal summarizes the technical innovations in Diads: (i) a powerful abstraction called Annotated Plan Graphs (APGs) that ties together the execution path of queries in the database and the SAN using low-overhead monitoring data, and (ii) a diagnosis workflow that combines domain-specific knowledge with machine-learning techniques. The scenarios presented in the demonstration are also described. © 2009 VLDB Endowment.",
      "publication_location": "Proceedings of the Vldb Endowment",
      "link": "http://dx.doi.org/10.14778/1687553.1687587",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Quantitative phase microscopy spatial signatures of cancer cells.",
      "authors": "Roitshtain, D; Wolbromsky, L; Bal, E; Greenspan, H; Satterwhite, LL; Shaked, NT",
      "published_date": "May 2017",
      "doi": "10.1002/cyto.a.23100",
      "abstract": "We present cytometric classification of live healthy and cancerous cells by using the spatial morphological and textural information found in the label-free quantitative phase images of the cells. We compare both healthy cells to primary tumor cells and primary tumor cells to metastatic cancer cells, where tumor biopsies and normal tissues were isolated from the same individuals. To mimic analysis of liquid biopsies by flow cytometry, the cells were imaged while unattached to the substrate. We used low-coherence off-axis interferometric phase microscopy setup, which allows a single-exposure acquisition mode, and thus is suitable for quantitative imaging of dynamic cells during flow. After acquisition, the optical path delay maps of the cells were extracted and then used to calculate 15 parameters derived from the cellular 3D morphology and texture. Upon analyzing tens of cells in each group, we found high statistical significance in the difference between the groups in most of the parameters calculated, with the same trends for all statistically significant parameters. Furthermore, a specially designed machine learning algorithm, implemented on the phase map extracted features, classified the correct cell type (healthy/cancer/metastatic) with 81-93% sensitivity and 81-99% specificity. The quantitative phase imaging approach for liquid biopsies presented in this paper could be the basis for advanced techniques of staging freshly isolated live cancer cells in imaging flow cytometers. © 2017 International Society for Advancement of Cytometry.",
      "publication_location": "Cytometry. Part a : the Journal of the International Society for Analytical Cytology",
      "link": "http://dx.doi.org/10.1002/cyto.a.23100",
      "citations": 33,
      "readership": 47,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Stabilizing the unstable output of persistent homology computations",
      "authors": "Bendich, P; Bubenik, P; Wagner, A",
      "published_date": "November 9, 2019",
      "doi": "",
      "abstract": "We propose a general technique for extracting a larger set of stable\ninformation from persistent homology computations than is currently done. The\npersistent homology algorithm is usually viewed as a procedure which starts\nwith a filtered complex and ends with a persistence diagram. This procedure is\nstable (at least to certain types of perturbations of the input). This\njustifies the use of the diagram as a signature of the input, and the use of\nfeatures derived from it in statistics and machine learning. However, these\ncomputations also produce other information of great interest to practitioners\nthat is unfortunately unstable. For example, each point in the diagram\ncorresponds to a simplex whose addition in the filtration results in the birth\nof the corresponding persistent homology class, but this correspondence is\nunstable. In addition, the persistence diagram is not stable with respect to\nother procedures that are employed in practice, such as thresholding a point\ncloud by density. We recast these problems as real-valued functions which are\ndiscontinuous but measurable, and then observe that convolving such a function\nwith a suitable function produces a Lipschitz function. The resulting stable\nfunction can be estimated by perturbing the input and averaging the output. We\nillustrate this approach with a number of examples, including a stable\nlocalization of a persistent homology generator from brain imaging data.",
      "publication_location": "SPRINGER",
      "link": "https://link.springer.com/article/10.1007/s41468-019-00044-9",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Architecting a stochastic computing unit with molecular optical devices",
      "authors": "Zhang, X; Bashizade, R; LaBoda, C; Dwyer, C; Lebeck, AR",
      "published_date": "July 19, 2018",
      "doi": "10.1109/ISCA.2018.00034",
      "abstract": "© 2018 IEEE. The increasing difficulty in leveraging CMOS scaling for improved performance requires exploring alternative technologies. A promising technique is to exploit the physical properties of devices to specialize certain computations. A recently proposed approach uses molecular-scale optical devices to construct a Resonance Energy based Sampling Unit (RSU) to accelerate sampling from parameterized probability distributions. Sampling is an important component of many algorithms, including statistical Machine learning. This paper explores the relationship between application result quality and RSU design. The previously proposed RSU-G focuses on Gibbs sampling using Markov Chain Monte Carlo (MCMC) solvers for Markov Random Field (MRF) Bayesian Inference. By quantitatively analyzing the result quality across three computer vision applications, we find that the previously proposed RSU-G lacks both sufficient precision and dynamic range in key design parameters, which limits the overall result quality compared to software-only MCMC implementations. Naively scaling the problematic parameters to increase precision and dynamic range consumes too much area and power. Therefore, we introduce a new RSU-G microarchitecture that exploits an alternative approach to increase precision that incurs 1.27× power and equivalent area, while maintaining the significant speedups of the previous design and supporting a wider set of applications.",
      "publication_location": "Proceedings   International Symposium on Computer Architecture",
      "link": "http://dx.doi.org/10.1109/ISCA.2018.00034",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Identifying determinants of persistent MRSA bacteremia using mathematical modeling.",
      "authors": "Mikkaichi, T; Yeaman, MR; Hoffmann, A; MRSA Systems Immunobiology Group,",
      "published_date": "July 2019",
      "doi": "10.1371/journal.pcbi.1007087",
      "abstract": "Persistent bacteremia caused by Staphylococcus aureus (SA), especially methicillin-resistant SA (MRSA), is a significant cause of morbidity and mortality. Despite susceptibility phenotypes in vitro, persistent MRSA strains fail to clear with appropriate anti-MRSA therapy during bacteremia in vivo. Thus, identifying the factors that cause such MRSA persistence is of direct and urgent clinical relevance. To address the dynamics of MRSA persistence in the face of host immunity and typical antibiotic regimens, we developed a mathematical model based on the overarching assumption that phenotypic heterogeneity is a hallmark of MRSA persistence. First, we applied an ensemble modeling approach and obtained parameter sets that satisfied the condition of a minimum inoculum dose to establish infection. Second, by simulating with the selected parameter sets under vancomycin therapy which follows clinical practices, we distinguished the models resulting in resolving or persistent bacteremia, based on the total SA exceeding a detection limit after five days of treatment. Third, to find key determinants that discriminate resolving and persistent bacteremia, we applied a machine learning approach and found that the immune clearance rate of persister cells is a key feature. But, fourth, when relapsing bacteremia was considered, the growth rate of persister cells was also found to be a key feature. Finally, we explored pharmacological strategies for persistent and relapsing bacteremia and found that a persister killer, but not a persister formation inhibitor, could provide for an effective cure the persistent bacteremia. Thus, to develop better clinical solutions for MRSA persistence and relapse, our modeling results indicate that we need to better understand the pathogen-host interactions of persister MRSAs in vivo.",
      "publication_location": "Plos Computational Biology",
      "link": "http://dx.doi.org/10.1371/journal.pcbi.1007087",
      "citations": 1,
      "readership": 16,
      "tweets": 3,
      "news_mentions": 4
    },
    {
      "title": "Large-scale mapping and validation of Escherichia coli transcriptional regulation from a compendium of expression profiles.",
      "authors": "Faith, JJ; Hayete, B; Thaden, JT; Mogno, I; Wierzbowski, J; Cottarel, G; Kasif, S; Collins, JJ; Gardner, TS",
      "published_date": "January 1, 2007",
      "doi": "10.1371/journal.pbio.0050008",
      "abstract": "Machine learning approaches offer the potential to systematically identify transcriptional regulatory interactions from a compendium of microarray expression profiles. However, experimental validation of the performance of these methods at the genome scale has remained elusive. Here we assess the global performance of four existing classes of inference algorithms using 445 Escherichia coli Affymetrix arrays and 3,216 known E. coli regulatory interactions from RegulonDB. We also developed and applied the context likelihood of relatedness (CLR) algorithm, a novel extension of the relevance networks class of algorithms. CLR demonstrates an average precision gain of 36% relative to the next-best performing algorithm. At a 60% true positive rate, CLR identifies 1,079 regulatory interactions, of which 338 were in the previously known network and 741 were novel predictions. We tested the predicted interactions for three transcription factors with chromatin immunoprecipitation, confirming 21 novel interactions and verifying our RegulonDB-based performance estimates. CLR also identified a regulatory link providing central metabolic control of iron transport, which we confirmed with real-time quantitative PCR. The compendium of expression data compiled in this study, coupled with RegulonDB, provides a valuable model system for further improvement of network inference algorithms using experimental data.",
      "publication_location": "Plos Biology",
      "link": "http://dx.doi.org/10.1371/journal.pbio.0050008",
      "citations": 1017,
      "readership": 867,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "POLARIS: A 30-meter probabilistic soil series map of the contiguous United States",
      "authors": "Chaney, NW; Wood, EF; McBratney, AB; Hempel, JW; Nauman, TW; Brungard, CW; Odgers, NP",
      "published_date": "July 15, 2016",
      "doi": "10.1016/j.geoderma.2016.03.025",
      "abstract": "© 2016 Elsevier B.V. A new complete map of soil series probabilities has been produced for the contiguous United States at a 30 m spatial resolution. This innovative database, named POLARIS, is constructed using available high-resolution geospatial environmental data and a state-of-the-art machine learning algorithm (DSMART-HPC) to remap the Soil Survey Geographic (SSURGO) database. This 9 billion grid cell database is possible using available high performance computing resources. POLARIS provides a spatially continuous, internally consistent, quantitative prediction of soil series. It offers potential solutions to the primary weaknesses in SSURGO: 1) unmapped areas are gap-filled using survey data from the surrounding regions, 2) the artificial discontinuities at political boundaries are removed, and 3) the use of high resolution environmental covariate data leads to a spatial disaggregation of the coarse polygons. The geospatial environmental covariates that have the largest role in assembling POLARIS over the contiguous United States (CONUS) are fine-scale (30 m) elevation data and coarse-scale (~. 2 km) estimates of the geographic distribution of uranium, thorium, and potassium. A preliminary validation of POLARIS using the NRCS National Soil Information System (NASIS) database shows variable performance over CONUS. In general, the best performance is obtained at grid cells where DSMART-HPC is most able to reduce the chance of misclassification. The important role of environmental covariates in limiting prediction uncertainty suggests including additional covariates is pivotal to improving POLARIS' accuracy. This database has the potential to improve the modeling of biogeochemical, water, and energy cycles in environmental models; enhance availability of data for precision agriculture; and assist hydrologic monitoring and forecasting to ensure food and water security.",
      "publication_location": "Geoderma",
      "link": "http://dx.doi.org/10.1016/j.geoderma.2016.03.025",
      "citations": 69,
      "readership": 156,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Algorithmic handwriting analysis of Judah's military correspondence sheds light on composition of biblical texts.",
      "authors": "Faigenbaum-Golovin, S; Shaus, A; Sober, B; Levin, D; Na'aman, N; Sass, B; Turkel, E; Piasetzky, E; Finkelstein, I",
      "published_date": "April 11, 2016",
      "doi": "10.1073/pnas.1522200113",
      "abstract": "The relationship between the expansion of literacy in Judah and composition of biblical texts has attracted scholarly attention for over a century. Information on this issue can be deduced from Hebrew inscriptions from the final phase of the first Temple period. We report our investigation of 16 inscriptions from the Judahite desert fortress of Arad, dated ca 600 BCE-the eve of Nebuchadnezzar's destruction of Jerusalem. The inquiry is based on new methods for image processing and document analysis, as well as machine learning algorithms. These techniques enable identification of the minimal number of authors in a given group of inscriptions. Our algorithmic analysis, complemented by the textual information, reveals a minimum of six authors within the examined inscriptions. The results indicate that in this remote fort literacy had spread throughout the military hierarchy, down to the quartermaster and probably even below that rank. This implies that an educational infrastructure that could support the composition of literary texts in Judah already existed before the destruction of the first Temple. A similar level of literacy in this area is attested again only 400 y later, ca 200 BCE.",
      "publication_location": "Proceedings of the National Academy of Sciences of the United States of America",
      "link": "http://dx.doi.org/10.1073/pnas.1522200113",
      "citations": 37,
      "readership": 27,
      "tweets": 79,
      "news_mentions": 117
    },
    {
      "title": "Computerized paleographic investigation of hebrew iron age Ostraca",
      "authors": "Faigenbaum-Golovin, S; Shaus, A; Sober, B; Finkelstein, I; Levin, D; Moinester, M; Piasetzky, E; Turkel, E",
      "published_date": "January 1, 2015",
      "doi": "10.2458/azu_rc.57.18565",
      "abstract": "© 2015 by the Arizona Board of Regents on behalf of the University of Arizona. This article surveys ongoing research of the Legibility Enhancement of Ostraca (LEO) team of Tel Aviv University in the field of computerized paleography of Hebrew Iron Age ink-written ostraca. We perform paleographic tasks using tools from the fields of image processing and machine learning. Several new techniques serving this aim, as well as an adaptation of existing ones, are described herein. This includes testing a range of signal-acquisition methodologies, out of which multispectral imaging and Raman spectroscopy have matured into imaging systems. In addition, we deal with semi- or fully automated facsimile construction and refinement, facsimile, and character evaluation, as well as the reconstruction of broken character strokes. We conclude with future research directions, addressing some of the long-standing epigraphic questions, such as the number of scribes in specific corpora or detection of chronological concurrences and inconsistencies.",
      "publication_location": "Radiocarbon",
      "link": "http://dx.doi.org/10.2458/azu_rc.57.18565",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Design-Space Exploration and Optimization of an Energy-Efficient and Reliable 3-D Small-World Network-on-Chip",
      "authors": "Das, S; Doppa, JR; Pande, PP; Chakrabarty, K",
      "published_date": "May 1, 2017",
      "doi": "10.1109/TCAD.2016.2604288",
      "abstract": "© 1982-2012 IEEE. A 3-D network-on-chip (NoC) enables the design of high performance and low power many-core chips. Existing 3-D NoCs are inadequate for meeting the ever-increasing performance requirements of many-core processors since they are simple extensions of regular 2-D architectures and they do not fully exploit the advantages provided by 3-D integration. Moreover, the anticipated performance gain of a 3-D NoC-enabled many-core chip may be compromised due to the potential failures of through-silicon-vias that are predominantly used as vertical interconnects in a 3-D IC. To address these problems, we propose a machine-learning-inspired predictive design methodology for energy-efficient and reliable many-core architectures enabled by 3-D integration. We demonstrate that a small-world network-based 3-D NoC (3-D SWNoC) performs significantly better than its 3-D MESH-based counterparts. On average, the 3-D SWNoC shows 35% energy-delay-product improvement over 3-D MESH for the PARSEC and SPLASH2 benchmarks considered in this paper. To improve the reliability of 3-D NoC, we propose a computationally efficient spare-vertical link (sVL) allocation algorithm based on a state-space search formulation. Our results show that the proposed sVL allocation algorithm can significantly improve the reliability as well as the lifetime of 3-D SWNoC.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2016.2604288",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Representative critical-path selection for aging-induced delay monitoring",
      "authors": "Firouzi, F; Ye, F; Chakrabarty, K; Tahoori, MB",
      "published_date": "December 1, 2013",
      "doi": "10.1109/TEST.2013.6651924",
      "abstract": "Transistor aging degrades path delay over time and may eventually induce circuit failure due to timing variations. Therefore, in-field tracking of path delays is essential and to respond to this need, several delay sensor designs have been proposed in the literature. However, due to the significant overhead of these designs and the large number of critical paths in today's IC, it is infeasible to monitor the delay of every critical path in silicon. We present an aging-aware representative path-selection method that allows us to measure the delay of a small set of paths and infer the delay of a larger pool of paths that are likely to fail due to transistor aging. Moreover, since aging is affected by process variations and runtime variations in temperature and voltage, we use machine learning and linear algebra to incorporate these variations during representative path selection. Simulation results for benchmark circuits highlight the accuracy of the proposed approach for predicting critical path delay based on the selected representative paths. © 2013 IEEE.",
      "publication_location": "Proceedings   International Test Conference",
      "link": "http://dx.doi.org/10.1109/TEST.2013.6651924",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Fine-Grained Aging-Induced Delay Prediction Based on the Monitoring of Run-Time Stress",
      "authors": "Vijayan, A; Koneru, A; Kiamehr, S; Chakrabarty, K; Tahoori, MB",
      "published_date": "May 1, 2018",
      "doi": "10.1109/TCAD.2016.2620903",
      "abstract": "© 1982-2012 IEEE. Run-time solutions based on online monitoring and adaptation are required for resilience in nanoscale integrated circuits, as design-time solutions and guard bands are no longer sufficient. Bias temperature instability-induced transistor aging, one of the major reliability threats in nanoscale very large scale integration, degrades path delay over time and may lead to timing failures. Chip health monitoring is, therefore, necessary to track delay changes on a per-chip basis over the chip lifetime operation. However, direct monitoring based on actual measurement of path delays can only track a coarse-grained aging trend in a reactive manner, not suitable for proactive fine-grain adaptations. In this paper, we propose a low cost and fine-grained workload-induced stress monitoring approach, based on machine learning techniques, to accurately predict aging-induced delay. We integrate space and time sampling of selective flip-flops into the runtime monitoring infrastructure in order to reduce the cost of monitoring the workload. The prediction model is trained offline using support-vector regression and implemented in software. This approach can leverage proactive adaptation techniques to mitigate further aging of the circuit by monitoring aging trends. Simulation results for realistic open-source benchmark circuits highlight the accuracy of the proposed approach.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2016.2620903",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Activity classification at a higher level: What to do after the classifier does its best?",
      "authors": "Younes, R; Martin, TL; Jones, M",
      "published_date": "September 7, 2015",
      "doi": "10.1145/2802083.2808405",
      "abstract": "© Copyright 2015 ACM. Research in activity classification has focused on the sensors, the classification techniques and the machine learning algorithms used in the classifier. In this work, we study a higher level of activity classification. We present two methods that can take the final observations of a classifier and improve them. The first method uses hidden Markov models to define a probabilistic model that can be used to improve classification accuracy. The second method is a novel method that we developed that uses probabilistic models along with matching costs in order to improve accuracy. Testing showed that both proposed methods presented a significant increase in classification accuracy rates, while also proving that they can both run in real time.",
      "publication_location": "Iswc 2015   Proceedings of the 2015 Acm International Symposium on Wearable Computers",
      "link": "http://dx.doi.org/10.1145/2802083.2808405",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sensor-Array optimization based on mutual information for sanitation-related malodor alerts",
      "authors": "Zhou, J; Welling, CM; Kawadiya, S; Deshusses, MA; Grego, S; Chakrabarty, K",
      "published_date": "October 1, 2019",
      "doi": "10.1109/BIOCAS.2019.8919132",
      "abstract": "© 2019 IEEE. There is an unmet need for a low-cost instrumented technology for detecting malodor around toilets and emerging sanitation technologies for onsite waste treatment. Our approach to an electronic nose for sanitation-related malodor is based on the use of electrochemical gas sensors, and machine learning techniques are utilized to optimize the sensor array and for odor classification. We screened 12 sensors for different vendors and target gases and recorded response to odorants from fecal specimen and from confounding good odors such as popcorn. The analysis by two feature selection methods based on mutual information indicates that the feature dimensionality can be reduced to five features extracted from only three sensors. A logistic regression classifier with five features achieved 74.8% accuracy and 84.2% F1 score in odor classification. These early results are promising, and they can potentially enable the optimized design of an integrated e-nose system for alerting malodor, and which can be utilized in public toilets and onsite waste treatment systems.",
      "publication_location": "Biocas 2019   Biomedical Circuits and Systems Conference, Proceedings",
      "link": "http://dx.doi.org/10.1109/BIOCAS.2019.8919132",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Roughness of microarchitectural design topologies and its implications for optimization",
      "authors": "Lee, BC; Brooks, D",
      "published_date": "December 24, 2008",
      "doi": "10.1109/HPCA.2008.4658643",
      "abstract": "Recent advances in statistical inference and machine learning close the divide between simulation and classical optimization, thereby enabling more rigorous and robust microarchitectural studies. To most effectively utilize these now computationally tractable techniques, we characterize design topology roughness and leverage this characterization to guide our usage of analysis and optimization methods. In particular, we compute roughness metrics that require high-order derivatives and multi-dimensional integrals of design metrics, such as performance and power. These roughness metrics exhibit noteworthy correlations (1) against regression model error, (2) against non-linearities and non-monotonicities of contour maps, and (3) against the effectiveness of optimization heuristics such as gradient ascent. Thus, this work quantifies the implications of design topology roughness for commonly used methods and practices in microarchitectural analysis. ©2008 IEEE.",
      "publication_location": "Proceedings   International Symposium on High Performance Computer Architecture",
      "link": "http://dx.doi.org/10.1109/HPCA.2008.4658643",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Moving Away From Error-Related Potentials to Achieve Spelling Correction in P300 Spellers.",
      "authors": "Mainsah, BO; Morton, KD; Collins, LM; Sellers, EW; Throckmorton, CS",
      "published_date": "September 2015",
      "doi": "10.1109/TNSRE.2014.2374471",
      "abstract": "P300 spellers can provide a means of communication for individuals with severe neuromuscular limitations. However, its use as an effective communication tool is reliant on high P300 classification accuracies ( > 70%) to account for error revisions. Error-related potentials (ErrP), which are changes in EEG potentials when a person is aware of or perceives erroneous behavior or feedback, have been proposed as inputs to drive corrective mechanisms that veto erroneous actions by BCI systems. The goal of this study is to demonstrate that training an additional ErrP classifier for a P300 speller is not necessary, as we hypothesize that error information is encoded in the P300 classifier responses used for character selection. We perform offline simulations of P300 spelling to compare ErrP and non-ErrP based corrective algorithms. A simple dictionary correction based on string matching and word frequency significantly improved accuracy (35-185%), in contrast to an ErrP-based method that flagged, deleted and replaced erroneous characters (-47-0%) . Providing additional information about the likelihood of characters to a dictionary-based correction further improves accuracy. Our Bayesian dictionary-based correction algorithm that utilizes P300 classifier confidences performed comparably (44-416%) to an oracle ErrP dictionary-based method that assumed perfect ErrP classification (43-433%).",
      "publication_location": "Ieee Transactions on Neural Systems and Rehabilitation Engineering : a Publication of the Ieee Engineering in Medicine and Biology Society",
      "link": "http://dx.doi.org/10.1109/TNSRE.2014.2374471",
      "citations": 7,
      "readership": 35,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "How do we choose the best model? The impact of cross-validation design on model evaluation for buried threat detection in ground penetrating radar",
      "authors": "Malof, JM; Reichman, D; Collins, LM",
      "published_date": "January 1, 2018",
      "doi": "10.1117/12.2305793",
      "abstract": "© 2018 SPIE. A great deal of research has been focused on the development of computer algorithms for buried threat detection (BTD) in ground penetrating radar (GPR) data. Most recently proposed BTD algorithms are supervised, and therefore they employ machine learning models that infer their parameters using training data. Cross-validation (CV) is a popular method for evaluating the performance of such algorithms, in which the available data is systematically split into N disjoint subsets, and an algorithm is repeatedly trained on N-1 subsets and tested on the excluded subset. There are several common types of CV in BTD, which vary principally upon the spatial criterion used to partition the data: site-based, lane-based, region-based, etc. The performance metrics obtained via CV are often used to suggest the superiority of one model over others, however, most studies utilize just one type of CV, and the impact of this choice is unclear. Here we employ several types of CV to evaluate algorithms from a recent large-scale BTD study. The results indicate that the rank-order of the performance of the algorithms varies substantially depending upon which type of CV is used. For example, the rank-1 algorithm for region-based CV is the lowest ranked algorithm for site-based CV. This suggests that any algorithm results should be interpreted carefully with respect to the type of CV employed. We discuss some potential interpretations of performance, given a particular type of CV.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2305793",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Constructing Bayesian networks for criminal profiling from limited data",
      "authors": "Baumgartner, K; Ferrari, S; Palermo, G",
      "published_date": "October 1, 2008",
      "doi": "10.1016/j.knosys.2008.03.019",
      "abstract": "The increased availability of information technologies has enabled law enforcement agencies to compile databases with detailed information about major felonies. Machine learning techniques can utilize these databases to produce decision-aid tools to support police investigations. This paper presents a methodology for obtaining a Bayesian network (BN) model of offender behavior from a database of cleared homicides. The BN can infer the characteristics of an unknown offender from the crime scene evidence, and help narrow the list of suspects in an unsolved homicide. Our research shows that 80% of offender characteristics are predicted correctly on average in new single-victim homicides, and when confidence levels are taken into account this accuracy increases to 95.6%. © 2008 Elsevier B.V. All rights reserved.",
      "publication_location": "Knowledge Based Systems",
      "link": "http://dx.doi.org/10.1016/j.knosys.2008.03.019",
      "citations": 48,
      "readership": 110,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "TU-C-17A-11: Progressive Knowledge Modeling for Pelvic IMRT/VMAT Treatment Planning.",
      "authors": "Lu, S; Yuan, L; Craciunescu, O; Ge, Y; Yin, F; Wu, Q",
      "published_date": "June 2014",
      "doi": "10.1118/1.4889286",
      "abstract": "PURPOSE: To investigate the feasibility of progressive knowledge modeling for IMRT/VMAT treatment planning for multiple cancer types in the pelvic region. METHODS: The treatment planning knowledge model quantifies correlations between patient anatomical features and the OAR dose sparing features. The model is trained with prior plans using a stepwise regression machine learning technique. The progressive modeling process starts with 20 low risk prostate plans (type 1) which offer simplest PTV-OAR geometry. Cases with more complex PTV-OAR anatomies (prostate with lymph node, type 2 and anal rectal, type 3) are added to the training dataset one by one until the model prediction accuracies reach a plateau. The starting point of the plateau also defines the minimum numbers of type 2 and 3 training cases required for modelling. The DVHs predicted by the knowledge model for bladder, femoral heads and rectum were validated by 20, 9 and 18 cases with type 1, 2, and 3 geometries, respectively (rectum DVHs are omitted for type 3). Mean and standard deviation of differences between the dosimetric parameters sampled from the DVHs and the corresponding actual plan values measure the prediction accuracy of the model. Further, the accuracy was also compared with the single-type models which were trained by single type cases. RESULTS: Prediction accuracy reaches plateau when 6 type 2 and 8 type 3 cases were added to the training dataset. The determination coefficients R2 (should be square, font) for the OARs are: Bladder 0.90, rectum 0.64, and femoral heads 0.82. The prediction accuracies by the multiple-type model and single-type model have no significant differences by F-test (p-value: bladder: 0.58, femoral head: 0.44, rectum: 0.97). CONCLUSION: Progressive knowledge modeling of OAR sparing for multiple cancer types in pelvic region is feasible and has comparable accuracy to single cancer type modeling. Partially supported by NIH/NCI under grant #R21CA161389 and a master research grant by Varian Medical System.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.4889286",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Personalized prediction of tumor response and cancer progression on prostate needle biopsy.",
      "authors": "Donovan, MJ; Khan, FM; Fernandez, G; Mesa-Tejada, R; Sapir, M; Zubek, VB; Powell, D; Fogarasi, S; Vengrenyuk, Y; Teverovskiy, M; Segal, MR; Karnes, RJ; Gaffey, TA; Busch, C; Haggman, M; Hlavcak, P; Freedland, SJ; Vollmer, RT; Albertsen, P; Costa, J; Cordon-Cardo, C",
      "published_date": "July 2009",
      "doi": "10.1016/j.juro.2009.02.135",
      "abstract": "PURPOSE: To our knowledge in patients with prostate cancer there are no available tests except clinical variables to determine the likelihood of disease progression. We developed a patient specific, biology driven tool to predict outcome at diagnosis. We also investigated whether biopsy androgen receptor levels predict a durable response to therapy after secondary treatment. MATERIALS AND METHODS: We evaluated paraffin embedded prostate needle biopsy tissue from 1,027 patients with cT1c-T3 prostate cancer treated with surgery and followed a median of 8 years. Machine learning was done to integrate clinical data with biopsy quantitative biometric features. Multivariate models were constructed to predict disease progression with the C index to estimate performance. RESULTS: In a training set of 686 patients (total of 87 progression events) 3 clinical and 3 biopsy tissue characteristics were identified to predict clinical progression within 8 years after prostatectomy with 78% sensitivity, 69% specificity, a C index of 0.74 and a HR of 5.12. Validation in an independent cohort of 341 patients (total of 44 progression events) yielded 76% sensitivity, 64% specificity, a C index of 0.73 and a HR of 3.47. Increased androgen receptor in tumor cells in the biopsy highly significantly predicted resistance to therapy, ie androgen ablation with or without salvage radiotherapy, and clinical failure (p <0.0001). CONCLUSIONS: Morphometry reliably classifies Gleason pattern 3 tumors. When combined with biomarker data, it adds to the hematoxylin and eosin analysis, and prostate specific antigen values currently used to assess outcome at diagnosis. Biopsy androgen receptor levels predict the likelihood of a response to therapy after recurrence and may guide future treatment decisions.",
      "publication_location": "The Journal of Urology",
      "link": "http://dx.doi.org/10.1016/j.juro.2009.02.135",
      "citations": 43,
      "readership": 50,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Infobuttons and classification models: a method for the automatic selection of on-line information resources to fulfill clinicians' information needs.",
      "authors": "Del Fiol, G; Haug, PJ",
      "published_date": "August 2008",
      "doi": "10.1016/j.jbi.2007.11.007",
      "abstract": "OBJECTIVE: Infobuttons are decision support tools that offer links to information resources based on the context of the interaction between a clinician and an electronic medical record (EMR) system. The objective of this study was to explore machine learning and web usage mining methods to produce classification models for the prediction of information resources that might be relevant in a particular infobutton context. DESIGN: Classification models were developed and evaluated with an infobutton usage dataset. The performance of the models was measured and compared with a reference implementation in a series of experiments. MEASUREMENTS: Level of agreement (kappa) between the models and the resources that clinicians actually used in each infobutton session. RESULTS: The classification models performed significantly better than the reference implementation (p<.0001). The performance of these models tended to decrease over time, probably due to a phenomenon known as concept drift. However, the performance of the models remained stable when concept drift handling techniques were used. CONCLUSIONS: The results suggest that classification models are a promising method for the prediction of information resources that a clinician would use to answer patient care questions.",
      "publication_location": "J Biomed Inform",
      "link": "http://dx.doi.org/10.1016/j.jbi.2007.11.007",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Classification models for the prediction of clinicians' information needs.",
      "authors": "Del Fiol, G; Haug, PJ",
      "published_date": "February 2009",
      "doi": "10.1016/j.jbi.2008.07.001",
      "abstract": "OBJECTIVE: Clinicians face numerous information needs during patient care activities and most of these needs are not met. Infobuttons are information retrieval tools that help clinicians to fulfill their information needs by providing links to on-line health information resources from within an electronic medical record (EMR) system. The aim of this study was to produce classification models based on medication infobutton usage data to predict the medication-related content topics (e.g., dose, adverse effects, drug interactions, patient education) that a clinician is most likely to choose while entering medication orders in a particular clinical context. DESIGN: We prepared a dataset with 3078 infobutton sessions and 26 attributes describing characteristics of the user, the medication, and the patient. In these sessions, users selected one out of eight content topics. Automatic attribute selection methods were then applied to the dataset to eliminate redundant and useless attributes. The reduced dataset was used to produce nine classification models from a set of state-of-the-art machine learning algorithms. Finally, the performance of the models was measured and compared. MEASUREMENTS: Area under the ROC curve (AUC) and agreement (kappa) between the content topics predicted by the models and those chosen by clinicians in each infobutton session. RESULTS: The performance of the models ranged from 0.49 to 0.56 (kappa). The AUC of the best model ranged from 0.73 to 0.99. The best performance was achieved when predicting choice of the adult dose, pediatric dose, patient education, and pregnancy category content topics. CONCLUSION: The results suggest that classification models based on infobutton usage data are a promising method for the prediction of content topics that a clinician would choose to answer patient care questions while using an EMR system.",
      "publication_location": "J Biomed Inform",
      "link": "http://dx.doi.org/10.1016/j.jbi.2008.07.001",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Performance of a Genomic Sequencing Classifier for the Preoperative Diagnosis of Cytologically Indeterminate Thyroid Nodules.",
      "authors": "",
      "published_date": "September 2018",
      "doi": "10.1001/jamasurg.2018.1153",
      "abstract": "Importance:Use of next-generation sequencing of RNA and machine learning algorithms can classify the risk of malignancy in cytologically indeterminate thyroid nodules to limit unnecessary diagnostic surgery. Objective:To measure the performance of a genomic sequencing classifier for cytologically indeterminate thyroid nodules. Design, Setting, and Participants:A blinded validation study was conducted on a set of cytologically indeterminate thyroid nodules collected by fine-needle aspiration biopsy between June 2009 and December 2010 from 49 academic and community centers in the United States. All patients underwent surgery without genomic information and were assigned a histopathology diagnosis by an expert panel blinded to all genomic information. There were 210 potentially eligible thyroid biopsy samples with Bethesda III or IV indeterminate cytopathology that constituted a cohort previously used to validate the gene expression classifier. Of these, 191 samples (91.0%) had adequate residual RNA for validation of the genomic sequencing classifier. Algorithm development and independent validation occurred between August 2016 and May 2017. Exposures:Thyroid nodule surgical histopathology diagnosis by an expert panel blinded to all genomic data. Main Outcomes and Measures:The primary end point was measurement of genomic sequencing classifier sensitivity, specificity, and negative and positive predictive values in biopsies from Bethesda III and IV nodules. The secondary end point was measurement of classifier performance in biopsies from Bethesda II, V, and VI nodules. Results:Of the 183 included patients, 142 (77.6%) were women, and the mean (range) age was 51.7 (22.0-85.0) years. The genomic sequencing classifier had a sensitivity of 91% (95% CI, 79-98) and a specificity of 68% (95% CI, 60-76). At 24% cancer prevalence, the negative predictive value was 96% (95% CI, 90-99) and the positive predictive value was 47% (95% CI, 36-58). Conclusions and Relevance:The genomic sequencing classifier demonstrates high sensitivity and accuracy for identifying benign nodules. Its 36% increase in specificity compared with the gene expression classifier potentially increases the number of patients with benign nodules who can safely avoid unnecessary diagnostic surgery.",
      "publication_location": "Jama Surgery",
      "link": "http://dx.doi.org/10.1001/jamasurg.2018.1153",
      "citations": 62,
      "readership": 64,
      "tweets": 22,
      "news_mentions": 8
    },
    {
      "title": "An Inductive Logic Programming Approach to Validate Hexose Binding Biochemical Knowledge.",
      "authors": "Nassif, H; Al-Ali, H; Khuri, S; Keirouz, W; Page, D",
      "published_date": 2010,
      "doi": "10.1007/978-3-642-13840-9_14",
      "abstract": "Hexoses are simple sugars that play a key role in many cellular pathways, and in the regulation of development and disease mechanisms. Current protein-sugar computational models are based, at least partially, on prior biochemical findings and knowledge. They incorporate different parts of these findings in predictive black-box models. We investigate the empirical support for biochemical findings by comparing Inductive Logic Programming (ILP) induced rules to actual biochemical results. We mine the Protein Data Bank for a representative data set of hexose binding sites, non-hexose binding sites and surface grooves. We build an ILP model of hexose-binding sites and evaluate our results against several baseline machine learning classifiers. Our method achieves an accuracy similar to that of other black-box classifiers while providing insight into the discriminating process. In addition, it confirms wet-lab findings and reveals a previously unreported Trp-Glu amino acids dependency.",
      "publication_location": "Inductive Log Program",
      "link": "http://dx.doi.org/10.1007/978-3-642-13840-9_14",
      "citations": 7,
      "readership": 9,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Inferring high-dimensional poisson autoregressive models",
      "authors": "",
      "published_date": "August 24, 2016",
      "doi": "10.1109/SSP.2016.7551762",
      "abstract": "© 2016 IEEE. Consider observing a series of events associated with a group of interacting nodes in a network, where the interactions among those nodes govern the likelihood of future events. Such data are common in spike trains recorded from biological neural networks, interactions within a social network, and pricing changes within financial networks. Vector autoregressive point processes accurately model these settings and are widely used in practice. This paper addresses the inference of the network structure and autoregressive parameters from such data. A sparsity-regularized maximum likelihood estimator is proposed for a Poisson autoregressive process. While sparsity-regularization is well-studied in the statistics and machine learning communities, common assumptions from that literature are difficult to verify here because of correlations and heteroscedasticity inherent in the problem. Novel performance guarantees characterize how much data must be collected to ensure reliable inference depending on the size and sparsity of the autoregressive parameters, and these bounds are supported by several simulation studies.",
      "publication_location": "Ieee Workshop on Statistical Signal Processing Proceedings",
      "link": "http://dx.doi.org/10.1109/SSP.2016.7551762",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Sparse Transition Matrix Estimation for Sub-Gaussian Autoregressive Processes with Missing Data",
      "authors": "",
      "published_date": "August 9, 2018",
      "doi": "10.23919/ACC.2018.8431255",
      "abstract": "© 2018 AACC. High-dimensional time series data exist in numerous areas such as finance, genomics, healthcare, and neuroscience. An unavoidable aspect of all such datasets is missing data, and dealing with this issue has been an important focus in statistics, control, and machine learning. In this work, we consider a high-dimensional estimation problem where a dynamical system, governed by a stable vector autoregressive model, is randomly and only partially observed at each time point. Our task amounts to estimating the transition matrix, which is assumed to be sparse. In such a scenario, where covariates are highly interdependent and partially missing, new theoretical challenges arise. While transition matrix estimation in vector autoregressive models has been studied previously, the missing data scenario requires separate efforts. Moreover, while transition matrix estimation can be studied from a high-dimensional sparse linear regression perspective, the covariates are highly dependent and existing results on regularized estimation with missing data from i.i.d. covariates are not applicable. At the heart of our analysis lies 1) a novel concentration result when the innovation noise satisfies the convex concentration property, as well as 2) a new quantity for characterizing the interactions of the time-varying observation process with the underlying dynamical system.",
      "publication_location": "Proceedings of the American Control Conference",
      "link": "http://dx.doi.org/10.23919/ACC.2018.8431255",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The Impact of Increasing Autonomy on Training Requirements in a UAV Supervisory Control Task",
      "authors": "Cummings, M; Huang, L; Zhu, H; Finkelstein, D; Wei, R",
      "published_date": "December 1, 2019",
      "doi": "10.1177/1555343419868917",
      "abstract": "© 2019, Human Factors and Ergonomics Society. A common assumption across many industries is that inserting advanced autonomy can often replace humans for low-level tasks, with cost reduction benefits. However, humans are often only partially replaced and moved into a supervisory capacity with reduced training. It is not clear how this shift from human to automation control and subsequent training reduction influences human performance, errors, and a tendency toward automation bias. To this end, a study was conducted to determine whether adding autonomy and skipping skill-based training could influence performance in a supervisory control task. In the human-in-the-loop experiment, operators performed unmanned aerial vehicle (UAV) search tasks with varying degrees of autonomy and training. At the lowest level of autonomy, operators searched images and, at the highest level, an automated target recognition algorithm presented its best estimate of a possible target, occasionally incorrectly. Results were mixed, with search time not affected by skill-based training. However, novices with skill-based training and automated target search misclassified more targets, suggesting a propensity toward automation bias. More experienced operators had significantly fewer misclassifications when the autonomy erred. A descriptive machine learning model in the form of a hidden Markov model also provided new insights for improved training protocols and interventional technologies.",
      "publication_location": "Journal of Cognitive Engineering and Decision Making",
      "link": "http://dx.doi.org/10.1177/1555343419868917",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Ground water solute transport, optimal remediation planning, and decision making under uncertainty",
      "authors": "Medina, MA; Jacobs, TL; Lin, W; Lin, KC",
      "published_date": "January 1, 1996",
      "doi": "10.1111/j.1752-1688.1996.tb03429.x",
      "abstract": "A groundwater quality modeling advisory system has been developed for the U.S. Air Force for use in investigating remediation alternatives for the cleanup of subsurface contamination. The system is capable of accounting for uncertainty, not only in the prediction of solute transport but also in the optimization of the remediation scheme through chance constraints. The system guides users in the selection of appropriate transport models through an algorithm independently tested with machine learning codes. An application to Hill Air Force Base, Utah, is presented for which different pump-and-treat strategies are considered: the results are evaluated in terms of the cumulative distribution of the contaminant concentration for each case and the tradeoff relationship between the cost of remediation and the probability that the remediation strategy exceeds an established maximum allowable contaminant concentration.",
      "publication_location": "Journal of the American Water Resources Association",
      "link": "http://dx.doi.org/10.1111/j.1752-1688.1996.tb03429.x",
      "citations": 8,
      "readership": 7,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Policy and the structure of roll call voting in the US house",
      "authors": "De Marchi, S; Dorsey, S; Ensley, MJ",
      "published_date": "January 1, 2020",
      "doi": "10.1017/S0143814X20000069",
      "abstract": "© The Author(s) 2020. Published by Cambridge University Press. Competition in the US Congress has been characterised along a single, left-right ideological dimension. We challenge this characterisation by showing that the content of legislation has far more predictive power than alternative measures, most notably legislators' ideological positions derived from scaling roll call votes. Using a machine learning approach, we identify a topic model for final passage votes in the 111th through the 113th House of Representatives and conduct out-of-sample tests to evaluate the predictive power of bill topics relative to other measures. We find that bill topics and congressional committees are important for predicting roll call votes but that other variables, including member ideology, lack predictive power. These findings raise serious doubts about the claim that congressional politics can be boiled down to competition along a single left-right continuum and shed new light on the debate about levels of polarisation in Congress.",
      "publication_location": "Journal of Public Policy",
      "link": "http://dx.doi.org/10.1017/S0143814X20000069",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 10,
      "news_mentions": ""
    },
    {
      "title": "Health Profiles of Mosaic Versus Non-mosaic FMR1 Premutation Carrier Mothers of Children With Fragile X Syndrome.",
      "authors": "Mailick, MR; Movaghar, A; Hong, J; Greenberg, JS; DaWalt, LS; Zhou, L; Jackson, J; Rathouz, PJ; Baker, MW; Brilliant, M; Page, D; Berry-Kravis, E",
      "published_date": 2018,
      "doi": "10.3389/fgene.2018.00173",
      "abstract": "The FMR1 premutation is of increasing interest to the FXS community, as questions about a primary premutation phenotype warrant research attention. 100 FMR1 premutation carrier mothers (mean age = 58; 67-138 CGG repeats) of adults with fragile X syndrome were studied with respect to their physical and mental health, motor, and neurocognitive characteristics. We explored the correlates of CGG repeat mosaicism in women with expanded alleles. Mothers provided buccal swabs from which DNA was extracted and the FMR1 CGG genotyping was performed (Amplidex Kit, Asuragen). Mothers were categorized into three groups: Group 1: premutation non-mosaic (n = 45); Group 2: premutation mosaic (n = 41), and Group 3: premutation/full mutation mosaic (n = 14). Group 2 mothers had at least two populations of cells with different allele sizes in the premutation range besides their major expanded allele. Group 3 mothers had a very small population of cells in the full mutation range (>200 CGGs) in addition to one or multiple populations of cells with different allele sizes in the premutation range. Machine learning (random forest) was used to identify symptoms and conditions that correctly classified mothers with respect to mosaicism; follow-up comparisons were made to characterize the three groups. In categorizing mosaicism, the random forest yielded significantly better classification than random classification, with overall area under the receiver operating characteristic curve (AUROC) of 0.737. Among the most important symptoms and conditions that contributed to the classification were anxiety, menopause symptoms, executive functioning limitations, and difficulty walking several blocks, with the women who had full mutation mosaicism (Group 3) unexpectedly having better health. Although only 14 premutation carrier mothers in the present sample also had a small population of full mutation cells, their profile of comparatively better health, mental health, and executive functioning was unexpected. This preliminary finding should prompt additional research on larger numbers of participants with more extensive phenotyping to confirm the clinical correlates of low-level full mutation mosaicism in premutation carriers and to probe possible mechanisms.",
      "publication_location": "Frontiers in Genetics",
      "link": "http://dx.doi.org/10.3389/fgene.2018.00173",
      "citations": 4,
      "readership": 23,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "Differential privacy for classifier evaluation",
      "authors": "Boyd, K; Lantz, E; Page, D",
      "published_date": "October 16, 2015",
      "doi": "10.1145/2808769.2808775",
      "abstract": "© 2015 ACM. Differential privacy provides powerful guarantees that individuals incur minimal additional risk by including their personal data in a database. Most work in differential privacy has focused on differentially private algorithms that produce models, counts, and histograms. Nevertheless, even with a classification model produced by a differentially private algorithm, directly reporting the classifier's performance on a database has the potential for disclosure. Thus, differentially private computation of evaluation metrics for machine learning is an important research area. We find effective mechanisms for area under the receiver-operating characteristic (ROC) curve and average precision.",
      "publication_location": "Aisec 2015   Proceedings of the 8th Acm Workshop on Artificial Intelligence and Security, Co Located With Ccs 2015",
      "link": "http://dx.doi.org/10.1145/2808769.2808775",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing",
      "authors": "Fredrikson, M; Lantz, E; Jha, S; Lin, S; Page, D; Ristenpart, T",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "copyright © 2014 USENIX Security Symposium.All right reserved. We initiate the study of privacy in pharmacogenetics, wherein machine learning models are used to guide medical treatments based on a patient's genotype and background. Performing an in-depth case study on privacy in personalized warfarin dosing, we show that suggested models carry privacy risks, in particular because attackers can perform what we call model inversion: an attacker, given the model and some demographic information about a patient, can predict the patient's genetic markers. As differential privacy (DP) is an oft-proposed solution for medical settings such as this, we evaluate its effectiveness for building private versions of pharmacoge-netic models. We show that DP mechanisms prevent our model inversion attacks when the privacy budget is carefully selected. We go on to analyze the impact on utility by performing simulated clinical trials with DP dosing models. We find that for privacy budgets effective at preventing attacks, patients would be exposed to increased risk of stroke, bleeding events, and mortality. We conclude that current DP mechanisms do not simultaneously improve genomic privacy while retaining desirable clinical efficacy, highlighting the need for new mechanisms that should be evaluated in situ using the general methodology introduced by our work.",
      "publication_location": "Proceedings of the 23rd Usenix Security Symposium",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Artificial intelligence and the future of psychiatry: Insights from a global physician survey.",
      "authors": "",
      "published_date": "January 2020",
      "doi": "10.1016/j.artmed.2019.101753",
      "abstract": "BACKGROUND:Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. OBJECTIVE:To characterize the global psychiatrist community's opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. DESIGN:Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. MAIN OUTCOME MEASURES:We measured opinions about the likelihood that AI/ML tools would be able to fully replace - not just assist - the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist's perceptions about whether benefits of AI/ML would outweigh the risks. RESULTS:Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. CONCLUSIONS:Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.",
      "publication_location": "Artificial Intelligence in Medicine",
      "link": "http://dx.doi.org/10.1016/j.artmed.2019.101753",
      "citations": 2,
      "readership": 20,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Geometric diffusions as a tool for harmonic analysis and structure definition of data: diffusion maps.",
      "authors": "",
      "published_date": "May 17, 2005",
      "doi": "10.1073/pnas.0500334102",
      "abstract": "We provide a framework for structural multiscale geometric organization of graphs and subsets of R(n). We use diffusion semigroups to generate multiscale geometries in order to organize and represent complex structures. We show that appropriately selected eigenfunctions or scaling functions of Markov matrices, which describe local transitions, lead to macroscopic descriptions at different scales. The process of iterating or diffusing the Markov matrix is seen as a generalization of some aspects of the Newtonian paradigm, in which local infinitesimal transitions of a system lead to global macroscopic descriptions by integration. We provide a unified view of ideas from data analysis, machine learning, and numerical analysis.",
      "publication_location": "Proceedings of the National Academy of Sciences of the United States of America",
      "link": "http://dx.doi.org/10.1073/pnas.0500334102",
      "citations": 749,
      "readership": 668,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Sensor fusion approaches for EMI & GPR based subsurface threat identification",
      "authors": "",
      "published_date": "July 13, 2011",
      "doi": "10.1117/12.884130",
      "abstract": "Despite advances in both electromagnetic induction (EMI) and ground penetrating radar (GPR) sensing and related signal processing, neither sensor alone provides a perfect tool for detecting the myriad of possible buried objects that threaten the lives of Soldiers and civilians. However, while neither GPR nor EMI sensing alone can provide optimal detection across all target types, the two approaches are highly complementary. As a result, many landmine systems seek to make use of both sensing modalities simultaneously and fuse the results from both sensors to improve detection performance for targets with widely varying metal content and GPR responses. Despite this, little work has focused on large-scale comparisons of different approaches to sensor fusion and machine learning for combining data from these highly orthogonal phenomenologies. In this work we explore a wide array of pattern recognition techniques for algorithm development and sensor fusion. Results with the ARA Nemesis landmine detection system suggest that nonlinear and non-parametric classification algorithms provide significant performance benefits for single-sensor algorithm development, and that fusion of multiple algorithms can be performed satisfactorily using basic parametric approaches, such as logistic discriminant classification, for the targets under consideration in our data sets. © 2011 SPIE.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.884130",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Random Forests approach for identifying additive and epistatic single nucleotide polymorphisms associated with residual feed intake in dairy cattle.",
      "authors": "Yao, C; Spurlock, DM; Armentano, LE; Page, CD; VandeHaar, MJ; Bickhart, DM; Weigel, KA",
      "published_date": "October 2013",
      "doi": "10.3168/jds.2012-6237",
      "abstract": "Feed efficiency is an economically important trait in the beef and dairy cattle industries. Residual feed intake (RFI) is a measure of partial efficiency that is independent of production level per unit of body weight. The objective of this study was to identify significant associations between single nucleotide polymorphism (SNP) markers and RFI in dairy cattle using the Random Forests (RF) algorithm. Genomic data included 42,275 SNP genotypes for 395 Holstein cows, whereas phenotypic measurements were daily RFI from 50 to 150 d postpartum. Residual feed intake was defined as the difference between an animal's feed intake and the average intake of its cohort, after adjustment for year and season of calving, year and season of measurement, age at calving nested within parity, days in milk, milk yield, body weight, and body weight change. Random Forests is a widely used machine-learning algorithm that has been applied to classification and regression problems. By analyzing the tree structures produced within RF, the 25 most frequent pairwise SNP interactions were reported as possible epistatic interactions. The importance scores that are generated by RF take into account both main effects of variables and interactions between variables, and the most negative value of all importance scores can be used as the cutoff level for declaring SNP effects as significant. Ranking by importance scores, 188 SNP surpassed the threshold, among which 38 SNP were mapped to RFI quantitative trait loci (QTL) regions reported in a previous study in beef cattle, and 2 SNP were also detected by a genome-wide association study in beef cattle. The ratio of number of SNP located in RFI QTL to the total number of SNP in the top 188 SNP chosen by RF was significantly higher than in all 42,275 whole-genome markers. Pathway analysis indicated that many of the top 188 SNP are in genomic regions that contain annotated genes with biological functions that may influence RFI. Frequently occurring ancestor-descendant SNP pairs can be explored as possible epistatic effects for further study. The importance scores generated by RF can be used effectively to identify large additive or epistatic SNP and informative QTL. The consistency in results of our study and previous studies in beef cattle indicates that the genetic architecture of RFI in dairy cattle might be similar to that of beef cattle.",
      "publication_location": "J Dairy Sci",
      "link": "http://dx.doi.org/10.3168/jds.2012-6237",
      "citations": 28,
      "readership": 63,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Adaptive mitigation of parameter variations",
      "authors": "Firouzi, F; Ye, F; Kiamehr, S; Chakrabarty, K; Tahoori, MB",
      "published_date": "January 1, 2014",
      "doi": "10.1109/ATS.2014.21",
      "abstract": "© 2014 IEEE. In the deep nanoscale regime, process and runtime variations have emerged as the major sources of uncertainty and unpredictability in circuit operation. Static mitigation approaches do not consider the dependence of variations on workload and chip usage, while adaptive techniques do not incorporate detailed circuit-level information. We propose a fine-grained adaptive technique in which machine learning is exploited to perform circuit clustering and obtain a representative for each cluster. By monitoring the representative in each cluster at runtime, performance variations in the entire cluster can be tracked such that appropriate fine-grained adaptation can be applied to each cluster. Experimental results for ISCAS'89, IWLS'05, and ITC'99 benchmarks as well as the LEON processor show that the proposed approach introduces negligible overhead significantly extends circuit lifetime, facilitates higher operating frequencies, and reduces the leakage power.",
      "publication_location": "Proceedings of the Asian Test Symposium",
      "link": "http://dx.doi.org/10.1109/ATS.2014.21",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Failure prediction based on anomaly detection for complex core routers",
      "authors": "Jin, S; Zhang, Z; Chakrabarty, K; Gu, X",
      "published_date": "November 5, 2018",
      "doi": "10.1145/3240765.3243476",
      "abstract": "© 2018 ACM. Data-driven prognostic health management is essential to ensure high reliability and rapid error recovery in commercial core router systems. The effectiveness of prognostic health management depends on whether failures can be accurately predicted with sufficient lead time. This paper describes how time-series analysis and machine-learning techniques can be used to detect anomalies and predict failures in complex core router systems. First, both a feature-categorization-based hybrid method and a changepoint-based method have been developed to detect anomalies in time-varying features with different statistical characteristics. Next, a SVM-based failure predictor is developed to predict both categories and lead time of system failures from collected anomalies. A comprehensive set of experimental results is presented for data collected during 30 days of field operation from over 20 core routers deployed by customers of a major telecom company.",
      "publication_location": "Ieee/Acm International Conference on Computer Aided Design, Digest of Technical Papers, Iccad",
      "link": "http://dx.doi.org/10.1145/3240765.3243476",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Aging-and variation-aware delay monitoring using representative critical path selection",
      "authors": "Firouzi, F; Ye, F; Chakrabarty, K; Tahoori, MB",
      "published_date": "January 1, 2015",
      "doi": "10.1145/2746237",
      "abstract": "© 2015 ACM. Process together with runtime variations in temperature and voltage, as well as transistor aging, degrade path delay and may eventually induce circuit failure due to timing variations. Therefore, in-field tracking of path delays is essential, and to respond to this need, several delay sensor designs have been proposed in the literature. However, due to the significant overhead of these sensors and the large number of critical paths in today's IC, it is infeasible to monitor the delay of every critical path in silicon. We present an aging-and variationaware representative path selection technique based on machine learning that allows to measure the delay of a small set of paths and infer the delay of a larger pool of paths that are likely to fail due to delay variations. Simulation results for benchmark circuits highlight the accuracy of the proposed approach for predicting critical-path delay based on the selected representative paths.",
      "publication_location": "Acm Transactions on Design Automation of Electronic Systems",
      "link": "http://dx.doi.org/10.1145/2746237",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Online soft-error vulnerability estimation for memory arrays",
      "authors": "Vijayan, A; Koneru, A; Ebrahimit, M; Chakrabarty, K; Tahoori, MB",
      "published_date": "May 23, 2016",
      "doi": "10.1109/VTS.2016.7477301",
      "abstract": "© 2016 IEEE. Radiation-induced soft errors are a major reliability concern in circuits fabricated at advanced technology nodes. Online soft-error vulnerability estimation offers the flexibility of exploiting dynamic fault-tolerant mechanisms for cost-effective reliability enhancement. We propose a generic run-time method with low area and power overhead to predict the soft-error vulnerability of on-chip memory arrays. The vulnerability prediction is based on signal probabilities (SPs) of a small set of flip-flops, chosen at design time, by studying the correlation between the soft-error vulnerability and the flip-flop SPs for representative workloads. We exploit machine learning to develop a predictive model that can be deployed in the system in software form. Simulation results on two processor designs show that the proposed technique can accurately estimate the soft-error vulnerability of on-chip memory arrays that constitute the instruction cache, the data cache, and the register file.",
      "publication_location": "Proceedings of the Ieee Vlsi Test Symposium",
      "link": "http://dx.doi.org/10.1109/VTS.2016.7477301",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Monolithic 3D-enabled high performance and energy efficient network-on-chip",
      "authors": "Das, S; Doppa, JR; Pande, PP; Chakrabarty, K",
      "published_date": "November 22, 2017",
      "doi": "10.1109/ICCD.2017.43",
      "abstract": "© 2017 IEEE. Emergence of monolithic 3D (M3D) integration has opened up the possibility of designing the ultra-low-power and high-performance circuits and systems. The smaller dimensions of monolithic inter-tier vias (MIVs) offer high density integration, the flexibility of partitioning logic blocks across multiple tiers, and significantly reduced total wire-length. In this work, we explore the design space of M3D-enabled energy-efficient NoC architectures and present a comparative performance evaluation with TSV-based counterparts. We describe the optimization of the link and router placements of the M3D-enabled NoC to ensure maximum achievable performance. The placement of M3D-enabled routers and links are explored using a machine-learning-inspired optimization algorithm. The proposed M3D-enabled NoC architecture achieves 32% lower energy-delay-product (EDP) compared to the conventional mesh-based counterpart. We also demonstrate that for the diverse set of benchmarks considered in this work, the M3D-enabled NoC, on an average, achieves 28% lower EDP than the TSV-based counterpart.",
      "publication_location": "Proceedings   35th Ieee International Conference on Computer Design, Iccd 2017",
      "link": "http://dx.doi.org/10.1109/ICCD.2017.43",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Online soft-error vulnerability estimation for memory arrays and logic cores",
      "authors": "Vijayan, A; Kiamehr, S; Ebrahimi, M; Chakrabarty, K; Tahoori, MB",
      "published_date": "February 1, 2018",
      "doi": "10.1109/TCAD.2017.2706558",
      "abstract": "© 2017 IEEE. Radiation-induced soft errors are a major reliability concern in circuits fabricated at advanced technology nodes. Online soft-error vulnerability estimation offers the flexibility of exploiting dynamic fault-tolerant mechanisms for cost-effective reliability enhancement. We propose a generic run-time method with low area and power overhead to predict the soft-error vulnerability of on-chip memory arrays as well as logic cores. The vulnerability prediction is based on signal probabilities (SPs) of a small set of flip-flops, chosen at design time, by studying the correlation between the soft-error vulnerability and the flip-flop SPs for representative workloads. We exploit machine learning to develop a predictive model that can be deployed in the system in software form. Simulation results on two processor designs show that the proposed technique can accurately estimate the soft-error vulnerability of on-chip logic core, such as sequential pipeline logic and functional units as well as memory arrays that constitute the instruction cache, the data cache, and the register file.",
      "publication_location": "Ieee Transactions on Computer Aided Design of Integrated Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/TCAD.2017.2706558",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Data-Driven Resiliency Solutions for Boards and Systems",
      "authors": "Jin, S; Chakrabarty, K",
      "published_date": "March 27, 2018",
      "doi": "10.1109/VLSID.2018.70",
      "abstract": "© 2018 IEEE. Data analytics and real-Time monitoring can be used to ensure that boards and systems operate as intended. This paper first describes how machine learning, statistical techniques, and information-Theoretic analysis can be used to close the gap between working silicon and a working system. Next, it describes how time-series analysis can be used to analyze health status and detect anomalies in complex core router systems. Traditional techniques fail to identify abnormal or suspect patterns when the monitored data involves temporal measurements and exhibits significantly different statistical characteristics for its constituent features. This paper thus not only describes a feature-categorization-based hybrid method and a changepoint-based method to detect anomalies in time-varying features with different statistical characteristics, but also proposes a symbol-based health analyzer to obtain a full picture of the health status of monitored core routers. A comprehensive set of experimental results is presented for data collected during 30 days of field operation from over 20 core routers deployed by customers of a major telecom company.",
      "publication_location": "Proceedings of the Ieee International Conference on Vlsi Design",
      "link": "http://dx.doi.org/10.1109/VLSID.2018.70",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Automatic detection of omissions in medication lists.",
      "authors": "Hasan, S; Duncan, GT; Neill, DB; Padman, R",
      "published_date": "July 2011",
      "doi": "10.1136/amiajnl-2011-000106",
      "abstract": "OBJECTIVE: Evidence suggests that the medication lists of patients are often incomplete and could negatively affect patient outcomes. In this article, the authors propose the application of collaborative filtering methods to the medication reconciliation task. Given a current medication list for a patient, the authors employ collaborative filtering approaches to predict drugs the patient could be taking but are missing from their observed list. DESIGN: The collaborative filtering approach presented in this paper emerges from the insight that an omission in a medication list is analogous to an item a consumer might purchase from a product list. Online retailers use collaborative filtering to recommend relevant products using retrospective purchase data. In this article, the authors argue that patient information in electronic medical records, combined with artificial intelligence methods, can enhance medication reconciliation. The authors formulate the detection of omissions in medication lists as a collaborative filtering problem. Detection of omissions is accomplished using several machine-learning approaches. The effectiveness of these approaches is evaluated using medication data from three long-term care centers. The authors also propose several decision-theoretic extensions to the methodology for incorporating medical knowledge into recommendations. RESULTS: Results show that collaborative filtering identifies the missing drug in the top-10 list about 40-50% of the time and the therapeutic class of the missing drug 50%-65% of the time at the three clinics in this study. CONCLUSION: Results suggest that collaborative filtering can be a valuable tool for reconciling medication lists, complementing currently recommended process-driven approaches. However, a one-size-fits-all approach is not optimal, and consideration should be given to context (eg, types of patients and drug regimens) and consequence (eg, the impact of omission on outcomes).",
      "publication_location": "Journal of the American Medical Informatics Association : Jamia",
      "link": "http://dx.doi.org/10.1136/amiajnl-2011-000106",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Surface approximation and geometric partitions",
      "authors": "Agarwal, PK",
      "published_date": "January 1, 1998",
      "doi": "10.1137/S0097539794269801",
      "abstract": "Motivated by applications in computer graphics, visualization, and scientific computation, we study the computational complexity of the following problem: given a set S of n points sampled from a bivariate function f(x, y) and an input parameter ε > 0, compute a piecewise-linear function ∑(x, y) of minimum complexity (that is, an xy-monotone polyhedral surface, with a minimum number of vertices, edges, or faces) such that |∑(xp,yp) - zp| ≤ ε for all (xp, yp, zp) ∈ S. We give hardness evidence for this problem, by showing that a closely related problem is NP-hard. The main result of our paper is a polynomial-time approximation algorithm that computes a piecewise-linear surface of size O(Ko log Ko), where Ko is the complexity of an optimal surface satisfying the constraints of the problem. The technique developed in our paper is more general and applies to several other problems that deal with partitioning of points (or other objects) subject to certain geometric constraints. For instance, we get the same approximation bound for the following problem arising in machine learning: given n \"red\" and m \"blue\" points in the plane, find a minimum number of pairwise disjoint triangles such that each blue point is covered by some triangle and no red point lies in any of the triangles. © 1998 Society for Industrial and Applied Mathematics.",
      "publication_location": "Siam Journal on Computing",
      "link": "http://dx.doi.org/10.1137/S0097539794269801",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Surface approximation and geometric partitions",
      "authors": "Agarwal, PK; Suri, S",
      "published_date": "January 1, 1994",
      "doi": "",
      "abstract": "Motivated by applications in scientific computation, visualization, and computer graphics, we study the computational complexity of the following problem: Given a set S of n points sampled from a bivariate function f(x,y) and an input parameter ε<0, compute a piecewise linear function Σ(x,y) of minimum complexity (that is, a xy-monotone polyhedral surface, with a minimum number of vertices, edges, or faces) such that |Σ(xp,yp)-zp|≤ε, for any (xp,yp,zp) ∈ S. We prove that the decision version of this problem is NP-Hard. The main result of our paper is a polynomial-time approximation algorithm that computes a piecewise linear surface of size O(Ko log Ko), where Ko is the complexity of an optimal surface satisfying the constraints of the problem. The technique developed in our paper is more general and applies to several other problems that deal with partitioning of points (or other objects) subject to certain geometric constraints. For instance, we get the same approximation bound for the following problem, which arises in machine learning: given n `red' and m `blue' points in the plane, find a minimum number of pairwise disjoint triangles such that each blue point is covered by some triangle and no red point lies in any of the triangles.",
      "publication_location": "Proceedings of the Annual Acm Siam Symposium on Discrete Algorithms",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multimodal Fusion With Reference: Searching for Joint Neuromarkers of Working Memory Deficits in Schizophrenia.",
      "authors": "Qi, S; Calhoun, VD; van Erp, TGM; Bustillo, J; Damaraju, E; Turner, JA; Du, Y; Yang, J; Chen, J; Yu, Q; Mathalon, DH; Ford, JM; Voyvodic, J; Mueller, BA; Belger, A; McEwen, S; Potkin, SG; Preda, A; Jiang, T; Sui, J",
      "published_date": "January 2018",
      "doi": "10.1109/TMI.2017.2725306",
      "abstract": "By exploiting cross-information among multiple imaging data, multimodal fusion has often been used to better understand brain diseases. However, most current fusion approaches are blind, without adopting any prior information. There is increasing interest to uncover the neurocognitive mapping of specific clinical measurements on enriched brain imaging data; hence, a supervised, goal-directed model that employs prior information as a reference to guide multimodal data fusion is much needed and becomes a natural option. Here, we proposed a fusion with reference model called \"multi-site canonical correlation analysis with reference + joint-independent component analysis\" (MCCAR+jICA), which can precisely identify co-varying multimodal imaging patterns closely related to the reference, such as cognitive scores. In a three-way fusion simulation, the proposed method was compared with its alternatives on multiple facets; MCCAR+jICA outperforms others with higher estimation precision and high accuracy on identifying a target component with the right correspondence. In human imaging data, working memory performance was utilized as a reference to investigate the co-varying working memory-associated brain patterns among three modalities and how they are impaired in schizophrenia. Two independent cohorts (294 and 83 subjects respectively) were used. Similar brain maps were identified between the two cohorts along with substantial overlaps in the central executive network in fMRI, salience network in sMRI, and major white matter tracts in dMRI. These regions have been linked with working memory deficits in schizophrenia in multiple reports and MCCAR+jICA further verified them in a repeatable, joint manner, demonstrating the ability of the proposed method to identify potential neuromarkers for mental disorders.",
      "publication_location": "Ieee Trans Med Imaging",
      "link": "http://dx.doi.org/10.1109/TMI.2017.2725306",
      "citations": 20,
      "readership": 69,
      "tweets": 17,
      "news_mentions": ""
    },
    {
      "title": "Individualized computer-aided education in mammography based on user modeling: concept and preliminary experiments.",
      "authors": "Mazurowski, MA; Baker, JA; Barnhart, HX; Tourassi, GD",
      "published_date": "March 2010",
      "doi": "10.1118/1.3301575",
      "abstract": "PURPOSE: The authors propose the framework for an individualized adaptive computer-aided educational system in mammography that is based on user modeling. The underlying hypothesis is that user models can be developed to capture the individual error making patterns of radiologists-in-training. In this pilot study, the authors test the above hypothesis for the task of breast cancer diagnosis in mammograms. METHODS: The concept of a user model was formalized as the function that relates image features to the likelihood/extent of the diagnostic error made by a radiologist-in-training and therefore to the level of difficulty that a case will pose to the radiologist-in-training (or \"user\"). Then, machine learning algorithms were implemented to build such user models. Specifically, the authors explored k-nearest neighbor, artificial neural networks, and multiple regression for the task of building the model using observer data collected from ten Radiology residents at Duke University Medical Center for the problem of breast mass diagnosis in mammograms. For each resident, a user-specific model was constructed that predicts the user's expected level of difficulty for each presented case based on two BI-RADS image features. In the experiments, leave-one-out data handling scheme was applied to assign each case to a low-predicted-difficulty or a high-predicted-difficulty group for each resident based on each of the three user models. To evaluate whether the user model is useful in predicting difficulty, the authors performed statistical tests using the generalized estimating equations approach to determine whether the mean actual error is the same or not between the low-predicted-difficulty group and the high-predicted-difficulty group. RESULTS: When the results for all observers were pulled together, the actual errors made by residents were statistically significantly higher for cases in the high-predicted-difficulty group than for cases in the low-predicted-difficulty group for all modeling algorithms (p < or = 0.002 for all methods). This indicates that the user models were able to accurately predict difficulty level of the analyzed cases. Furthermore, the authors determined that among the two BI-RADS features that were used in this study, mass margin was the most useful in predicting individual user errors. CONCLUSIONS: The pilot study shows promise for developing individual user models that can accurately predict the level of difficulty that each case will pose to the radiologist-in-training. These models could allow for constructing adaptive computer-aided educational systems in mammography.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3301575",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "PowerNet: Transferable Dynamic IR Drop Estimation via Maximum Convolutional Neural Network",
      "authors": "",
      "published_date": "January 1, 2020",
      "doi": "10.1109/ASP-DAC47756.2020.9045574",
      "abstract": "© 2020 IEEE. IR drop is a fundamental constraint required by almost all chip designs. However, its evaluation usually takes a long time that hinders mitigation techniques for fixing its violations. In this work, we develop a fast dynamic IR drop estimation technique, named PowerNet, based on a convolutional neural network (CNN). It can handle both vector-based and vectorless IR analyses. Moreover, the proposed CNN model is general and transferable to different designs. This is in contrast to most existing machine learning (ML) approaches, where a model is applicable only to a specific design. Experimental results show that PowerNet outperforms the latest ML method by 9% in accuracy for the challenging case of vectorless IR drop and achieves a 30× speedup compared to an accurate IR drop commercial tool. Further, a mitigation tool guided by PowerNet reduces IR drop hotspots by 26% and 31% on two industrial designs, respectively, with very limited modification on their power grids.",
      "publication_location": "Proceedings of the Asia and South Pacific Design Automation Conference, Asp Dac",
      "link": "http://dx.doi.org/10.1109/ASP-DAC47756.2020.9045574",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A Survey of Accelerator Architectures for Deep Neural Networks",
      "authors": "",
      "published_date": "March 1, 2020",
      "doi": "10.1016/j.eng.2020.01.007",
      "abstract": "© 2020 Recently, due to the availability of big data and the rapid growth of computing power, artificial intelligence (AI) has regained tremendous attention and investment. Machine learning (ML) approaches have been successfully applied to solve many problems in academia and in industry. Although the explosion of big data applications is driving the development of ML, it also imposes severe challenges of data processing speed and scalability on conventional computer systems. Computing platforms that are dedicatedly designed for AI applications have been considered, ranging from a complement to von Neumann platforms to a “must-have” and stand-alone technical solution. These platforms, which belong to a larger category named “domain-specific computing,” focus on specific customization for AI. In this article, we focus on summarizing the recent advances in accelerator designs for deep neural networks (DNNs)—that is, DNN accelerators. We discuss various architectures that support DNN executions in terms of computing units, dataflow optimization, targeted network topologies, architectures on emerging technologies, and accelerators for emerging applications. We also provide our visions on the future trend of AI chip designs.",
      "publication_location": "Engineering",
      "link": "http://dx.doi.org/10.1016/j.eng.2020.01.007",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Subspace segmentation by dense block and sparse representation.",
      "authors": "Tang, K; Dunson, DB; Su, Z; Liu, R; Zhang, J; Dong, J",
      "published_date": "March 2016",
      "doi": "10.1016/j.neunet.2015.11.011",
      "abstract": "Subspace segmentation is a fundamental topic in computer vision and machine learning. However, the success of many popular methods is about independent subspace segmentation instead of the more flexible and realistic disjoint subspace segmentation. Focusing on the disjoint subspaces, we provide theoretical and empirical evidence of inferior performance for popular algorithms such as LRR. To solve these problems, we propose a novel dense block and sparse representation (DBSR) for subspace segmentation and provide related theoretical results. DBSR minimizes a combination of the 1,1-norm and maximum singular value of the representation matrix, leading to a combination of dense block and sparsity. We provide experimental results for synthetic and benchmark data showing that our method can outperform the state-of-the-art.",
      "publication_location": "Neural Networks : the Official Journal of the International Neural Network Society",
      "link": "http://dx.doi.org/10.1016/j.neunet.2015.11.011",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Nanograined half-heusler semiconductors as advanced thermoelectrics: An ab initio high-throughput statistical study",
      "authors": "Carrete, J; Mingo, N; Wang, S; Curtarolo, S",
      "published_date": "December 17, 2014",
      "doi": "10.1002/adfm.201401201",
      "abstract": "© 2014 WILEY-VCH Verlag GmbH  &  Co. KGaA, Weinheim. Nanostructuring has spurred a revival in the field of direct thermoelectric energy conversion. Nanograined materials can now be synthesized with higher figures of merit (ZT) than the bulk counterparts. This leads to increased conversion efficiencies. Despite considerable effort in optimizing the known and discovering the unknown, technology still relies upon a few limited solutions. Here ab initio modeling of ZT is performed for 75 nanograined compounds-the result of accurate distillation with electronic and thermodynamic filtering techniques from the 79 057 half-Heusler entries available in the AFLOWLIB.org repository. For many of the compounds, the ZT s are markedly above those attainable with nanograined IV and III-V semiconductors. About 15% of them may even outperform ZT 2 at high temperatures. This analysis elucidates the origin of the advantageous thermoelectric properties found within this broad material class. Machine learning techniques are used to unveil simple rules determining if a nanograined half-Heusler compound is likely to be a good thermoelectric given its chemical composition.",
      "publication_location": "Advanced Functional Materials",
      "link": "http://dx.doi.org/10.1002/adfm.201401201",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "High-throughput computation of thermal conductivity of high-temperature solid phases: The case of oxide and fluoride perovskites",
      "authors": "Roekeghem, A; Carrete, J; Oses, C; Curtarolo, S; Mingo, N",
      "published_date": "January 1, 2016",
      "doi": "10.1103/PhysRevX.6.041061",
      "abstract": "Using finite-temperature phonon calculations and machine-learning methods, we assess the mechanical stability of about 400 semiconducting oxides and fluorides with cubic perovskite structures at 0, 300, and 1000 K. We find 92 mechanically stable compounds at high temperatures-including 36 not mentioned in the literature so far-for which we calculate the thermal conductivity. We show that the thermal conductivity is generally smaller in fluorides than in oxides, largely due to a lower ionic charge, and describe simple structural descriptors that are correlated with its magnitude. Furthermore, we show that the thermal conductivities of most cubic perovskites decrease more slowly than the usual T-1 behavior.Within this set, we also screen for materials exhibiting negative thermal expansion. Finally, we describe a strategy to accelerate the discovery of mechanically stable compounds at high temperatures.",
      "publication_location": "Physical Review X",
      "link": "http://dx.doi.org/10.1103/PhysRevX.6.041061",
      "citations": 36,
      "readership": 93,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "How Chemical Composition Alone Can Predict Vibrational Free Energies and Entropies of Solids",
      "authors": "Legrain, F; Carrete, J; Van Roekeghem, A; Curtarolo, S; Mingo, N",
      "published_date": "August 8, 2017",
      "doi": "10.1021/acs.chemmater.7b00789",
      "abstract": "© 2017 American Chemical Society. Computing vibrational free energies (Fvib) and entropies (Svib) has posed a long-standing challenge to the high-throughput ab initio investigation of finite temperature properties of solids. Here, we use machine-learning techniques to efficiently predict Fvib and Svib of crystalline compounds in the Inorganic Crystal Structure Database. Using descriptors based simply on the chemical formula and using a training set of only 300 compounds, mean absolute errors of less than 0.04 meV/K/atom (15 meV/atom) are achieved for Svib (Fvib), whose values are distributed within a range of 0.9 meV/K/atom (300 meV/atom.) In addition, for training sets containing fewer than 2000 compounds, the chemical formula alone is shown to perform as well as, if not better than, four other more complex descriptors previously used in the literature. The accuracy and simplicity of the approach means that it can be advantageously used for fast screening of chemical reactions at finite temperatures.",
      "publication_location": "Chemistry of Materials",
      "link": "http://dx.doi.org/10.1021/acs.chemmater.7b00789",
      "citations": 29,
      "readership": 86,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Drivers of Long-Term Care Considerations by Persons With Cognitive Impairment.",
      "authors": "Shepherd-Banigan, M; James, HJ; Smith, VA; Plassman, BL; Jutkowitz, E; Belanger, E; Van Houtven, CH",
      "published_date": "February 6, 2020",
      "doi": "10.1177/0733464820903908",
      "abstract": "Consideration of place of care is the first step in long-term care (LTC) planning and is critical for patients diagnosed with Alzheimer's disease; yet, drivers of consideration of place of care are unknown. We apply machine learning algorithms to cross-sectional data from the CARE-IDEAS (Caregivers' Reactions and Experience: Imaging Dementia-Evidence for Amyloid Scanning) study (n = 869 dyads) to identify drivers of patient consideration of institutional, in-home paid, and family care. Although decisions about LTC are complex, important drivers included whether patients consulted with a financial planner about LTC, patient demographics, loneliness, and geographical proximity of family members. Findings about consulting with a financial planner match literature showing that perceived financial constraints limit the range of choices in LTC planning. Well-documented drivers of institutionalization, such as care partner burden, were not identified as important variables. By understanding which factors drive patients to consider each type of care, clinicians can guide patients and their families in LTC planning.",
      "publication_location": "J Appl Gerontol",
      "link": "http://dx.doi.org/10.1177/0733464820903908",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Optimized approach to decision fusion of heterogeneous data for breast cancer diagnosis.",
      "authors": "Jesneck, JL; Nolte, LW; Baker, JA; Floyd, CE; Lo, JY",
      "published_date": "August 2006",
      "doi": "10.1118/1.2208934",
      "abstract": "As more diagnostic testing options become available to physicians, it becomes more difficult to combine various types of medical information together in order to optimize the overall diagnosis. To improve diagnostic performance, here we introduce an approach to optimize a decision-fusion technique to combine heterogeneous information, such as from different modalities, feature categories, or institutions. For classifier comparison we used two performance metrics: The receiving operator characteristic (ROC) area under the curve [area under the ROC curve (AUC)] and the normalized partial area under the curve (pAUC). This study used four classifiers: Linear discriminant analysis (LDA), artificial neural network (ANN), and two variants of our decision-fusion technique, AUC-optimized (DF-A) and pAUC-optimized (DF-P) decision fusion. We applied each of these classifiers with 100-fold cross-validation to two heterogeneous breast cancer data sets: One of mass lesion features and a much more challenging one of microcalcification lesion features. For the calcification data set, DF-A outperformed the other classifiers in terms of AUC (p < 0.02) and achieved AUC=0.85 +/- 0.01. The DF-P surpassed the other classifiers in terms of pAUC (p < 0.01) and reached pAUC=0.38 +/- 0.02. For the mass data set, DF-A outperformed both the ANN and the LDA (p < 0.04) and achieved AUC=0.94 +/- 0.01. Although for this data set there were no statistically significant differences among the classifiers' pAUC values (pAUC=0.57 +/- 0.07 to 0.67 +/- 0.05, p > 0.10), the DF-P did significantly improve specificity versus the LDA at both 98% and 100% sensitivity (p < 0.04). In conclusion, decision fusion directly optimized clinically significant performance measures, such as AUC and pAUC, and sometimes outperformed two well-known machine-learning techniques when applied to two different breast cancer data sets.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.2208934",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Unraveling the dynamics that scale cross-shore headland relief on rocky coastlines: 1. Model development",
      "authors": "Limber, PW; Murray, AB; Adams, PN; Goldstein, EB",
      "published_date": "January 1, 2014",
      "doi": "10.1002/2013JF002950",
      "abstract": "We have developed an exploratory model of plan view, millennial-scale headland and bay evolution on rocky coastlines. Cross-shore coastline relief, or amplitude, arises from alongshore differences in sea cliff lithology, where durable, erosion-resistant rocks protrude seaward as headlands and weaker rocks retreat landward as bays. The model is built around two concurrent negative feedbacks that control headland amplitude: (1) wave energy convergence and divergence at headlands and bays, respectively, that increases in intensity as cross-shore amplitude grows and (2) the combined processes of beach sediment production by sea cliff erosion, distribution of sediment to bays by waves, and beach accumulation that buffers sea cliffs from wave attack and limits further sea cliff retreat. Paired with the coastline relief model is a numerical wave transformation model that explores how wave energy is distributed along an embayed coastline. The two models are linked through genetic programming, a machine learning technique that parses wave model results into a tractable input for the coastline model. Using a pool of 4800 wave model simulations, genetic programming yields a function that relates breaking wave power density to cross-shore headland amplitude, offshore wave height, approach angle, and period. The goal of the coastline model is to make simple, but fundamental, scaling arguments on how different variables (such as sea cliff height and composition) affect the equilibrium cross-shore relief of headland and bays. The model's generality highlights the key feedbacks involved in coastline evolution and allows its equations (and model behaviors) to be easily modified by future users. © 2014. American Geophysical Union. All Rights Reserved.",
      "publication_location": "Journal of Geophysical Research: Earth Surface",
      "link": "http://dx.doi.org/10.1002/2013JF002950",
      "citations": 39,
      "readership": 35,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Metabolomic analysis of insulin resistance across different mouse strains and diets.",
      "authors": "Stöckli, J; Fisher-Wellman, KH; Chaudhuri, R; Zeng, X-Y; Fazakerley, DJ; Meoli, CC; Thomas, KC; Hoffman, NJ; Mangiafico, SP; Xirouchaki, CE; Yang, C-H; Ilkayeva, O; Wong, K; Cooney, GJ; Andrikopoulos, S; Muoio, DM; James, DE",
      "published_date": "November 24, 2017",
      "doi": "10.1074/jbc.M117.818351",
      "abstract": "Insulin resistance is a major risk factor for many diseases. However, its underlying mechanism remains unclear in part because it is triggered by a complex relationship between multiple factors, including genes and the environment. Here, we used metabolomics combined with computational methods to identify factors that classified insulin resistance across individual mice derived from three different mouse strains fed two different diets. Three inbred ILSXISS strains were fed high-fat or chow diets and subjected to metabolic phenotyping and metabolomics analysis of skeletal muscle. There was significant metabolic heterogeneity between strains, diets, and individual animals. Distinct metabolites were changed with insulin resistance, diet, and between strains. Computational analysis revealed 113 metabolites that were correlated with metabolic phenotypes. Using these 113 metabolites, combined with machine learning to segregate mice based on insulin sensitivity, we identified C22:1-CoA, C2-carnitine, and C16-ceramide as the best classifiers. Strikingly, when these three metabolites were combined into one signature, they classified mice based on insulin sensitivity more accurately than each metabolite on its own or other published metabolic signatures. Furthermore, C22:1-CoA was 2.3-fold higher in insulin-resistant mice and correlated significantly with insulin resistance. We have identified a metabolomic signature composed of three functionally unrelated metabolites that accurately predicts whole-body insulin sensitivity across three mouse strains. These data indicate the power of simultaneous analysis of individual, genetic, and environmental variance in mice for identifying novel factors that accurately predict metabolic phenotypes like whole-body insulin sensitivity.",
      "publication_location": "The Journal of Biological Chemistry",
      "link": "http://dx.doi.org/10.1074/jbc.M117.818351",
      "citations": 8,
      "readership": 55,
      "tweets": 33,
      "news_mentions": 8
    },
    {
      "title": "A deep convolutional neural network and a random forest classifier for solar photovoltaic array detection in aerial imagery",
      "authors": "Malof, JM; Collins, LM; Bradbury, K; Newell, RG",
      "published_date": "January 1, 2016",
      "doi": "10.1109/ICRERA.2016.7884415",
      "abstract": "© 2016 IEEE. Power generation from distributed solar photovoltaic PV arrays has grown rapidly in recent years. As a result, there is interest in collecting information about the quantity, power capacity, and energy generated by such arrays; and to do so over small geo-spatial regions (e.g., counties, cities, or even smaller regions). Unfortunately, existing sources of such information are dispersed, limited in geospatial resolution, and otherwise incomplete or publically unavailable. As result, we recently proposed a new approach for collecting such distributed PV information that relies on computer algorithms to automatically detect PV arrays in high resolution aerial imagery [1], Here we build on this work by investigating two machine learning algorithms for PV array detection: a Random Forest classifier (RF) [2] and a deep convolutional neural network (CNN) [3]. We use the RF algorithm as a benchmark, or baseline, for comparison with a CNN model. The two models are developed and tested using a large collection of publicly available [4] aerial imagery, covering 135 km2, and including over 2,700 manually annotated distributed PV array locations. The results indicate that the CNN substantially improves over the RF. The CNN is capable of excellent performance, detecting nearly 80% of true panels with a precision measure of 72%.",
      "publication_location": "2016 Ieee International Conference on Renewable Energy Research and Applications, Icrera 2016",
      "link": "http://dx.doi.org/10.1109/ICRERA.2016.7884415",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Supernova Photometric Classification Pipelines Trained on Spectroscopically Classified Supernovae from the Pan-STARRS1 Medium-deep Survey",
      "authors": "Villar, VA; Berger, E; Miller, G; Chornock, R; Rest, A; Jones, DO; Drout, MR; Foley, RJ; Kirshner, R; Lunnan, R; Magnier, E; Milisavljevic, D; Sanders, N; Scolnic, D",
      "published_date": "October 10, 2019",
      "doi": "10.3847/1538-4357/ab418c",
      "abstract": "© 2019. The American Astronomical Society. All rights reserved. Photometric classification of supernovae (SNe) is imperative as recent and upcoming optical time-domain surveys, such as the Large Synoptic Survey Telescope (LSST), overwhelm the available resources for spectrosopic follow-up. Here we develop a range of light curve (LC) classification pipelines, trained on 513 spectroscopically classified SNe from the Pan-STARRS1 Medium-Deep Survey (PS1-MDS): 357 Type Ia, 93 Type II, 25 Type IIn, 21 Type Ibc, and 17 Type I superluminous SNe (SLSNe). We present a new parametric analytical model that can accommodate a broad range of SN LC morphologies, including those with a plateau, and fit this model to data in four PS1 filters (g P1 r P1 i P1 z P1). We test a number of feature extraction methods, data augmentation strategies, and machine-learning algorithms to predict the class of each SN. Our best pipelines result in ≈90% average accuracy, ≈70% average purity, and ≈80% average completeness for all SN classes, with the highest success rates for SNe Ia and SLSNe and the lowest for SNe Ibc. Despite the greater complexity of our classification scheme, the purity of our SN Ia classification, ≈95%, is on par with methods developed specifically for Type Ia versus non-Type Ia binary classification. As the first of its kind, this study serves as a guide to developing and training classification algorithms for a wide range of SN types with a purely empirical training set, particularly one that is similar in its characteristics to the expected LSST main survey strategy. Future work will implement this classification pipeline on ≈3000 PS1/MDS LCs that lack spectroscopic classification.",
      "publication_location": "The Astrophysical Journal",
      "link": "http://dx.doi.org/10.3847/1538-4357/ab418c",
      "citations": "(None,)",
      "readership": 16,
      "tweets": 1,
      "news_mentions": 2
    },
    {
      "title": "Correcting Type Ia Supernova Distances for Selection Biases and Contamination in Photometrically Identified Samples",
      "authors": "Kessler, R; Scolnic, D",
      "published_date": "February 10, 2017",
      "doi": "10.3847/1538-4357/836/1/56",
      "abstract": "© 2017. The American Astronomical Society. All rights reserved. We present a new technique to create a bin-averaged Hubble diagram (HD) from photometrically identified SN Ia data. The resulting HD is corrected for selection biases and contamination from core-collapse (CC) SNe, and can be used to infer cosmological parameters. This method, called \"BEAMS with Bias Corrections\" (BBC), includes two fitting stages. The first BBC fitting stage uses a posterior distribution that includes multiple SN likelihoods, a Monte Carlo simulation to bias-correct the fitted SALT-II parameters, and CC probabilities determined from a machine-learning technique. The BBC fit determines (1) a bin-averaged HD (average distance versus redshift), and (2) the nuisance parameters α and β, which multiply the stretch and color (respectively) to standardize the SN brightness. In the second stage, the bin-averaged HD is fit to a cosmological model where priors can be imposed. We perform high-precision tests of the BBC method by simulating large (150,000 event) data samples corresponding to the Dark Energy Survey Supernova Program. Our tests include three models of intrinsic scatter, each with two different CC rates. In the BBC fit, the SALT-II nuisance parameters α and β are recovered to within 1% of their true values. In the cosmology fit, we determine the dark energy equation of state parameter w using a fixed value of ΩM as a prior: averaging over all six tests based on 6 × 150,000 = 900,000 SNe, there is a small w-bias of . Finally, the BBC fitting code is publicly available in the SNANA package.",
      "publication_location": "The Astrophysical Journal",
      "link": "http://dx.doi.org/10.3847/1538-4357/836/1/56",
      "citations": 43,
      "readership": 31,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "HOST GALAXY IDENTIFICATION for SUPERNOVA SURVEYS",
      "authors": "Gupta, RR; Kuhlmann, S; Kovacs, E; Spinka, H; Kessler, R; Goldstein, DA; Liotine, C; Pomian, K; D'Andrea, CB; Sullivan, M; Carretero, J; Castander, FJ; Nichol, RC; Finley, DA; Fischer, JA; Foley, RJ; Kim, AG; Papadopoulos, A; Sako, M; Scolnic, DM; Smith, M; Tucker, BE; Uddin, S; Wolf, RC; Yuan, F; Abbott, TMC; Abdalla, FB; Benoit-Lévy, A; Bertin, E; Brooks, D; Rosell, AC; Kind, MC; Cunha, CE; Costa, LND; Desai, S; Doel, P; Eifler, TF; Evrard, AE; Flaugher, B; Fosalba, P; Gaztaaga, E; Gruen, D; Gruendl, R; James, DJ; Kuehn, K; Kuropatkin, N; Maia, MAG; Marshall, JL; Miquel, R; Plazas, AA; Romer, AK; Sánchez, E; Schubnell, M; Sevilla-Noarbe, I; Sobreira, F; Suchyta, E; Swanson, MEC; Tarle, G; Walker, AR; Wester, W",
      "published_date": "December 1, 2016",
      "doi": "10.3847/0004-6256/152/6/154",
      "abstract": "© 2016. The American Astronomical Society. All rights reserved. Host galaxy identification is a crucial step for modern supernova (SN) surveys such as the Dark Energy Survey and the Large Synoptic Survey Telescope, which will discover SNe by the thousands. Spectroscopic resources are limited, and so in the absence of real-time SN spectra these surveys must rely on host galaxy spectra to obtain accurate redshifts for the Hubble diagram and to improve photometric classification of SNe. In addition, SN luminosities are known to correlate with host-galaxy properties. Therefore, reliable identification of host galaxies is essential for cosmology and SN science. We simulate SN events and their locations within their host galaxies to develop and test methods for matching SNe to their hosts. We use both real and simulated galaxy catalog data from the Advanced Camera for Surveys General Catalog and MICECATv2.0, respectively. We also incorporate \"hostless\" SNe residing in undetected faint hosts into our analysis, with an assumed hostless rate of 5%. Our fully automated algorithm is run on catalog data and matches SNe to their hosts with 91% accuracy. We find that including a machine learning component, run after the initial matching algorithm, improves the accuracy (purity) of the matching to 97% with a 2% cost in efficiency (true positive rate). Although the exact results are dependent on the details of the survey and the galaxy catalogs used, the method of identifying host galaxies we outline here can be applied to any transient survey.",
      "publication_location": "The Astronomical Journal",
      "link": "http://dx.doi.org/10.3847/0004-6256/152/6/154",
      "citations": 28,
      "readership": 36,
      "tweets": 4,
      "news_mentions": 3
    },
    {
      "title": "Imaging Genetics and Genomics in Psychiatry: A Critical Review of Progress and Potential.",
      "authors": "Bogdan, R; Salmeron, BJ; Carey, CE; Agrawal, A; Calhoun, VD; Garavan, H; Hariri, AR; Heinz, A; Hill, MN; Holmes, A; Kalin, NH; Goldman, D",
      "published_date": "August 2017",
      "doi": "10.1016/j.biopsych.2016.12.030",
      "abstract": "Imaging genetics and genomics research has begun to provide insight into the molecular and genetic architecture of neural phenotypes and the neural mechanisms through which genetic risk for psychopathology may emerge. As it approaches its third decade, imaging genetics is confronted by many challenges, including the proliferation of studies using small sample sizes and diverse designs, limited replication, problems with harmonization of neural phenotypes for meta-analysis, unclear mechanisms, and evidence that effect sizes may be more modest than originally posited, with increasing evidence of polygenicity. These concerns have encouraged the field to grow in many new directions, including the development of consortia and large-scale data collection projects and the use of novel methods (e.g., polygenic approaches, machine learning) that enhance the quality of imaging genetic studies but also introduce new challenges. We critically review progress in imaging genetics and offer suggestions and highlight potential pitfalls of novel approaches. Ultimately, the strength of imaging genetics and genomics lies in their translational and integrative potential with other research approaches (e.g., nonhuman animal models, psychiatric genetics, pharmacologic challenge) to elucidate brain-based pathways that give rise to the vast individual differences in behavior as well as risk for psychopathology.",
      "publication_location": "Biological Psychiatry",
      "link": "http://dx.doi.org/10.1016/j.biopsych.2016.12.030",
      "citations": 60,
      "readership": 155,
      "tweets": 31,
      "news_mentions": ""
    },
    {
      "title": "Drosophila ORC localizes to open chromatin and marks sites of cohesin complex loading.",
      "authors": "MacAlpine, HK; Gordân, R; Powell, SK; Hartemink, AJ; MacAlpine, DM",
      "published_date": "February 2010",
      "doi": "10.1101/gr.097873.109",
      "abstract": "The origin recognition complex (ORC) is an essential DNA replication initiation factor conserved in all eukaryotes. In Saccharomyces cerevisiae, ORC binds to specific DNA elements; however, in higher eukaryotes, ORC exhibits little sequence specificity in vitro or in vivo. We investigated the genome-wide distribution of ORC in Drosophila and found that ORC localizes to specific chromosomal locations in the absence of any discernible simple motif. Although no clear sequence motif emerged, we were able to use machine learning approaches to accurately discriminate between ORC-associated sequences and ORC-free sequences based solely on primary sequence. The complex sequence features that define ORC binding sites are highly correlated with nucleosome positioning signals and likely represent a preferred nucleosomal landscape for ORC association. Open chromatin appears to be the underlying feature that is deterministic for ORC binding. ORC-associated sequences are enriched for the histone variant, H3.3, often at transcription start sites, and depleted for bulk nucleosomes. The density of ORC binding along the chromosome is reflected in the time at which a sequence replicates, with early replicating sequences having a high density of ORC binding. Finally, we found a high concordance between sites of ORC binding and cohesin loading, suggesting that, in addition to DNA replication, ORC may be required for the loading of cohesin on DNA in Drosophila.",
      "publication_location": "Genome Res",
      "link": "http://dx.doi.org/10.1101/gr.097873.109",
      "citations": 197,
      "readership": 158,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "A novel, data-driven conceptualization for critical left heart obstruction.",
      "authors": "Meza, JM; Slieker, M; Blackstone, EH; Mertens, L; DeCampli, WM; Kirklin, JK; Karimi, M; Eghtesady, P; Pourmoghadam, K; Kim, RW; Burch, PT; Jacobs, ML; Karamlou, T; McCrindle, BW; Congenital Heart Surgeons’ Society,",
      "published_date": "October 2018",
      "doi": "10.1016/j.cmpb.2018.08.014",
      "abstract": "BACKGROUND:Qualitative features of aortic and mitral valvar pathology have traditionally been used to classify congenital cardiac anomalies for which the left heart structures are unable to sustain adequate systemic cardiac output. We aimed to determine if novel groups of patients with greater clinical relevance could be defined within this population of patients with critical left heart obstruction (CLHO) using a data-driven approach based on both qualitative and quantitative echocardiographic measures. METHODS:An independent standardized review of recordings from pre-intervention transthoracic echocardiograms for 651 neonates with CLHO was performed. An unsupervised cluster analysis, incorporating 136 echocardiographic measures, was used to group patients with similar characteristics. Key measures differentiating the groups were then identified. RESULTS:Based on all measures, cluster analysis linked the 651 neonates into groups of 215 (Group 1), 338 (Group 2), and 98 (Group 3) patients. Aortic valve atresia and left ventricular (LV) end diastolic volume were identified as significant variables differentiating the groups. The median LV end diastolic area was 1.35, 0.69, and 2.47 cm2 in Groups 1, 2, and 3, respectively (p < 0.0001). Aortic atresia was present in 11% (24/215), 87% (294/338), and 8% (8/98), in Groups 1, 2, and 3, respectively (p < 0.0001). Balloon aortic valvotomy was the first intervention for 9% (19/215), 2% (6/338), and 61% (60/98), respectively (p < 0.0001). For those with an initial operation, single ventricle palliation was performed in 90% (176/215), 98% (326/338), and 58% (22/38) (p < 0.0001). Overall mortality in each group was 27% (59/215), 41% (138/338), and 12% (12/98) (p < 0.0001). CONCLUSIONS:Using a data-driven approach, we conceptualized three distinct patient groups, primarily based quantitatively on baseline LV size and qualitatively by the presence of aortic valve atresia. Management strategy and overall mortality differed significantly by group. These groups roughly correspond anatomically and are analogous to multi-level LV hypoplasia, hypoplastic left heart syndrome, and critical aortic stenosis, respectively. Our analysis suggests that quantitative and qualitative assessment of left heart structures, particularly LV size and type of aortic valve pathology, may yield conceptually more internally consistent groups than a simplistic scheme limited to valvar pathology alone.",
      "publication_location": "Computer Methods and Programs in Biomedicine",
      "link": "http://dx.doi.org/10.1016/j.cmpb.2018.08.014",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "New Concepts in Sudden Cardiac Arrest to Address an Intractable Epidemic: JACC State-of-the-Art Review.",
      "authors": "Narayan, SM; Wang, PJ; Daubert, JP",
      "published_date": "January 8, 2019",
      "doi": "10.1016/j.jacc.2018.09.083",
      "abstract": "Sudden cardiac arrest (SCA) is one of the largest causes of mortality globally, with an out-of-hospital survival below 10% despite intense research. This document outlines challenges in addressing the epidemic of SCA, along the framework of respond, understand and predict, and prevent. Response could be improved by technology-assisted orchestration of community responder systems, access to automated external defibrillators, and innovations to match resuscitation resources to victims in place and time. Efforts to understand and predict SCA may be enhanced by refining taxonomy along phenotypical and pathophysiological \"axes of risk,\" extending beyond cardiovascular pathology to identify less heterogeneous cohorts, facilitated by open-data platforms and analytics including machine learning to integrate discoveries across disciplines. Prevention of SCA must integrate these concepts, recognizing that all members of society are stakeholders. Ultimately, solutions to the public health challenge of SCA will require greater awareness, societal debate and focused public policy.",
      "publication_location": "J Am Coll Cardiol",
      "link": "http://dx.doi.org/10.1016/j.jacc.2018.09.083",
      "citations": 10,
      "readership": 86,
      "tweets": 131,
      "news_mentions": ""
    },
    {
      "title": "Computational intelligence virtual community: Framework and implementation issues",
      "authors": "Zurada, JM; Wojtusiak, J; Chowdhury, F; Gentle, JE; Jeannot, CJ; Mazurowski, MA",
      "published_date": "November 24, 2008",
      "doi": "10.1109/IJCNN.2008.4634244",
      "abstract": "This paper discusses the framework for virtual collaborative environment for researchers, practitioners, users and learners in the areas of computational intelligence and machine learning (CIML) that is currently developed by our group. It also outlines main features of the community portal under construction that will support communication and sharing of computational resources. In particular, selected aspects of structure of the portal such as common formats of data, models, software, publications and software documentation are discussed. The preliminary portal is available at UKL: www.cimlcommunity.org. © 2008 IEEE.",
      "publication_location": "Proceedings of the International Joint Conference on Neural Networks",
      "link": "http://dx.doi.org/10.1109/IJCNN.2008.4634244",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A comparative study of database reduction methods for case-based computer-aided detection systems: Preliminary results",
      "authors": "Mazurowski, MA; Malof, JM; Zurada, JM; Tourassi, GD",
      "published_date": "June 15, 2009",
      "doi": "10.1117/12.812442",
      "abstract": "In case-based computer-aided decision systems (CB-CAD) a query case is compared to known examples stored in the systems case base (also called a reference library). These systems offer competitive classification performance and are easy to expand. However, they also require efficient management of the case base. As CB-CAD systems are becoming more popular, the problem of case base optimization has recently attracted interest among CAD researchers. In this paper we present preliminary results of a study comparing several case base reduction techniques. We implemented six techniques previously proposed in machine learning literature and applied it to the classification problem of distinguishing masses and normal tissue in mammographic regions of interest. The results show that the random mutation hill climbing technique offers a drastic reduction of the number of case base examples while providing a significant improvement in classification performance. Random selection allowed for reduction of the case base to 30% without notable decrease in performance. The remaining techniques (i.e., condensed nearest neighbor, reduced nearest neighbor, edited nearest neighbor, and All k-NN) resulted in moderate reduction (to 50-70% of the original size) at the cost of decrease in CB-CAD performance.©2009 SPIE.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.812442",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Computational approach to radiogenomics of breast cancer: Luminal A and luminal B molecular subtypes are associated with imaging features on routine breast MRI extracted using computer vision algorithms.",
      "authors": "Grimm, LJ; Zhang, J; Mazurowski, MA",
      "published_date": "October 2015",
      "doi": "10.1002/jmri.24879",
      "abstract": "PURPOSE: To identify associations between semiautomatically extracted MRI features and breast cancer molecular subtypes. METHODS: We analyzed routine clinical pre-operative breast MRIs from 275 breast cancer patients at a single institution in this retrospective, Institutional Review Board-approved study. Six fellowship-trained breast imagers reviewed the MRIs and annotated the cancers. Computer vision algorithms were then used to extract 56 imaging features from the cancers including morphologic, texture, and dynamic features. Surrogate markers (estrogen receptor [ER], progesterone receptor [PR], human epidermal growth factor receptor-2 [HER2]) were used to categorize tumors by molecular subtype: ER/PR+, HER2- (luminal A); ER/PR+, HER2+ (luminal B); ER/PR-, HER2+ (HER2); ER/PR/HER2- (basal). A multivariate analysis was used to determine associations between the imaging features and molecular subtype. RESULTS: The imaging features were associated with both luminal A (P = 0.0007) and luminal B (P = 0.0063) molecular subtypes. No association was found for either HER2 (P = 0.2465) or basal (P = 0.1014) molecular subtype and the imaging features. A P-value of 0.0125 (0.05/4) was considered significant. CONCLUSION: Luminal A and luminal B molecular subtype breast cancer are associated with semiautomatically extracted features from routine contrast enhanced breast MRI.",
      "publication_location": "J Magn Reson Imaging",
      "link": "http://dx.doi.org/10.1002/jmri.24879",
      "citations": 69,
      "readership": 80,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Database decomposition of a knowledge-based CAD system in mammography; An ensemble approach to improve detection",
      "authors": "Mazurowski, MA; Zurada, JM; Tourassi, GD",
      "published_date": "June 2, 2008",
      "doi": "10.1117/12.771556",
      "abstract": "Although ensemble techniques have been investigated in supervised machine learning, their potential with knowledge-based systems is unexplored. The purpose of this study is to investigate the ensemble approach with a knowledge-based (KB) CAD system for the detection of masses in screening mammograms. The system is designed to determine the presence of a mass in a query mammographic region of interest (ROI) based on its similarity with previously acquired examples of mass and normal cases. Similarity between images is assessed using normalized mutual information. Two different approaches of knowledge database decomposition were investigated to create the ensemble. The first approach was random division of the knowledge database into a pre-specified number of equal size, separate groups. The second approach was based on k-means clustering of the knowledge cases according to common texture features extracted from the ROIs. The ensemble components were fused using a linear classifier. Based on a database of 1820 ROIs (901 masses and 919 and the leave-one-out crossvalidation scheme, the ensemble techniques improved the performance of the original KB-CAD system (Az = 0.86±0.01). Specifically, random division resulted in ROC area index of Az = 0.90 ± 0.01 while k-means clustering provided further improvement (A z = 0.91 ± 0.01). Although marginally better, the improvement was statistically significant. The superiority of the k-means clustering scheme was robust regardless of the number of clusters. This study supports the idea of incorporation of ensemble techniques with knowledge-based systems in mammography.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.771556",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Modeling false positive error making patterns in radiology trainees for improved mammography education.",
      "authors": "Zhang, J; Silber, JI; Mazurowski, MA",
      "published_date": "April 2015",
      "doi": "10.1016/j.jbi.2015.01.007",
      "abstract": "INTRODUCTION: While mammography notably contributes to earlier detection of breast cancer, it has its limitations, including a large number of false positive exams. Improved radiology education could potentially contribute to alleviating this issue. Toward this goal, in this paper we propose an algorithm for modeling of false positive error making among radiology trainees. Identifying troublesome locations for the trainees could focus their training and in turn improve their performance. METHODS: The algorithm proposed in this paper predicts locations that are likely to result in a false positive error for each trainee based on the previous annotations made by the trainee. The algorithm consists of three steps. First, the suspicious false positive locations are identified in mammograms by Difference of Gaussian filter and suspicious regions are segmented by computer vision-based segmentation algorithms. Second, 133 features are extracted for each suspicious region to describe its distinctive characteristics. Third, a random forest classifier is applied to predict the likelihood of the trainee making a false positive error using the extracted features. The random forest classifier is trained using previous annotations made by the trainee. We evaluated the algorithm using data from a reader study in which 3 experts and 10 trainees interpreted 100 mammographic cases. RESULTS: The algorithm was able to identify locations where the trainee will commit a false positive error with accuracy higher than an algorithm that selects such locations randomly. Specifically, our algorithm found false positive locations with 40% accuracy when only 1 location was selected for all cases for each trainee and 12% accuracy when 10 locations were selected. The accuracies for randomly identified locations were both 0% for these two scenarios. CONCLUSIONS: In this first study on the topic, we were able to build computer models that were able to find locations for which a trainee will make a false positive error in images that were not previously seen by the trainee. Presenting the trainees with such locations rather than randomly selected ones may improve their educational outcomes.",
      "publication_location": "J Biomed Inform",
      "link": "http://dx.doi.org/10.1016/j.jbi.2015.01.007",
      "citations": 9,
      "readership": 47,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "Reports of the AAAI 2014 conference workshops",
      "authors": "Albrecht, SV; Barreto, AMS; Braziunas, D; Buckeridge, DL; Cuayáhuitl, H; Dethlefs, N; Endres, M; Farahmand, AM; Fox, M; Frommberger, L; Ganzfried, S; Guillet, S; Gil, Y; Hunter, LE; Jhala, A; Kersting, K; Konidaris, G; Lecue, F; McIlraith, S; Natarajan, S; Noorian, Z; Poole, D; Ronfard, R; Saffiotti, A; Shaban-Nejad, A; Srivastava, B; Tesauro, G; Uceda-Sosa, R; Van Den Broeck, G; Van Otterlo, M; Wallace, BC; Weng, P; Wiens, J; Zhang, J",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015, Association for the Advancement of Artificial Intelligence. All rights reserved. The AAAI-14 Workshop program was held Sunday and Monday, July 27-28, 2014, at the Québec City Convention Centre in Québec, Canada. The AAAI-14 workshop program included 15 workshops covering a wide range of topics in artificial intelligence. The titles of the workshops were Artificial Intelligence and Robotics; Artificial Intelligence Applied to Assistive Technologies and Smart Environments; Cognitive Computing for Augmented Human Intelligence; Computer Poker and Imperfect Information; Discovery Informatics; Incentives and Trust in Electronic Communities; Intelligent Cinematography and Editing; Machine Learning for Interactive Systems: Bridging the Gap Between Perception, Action, and Communication; Modern Artificial Intelligence for Health Analytics; Multiagent Interaction Without Prior Coordination; Multidisciplinary Workshop on Advances in Preference Handling; Semantic Cities - Beyond Open Data to Models, Standards, and Reasoning; Sequential Decision Making with Big Data; Statistical Relational AI; and the World Wide Web and Public Health Intelligence. This article presents short summaries of those events.",
      "publication_location": "Ai Magazine",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Atomic connectomics signatures for characterization and differentiation of mild cognitive impairment.",
      "authors": "Ou, J; Xie, L; Li, X; Zhu, D; Terry, DP; Puente, AN; Jiang, R; Chen, Y; Wang, L; Shen, D; Zhang, J; Miller, LS; Liu, T",
      "published_date": "December 2015",
      "doi": "10.1007/s11682-014-9320-1",
      "abstract": "In recent years, functional connectomics signatures have been shown to be a very valuable tool in characterizing and differentiating brain disorders from normal controls. However, if the functional connectivity alterations in a brain disease are localized within sub-networks of a connectome, then accurate identification of such disease-specific sub-networks is critical and this capability entails both fine-granularity definition of connectome nodes and effective clustering of connectome nodes into disease-specific and non-disease-specific sub-networks. In this work, we adopted the recently developed DICCCOL (dense individualized and common connectivity-based cortical landmarks) system as a fine-granularity high-resolution connectome construction method to deal with the first issue, and employed an effective variant of non-negative matrix factorization (NMF) method to pinpoint disease-specific sub-networks, which we called atomic connectomics signatures in this work. We have implemented and applied this novel framework to two mild cognitive impairment (MCI) datasets from two different research centers, and our experimental results demonstrated that the derived atomic connectomics signatures can effectively characterize and differentiate MCI patients from their normal controls. In general, our work contributed a novel computational framework for deriving descriptive and distinctive atomic connectomics signatures in brain disorders.",
      "publication_location": "Brain Imaging and Behavior",
      "link": "http://dx.doi.org/10.1007/s11682-014-9320-1",
      "citations": 6,
      "readership": 21,
      "tweets": 7,
      "news_mentions": ""
    },
    {
      "title": "Predicting Vibrio cholerae infection and disease severity using metagenomics in a prospective cohort study",
      "authors": "Levade, I; Saber, MM; Midani, F; Chowdhury, F; Khan, AI; Begum, YA; Ryan, ET; David, L; Calderwood, SB; Harris, JB; LaRocque, RC; Qadri, F; Shapiro, BJ; Weil, AA",
      "published_date": "",
      "doi": "10.1101/2020.02.25.960930",
      "abstract": "ABSTRACTBackgroundSusceptibility to Vibrio cholerae infection is impacted by blood group, age, and pre-existing immunity, but these factors only partially explain who becomes infected. A recent study used 16S rRNA amplicon sequencing to quantify the composition of the gut microbiome and identify predictive biomarkers of infection with limited taxonomic resolution.MethodsTo achieve increased resolution of gut microbial factors associated with V. cholerae susceptibility and identify predictors of symptomatic disease, we applied deep shotgun metagenomic sequencing to a cohort of household contacts of patients with cholera.ResultsUsing machine learning, we resolved species, strains, gene families, and cellular pathways in the microbiome at the time of exposure to V. cholerae to identify markers that predict infection and symptoms. Use of metagenomic features improved the precision and accuracy of prediction relative to 16S sequencing. We also predicted disease severity, although with greater uncertainty than our infection prediction. Species within the genera Prevotella and Bifidobacterium predicted protection from infection, and genes involved in iron metabolism also correlated with protection.ConclusionOur results highlight the power of metagenomics to predict disease outcomes and suggest specific species and genes for experimental testing to investigate mechanisms of microbiome-related protection from cholera.",
      "publication_location": "",
      "link": "http://dx.doi.org/10.1101/2020.02.25.960930",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 22,
      "news_mentions": ""
    },
    {
      "title": "Beyond log-concavity: Provable guarantees for sampling multi-modal distributions using simulated tempering langevin Monte Carlo",
      "authors": "Ge, R; Lee, H; Risteski, A",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 Curran Associates Inc.All rights reserved. A key task in Bayesian machine learning is sampling from distributions that are only specified up to a partition function (i.e., constant of proportionality). One prevalent example of this is sampling posteriors in parametric distributions, such as latent-variable generative models. However sampling (even very approximately) can be #P-hard. Classical results (going back to [BÉ85]) on sampling focus on log-concave distributions, and show a natural Markov chain called Langevin diffusion mixes in polynomial time. However, all log-concave distributions are uni-modal, while in practice it is very common for the distribution of interest to have multiple modes. In this case, Langevin diffusion suffers from torpid mixing. We address this problem by combining Langevin diffusion with simulated tempering. The result is a Markov chain that mixes more rapidly by transitioning between different temperatures of the distribution. We analyze this Markov chain for a mixture of (strongly) log-concave distributions of the same shape. In particular, our technique applies to the canonical multi-modal distribution: a mixture of gaussians (of equal variance). Our algorithm efficiently samples from these distributions given only access to the gradient of the log-pdf. To the best of our knowledge, this is the first result that proves fast mixing for multimodal distributions in this setting. For the analysis, we introduce novel techniques for proving spectral gaps based on decomposing the action of the generator of the diffusion. Previous approaches rely on decomposing the state space as a partition of sets, while our approach can be thought of as decomposing the stationary measure as a mixture of distributions (a “soft partition”). Additional materials for the paper can be found at http://tiny.cc/glr17. Note that the proof and results have been improved and generalized from the precursor at http://www.arxiv.org/abs/1710.02736. See Section for a comparison.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Computing a nonnegative matrix factorization-provably",
      "authors": "Arora, S; Ge, R; Kannan, R; Moitra, A",
      "published_date": "January 1, 2016",
      "doi": "10.1137/130913869",
      "abstract": "© 2016 the authors. In the nonnegative matrix factorization (NMF) problem we are given an n × m nonnegative matrix M and an integer r > 0. Our goal is to express M as AW, where A and W are nonnegative matrices of size n×r and r×m, respectively. In some applications, it makes sense to ask instead for the product AW to approximate M, i.e. (approximately) minimize ||M - AWF||, where || ||F,denotes the Frobenius norm; we refer to this as approximate NMF. This problem has a rich history spanning quantum mechanics, probability theory, data analysis, polyhedral combinatorics, communication complexity, demography, chemometrics, etc. In the past decade NMF has become enormously popular in machine learning, where A and W are computed using a variety of local search heuristics. Vavasis recently proved that this problem is NP-complete. (Without the restriction that A and W be nonnegative, both the exact and approximate problems can be solved optimally via the singular value decomposition.) We initiate a study of when this problem is solvable in polynomial time. Our results are the following: 1. We give a polynomial-time algorithm for exact and approximate NMF for every constant r. Indeed NMF is most interesting in applications precisely when r is small. 2. We complement this with a hardness result, that if exact NMF can be solved in time (nm)o(r), 3-SAT has a subexponential-time algorithm. This rules out substantial improvements to the above algorithm. 3. We give an algorithm that runs in time polynomial in n, m, and r under the separablity condition identified by Donoho and Stodden in 2003. The algorithm may be practical since it is simple and noise tolerant (under benign assumptions). Separability is believed to hold in many practical settings. To the best of our knowledge, this last result is the first example of a polynomial-time algorithm that provably works under a non-trivial condition on the input and we believe that this will be an interesting and important direction for future work.",
      "publication_location": "Siam Journal on Computing",
      "link": "http://dx.doi.org/10.1137/130913869",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Computing a nonnegative matrix factorization - Provably",
      "authors": "Arora, S; Ge, R; Kannan, R; Moitra, A",
      "published_date": "June 26, 2012",
      "doi": "10.1145/2213977.2213994",
      "abstract": "The Nonnegative Matrix Factorization (NMF) problem has a rich history spanning quantum mechanics, probability theory, data analysis, polyhedral combinatorics, communication complexity, demography, chemometrics, etc. In the past decade NMF has become enormously popular in machine learning, where the factorization is computed using a variety of local search heuristics. Vavasis recently proved that this problem is NP-complete. We initiate a study of when this problem is solvable in polynomial time. Consider a nonnegative m x n matrix M and a target inner-dimension r. Our results are the following: 1. We give a polynomial-time algorithm for exact and approximate NMF for every constant r. Indeed NMF is most interesting in applications precisely when r is small. 2. We complement this with a hardness result, that if exact NMF can be solved in time (nm) o(r), 3-SAT has a sub-exponential time algorithm. Hence, substantial improvements to the above algorithm are unlikely. 3. We give an algorithm that runs in time polynomial in n, m and r under the separablity condition identified by Donoho and Stodden in 2003. The algorithm may be practical since it is simple and noise tolerant (under benign assumptions). Separability is believed to hold in many practical settings. To the best of our knowledge, this last result is the first polynomial-time algorithm that provably works under a non-trivial condition on the input matrix and we believe that this will be an interesting and important direction for future work. © 2012 ACM.",
      "publication_location": "Proceedings of the Annual Acm Symposium on Theory of Computing",
      "link": "http://dx.doi.org/10.1145/2213977.2213994",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Matrix completion has no spurious local minimum",
      "authors": "Ge, R; Lee, JD; Ma, T",
      "published_date": "January 1, 2016",
      "doi": "",
      "abstract": "© 2016 NIPS Foundation - All Rights Reserved. Matrix completion is a basic machine learning problem that has wide applications, especially in collaborative filtering and recommender systems. Simple non-convex optimization algorithms are popular and effective in practice. Despite recent progress in proving various non-convex algorithms converge from a good initial point, it remains unclear why random or arbitrary initialization suffices in practice. We prove that the commonly used non-convex objective function for positive semidefinite matrix completion has no spurious local minima - all local minima must also be global. Therefore, many popular optimization algorithms such as (stochastic) gradient descent can provably solve positive semidefinite matrix completion with arbitrary initialization in polynomial time. The result can be generalized to the setting when the observed entries contain noise. We believe that our main proof strategy can be useful for understanding geometric properties of other statistical problems involving partial or noisy observations.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Banff Digital Pathology Working Group: Going digital in transplant pathology.",
      "authors": "Farris, AB; Moghe, I; Wu, S; Hogan, J; Cornell, LD; Alexander, MP; Kers, J; Demetris, AJ; Levenson, RM; Tomaszewski, J; Barisoni, L; Yagi, Y; Solez, K",
      "published_date": "March 17, 2020",
      "doi": "10.1111/ajt.15850",
      "abstract": "The Banff Digital Pathology Working Group (DPWG) was formed in the time leading up to and during the joint American Society for Histocompatibility and Immunogenetics/Banff Meeting, September 23-27, 2019, held in Pittsburgh, Pennsylvania. At the meeting, the 14th Banff Conference, presentations directly and peripherally related to the topic of \"digital pathology\" were presented; and discussions before, during, and after the meeting have resulted in a list of issues to address for the DPWG. Included are practice standardization, integrative approaches for study classification, scoring of histologic parameters (eg, interstitial fibrosis and tubular atrophy and inflammation), algorithm classification, and precision diagnosis (eg, molecular pathways and therapeutics). Since the meeting, a survey with international participation of mostly pathologists (81%) was conducted, showing that whole slide imaging is available at the majority of centers (71%) but that artificial intelligence (AI)/machine learning was only used in ≈12% of centers, with a wide variety of programs/algorithms employed. Digitalization is not just an end in itself. It also is a necessary precondition for AI and other approaches. Discussions at the meeting and the survey highlight the unmet need for a Banff DPWG and point the way toward future contributions that can be made.",
      "publication_location": "Am J Transplant",
      "link": "http://dx.doi.org/10.1111/ajt.15850",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 19,
      "news_mentions": ""
    },
    {
      "title": "A phylogenetic transform enhances analysis of compositional microbiota data",
      "authors": "Silverman, J; Washburne, A; Mukherjee, S; David, L",
      "published_date": "August 31, 2016",
      "doi": "10.1101/072413",
      "abstract": "ABSTRACT High-throughput DNA sequencing technologies have revolutionized the study of microbial communities (microbiota) and have revealed their importance in both human health and disease. However, due to technical limitations, data from microbiota surveys reflect the relative abundance of bacterial taxa and not their absolute levels. It is well known that applying common statistical methods, such as correlation or hypothesis testing, to relative abundance data can lead to spurious results. Here, we introduce the PhILR transform, a data transform that utilizes microbial phylogenetic information. This transform enables off-the-shelf statistical tools to be applied to microbiota surveys free from artifacts usually associated with analysis of relative abundance data. Using environmental and human-associated microbial community datasets as benchmarks, we find that the PhILR transform significantly improves the performance of distance-based and machine learning-based statistics, boosting the accuracy of widely used algorithms on reference benchmarks by 90%. Because the PhILR transform relies on bacterial phylogenies, statistics applied in the PhILR coordinate system are also framed within an evolutionary perspective. Regression on PhILR transformed human microbiota data identified evolutionarily neighboring bacterial clades that may have differentiated to adapt to distinct body sites. Variance statistics showed that the degree of covariation of bacterial clades across human body sites tended to increase with phylogenetic relatedness between clades. These findings support the hypothesis that environmental selection, not competition between bacteria, plays a dominant role in structuring human-associated microbial communities.",
      "publication_location": "",
      "link": "http://dx.doi.org/10.1101/072413",
      "citations": 5,
      "readership": 22,
      "tweets": 24,
      "news_mentions": ""
    },
    {
      "title": "Ads-portal domains: Identification and measurements",
      "authors": "Almishari, M; Yang, X",
      "published_date": "April 1, 2010",
      "doi": "10.1145/1734200.1734201",
      "abstract": "An ads-portal domain refers to a Web domain that shows only advertisements, served by a third-party advertisement syndication service, in the form of ads listing. We develop a machine-learning-based classifier to identify ads-portal domains, which has 96% accuracy. We use this classifier to measure the prevalence of ads-portal domains on the Internet. Surprisingly, 28.3/25% of the (two-level) *.com/*.net web domains are ads-portal domains. Also, 41/39.8% of *.com/ *.net ads-portal domains are typos of well-known domains, also known as typo-squatting domains. In addition, we use the classifier along with DNS trace files to estimate how often Internet users visit ads-portal domains. It turns out that ∼5% of the two-level *.com, *.net, *.org, *.biz and *.info web domains on the traces are ads-portal domains and ∼50% of these accessed ads-portal domains are typos. These numbers show that ads-portal domains and typo-squatting ads-portal domains are prevalent on the Internet and successful in attracting many visits. Our classifier represents a step towards better categorizing the web documents. It can also be helpful to search engines ranking algorithms, helpful in identifying web spams that redirects to ads-portal domains, and used to discourage access to typo-squatting ads-portal domains. © 2010 ACM.",
      "publication_location": "Acm Transactions on the Web",
      "link": "http://dx.doi.org/10.1145/1734200.1734201",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Growing a list",
      "authors": "Letham, B; Rudin, C; Heller, KA",
      "published_date": "December 1, 2013",
      "doi": "10.1007/s10618-013-0329-7",
      "abstract": "It is easy to find expert knowledge on the Internet on almost any topic, but obtaining a complete overview of a given topic is not always easy: information can be scattered across many sources and must be aggregated to be useful. We introduce a method for intelligently growing a list of relevant items, starting from a small seed of examples. Our algorithm takes advantage of the wisdom of the crowd, in the sense that there are many experts who post lists of things on the Internet. We use a collection of simple machine learning components to find these experts and aggregate their lists to produce a single complete and meaningful list. We use experiments with gold standards and open-ended experiments without gold standards to show that our method significantly outperforms the state of the art. Our method uses the ranking algorithm Bayesian Sets even when its underlying independence assumption is violated, and we provide a theoretical generalization bound to motivate its use. © 2013 The Author(s).",
      "publication_location": "Data Mining and Knowledge Discovery",
      "link": "http://dx.doi.org/10.1007/s10618-013-0329-7",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Clinical Prediction Models for Sleep Apnea: The Importance of Medical History over Symptoms.",
      "authors": "Ustun, B; Westover, MB; Rudin, C; Bianchi, MT",
      "published_date": "February 2016",
      "doi": "10.5664/jcsm.5476",
      "abstract": "Obstructive sleep apnea (OSA) is a treatable contributor to morbidity and mortality. However, most patients with OSA remain undiagnosed. We used a new machine learning method known as SLIM (Supersparse Linear Integer Models) to test the hypothesis that a diagnostic screening tool based on routinely available medical information would be superior to one based solely on patient-reported sleep-related symptoms.We analyzed polysomnography (PSG) and self-reported clinical information from 1,922 patients tested in our clinical sleep laboratory. We used SLIM and 7 state-of-the-art classification methods to produce predictive models for OSA screening using features from: (i) self-reported symptoms; (ii) self-reported medical information that could, in principle, be extracted from electronic health records (demographics, comorbidities), or (iii) both.For diagnosing OSA, we found that model performance using only medical history features was superior to model performance using symptoms alone, and similar to model performance using all features. Performance was similar to that reported for other widely used tools: sensitivity 64.2% and specificity 77%. SLIM accuracy was similar to state-of-the-art classification models applied to this dataset, but with the benefit of full transparency, allowing for hands-on prediction using yes/no answers to a small number of clinical queries.To predict OSA, variables such as age, sex, BMI, and medical history are superior to the symptom variables we examined for predicting OSA. SLIM produces an actionable clinical tool that can be applied to data that is routinely available in modern electronic health records, which may facilitate automated, rather than manual, OSA screening.A commentary on this article appears in this issue on page 159.",
      "publication_location": "Journal of Clinical Sleep Medicine : Jcsm : Official Publication of the American Academy of Sleep Medicine",
      "link": "http://dx.doi.org/10.5664/jcsm.5476",
      "citations": 30,
      "readership": 50,
      "tweets": "(None,)",
      "news_mentions": 2
    },
    {
      "title": "Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model",
      "authors": "Letham, B; Rudin, C; McCormick, TH; Madigan, D",
      "published_date": "January 1, 2015",
      "doi": "10.1214/15-AOAS848",
      "abstract": "© Institute of Mathematical Statistics, 2015. We aim to produce predictive models that are not only accurate, but are also interpretable to human experts. Our models are decision lists, which consist of a series of if … then. . . statements (e.g., if high blood pressure, then stroke) that discretize a high-dimensional, multivariate feature space into a series of simple, readily interpretable decision statements. We introduce a generative model called Bayesian Rule Lists that yields a posterior distribution over possible decision lists. It employs a novel prior structure to encourage sparsity. Our experiments show that Bayesian Rule Lists has predictive accuracy on par with the current top algorithms for prediction in machine learning. Our method is motivated by recent developments in personalized medicine, and can be used to produce highly accurate and interpretable medical scoring systems. We demonstrate this by producing an alternative to the CHADS2 score, actively used in clinical practice for estimating the risk of stroke in patients that have atrial fibrillation. Our model is as interpretable as CHADS2, but more accurate.",
      "publication_location": "The Annals of Applied Statistics",
      "link": "http://dx.doi.org/10.1214/15-AOAS848",
      "citations": 127,
      "readership": 405,
      "tweets": 10,
      "news_mentions": ""
    },
    {
      "title": "Do as they did: Peer effects explain adoption of conservation agriculture in Malawi",
      "authors": "Bell, AR; Cheek, JZ; Mataya, F; Ward, PS",
      "published_date": "January 10, 2018",
      "doi": "10.3390/w10010051",
      "abstract": "© 2018 by the authors. Adoption of the trinity of practices known commonly today as conservation agriculture (CA)-maintaining soil cover, reducing tillage, and enhancing soil nitrogen through legumes-is a critical process to the management of erosion in rural landscapes, and maintenance of aquatic habitats and hydropower potential. However, the large literature on the benefits and risks of CA fails to find any universal determinants of adoption, with competing uses for crop residues, availability of labor, and access to physical inputs common constraints appearing in different contexts. We conduct a study in the specific context of Malawi, using ethnographic interviewing to draw out possible decision criteria and machine learning to identify their explanatory power. This study is structured to inform the question: \"How do farmers decide to adopt the specific activities of CA in Malawi?\" We find that more than any other factor, adoption by neighbors (i.e., peer effects) matters, with possible implications for the overall cost of encouraging CA (e.g., through subsidies) as it is taken up across a landscape. Further, we note that little else within our household survey (save for more detailed articulation of neighbor and neighborhood characteristics) offers greater explanatory power than those factors identified by farmers themselves. Finally, we note that decisions made in the presence of an incentive are structurally different than those made without incentives, validating previous concerns in the literature regarding the basis most CA adoption studies, within CA promotion interventions.",
      "publication_location": "Water (Switzerland)",
      "link": "http://dx.doi.org/10.3390/w10010051",
      "citations": 8,
      "readership": 44,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Topological and statistical behavior classifiers for tracking applications",
      "authors": "Bendich, P; Chin, SP; Clark, J; DeSena, J; Harer, J; Munch, E; Newman, A; Porter, D; Rouse, D; Strawn, N; Watkins, A",
      "published_date": "December 1, 2016",
      "doi": "10.1109/TAES.2016.160405",
      "abstract": "© 1965-2011 IEEE. This paper introduces a method to integrate target behavior into the multiple hypothesis tracker (MHT) likelihood ratio. In particular, a periodic track appraisal based on behavior is introduced. The track appraisal uses elementary topological data analysis coupled with basic machine-learning techniques, and it adjusts the traditional kinematic data association likelihood (i.e., track score) using an established formulation for feature-aided data association. The proposed method is tested and demonstrated on synthetic vehicular data representing an urban traffic scene generated by the Simulation of Urban Mobility package. The vehicles in the scene exhibit different driving behaviors. The proposed method distinguishes those behaviors and shows improved data association decisions relative to a conventional, kinematic MHT.",
      "publication_location": "Ieee Transactions on Aerospace and Electronic Systems",
      "link": "http://dx.doi.org/10.1109/TAES.2016.160405",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Feature-aided multiple hypothesis tracking using topological and statistical behavior classifiers",
      "authors": "Rouse, D; Watkins, A; Porter, D; Harer, J; Bendich, P; Strawn, N; Munch, E; Desena, J; Clarke, J; Gilbert, J; Chin, S; Newman, A",
      "published_date": "January 1, 2015",
      "doi": "10.1117/12.2179555",
      "abstract": "© 2015 SPIE. This paper introduces a method to integrate target behavior into the multiple hypothesis tracker (MHT) likelihood ratio. In particular, a periodic track appraisal based on behavior is introduced that uses elementary topological data analysis coupled with basic machine learning techniques. The track appraisal adjusts the traditional kinematic data association likelihood (i.e., track score) using an established formulation for classification-aided data association. The proposed method is tested and demonstrated on synthetic vehicular data representing an urban traffic scene generated by the Simulation of Urban Mobility package. The vehicles in the scene exhibit different driving behaviors. The proposed method distinguishes those behaviors and shows improved data association decisions relative to a conventional, kinematic MHT.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2179555",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Novel non-histocompatibility antigen mismatched variants improve the ability to predict antibody-mediated rejection risk in kidney transplant",
      "authors": "Pineda, S; Sigdel, TK; Chen, J; Jackson, AM; Sirota, M; Sarwal, MM",
      "published_date": "December 5, 2017",
      "doi": "10.3389/fimmu.2017.01687",
      "abstract": "© 2017 Pineda, Sigdel, Chen, Jackson, Sirota and Sarwal. Transplant rejection is the critical clinical end-point limiting indefinite survival after histocompatibility antigen (HLA) mismatched organ transplantation. The predominant cause of late graft loss is antibody-mediated rejection (AMR), a process whereby injury to the organ is caused by donor-specific antibodies, which bind to HLA and non-HLA (nHLA) antigens. AMR is incompletely diagnosed as donor/recipient (D/R) matching is only limited to the HLA locus and critical nHLA immunogenic antigens remain to be identified. We have developed an integrative computational approach leveraging D/R exome sequencing and gene expression to predict clinical post-transplant outcome. We performed a rigorous statistical analysis of 28 highly annotated D/R kidney transplant pairs with biopsy-confirmed clinical outcomes of rejection [either AMR or T-cell-mediated rejection (CMR)] and no-rejection (NoRej), identifying a significantly higher number of mismatched nHLA variants in AMR (ANOVA-p-value = 0.02). Using Fisher's exact test, we identified 123 variants associated mainly with risk of AMR (p-value < 0.001). In addition, we applied a machine-learning technique to circumvent the issue of statistical power and we found a subset of 65 variants using random forest, that are predictive of post-tx AMR showing a very low error rate. These variants are functionally relevant to the rejection process in the kidney and AMR as they relate to genes and/or expression quantitative trait loci (eQTLs) that are enriched in genes expressed in kidney and vascular endothelium and underlie the immunobiology of graft rejection. In addition to current D/R HLA mismatch evaluation, additional mismatch nHLA D/R variants will enhance the stratification of post-tx AMR risk even before engraftment of the organ. This innovative study design is applicable in all solid organ transplants, where the impact of mitigating AMR on graft survival may be greater, with considerable benefits on improving human morbidity and mortality and opens the door to precision immunosuppression and extended tx survival.",
      "publication_location": "Frontiers in Immunology",
      "link": "http://dx.doi.org/10.3389/fimmu.2017.01687",
      "citations": 13,
      "readership": 32,
      "tweets": 12,
      "news_mentions": ""
    },
    {
      "title": "Uncovering the heterogeneity and temporal complexity of neurodegenerative diseases with Subtype and Stage Inference.",
      "authors": "Young, AL; Marinescu, RV; Oxtoby, NP; Bocchetta, M; Yong, K; Firth, NC; Cash, DM; Thomas, DL; Dick, KM; Cardoso, J; van Swieten, J; Borroni, B; Galimberti, D; Masellis, M; Tartaglia, MC; Rowe, JB; Graff, C; Tagliavini, F; Frisoni, GB; Laforce, R; Finger, E; de Mendonça, A; Sorbi, S; Warren, JD; Crutch, S; Fox, NC; Ourselin, S; Schott, JM; Rohrer, JD; Alexander, DC; Genetic FTD Initiative (GENFI), ; Alzheimer’s Disease Neuroimaging Initiative (ADNI),",
      "published_date": "October 15, 2018",
      "doi": "10.1038/s41467-018-05892-0",
      "abstract": "The heterogeneity of neurodegenerative diseases is a key confound to disease understanding and treatment development, as study cohorts typically include multiple phenotypes on distinct disease trajectories. Here we introduce a machine-learning technique-Subtype and Stage Inference (SuStaIn)-able to uncover data-driven disease phenotypes with distinct temporal progression patterns, from widely available cross-sectional patient studies. Results from imaging studies in two neurodegenerative diseases reveal subgroups and their distinct trajectories of regional neurodegeneration. In genetic frontotemporal dementia, SuStaIn identifies genotypes from imaging alone, validating its ability to identify subtypes; further the technique reveals within-genotype heterogeneity. In Alzheimer's disease, SuStaIn uncovers three subtypes, uniquely characterising their temporal complexity. SuStaIn provides fine-grained patient stratification, which substantially enhances the ability to predict conversion between diagnostic categories over standard models that ignore subtype (p = 7.18 × 10-4) or temporal stage (p = 3.96 × 10-5). SuStaIn offers new promise for enabling disease subtype discovery and precision medicine.",
      "publication_location": "Nature Communications",
      "link": "http://dx.doi.org/10.1038/s41467-018-05892-0",
      "citations": 29,
      "readership": 210,
      "tweets": 113,
      "news_mentions": 6
    },
    {
      "title": "Patient-informed and physiology-based modelling of contrast dynamics in cross-sectional imaging",
      "authors": "Setiawan, H; Abadi, E; Fu, W; Smith, TB; Samei, E",
      "published_date": "January 1, 2019",
      "doi": "10.1117/12.2513431",
      "abstract": "© SPIE. Downloading of the abstract is permitted for personal use only. Previous studies have shown that many factors including body habitus, sex, and age of the patient, as well as contrast injection protocol contribute to the variability in contrast-enhanced cross-sectional imaging (i.e., CT). We have previously developed a compartmentalized differential-equation physiology-based pharmacokinetics (PBPK) model incorporated into computational human models (XCAT) to estimate contrast concentration and CT number (HU) enhancement of organs over time. While input to the PBPK model requires certain attributes (height, weight, age, and sex), this still results in a generic prediction as it only cohorts patients into 4 groups. In addition, it does not account for scanning parameters which influence the quality of the image. The PBPK model also requires an estimate of patient's major organ volumes, not readily-available before a scan, which limits its potential application in prospective personalization of contrast-enhanced protocols. To address these limitations, this study used a machine learning approach to prospectively model contrast dynamics for an organ of interest (liver), given the patient attributes, contrast administration, and imaging parameters. To evaluate its accuracy, we compared the proposed model against the PBPK model. A library of 170 clinical images, with their corresponding patient attributes and contrast and imaging protocols, was used to build the network. The developed network used 70% of the cases for training and validation and the rest for testing. The results indicated a more accurate predictive performance (higher R2), as compared to the PBPK model, in estimating hepatic HU values using patient attributes, scanning parameters, and contrast administration.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2513431",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A Data-Centric Strategy for Developing CT Dose and Noise Reference Levels from Clinical Patient Populations",
      "authors": "Ding, A; Ria, F; Zhang, Y; Solomon, J; Samei, E",
      "published_date": "November 27, 2018",
      "doi": "",
      "abstract": "PURPOSE\nTo develop a data-centric strategy solution for developing CT dose and noise reference levels across large clinical patient populations and in CT scanners.\n \nMETHOD AND MATERIALS\nThis IRB-exempt study evaluated CT abdominopelvic (AP)-related examinations performed in 2017 by 22 scanners from two vendors with 11 models in 3 site hospitals. An in-house developed informatics system automatically extracted protocol information, patient size (cross-sectional diameter), dose, and in vivo noise magnitude within images. Protocol nomenclature categorization was performed using a decision tree machine learning algorithm. Four reference patient size intervals were identified: 13-20, 20-30, 30-40, and 40-50 cm. Noise Reference Level (NRL), Noise Reference Range (NRR), Dose Reference Level (DoRL), and Dose Reference Range (DoRR) were defined for each size range as the median and interquartile interval of noise and dose, respectively.\n \nRESULTS\n60,000 CT AP studies with 64 different convolution kernels for patients ages 0-70 and sizes 13-48 cm were identified. NRLs ranged between 15.8 to 18.4 HU with NRRs for the four size ranges were the following: 13.2-24.7,12.6-22.5,12.5-23.2, and 12.1-22.8 HU. DoRLs ranged within 11.9-16.1 mGy. The four DoRRs were 9.5-21.4,7.9-17.3,9.9-21.3, and 10.8-23.2mGy.\n \nCONCLUSION\nThis study offers the first even data-crunching solution for developing CT dose and noise reference levels using clinical patient data. New reference levels and ranges simultaneously consider image noise and radiation dose information across patient populations. The new metrics enables prospective optimization of clinical practice to maximize the imaging benefit and patient safety.\n \nCLINICAL RELEVANCE/APPLICATION\nA new solution is introduced for simultaneously defining image quality and dose reference levels across different patient body habitus. The methodology enables prospective optimization of clinical practice to maximize the imaging benefit and patient safety.",
      "publication_location": "",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Validation of lesion simulations in clinical CT data for anonymized chest and abdominal CT databases.",
      "authors": "Robins, M; Solomon, J; Koweek, LMH; Christensen, J; Samei, E",
      "published_date": "April 2019",
      "doi": "10.1002/mp.13412",
      "abstract": "PURPOSE: To make available to the medical imaging community a computed tomography (CT) image database composed of hybrid datasets (patient CT images with digitally inserted anthropomorphic lesions) where lesion ground truth is known a priori. It is envisioned that such a dataset could be a resource for the assessment of CT image quality, machine learning, and imaging technologies [e.g., computer aided detection (CAD) and segmentation algorithms]. ACQUISITION AND VALIDATION METHODS: This HIPPA compliant, IRB waiver of approval study consisted of utilizing 120 chest and 100 abdominal clinically acquired adult CT exams. One image series per patient exam was utilized based on coverage of the anatomical region of interest (either the thorax or abdomen). All image series were de-identified. Simulated lesions were derived from a library of anatomically informed digital lesions (93 lung and 50 liver lesions) where six and four digital lesions with nominal diameters ranging from 4 to 20 mm were inserted into lung and liver image series, respectively. Locations for lesion insertion were randomly chosen. A previously validated lesion simulation and virtual insertion technique were utilized. The resulting hybrid images were reviewed by three experienced radiologists to assure similarity with routine clinical imaging in a diverse adult population. DATA FORMAT AND USAGE NOTES: The database is composed of four datasets that contain 100 patient cases each, for a total of 400 image series accompanied by Matlab.mat tables that provide descriptive information about the virtually inserted lesions (i.e., size, shape, opacity, and insertion location in physical (world) coordinates and voxel indices). All image and metadata are stored in DICOM format on the Quantitative Imaging Data Warehouse (https://qidw.rsna.org/#collection/57d463471cac0a4ec8ff8f46/folder/5b23dceb1cac0a4ec800a770?dialog=login), in two sets: (a) QIBA CT Hybrid Dataset I which contains Lung I and Liver I datasets, and (b) QIBA CT Hybrid Dataset II which contains Lung II and Liver II datasets. The QIDW is supported by the Radiological Society of North America (RSNA). Registration is required upon initial log in. POTENTIAL APPLICATIONS: By simulating lesion opacity (full solid, part solid and ground glass), size, and texture, the relationship between lesion morphology and segmentation or CAD algorithm performance can be investigated without the need for repetitive patient exams. This database can also serve as a reference standard for device and reader performance studies.",
      "publication_location": "Med Phys",
      "link": "http://dx.doi.org/10.1002/mp.13412",
      "citations": "(None,)",
      "readership": 18,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Contrasting Roles of Transcription Factors Spineless and EcR in the Highly Dynamic Chromatin Landscape of Butterfly Wing Metamorphosis.",
      "authors": "van der Burg, KRL; Lewis, JJ; Martin, A; Nijhout, HF; Danko, CG; Reed, RD",
      "published_date": "April 2019",
      "doi": "10.1016/j.celrep.2019.03.092",
      "abstract": "Development requires highly coordinated changes in chromatin accessibility in order for proper gene regulation to occur. Here, we identify factors associated with major, discrete changes in chromatin accessibility during butterfly wing metamorphosis. By combining mRNA sequencing (mRNA-seq), assay for transposase-accessible chromatin using sequencing (ATAC-seq), and machine learning analysis of motifs, we show that distinct sets of transcription factors are predictive of chromatin opening at different developmental stages. Our data suggest an important role for nuclear hormone receptors early in metamorphosis, whereas PAS-domain transcription factors are strongly associated with later chromatin opening. Chromatin immunoprecipitation sequencing (ChIP-seq) validation of select candidate factors showed spineless binding to be a major predictor of opening chromatin. Surprisingly, binding of ecdysone receptor (EcR), a candidate accessibility factor in Drosophila, was not predictive of opening but instead marked persistent sites. This work characterizes the chromatin dynamics of insect wing metamorphosis, identifies candidate chromatin remodeling factors in insects, and presents a genome assembly of the model butterfly Junonia coenia.",
      "publication_location": "Cell Reports",
      "link": "http://dx.doi.org/10.1016/j.celrep.2019.03.092",
      "citations": 6,
      "readership": 45,
      "tweets": 82,
      "news_mentions": ""
    },
    {
      "title": "Beyond the DRL: Applying Automated Quality Metrics to Assess Pediatric CT Program Liver Lesion Detection Performance",
      "authors": "Lacy, T; Ding, A; Abadi, E; Zhang, Y; Ria, F; Samei, E; Frush, DP",
      "published_date": "November 25, 2018",
      "doi": "",
      "abstract": "PURPOSE\nTo apply an automated program for evaluating pediatric body CT study quality which utilizes metrics of dose and image quality for optimization of liver lesion detection.\n \nMETHOD AND MATERIALS\nWith IRB approval, 880 clinical contrast-enhanced abdominopelvic (AP) CT scans of patients 0-18 years were evaluated. Studies were from Siemens Flash (n=621), GE 750 HD (n=151), and GE VCT (n=108). A quantitative metric of the detection of a potential 5 mm liver lesion was used as a marker for image quality (IQ). To generate this, metrics of spatial resolution, background noise, and lesion contrast were composited. Resolution was assessed by a validated method based on anatomical edges. For noise, phantom noise power spectra were matched to patient-specific scan parameters. For contrast, a 50 Hounsfield unit difference between the IV enhanced liver and a potential 5 mm lesion was the clinical task. The three quality metrics were used to calculate a single established detectability index (d’) which represents the relative likelihood of detecting the lesion and was previously correlated with observer performance. Dose reports were extracted for each dataset using an institutional dose monitoring program. Relationships between d’ and radiation dose were explored.\n \nRESULTS\nThere was little CTDIvol variability across ages. For example, AP studies at 100 kVp on one scanner model had a median CTDIvol of 3.0 mGy (2.8-3.4 mGy interquartile range). However, when applying d', the age groups separated such that the younger patients had higher IQ than the older patients (Figure). For the youngest age group, d' and CTDIvol (medians) were 80 and 2.7 mGy; middle groups, 59 and 2.9 mGy; and oldest group, 42 and 3.4 mGy.\n \nCONCLUSION\nAn automated method to assess clinical IQ using a task-based and patient-specific metric was ascertained. The d’ allows establishment of quality reference levels (QRLs) which account for IQ and dose. This provides for robust quality quantification that can serve for single or collective patient CT performance assessment and optimization. Automation also facilitates potential integration with CT registries and investigations using machine learning approaches not feasible with observer ratings alone.\n \nCLINICAL RELEVANCE/APPLICATION\nOptimization in CT utilizes DRLs based on dose estimates without metrics of image quality. The addition of quality measures taken from clinical examinations affords improved CT performance assessment.",
      "publication_location": "",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Lost in space: Geolocation in event data",
      "authors": "Lee, SJ; Liu, H; Ward, MD",
      "published_date": "October 1, 2019",
      "doi": "10.1017/psrm.2018.23",
      "abstract": "© The European Political Science Association 2018. Improving geolocation accuracy in text data has long been a goal of automated text processing. We depart from the conventional method and introduce a two-stage supervised machine-learning algorithm that evaluates each location mention to be either correct or incorrect. We extract contextual information from texts, i.e., N-gram patterns for location words, mention frequency, and the context of sentences containing location words. We then estimate model parameters using a training data set and use this model to predict whether a location word in the test data set accurately represents the location of an event. We demonstrate these steps by constructing customized geolocation event data at the subnational level using news articles collected from around the world. The results show that the proposed algorithm outperforms existing geocoders even in a case added post hoc to test the generality of the developed algorithm.",
      "publication_location": "Political Science Research and Methods",
      "link": "http://dx.doi.org/10.1017/psrm.2018.23",
      "citations": 2,
      "readership": 19,
      "tweets": 49,
      "news_mentions": ""
    },
    {
      "title": "Gene selection using iterative feature elimination random forests for survival outcomes.",
      "authors": "Pang, H; George, SL; Hui, K; Tong, T",
      "published_date": "September 2012",
      "doi": "10.1109/TCBB.2012.63",
      "abstract": "Although many feature selection methods for classification have been developed, there is a need to identify genes in high-dimensional data with censored survival outcomes. Traditional methods for gene selection in classification problems have several drawbacks. First, the majority of the gene selection approaches for classification are single-gene based. Second, many of the gene selection procedures are not embedded within the algorithm itself. The technique of random forests has been found to perform well in high-dimensional data settings with survival outcomes. It also has an embedded feature to identify variables of importance. Therefore, it is an ideal candidate for gene selection in high-dimensional data with survival outcomes. In this paper, we develop a novel method based on the random forests to identify a set of prognostic genes. We compare our method with several machine learning methods and various node split criteria using several real data sets. Our method performed well in both simulations and real data analysis.Additionally, we have shown the advantages of our approach over single-gene-based approaches. Our method incorporates multivariate correlations in microarray data for survival outcomes. The described method allows us to better utilize the information available from microarray data with survival outcomes.",
      "publication_location": "Ieee/Acm Trans Comput Biol Bioinform",
      "link": "http://dx.doi.org/10.1109/TCBB.2012.63",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Pathway analysis using random forests classification and regression.",
      "authors": "Pang, H; Lin, A; Holford, M; Enerson, BE; Lu, B; Lawton, MP; Floyd, E; Zhao, H",
      "published_date": "August 15, 2006",
      "doi": "10.1093/bioinformatics/btl344",
      "abstract": "MOTIVATION: Although numerous methods have been developed to better capture biological information from microarray data, commonly used single gene-based methods neglect interactions among genes and leave room for other novel approaches. For example, most classification and regression methods for microarray data are based on the whole set of genes and have not made use of pathway information. Pathway-based analysis in microarray studies may lead to more informative and relevant knowledge for biological researchers. RESULTS: In this paper, we describe a pathway-based classification and regression method using Random Forests to analyze gene expression data. The proposed methods allow researchers to rank important pathways from externally available databases, discover important genes, find pathway-based outlying cases and make full use of a continuous outcome variable in the regression setting. We also compared Random Forests with other machine learning methods using several datasets and found that Random Forests classification error rates were either the lowest or the second-lowest. By combining pathway information and novel statistical methods, this procedure represents a promising computational strategy in dissecting pathways and can provide biological insight into the study of microarray data. AVAILABILITY: Source code written in R is available from http://bioinformatics.med.yale.edu/pathway-analysis/rf.htm.",
      "publication_location": "Bioinformatics",
      "link": "http://dx.doi.org/10.1093/bioinformatics/btl344",
      "citations": 150,
      "readership": 188,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "MobiEye: An efficient cloud-based video detection system for real-time mobile applications",
      "authors": "Mao, J; Yang, Q; Li, A; Li, H; Chen, Y",
      "published_date": "June 2, 2019",
      "doi": "10.1145/3316781.3317865",
      "abstract": "© 2019 Association for Computing Machinery. In recent years, machine learning research has largely shifted focus from the cloud to the edge. While the resulting algorithm- and hardware-level optimizations have enabled local execution for the majority of deep neural networks (DNNs) on edge devices, the sheer magnitude of DNNs associated with real-time video detection workloads has forced them to remain relegated to remote execution in the cloud. This problematic when combined with the strict latency requirements that are coupled with these workloads, and imposes a unique set of challenges not directly addressed in prior works. In this work, we design MobiEye, a cloud-based video detection system optimized for deployment in real-time mobile applications. MobiEye is able to achieve up to a 32% reduction in latency when compared to a conventional implementation of video detection system with only a marginal reduction in accuracy.",
      "publication_location": "Proceedings   Design Automation Conference",
      "link": "http://dx.doi.org/10.1145/3316781.3317865",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Search for 2νββ decay of Xe 136 to the 01+ excited state of Ba 136 with the EXO-200 liquid xenon detector",
      "authors": "Albert, JB; Auty, DJ; Barbeau, PS; Beck, D; Belov, V; Breidenbach, M; Brunner, T; Burenkov, A; Cao, GF; Chambers, C; Chaves, J; Cleveland, B; Coon, M; Craycraft, A; Daniels, T; Danilov, M; Daugherty, SJ; Davis, J; Delaquis, S; Der Mesrobian-Kabakian, A; Devoe, R; Didberidze, T; Dilling, J; Dolgolenko, A; Dolinski, MJ; Dunford, M; Fairbank, W; Farine, J; Feldmeier, W; Feyzbakhsh, S; Fierlinger, P; Fudenberg, D; Gornea, R; Graham, K; Gratta, G; Hall, C; Hughes, M; Jewell, MJ; Johnson, A; Johnson, TN; Johnston, S; Karelin, A; Kaufman, LJ; Killick, R; King, J; Koffas, T; Kravitz, S; Krücken, R; Kuchenkov, A; Kumar, KS; Leonard, DS; Licciardi, C; Lin, YH; Ling, J; Maclellan, R; Marino, MG; Mong, B; Moore, D; Njoya, O; Nelson, R; Odian, A; Ostrovskiy, I; Piepke, A; Pocar, A; Prescott, CY; Retière, F; Rowson, PC; Russell, JJ; Schubert, A; Sinclair, D; Smith, E; Stekhanov, V; Tarka, M; Tolba, T; Tsang, R; Twelker, K; Vogel, P; Vuilleumier, JL; Waite, A; Walton, J; Walton, T; Weber, M; Wen, LJ; Wichoski, U; Winick, TA; Wood, J; Xu, QY; Yang, L; Yen, YR; Zeldovich, OY",
      "published_date": "March 8, 2016",
      "doi": "10.1103/PhysRevC.93.035501",
      "abstract": "© 2016 American Physical Society. EXO-200 is a single phase liquid xenon detector designed to search for neutrinoless ββ decay of Xe136 to the ground state of Ba136. We report here on a search for the two-neutrino ββ decay of Xe136 to the first 0+ excited state, 01+, of Ba136 based on a 100 kgyr exposure of Xe136. Using a specialized analysis employing a machine learning algorithm, we obtain a 90% CL half-life sensitivity of 1.7×1024 yr. We find no statistically significant evidence for the 2νββ decay to the excited state resulting in a lower limit of T1/22ν (0+→01+) > 6.9 ×1023 yr at 90% CL. This observed limit is consistent with the estimated half-life of 2.5×1025 yr.",
      "publication_location": "Physical Review C",
      "link": "http://dx.doi.org/10.1103/PhysRevC.93.035501",
      "citations": 6,
      "readership": 13,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "A formalin-fixed paraffin-embedded (FFPE)-based prognostic signature to predict metastasis in clinically low risk stage I/II microsatellite stable colorectal cancer.",
      "authors": "Low, YS; Blöcker, C; McPherson, JR; Tang, SA; Cheng, YY; Wong, JYS; Chua, C; Lim, TKH; Tang, CL; Chew, MH; Tan, P; Tan, IB; Rozen, SG; Cheah, PY",
      "published_date": "September 10, 2017",
      "doi": "10.1016/j.canlet.2017.05.031",
      "abstract": "Approximately 20% early-stage (I/II) colorectal cancer (CRC) patients develop metastases despite curative surgery. We aim to develop a formalin-fixed and paraffin-embedded (FFPE)-based predictor of metastases in early-stage, clinically-defined low risk, microsatellite-stable (MSS) CRC patients. We considered genome-wide mRNA and miRNA expression and mutation status of 20 genes assayed in 150 fresh-frozen tumours with known metastasis status. We selected 193 genes for further analysis using NanoString nCounter arrays on corresponding FFPE tumours. Neither mutation status nor miRNA expression improved the estimated prediction. The final predictor, ColoMet19, based on the top 19 genes' mRNA levels trained by Random Forest machine-learning strategy, had an estimated positive-predictive-value (PPV) of 0.66. We tested ColoMet19 on an independent test-set of 131 tumours and obtained a population-adjusted PPV of 0.67 indicating that early-stage CRC patients who tested positive have a 67% risk of developing metastases, substantially higher than the metastasis risk of 40% for node-positive (Stage III) patients who are generally treated with chemotherapy. Predicted-positive patients also had poorer metastasis-free survival (hazard ratios [HR] = 1.92, design-set; HR = 2.05, test-set). Thus, early-stage CRC patients who test positive may be considered for adjuvant therapy after surgery.",
      "publication_location": "Cancer Lett",
      "link": "http://dx.doi.org/10.1016/j.canlet.2017.05.031",
      "citations": 2,
      "readership": 37,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Probability forecasts and their combination: A research perspective",
      "authors": "Winkler, RL; Grushka-Cockayne, Y; Lichtendahl, KC; Jose, VRR",
      "published_date": "January 1, 2019",
      "doi": "10.1287/deca.2019.0391",
      "abstract": "© 2019 INFORMS. We explore some recent, and not so recent, developments concerning the use of probability forecasts and their combination in decision making. Despite these advances, challenges still exist. We expand on some important challenges influencing the “goodness” of combined probability forecasts such as miscalibration, dependence among forecasters, and selection of an appropriate evaluation measure while connecting the processes of aggregating and evaluating forecasts to decision making. Through three important applications from the domains of meteorology, economics, and political science, we illustrate state-of-the-art usage of probability forecasts: how they are combined, evaluated, and communicated to stakeholders. We expect to see greater use and aggregation of probability forecasts, especially given developments in statistical modeling, machine learning, and expert forecasting; the popularity of forecasting competitions; and the increased reporting of probabilities in the media. Our vision is that increased exposure to and improved visualizations of probability forecasts will enhance the public’s understanding of probabilities and how they can contribute to better decisions.",
      "publication_location": "Decision Analysis",
      "link": "http://dx.doi.org/10.1287/deca.2019.0391",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Prophage Hunter: an integrative hunting tool for active prophages.",
      "authors": "Song, W; Sun, H-X; Zhang, C; Cheng, L; Peng, Y; Deng, Z; Wang, D; Wang, Y; Hu, M; Liu, W; Yang, H; Shen, Y; Li, J; You, L; Xiao, M",
      "published_date": "July 2019",
      "doi": "10.1093/nar/gkz380",
      "abstract": "Identifying active prophages is critical for studying coevolution of phage and bacteria, investigating phage physiology and biochemistry, and engineering designer phages for diverse applications. We present Prophage Hunter, a tool aimed at hunting for active prophages from whole genome assembly of bacteria. Combining sequence similarity-based matching and genetic features-based machine learning classification, we developed a novel scoring system that exhibits higher accuracy than current tools in predicting active prophages on the validation datasets. The option of skipping similarity matching is also available so that there's higher chance for novel phages to be discovered. Prophage Hunter provides a one-stop web service to extract prophage genomes from bacterial genomes, evaluate the activity of the prophages, identify phylogenetically related phages, and annotate the function of phage proteins. Prophage Hunter is freely available at https://pro-hunter.bgi.com/.",
      "publication_location": "Nucleic Acids Research",
      "link": "http://dx.doi.org/10.1093/nar/gkz380",
      "citations": 6,
      "readership": 72,
      "tweets": 35,
      "news_mentions": ""
    },
    {
      "title": "Redshift distributions of galaxies in the Dark Energy Survey Science Verification shear catalogue and implications for weak lensing",
      "authors": "Bonnett, C; Troxel, MA; Hartley, W; Amara, A; Leistedt, B; Becker, MR; Bernstein, GM; Bridle, SL; Bruderer, C; Busha, MT; Carrasco Kind, M; Childress, MJ; Castander, FJ; Chang, C; Crocce, M; Davis, TM; Eifler, TF; Frieman, J; Gangkofner, C; Gaztanaga, E; Glazebrook, K; Gruen, D; Kacprzak, T; King, A; Kwan, J; Lahav, O; Lewis, G; Lidman, C; Lin, H; MacCrann, N; Miquel, R; O'Neill, CR; Palmese, A; Peiris, HV; Refregier, A; Rozo, E; Rykoff, ES; Sadeh, I; Sánchez, C; Sheldon, E; Uddin, S; Wechsler, RH; Zuntz, J; Abbott, T; Abdalla, FB; Allam, S; Armstrong, R; Banerji, M; Bauer, AH; Benoit-Lévy, A; Bertin, E; Brooks, D; Buckley-Geer, E; Burke, DL; Capozzi, D; Carnero Rosell, A; Carretero, J; Cunha, CE; D'Andrea, CB; Da Costa, LN; Depoy, DL; Desai, S; Diehl, HT; Dietrich, JP; Doel, P; Fausti Neto, A; Fernandez, E; Flaugher, B; Fosalba, P; Gerdes, DW; Gruendl, RA; Honscheid, K; Jain, B; James, DJ; Jarvis, M; Kim, AG; Kuehn, K; Kuropatkin, N; Li, TS; Lima, M; Maia, MAG; March, M; Marshall, JL; Martini, P; Melchior, P; Miller, CJ; Neilsen, E; Nichol, RC; Nord, B; Ogando, R; Plazas, AA; Reil, K; Romer, AK; Roodman, A; Sako, M; Sanchez, E; Santiago, B; Smith, RC; Soares-Santos, M; Sobreira, F",
      "published_date": "August 30, 2016",
      "doi": "10.1103/PhysRevD.94.042005",
      "abstract": "© 2016 American Physical Society. We present photometric redshift estimates for galaxies used in the weak lensing analysis of the Dark Energy Survey Science Verification (DES SV) data. Four model- or machine learning-based photometric redshift methods - annz2, bpz calibrated against BCC-Ufig simulations, skynet, and tpz - are analyzed. For training, calibration, and testing of these methods, we construct a catalogue of spectroscopically confirmed galaxies matched against DES SV data. The performance of the methods is evaluated against the matched spectroscopic catalogue, focusing on metrics relevant for weak lensing analyses, with additional validation against COSMOS photo-z's. From the galaxies in the DES SV shear catalogue, which have mean redshift 0.72±0.01 over the range 0.3<1.3, we construct three tomographic bins with means of z={0.45,0.67,1.00}. These bins each have systematic uncertainties δz≲0.05 in the mean of the fiducial skynet photo-z n(z). We propagate the errors in the redshift distributions through to their impact on cosmological parameters estimated with cosmic shear, and find that they cause shifts in the value of σ8 of approximately 3%. This shift is within the one sigma statistical errors on σ8 for the DES SV shear catalogue. We further study the potential impact of systematic differences on the critical surface density, Σcrit, finding levels of bias safely less than the statistical power of DES SV data. We recommend a final Gaussian prior for the photo-z bias in the mean of n(z) of width 0.05 for each of the three tomographic bins, and show that this is a sufficient bias model for the corresponding cosmology analysis.",
      "publication_location": "Physical Review D",
      "link": "http://dx.doi.org/10.1103/PhysRevD.94.042005",
      "citations": 69,
      "readership": 47,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Dark Energy Survey Year 1 results: Measurement of the baryon acoustic oscillation scale in the distribution of galaxies to redshift 1",
      "authors": "Abbott, TMC; Abdalla, FB; Alarcon, A; Allam, S; Andrade-Oliveira, F; Annis, J; Avila, S; Banerji, M; Banik, N; Bechtol, K; Bernstein, RA; Bernstein, GM; Bertin, E; Brooks, D; Buckley-Geer, E; Burke, DL; Camacho, H; Carnero Rosell, A; Carrasco Kind, M; Carretero, J; Castander, FJ; Cawthon, R; Chan, KC; Crocce, M; Cunha, CE; D'Andrea, CB; Da Costa, LN; Davis, C; De Vicente, J; Depoy, DL; Desai, S; Diehl, HT; Doel, P; Drlica-Wagner, A; Eifler, TF; Elvin-Poole, J; Estrada, J; Evrard, AE; Flaugher, B; Fosalba, P; Frieman, J; García-Bellido, J; Gaztanaga, E; Gerdes, DW; Giannantonio, T; Gruen, D; Gruendl, RA; Gschwend, J; Gutierrez, G; Hartley, WG; Hollowood, D; Honscheid, K; Hoyle, B; Jain, B; James, DJ; Jeltema, T; Johnson, MD; Kent, S; Kokron, N; Krause, E; Kuehn, K; Kuhlmann, S; Kuropatkin, N; Lacasa, F; Lahav, O; Lima, M; Lin, H; Maia, MAG; Manera, M; Marriner, J; Marshall, JL; Martini, P; Melchior, P; Menanteau, F; Miller, CJ; Miquel, R; Mohr, JJ; Neilsen, E; Percival, WJ; Plazas, AA; Porredon, A; Romer, AK; Roodman, A; Rosenfeld, R; Ross, AJ; Rozo, E; Rykoff, ES; Sako, M; Sanchez, E; Santiago, B; Scarpine, V; Schindler, R; Schubnell, M; Serrano, S; Sevilla-Noarbe, I; Sheldon, E; Smith, RC; Smith, M; Sobreira, F; Suchyta, E",
      "published_date": "March 11, 2019",
      "doi": "10.1093/mnras/sty3351",
      "abstract": "© 2018 The Author(s) Published by Oxford University Press on behalf of the Royal Astronomical Society.  We present angular diameter distance measurements obtained by locating the baryon acoustic oscillations (BAO) scale in the distribution of galaxies selected from the first year of Dark Energy Survey data. We consider a sample of over 1.3 million galaxies distributed over a footprint of 1336 deg 2 witH 0 .6 < z photo < 1 and a typical redshift uncertainty of 0.03(1 + z). This sample was selected, as fully described in a companion paper, using a colour/magnitude selection that optimizes trade-offs between number density and redshift uncertainty. We investigate the BAO signal in the projected clustering using three conventions, the angular separation, the comoving transverse separation, and spherical harmonics. Further, we compare results obtained from template-based and machine-learning photometric redshift determinations. We use 1800 simulations that approximate our sample in order to produce covariance matrices and allow us to validate our distance scale measurement methodology. We measure the angular diameter distance, D A, at the effective redshift of our sample divided by the true physical scale of the BAO feature, r d. We obtain close to a 4 per cent distance measurement of D A (z eff = 0.81)/r d = 10.75 ± 0.43. These results are consistent with the flat δ cold dark matter concordance cosmological model supported by numerous other recent experimental results.",
      "publication_location": "Monthly Notices of the Royal Astronomical Society",
      "link": "http://dx.doi.org/10.1093/mnras/sty3351",
      "citations": 13,
      "readership": 22,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Paired-end analysis of transcription start sites in Arabidopsis reveals plant-specific promoter signatures.",
      "authors": "Morton, T; Petricka, J; Corcoran, DL; Li, S; Winter, CM; Carda, A; Benfey, PN; Ohler, U; Megraw, M",
      "published_date": "July 2014",
      "doi": "10.1105/tpc.114.125617",
      "abstract": "Understanding plant gene promoter architecture has long been a challenge due to the lack of relevant large-scale data sets and analysis methods. Here, we present a publicly available, large-scale transcription start site (TSS) data set in plants using a high-resolution method for analysis of 5' ends of mRNA transcripts. Our data set is produced using the paired-end analysis of transcription start sites (PEAT) protocol, providing millions of TSS locations from wild-type Columbia-0 Arabidopsis thaliana whole root samples. Using this data set, we grouped TSS reads into \"TSS tag clusters\" and categorized clusters into three spatial initiation patterns: narrow peak, broad with peak, and weak peak. We then designed a machine learning model that predicts the presence of TSS tag clusters with outstanding sensitivity and specificity for all three initiation patterns. We used this model to analyze the transcription factor binding site content of promoters exhibiting these initiation patterns. In contrast to the canonical notions of TATA-containing and more broad \"TATA-less\" promoters, the model shows that, in plants, the vast majority of transcription start sites are TATA free and are defined by a large compendium of known DNA sequence binding elements. We present results on the usage of these elements and provide our Plant PEAT Peaks (3PEAT) model that predicts the presence of TSSs directly from sequence.",
      "publication_location": "Plant Cell",
      "link": "http://dx.doi.org/10.1105/tpc.114.125617",
      "citations": 65,
      "readership": 166,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "The use of unlabeled data in predictive modeling",
      "authors": "Liang, F; Mukherjee, S; West, M",
      "published_date": "May 1, 2007",
      "doi": "10.1214/088342307000000032",
      "abstract": "The incorporation of unlabeled data in regression and classification analysis is an increasing focus of the applied statistics and machine learning literatures, with a number of recent examples demonstrating the potential for unlabeled data to contribute to improved predictive accuracy. The statistical basis for this semisupervised analysis does not appear to have been well delineated; as a result, the underlying theory and rationale may be underappreciated, especially by nonstatisticians. There is also room for statisticians to become more fully engaged in the vigorous research in this important area of intersection of the statistical and computer sciences. Much of the theoretical work in the literature has focused, for example, on geometric and structural properties of the unlabeled data in the context of particular algorithms, rather than probabilistic and statistical questions. This paper overviews the fundamental statistical foundations for predictive modeling and the general questions associated with unlabeled data, highlighting the relevance of venerable concepts of sampling design and prior specification. This theory, illustrated with a series of central illustrative examples and two substantial real data analyses, shows precisely when, why and how unlabeled data matter. © Institute of Mathematical Statistics, 2007.",
      "publication_location": "Statistical Science",
      "link": "http://dx.doi.org/10.1214/088342307000000032",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Recom: An efficient resistive accelerator for compressed deep neural networks",
      "authors": "Ji, H; Song, L; Jiang, L; Li, HH; Chen, Y",
      "published_date": "April 19, 2018",
      "doi": "10.23919/DATE.2018.8342009",
      "abstract": "© 2018 EDAA. Deep Neural Networks (DNNs) play a key role in prevailing machine learning applications. Resistive random-Access memory (ReRAM) is capable of both computation and storage, contributing to the acceleration on DNNs by processing in memory. Besides, a significant amount of zero weights is observed in DNNs, providing a space to reduce computation cost further by skipping ineffectual calculations associated with them. However, the irregular distribution of zero weights in DNNs makes it difficult for resistive accelerators to take advantage of the sparsity as expected efficiently, because of its high reliance on regular matrix-vector multiplication in ReRAM. In this work, we propose ReCom, the first resistive accelerator to support sparse DNN processing. ReCom is an efficient resistive accelerator for compressed deep neural networks, where DNN weights are structurally compressed to eliminate zero parameters and become hardware-friendly. Zero DNN activation is also considered at the same time. Two technologies, Structurally-compressed Weight Oriented Fetching (SWOF) and In-layer Pipeline for Memory and Computation (IPMC), are particularly proposed. In our evaluation, ReCom can achieve 3.37x speedup and 2.41x energy efficiency compared to a state-of-The-Art resistive accelerator.",
      "publication_location": "Proceedings of the 2018 Design, Automation and Test in Europe Conference and Exhibition, Date 2018",
      "link": "http://dx.doi.org/10.23919/DATE.2018.8342009",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Combined Performance of Screening and Variable Selection Methods in Ultra-High Dimensional Data in Predicting Time-To-Event Outcomes.",
      "authors": "Pi, L; Halabi, S",
      "published_date": 2018,
      "doi": "10.1186/s41512-018-0043-4",
      "abstract": "Background: Building prognostic models of clinical outcomes is an increasingly important research task and will remain a vital area in genomic medicine. Prognostic models of clinical outcomes are usually built and validated utilizing variable selection methods and machine learning tools. The challenges, however, in ultra-high dimensional space are not only to reduce the dimensionality of the data, but also to retain the important variables which predict the outcome. Screening approaches, such as the sure independence screening (SIS), iterative SIS (ISIS) and principled SIS (PSIS) have been developed to overcome the challenge of high dimensionality. We are interested in identifying important single-nucleotide polymorphisms (SNPs) and integrating them into a validated prognostic model of overall survival in patients with metastatic prostate cancer. While the abovementioned variable selection approaches have theoretical justification in selecting SNPs, the comparison and the performance of these combined methods in predicting time-to-event outcomes have not been previously studied in ultra-high dimensional space with hundreds of thousands of variables. Methods: We conducted a series of simulations to compare the performance of different combinations of variable selection approaches and classification trees, such as the least absolute shrinkage and selection operator (LASSO), adaptive least absolute shrinkage and selection operator (ALASSO) and random survival forest (RSF), in ultra-high dimensional setting data for the purpose of developing prognostic models for a time-to-event outcome that is subject to censoring. The variable selection methods were evaluated for discrimination (Harrell's concordance statistic), calibration and overall performance. In addition, we applied these approaches to 498,081 SNPs from 623 Caucasian patients with prostate cancer. Results: When n=300, ISIS-LASSO and ISIS-ALASSO chose all the informative variables which resulted in the highest Harrell's c-index (>0.80). On the other hand, with a small sample size (n=150), ALASSO performed better than any other combinations as demonstrated by the highest c-index and/or overall performance, although there was evidence of overfitting. In analyzing the prostate cancer data, ISIS-ALASSO, SIS-LASSO, and SIS-ALASSO combinations achieved the highest discrimination with c-index of 0.67. Conclusions: Choosing the appropriate variable selection method for training a model is a critical step in developing a robust prognostic model. Based on the simulation studies, the effective use of ALASSO or a combination of methods, such as ISIS-LASSO and ISIS-ALASSO, allows both for the development of prognostic models with high predictive accuracy and a low risk of overfitting assuming moderate sample sizes.",
      "publication_location": "Diagnostic and Prognostic Research",
      "link": "http://dx.doi.org/10.1186/s41512-018-0043-4",
      "citations": 2,
      "readership": 3,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Single-Cell Transcriptomics Reveals Heterogeneity and Drug Response of Human Colorectal Cancer Organoids.",
      "authors": "Chen, K-Y; Srinivasan, T; Lin, C; Tung, K-L; Gao, Z; Hsu, DS; Lipkin, SM; Shen, X",
      "published_date": "July 2018",
      "doi": "10.1109/EMBC.2018.8512784",
      "abstract": "Organoids are three-dimensional cell cultures that mimic organ functions and structures. The organoid model has been developed as a versatile in vitro platform for stem cell biology and diseases modeling. Tumor organoids are shown to share ~ 90% of genetic mutations with biopsies from same patients. However, it's not clear whether tumor organoids recapitulate the cellular heterogeneity observed in patient tumors. Here, we used single-cell RNA-Seq to investigate the transcriptomics of tumor organoids derived from human colorectal tumors, and applied machine learning methods to unbiasedly cluster subtypes in tumor organoids. Computational analysis reveals cancer heterogeneity sustained in tumor organoids, and the subtypes in organoids displayed high diversity. Furthermore, we treated the tumor organoids with a first-line cancer drug, Oxaliplatin, and investigated drug response in single-cell scale. Diversity of tumor cell populations in organoids were significantly perturbed by drug treatment. Single-cell analysis detected the depletion of chemosensitive subgroups and emergence of new drug tolerant subgroups after drug treatment. Our study suggests that the organoid model is capable of recapitulating clinical heterogeneity and its evolution in response to chemotherapy.",
      "publication_location": "Conference Proceedings : ... Annual International Conference of the Ieee Engineering in Medicine and Biology Society. Ieee Engineering in Medicine and Biology Society. Annual Conference",
      "link": "http://dx.doi.org/10.1109/EMBC.2018.8512784",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Complex biomarker discovery in neuroimaging data: Finding a needle in a haystack.",
      "authors": "Atluri, G; Padmanabhan, K; Fang, G; Steinbach, M; Petrella, JR; Lim, K; Macdonald, A; Samatova, NF; Doraiswamy, PM; Kumar, V",
      "published_date": "August 7, 2013",
      "doi": "10.1016/j.nicl.2013.07.004",
      "abstract": "Neuropsychiatric disorders such as schizophrenia, bipolar disorder and Alzheimer's disease are major public health problems. However, despite decades of research, we currently have no validated prognostic or diagnostic tests that can be applied at an individual patient level. Many neuropsychiatric diseases are due to a combination of alterations that occur in a human brain rather than the result of localized lesions. While there is hope that newer imaging technologies such as functional and anatomic connectivity MRI or molecular imaging may offer breakthroughs, the single biomarkers that are discovered using these datasets are limited by their inability to capture the heterogeneity and complexity of most multifactorial brain disorders. Recently, complex biomarkers have been explored to address this limitation using neuroimaging data. In this manuscript we consider the nature of complex biomarkers being investigated in the recent literature and present techniques to find such biomarkers that have been developed in related areas of data mining, statistics, machine learning and bioinformatics.",
      "publication_location": "Neuroimage. Clinical",
      "link": "http://dx.doi.org/10.1016/j.nicl.2013.07.004",
      "citations": 33,
      "readership": 130,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "NanoMine schema: An extensible data representation for polymer nanocomposites",
      "authors": "Zhao, H; Wang, Y; Lin, A; Hu, B; Yan, R; McCusker, J; Chen, W; McGuinness, DL; Schadler, L; Brinson, LC",
      "published_date": "November 1, 2018",
      "doi": "10.1063/1.5046839",
      "abstract": "© 2018 Author(s). Polymer nanocomposites consist of a polymer matrix and fillers with at least one dimension below 100 nanometers (nm) [L. Schadler et al., Jom 59(3), 53-60 (2007)]. A key challenge in constructing an effective data resource for polymer nanocomposites is building a consistent, coherent, and clear data representation of all relevant parameters and their interrelationships. The data resource must address (1) data representation for representing, saving, and accessing the data (e.g., a data schema used in a data resource such as a database management system), (2) data contribution and uploading (e.g., an MS Excel template file that users can use to input data), (3) concept and knowledge modeling in a computationally accessible form (e.g., generation of a knowledge graph and ontology), and (4) ultimately data analytics and mining for new materials discovery. This paper addresses the first three issues, paving the way for rich, nuanced data analysis. We present the NanoMine polymer nanocomposite schema as an XML-based data schema designed for nanocomposite materials data representation and distribution and discuss its relationship to a higher level polymer data core consistent with other centralized materials data efforts. We also demonstrate aspects of data entry in an accessible manner consistent with the XML schema and discuss our mapping and augmentation approach to provide a more comprehensive representation in the form of an ontology and an ontology-enabled knowledge graph framework for nanopolymer systems. The schema and ontology and their easy accessibility and compatibility with parallel material standards provide a platform for data storage and search, customized visualization, and machine learning tools for material discovery and design.",
      "publication_location": "Apl Materials",
      "link": "http://dx.doi.org/10.1063/1.5046839",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A multimodality test to guide the management of patients with a pancreatic cyst.",
      "authors": "Springer, S; Masica, DL; Dal Molin, M; Douville, C; Thoburn, CJ; Afsari, B; Li, L; Cohen, JD; Thompson, E; Allen, PJ; Klimstra, DS; Schattner, MA; Schmidt, CM; Yip-Schneider, M; Simpson, RE; Fernandez-Del Castillo, C; Mino-Kenudson, M; Brugge, W; Brand, RE; Singhi, AD; Scarpa, A; Lawlor, R; Salvia, R; Zamboni, G; Hong, S-M; Hwang, DW; Jang, J-Y; Kwon, W; Swan, N; Geoghegan, J; Falconi, M; Crippa, S; Doglioni, C; Paulino, J; Schulick, RD; Edil, BH; Park, W; Yachida, S; Hijioka, S; van Hooft, J; He, J; Weiss, MJ; Burkhart, R; Makary, M; Canto, MI; Goggins, MG; Ptak, J; Dobbyn, L; Schaefer, J; Sillman, N; Popoli, M; Klein, AP; Tomasetti, C; Karchin, R; Papadopoulos, N; Kinzler, KW; Vogelstein, B; Wolfgang, CL; Hruban, RH; Lennon, AM",
      "published_date": "July 17, 2019",
      "doi": "10.1126/scitranslmed.aav4772",
      "abstract": "Pancreatic cysts are common and often pose a management dilemma, because some cysts are precancerous, whereas others have little risk of developing into invasive cancers. We used supervised machine learning techniques to develop a comprehensive test, CompCyst, to guide the management of patients with pancreatic cysts. The test is based on selected clinical features, imaging characteristics, and cyst fluid genetic and biochemical markers. Using data from 436 patients with pancreatic cysts, we trained CompCyst to classify patients as those who required surgery, those who should be routinely monitored, and those who did not require further surveillance. We then tested CompCyst in an independent cohort of 426 patients, with histopathology used as the gold standard. We found that clinical management informed by the CompCyst test was more accurate than the management dictated by conventional clinical and imaging criteria alone. Application of the CompCyst test would have spared surgery in more than half of the patients who underwent unnecessary resection of their cysts. CompCyst therefore has the potential to reduce the patient morbidity and economic costs associated with current standard-of-care pancreatic cyst management practices.",
      "publication_location": "Sci Transl Med",
      "link": "http://dx.doi.org/10.1126/scitranslmed.aav4772",
      "citations": 7,
      "readership": 43,
      "tweets": 107,
      "news_mentions": 28
    },
    {
      "title": "An efficient matrix bi-factorization alternative optimization method for low-rank matrix recovery and completion.",
      "authors": "Liu, Y; Jiao, LC; Shang, F; Yin, F; Liu, F",
      "published_date": "December 2013",
      "doi": "10.1016/j.neunet.2013.06.013",
      "abstract": "In recent years, matrix rank minimization problems have aroused considerable interests from machine learning, data mining and computer vision communities. All of these problems can be solved via their convex relaxations which minimize the trace norm instead of the rank of the matrix, and have to be solved iteratively and involve singular value decomposition (SVD) at each iteration. Therefore, those algorithms for trace norm minimization problems suffer from high computation cost of multiple SVDs. In this paper, we propose an efficient Matrix Bi-Factorization (MBF) method to approximate the original trace norm minimization problem and mitigate the computation cost of performing SVDs. The proposed MBF method can be used to address a wide range of low-rank matrix recovery and completion problems such as low-rank and sparse matrix decomposition (LRSD), low-rank representation (LRR) and low-rank matrix completion (MC). We also present three small scale matrix trace norm models for LRSD, LRR and MC problems, respectively. Moreover, we develop two concrete linearized proximal alternative optimization algorithms for solving the above three problems. Experimental results on a variety of synthetic and real-world data sets validate the efficiency, robustness and effectiveness of our MBF method comparing with the state-of-the-art trace norm minimization algorithms.",
      "publication_location": "Neural Networks : the Official Journal of the International Neural Network Society",
      "link": "http://dx.doi.org/10.1016/j.neunet.2013.06.013",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Putative biomarkers for predicting tumor sample purity based on gene expression data.",
      "authors": "Li, Y; Umbach, DM; Bingham, A; Li, Q-J; Zhuang, Y; Li, L",
      "published_date": "December 27, 2019",
      "doi": "10.1186/s12864-019-6412-8",
      "abstract": "BACKGROUND: Tumor purity is the percent of cancer cells present in a sample of tumor tissue. The non-cancerous cells (immune cells, fibroblasts, etc.) have an important role in tumor biology. The ability to determine tumor purity is important to understand the roles of cancerous and non-cancerous cells in a tumor. METHODS: We applied a supervised machine learning method, XGBoost, to data from 33 TCGA tumor types to predict tumor purity using RNA-seq gene expression data. RESULTS: Across the 33 tumor types, the median correlation between observed and predicted tumor-purity ranged from 0.75 to 0.87 with small root mean square errors, suggesting that tumor purity can be accurately predicted υσινγ expression data. We further confirmed that expression levels of a ten-gene set (CSF2RB, RHOH, C1S, CCDC69, CCL22, CYTIP, POU2AF1, FGR, CCL21, and IL7R) were predictive of tumor purity regardless of tumor type. We tested whether our set of ten genes could accurately predict tumor purity of a TCGA-independent data set. We showed that expression levels from our set of ten genes were highly correlated (ρ = 0.88) with the actual observed tumor purity. CONCLUSIONS: Our analyses suggested that the ten-gene set may serve as a biomarker for tumor purity prediction using gene expression data.",
      "publication_location": "Bmc Genomics",
      "link": "http://dx.doi.org/10.1186/s12864-019-6412-8",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 13,
      "news_mentions": ""
    },
    {
      "title": "Development of realistic multi-contrast textured XCAT (MT-XCAT) phantoms using a dual-discriminator conditional-generative adversarial network (D-CGAN).",
      "authors": "Chang, Y; Lafata, K; Segars, WP; Yin, F-F; Ren, L",
      "published_date": "March 19, 2020",
      "doi": "10.1088/1361-6560/ab7309",
      "abstract": "Develop a machine learning-based method to generate multi-contrast anatomical textures in the 4D extended cardiac-torso (XCAT) phantom for more realistic imaging simulations. As a pilot study, we synthesize CT and CBCT textures in the chest region. For training purposes, major organs and gross tumor volumes (GTVs) in chest region were segmented from real patient images and assigned to different HU values to generate organ maps, which resemble the XCAT images. A dual-discriminator conditional-generative adversarial network (D-CGAN) was developed to synthesize anatomical textures in the corresponding organ maps. The D-CGAN was uniquely designed with two discriminators, one trained for the body and the other for the tumor. Various XCAT phantoms were input to the D-CGAN to generate textured XCAT phantoms. The D-CGAN model was trained separately using 62 CT and 63 CBCT images from lung SBRT patients to generate multi-contrast textured XCAT (MT-XCAT). The MT-XCAT phantoms were evaluated by comparing the intensity histograms and radiomic features with those from real patient images using Wilcoxon rank-sum test. The visual examination demonstrated that the MT-XCAT phantoms presented similar general contrast and anatomical textures as CT and CBCT images. The mean HU of the MT-XCAT-CT and MT-XCAT-CBCT were [Formula: see text] and [Formula: see text], compared with that of real CT ([Formula: see text]) and CBCT ([Formula: see text]). The majority of radiomic features from the MT-XCAT phantoms followed the same distribution as the real images according to the Wilcoxon rank-sum test, except for limited second-order features. The study demonstrated the feasibility of generating realistic MT-XCAT phantoms using D-CGAN. The MT-XCAT phantoms can be further expanded to include other modalities (MRI, PET, ultrasound, etc) under the same scheme. This crucial development greatly enhances the value of the phantom for various clinical applications, including testing and optimizing novel imaging techniques, validation of radiomics analysis methods, and virtual clinical trials.",
      "publication_location": "Phys Med Biol",
      "link": "http://dx.doi.org/10.1088/1361-6560/ab7309",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Advancing ecohydrology in the 21st century: A convergence of opportunities",
      "authors": "Guswa, AJ; Tetzlaff, D; Selker, JS; Carlyle-Moses, DE; Boyer, EW; Bruen, M; Cayuela, C; Creed, IF; van de Giesen, N; Grasso, D; Hannah, DM; Hudson, JE; Hudson, SA; Iida, S; Jackson, RB; Katul, GG; Kumagai, T; Llorens, P; Lopes Ribeiro, F; Michalzik, B; Nanko, K; Oster, C; Pataki, DE; Peters, CA; Rinaldo, A; Sanchez Carretero, D; Trifunovic, B; Zalewski, M; Haagsma, M; Levia, DF",
      "published_date": "January 1, 2020",
      "doi": "10.1002/eco.2208",
      "abstract": "© 2020 The Authors. Ecohydrology published by John Wiley  &  Sons Ltd Nature-based solutions for water-resource challenges require advances in the science of ecohydrology. Current understanding is limited by a shortage of observations and theories that can further our capability to synthesize complex processes across scales ranging from submillimetres to tens of kilometres. Recent developments in environmental sensing, data, and modelling have the potential to drive rapid improvements in ecohydrological understanding. After briefly reviewing advances in sensor technologies, this paper highlights how improved measurements and modelling can be applied to enhance understanding of the following ecohydrological examples: interception and canopy processes, root uptake and critical zone processes, and up-scaled effects of land use on streamflow. Novel and improved sensors will enable new questions and experiments, while machine learning and empirical methods provide additional opportunities to advance science. The synergy resulting from the convergence of these parallel developments will provide new insight into ecohydrological processes and thereby help identify nature-based solutions to address water-resource challenges in the 21st century.",
      "publication_location": "Ecohydrology",
      "link": "http://dx.doi.org/10.1002/eco.2208",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 23,
      "news_mentions": ""
    },
    {
      "title": "MO-D-BRB-10: Modeling Inter-Patient Variation of Organ-At-Risk Sparing in IMRT Plans: An Evidence-Based Plan Quality Evaluation.",
      "authors": "Yuan, L; Ge, Y; Li, T; Yin, F; Wu, QJ",
      "published_date": "June 2012",
      "doi": "10.1118/1.4735791",
      "abstract": "PURPOSE: To develop a predictive model to assess the quality of critical organ dose sparing in IMRT plans by providing patient specific dose sparing references, based on an array of patient anatomical features and prior planning experience. METHODS: Contributions of various patient anatomical features to the inter-patient OAR dose sparing variation in IMRT planning were systematically studied using machine learning method based on high quality prior plans. The dependence of anatomical factor on OAR dosimetric parameters is formulated into predictive models. The OAR dosimetric parameters generated by these predictive models represent the \"best feasible\" clinical outcomes based on past planning experiences. IMRT plans of 88 prostate, 106 head-and-neck (HN) and 21 spine SBRT treatments were used to train the models. The final models were tested by additional 24 prostate and 48 HN plans. The model for spine SBRT was tested by the leave-one-out method. RESULTS: For HN and prostate planning, the significant patient anatomical features that affect OAR sparing are: the distance between OAR and PTV, the portion of OAR volume within an OAR specific distance range, the overlap volume between OAR and PTV, and the portion of OAR volume outside the primary treatment field. For spine SBRT planning, the most significant patient anatomical feature that affects cord sparing is the tightness of the geometric enclosure of PTV surrounding the cord and the homogeneity of PTV dose coverage. The dosimetric parameters predicted for the test patient cases using the models were in agreement with those from the clinical plans in more than 75% of the cases. CONCLUSIONS: The developed predictive models indicated substantial correlation between some important patient anatomical features and OAR dose sparing based on expert experiences. These models can be used as effective tools for evaluating the quality of treatment plans customized to individual patient's anatomy. Partially supported by a master research agreement with Varian Medical System, Inc.",
      "publication_location": "Med Phys",
      "link": "http://dx.doi.org/10.1118/1.4735791",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Biomarkers of cavernous angioma with symptomatic hemorrhage.",
      "authors": "Lyne, SB; Girard, R; Koskimäki, J; Zeineddine, HA; Zhang, D; Cao, Y; Li, Y; Stadnik, A; Moore, T; Lightle, R; Shi, C; Shenkar, R; Carrión-Penagos, J; Polster, SP; Romanos, S; Akers, A; Lopez-Ramirez, M; Whitehead, KJ; Kahn, ML; Ginsberg, MH; Marchuk, DA; Awad, IA",
      "published_date": "June 20, 2019",
      "doi": "10.1172/jci.insight.128577",
      "abstract": "BACKGROUNDCerebral cavernous angiomas (CAs) with a symptomatic hemorrhage (CASH) have a high risk of recurrent hemorrhage and serious morbidity.METHODSEighteen plasma molecules with mechanistic roles in CA pathobiology were investigated in 114 patients and 12 healthy subjects. The diagnostic biomarker of a CASH in the prior year was derived as that minimizing the Akaike information criterion and validated using machine learning, and was compared with the prognostic CASH biomarker predicting bleeding in the subsequent year. Biomarkers were longitudinally followed in a subset of cases. The biomarkers were queried in the lesional neurovascular unit (NVU) transcriptome and in plasma miRNAs from CASH and non-CASH patients.RESULTSThe diagnostic CASH biomarker included a weighted combination of soluble CD14 (sCD14), VEGF, C-reactive protein (CRP), and IL-10 distinguishing CASH patients with 76% sensitivity and 80% specificity (P = 0.0003). The prognostic CASH biomarker (sCD14, VEGF, IL-1β, and sROBO-4) was confirmed to predict a bleed in the subsequent year with 83% sensitivity and 93% specificity (P = 0.001). Genes associated with diagnostic and prognostic CASH biomarkers were differentially expressed in CASH lesional NVUs. Thirteen plasma miRNAs were differentially expressed between CASH and non-CASH patients.CONCLUSIONShared and unique biomarkers of recent symptomatic hemorrhage and of future bleeding in CA are mechanistically linked to lesional transcriptome and miRNA. The biomarkers may be applied for risk stratification in clinical trials and developed as a tool in clinical practice.FUNDINGNIH, William and Judith Davis Fund in Neurovascular Surgery Research, Be Brave for Life Foundation, Safadi Translational Fellowship, Pritzker School of Medicine, and Sigrid Jusélius Foundation.",
      "publication_location": "Jci Insight",
      "link": "http://dx.doi.org/10.1172/jci.insight.128577",
      "citations": 1,
      "readership": 7,
      "tweets": 4,
      "news_mentions": ""
    },
    {
      "title": "Value of Neighborhood Socioeconomic Status in Predicting Risk of Outcomes in Studies That Use Electronic Health Record Data.",
      "authors": "Bhavsar, NA; Gao, A; Phelan, M; Pagidipati, NJ; Goldstein, BA",
      "published_date": "September 7, 2018",
      "doi": "10.1001/jamanetworkopen.2018.2716",
      "abstract": "Importance: Data from electronic health records (EHRs) are increasingly used for risk prediction. However, EHRs do not reliably collect sociodemographic and neighborhood information, which has been shown to be associated with health. The added contribution of neighborhood socioeconomic status (nSES) in predicting health events is unknown and may help inform population-level risk reduction strategies. Objective: To quantify the association of nSES with adverse outcomes and the value of nSES in predicting the risk of adverse outcomes in EHR-based risk models. Design, Setting, and Participants: Cohort study in which data from 90 097 patients 18 years or older in the Duke University Health System and Lincoln Community Health Center EHR from January 1, 2009, to December 31, 2015, with at least 1 health care encounter and residence in Durham County, North Carolina, in the year prior to the index date were linked with census tract data to quantify the association between nSES and the risk of adverse outcomes. Machine learning methods were used to develop risk models and determine how adding nSES to EHR data affects risk prediction. Neighborhood socioeconomic status was defined using the Agency for Healthcare Research and Quality SES index, a weighted measure of multiple indicators of neighborhood deprivation. Main Outcomes and Measures: Outcomes included use of health care services (emergency department and inpatient and outpatient encounters) and hospitalizations due to accidents, asthma, influenza, myocardial infarction, and stroke. Results: Among the 90 097 patients in the training set of the study (57 507 women and 32 590 men; mean [SD] age, 47.2 [17.7] years) and the 122 812 patients in the testing set of the study (75 517 women and 47 295 men; mean [SD] age, 46.2 [17.9] years), those living in neighborhoods with lower nSES had a shorter time to use of emergency department services and inpatient encounters, as well as a shorter time to hospitalizations due to accidents, asthma, influenza, myocardial infarction, and stroke. The predictive value of nSES varied by outcome of interest (C statistic ranged from 0.50 to 0.63). When added to EHR variables, nSES did not improve predictive performance for any health outcome. Conclusions and Relevance: Social determinants of health, including nSES, are associated with the health of a patient. However, the results of this study suggest that information on nSES may not contribute much more to risk prediction above and beyond what is already provided by EHR data. Although this result does not mean that integrating social determinants of health into the EHR has no benefit, researchers may be able to use EHR data alone for population risk assessment.",
      "publication_location": "Jama Network Open",
      "link": "http://dx.doi.org/10.1001/jamanetworkopen.2018.2716",
      "citations": 7,
      "readership": 53,
      "tweets": 64,
      "news_mentions": ""
    },
    {
      "title": "A comparison of risk prediction methods using repeated observations: an application to electronic health records for hemodialysis.",
      "authors": "Goldstein, BA; Pomann, GM; Winkelmayer, WC; Pencina, MJ",
      "published_date": "July 30, 2017",
      "doi": "10.1002/sim.7308",
      "abstract": "An increasingly important data source for the development of clinical risk prediction models is electronic health records (EHRs). One of their key advantages is that they contain data on many individuals collected over time. This allows one to incorporate more clinical information into a risk model. However, traditional methods for developing risk models are not well suited to these irregularly collected clinical covariates. In this paper, we compare a range of approaches for using longitudinal predictors in a clinical risk model. Using data from an EHR for patients undergoing hemodialysis, we incorporate five different clinical predictors into a risk model for patient mortality. We consider different approaches for treating the repeated measurements including use of summary statistics, machine learning methods, functional data analysis, and joint models. We follow up our empirical findings with a simulation study. Overall, our results suggest that simple approaches perform just as well, if not better, than more complex analytic approaches. These results have important implication for development of risk prediction models with EHRs. Copyright © 2017 John Wiley & Sons, Ltd.",
      "publication_location": "Stat Med",
      "link": "http://dx.doi.org/10.1002/sim.7308",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Prediction Models - Development, Evaluation, and Clinical Application.",
      "authors": "Pencina, MJ; Goldstein, BA; D'Agostino, RB",
      "published_date": "April 23, 2020",
      "doi": "10.1056/NEJMp2000589",
      "abstract": "",
      "publication_location": "The New England Journal of Medicine",
      "link": "http://dx.doi.org/10.1056/NEJMp2000589",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 80,
      "news_mentions": ""
    },
    {
      "title": "An outcome model approach to transporting a randomized controlled trial results to a target population.",
      "authors": "Goldstein, BA; Phelan, M; Pagidipati, NJ; Holman, RR; Pencina, MJ; Stuart, EA",
      "published_date": "May 1, 2019",
      "doi": "10.1093/jamia/ocy188",
      "abstract": "OBJECTIVE: Participants enrolled into randomized controlled trials (RCTs) often do not reflect real-world populations. Previous research in how best to transport RCT results to target populations has focused on weighting RCT data to look like the target data. Simulation work, however, has suggested that an outcome model approach may be preferable. Here, we describe such an approach using source data from the 2 × 2 factorial NAVIGATOR (Nateglinide And Valsartan in Impaired Glucose Tolerance Outcomes Research) trial, which evaluated the impact of valsartan and nateglinide on cardiovascular outcomes and new-onset diabetes in a prediabetic population. MATERIALS AND METHODS: Our target data consisted of people with prediabetes serviced at the Duke University Health System. We used random survival forests to develop separate outcome models for each of the 4 treatments, estimating the 5-year risk difference for progression to diabetes, and estimated the treatment effect in our local patient populations, as well as subpopulations, and compared the results with the traditional weighting approach. RESULTS: Our models suggested that the treatment effect for valsartan in our patient population was the same as in the trial, whereas for nateglinide treatment effect was stronger than observed in the original trial. Our effect estimates were more efficient than the weighting approach and we effectively estimated subgroup differences. CONCLUSIONS: The described method represents a straightforward approach to efficiently transporting an RCT result to any target population.",
      "publication_location": "J Am Med Inform Assoc",
      "link": "http://dx.doi.org/10.1093/jamia/ocy188",
      "citations": 1,
      "readership": 22,
      "tweets": 11,
      "news_mentions": ""
    },
    {
      "title": "Testing the Relative Performance of Data Adaptive Prediction Algorithms: A Generalized Test of Conditional Risk Differences.",
      "authors": "Goldstein, BA; Polley, EC; Briggs, FBS; van der Laan, MJ; Hubbard, A",
      "published_date": "May 1, 2016",
      "doi": "10.1515/ijb-2015-0014",
      "abstract": "Comparing the relative fit of competing models can be used to address many different scientific questions. In classical statistics one can, if appropriate, use likelihood ratio tests and information based criterion, whereas clinical medicine has tended to rely on comparisons of fit metrics like C-statistics. However, for many data adaptive modelling procedures such approaches are not suitable. In these cases, statisticians have used cross-validation, which can make inference challenging. In this paper we propose a general approach that focuses on the \"conditional\" risk difference (conditional on the model fits being fixed) for the improvement in prediction risk. Specifically, we derive a Wald-type test statistic and associated confidence intervals for cross-validated test sets utilizing the independent validation within cross-validation in conjunction with a test for multiple comparisons. We show that this test maintains proper Type I Error under the null fit, and can be used as a general test of relative fit for any semi-parametric model alternative. We apply the test to a candidate gene study to test for the association of a set of genes in a genetic pathway.",
      "publication_location": "Int J Biostat",
      "link": "http://dx.doi.org/10.1515/ijb-2015-0014",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Near-term prediction of sudden cardiac death in older hemodialysis patients using electronic health records.",
      "authors": "Goldstein, BA; Chang, TI; Mitani, AA; Assimes, TL; Winkelmayer, WC",
      "published_date": "January 2014",
      "doi": "10.2215/CJN.03050313",
      "abstract": "BACKGROUND AND OBJECTIVES: Sudden cardiac death is the most common cause of death among individuals undergoing hemodialysis. The epidemiology of sudden cardiac death has been well studied, and efforts are shifting to risk assessment. This study aimed to test whether assessment of acute changes during hemodialysis that are captured in electronic health records improved risk assessment. DESIGN, SETTING, PARTICIPANTS, & MEASUREMENTS: Data were collected from all hemodialysis sessions of patients 66 years and older receiving hemodialysis from a large national dialysis provider between 2004 and 2008. The primary outcome of interest was sudden cardiac death the day of or day after a dialysis session. This study used data from 2004 to 2006 as the training set and data from 2007 to 2008 as the validation set. The machine learning algorithm, Random Forests, was used to derive the prediction model. RESULTS: In 22 million sessions, 898 people between 2004 and 2006 and 826 people between 2007 and 2008 died on the day of or day after a dialysis session that was serving as a training or test data session, respectively. A reasonably strong predictor was derived using just predialysis information (concordance statistic=0.782), which showed modest but significant improvement after inclusion of postdialysis information (concordance statistic=0.799, P<0.001). However, risk prediction decreased the farther out that it was forecasted (up to 1 year), and postdialytic information became less important. CONCLUSION: Subtle changes in the experience of hemodialysis aid in the assessment of sudden cardiac death and are captured by modern electronic health records. The collected data are better for the assessment of near-term risk as opposed to longer-term risk.",
      "publication_location": "Clin J Am Soc Nephrol",
      "link": "http://dx.doi.org/10.2215/CJN.03050313",
      "citations": 9,
      "readership": 57,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Disrupted Maturation of the Microbiota and Metabolome among Extremely Preterm Infants with Postnatal Growth Failure.",
      "authors": "Younge, NE; Newgard, CB; Cotten, CM; Goldberg, RN; Muehlbauer, MJ; Bain, JR; Stevens, RD; O'Connell, TM; Rawls, JF; Seed, PC; Ashley, PL",
      "published_date": "June 3, 2019",
      "doi": "10.1038/s41598-019-44547-y",
      "abstract": "Growth failure during infancy is a major global problem that has adverse effects on long-term health and neurodevelopment. Preterm infants are disproportionately affected by growth failure and its effects. Herein we found that extremely preterm infants with postnatal growth failure have disrupted maturation of the intestinal microbiota, characterized by persistently low diversity, dominance of pathogenic bacteria within the Enterobacteriaceae family, and a paucity of strictly anaerobic taxa including Veillonella relative to infants with appropriate postnatal growth. Metabolomic profiling of infants with growth failure demonstrated elevated serum acylcarnitines, fatty acids, and other byproducts of lipolysis and fatty acid oxidation. Machine learning algorithms for normal maturation of the microbiota and metabolome among infants with appropriate growth revealed a pattern of delayed maturation of the microbiota and metabolome among infants with growth failure. Collectively, we identified novel microbial and metabolic features of growth failure in preterm infants and potentially modifiable targets for intervention.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/s41598-019-44547-y",
      "citations": 7,
      "readership": 37,
      "tweets": 24,
      "news_mentions": 15
    },
    {
      "title": "Semigroups of stochastic gradient descent and online principal component analysis: Properties and diffusion approximations",
      "authors": "Feng, Y; Li, L; Liu, JG",
      "published_date": "January 1, 2018",
      "doi": "",
      "abstract": "© 2018 International Press. We study the Markov semigroups for two important algorithms from machine learning: stochastic gradient descent (SGD) and online principal component analysis (PCA). We investigate the effects of small jumps on the properties of the semigroups. Properties including regularity preserving, L∞ contraction are discussed. These semigroups are the dual of the semigroups for evolution of probability, while the latter are L1 contracting and positivity preserving. Using these properties, we show that stochastic differential equations (SDEs) in Rd (on the sphere Sd-1) can be used to approximate SGD (online PCA) weakly. These SDEs may be used to provide some insights of the behaviors of these algorithms.",
      "publication_location": "Communications in Mathematical Sciences",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Accelerating Langevin Sampling with Birth-death",
      "authors": "Lu, Y; Lu, J; Nolen, J",
      "published_date": "",
      "doi": "",
      "abstract": "A fundamental problem in Bayesian inference and statistical machine learning\nis to efficiently sample from multimodal distributions. Due to metastability,\nmultimodal distributions are difficult to sample using standard Markov chain\nMonte Carlo methods. We propose a new sampling algorithm based on a birth-death\nmechanism to accelerate the mixing of Langevin diffusion. Our algorithm is\nmotivated by its mean field partial differential equation (PDE), which is a\nFokker-Planck equation supplemented by a nonlocal birth-death term. This PDE\ncan be viewed as a gradient flow of the Kullback-Leibler divergence with\nrespect to the Wasserstein-Fisher-Rao metric. We prove that under some\nassumptions the asymptotic convergence rate of the nonlocal PDE is independent\nof the potential barrier, in contrast to the exponential dependence in the case\nof the Langevin diffusion. We illustrate the efficiency of the birth-death\naccelerated Langevin method through several analytical examples and numerical\nexperiments.",
      "publication_location": "",
      "link": "http://arxiv.org/abs/1905.09863v1",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Predicting Short-term MCI-to-AD Progression Using Imaging, CSF, Genetic Factors, Cognitive Resilience, and Demographics.",
      "authors": "Varatharajah, Y; Ramanan, VK; Iyer, R; Vemuri, P; Alzheimer’s Disease Neuroimaging Initiative,",
      "published_date": "February 19, 2019",
      "doi": "10.1038/s41598-019-38793-3",
      "abstract": "In the Alzheimer's disease (AD) continuum, the prodromal state of mild cognitive impairment (MCI) precedes AD dementia and identifying MCI individuals at risk of progression is important for clinical management. Our goal was to develop generalizable multivariate models that integrate high-dimensional data (multimodal neuroimaging and cerebrospinal fluid biomarkers, genetic factors, and measures of cognitive resilience) for identification of MCI individuals who progress to AD within 3 years. Our main findings were i) we were able to build generalizable models with clinically relevant accuracy (~93%) for identifying MCI individuals who progress to AD within 3 years; ii) markers of AD pathophysiology (amyloid, tau, neuronal injury) accounted for large shares of the variance in predicting progression; iii) our methodology allowed us to discover that expression of CR1 (complement receptor 1), an AD susceptibility gene involved in immune pathways, uniquely added independent predictive value. This work highlights the value of optimized machine learning approaches for analyzing multimodal patient information for making predictive assessments.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/s41598-019-38793-3",
      "citations": 4,
      "readership": 48,
      "tweets": 19,
      "news_mentions": ""
    },
    {
      "title": "Estimating Normalizing Constants for Log-Concave Distributions:\n  Algorithms and Lower Bounds",
      "authors": "Ge, R; Lee, H; Lu, J",
      "published_date": "",
      "doi": "",
      "abstract": "Estimating the normalizing constant of an unnormalized probability\ndistribution has important applications in computer science, statistical\nphysics, machine learning, and statistics. In this work, we consider the\nproblem of estimating the normalizing constant $Z=\\int_{\\mathbb{R}^d}\ne^{-f(x)}\\,\\mathrm{d}x$ to within a multiplication factor of $1 \\pm\n\\varepsilon$ for a $\\mu$-strongly convex and $L$-smooth function $f$, given\nquery access to $f(x)$ and $\\nabla f(x)$. We give both algorithms and\nlowerbounds for this problem. Using an annealing algorithm combined with a\nmultilevel Monte Carlo method based on underdamped Langevin dynamics, we show\nthat $\\widetilde{\\mathcal{O}}\\Bigl(\\frac{d^{4/3}\\kappa +\nd^{7/6}\\kappa^{7/6}}{\\varepsilon^2}\\Bigr)$ queries to $\\nabla f$ are\nsufficient, where $\\kappa= L / \\mu$ is the condition number. Moreover, we\nprovide an information theoretic lowerbound, showing that at least\n$\\frac{d^{1-o(1)}}{\\varepsilon^{2-o(1)}}$ queries are necessary. This provides\na first nontrivial lowerbound for the problem.",
      "publication_location": "",
      "link": "http://arxiv.org/abs/1911.03043v1",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "WE‐G‐BRA‐01: A Framework to Determine Risk of Pneumonitis Following Radiotherapy for Lung Cancer",
      "authors": "Chawla, A; Marks, L; Deasy, J; Bradley, J; Das, S",
      "published_date": "January 1, 2011",
      "doi": "10.1118/1.3613406",
      "abstract": "Purpose: To assess external validity of a framework, which was previously developed to predict the incidence of radiation‐induced pneumontis in patients following radiotherapy for lung cancer, by testing it on an alternate dataset (other than the one used to develop it). Methods: The study employed two independent datasets: 1) a Duke University dataset of 219 patients, of whom 34 were diagnosed with post‐radiotherapy pneumonitis; and 2) a Washington University (WashU) dataset of 219 patients, of whom 52 developed pneumonitis post‐radiotherapy. While the Duke dataset was used to develop the framework, the WashU dataset was used to assess its validity. The framework was based on a predictive model that combined results from four machine learning models into a single fused model using a Bayesian decision fusion methodology. The results of testing the framework on the WashU dataset was measured in terms of the area under ROC curve (AUC) and compared to the AUC value obtained by Mean Lung Dose (MLD) — a metric commonly used to discriminate between patients with and without pneumonitis. Results: The framework yielded an overall AUC of 0.84 for cross‐validated testing on Duke data. Six patient features were identified as most significant. They consisted of two dose features: EUD (a=1.3) and V30; and four non‐dose features: female gender, tumor in central lung location, adenocarcinoma, and chemotherapy prior to radiotherapy. Most notably, when tested on the WashU dataset, the framework yielded an AUC value of 0.73. In comparison, the AUC value obtained by employing MLD values was only 0.68. Conclusions: Based on testing with an independent dataset, the framework to predict the incidence of radiation‐induced pneumonitis appears to be fairly robust. The framework may potentially be used in the clinic to improve the treatment decision‐making process. © 2011, American Association of Physicists in Medicine. All rights reserved.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3613406",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "MO‐EE‐A2‐04: A Framework to Determine the Risk of Developing Pneumonitis in Lung Cancer Patients Undergoing Radiotherapy",
      "authors": "Chawla, A; Das, S",
      "published_date": "January 1, 2010",
      "doi": "10.1118/1.3469088",
      "abstract": "Purpose: To determine which dose and non‐dose features of patients undergoing thoracic radiotherapy best predict the incidence of possible lung pneumonitis and to estimate the corresponding risk of developing pneumonitis. Method and Materials: The study employed a database of 235 patients, out of which 34 were diagnosed with Grade 2+ pneumonitis. A total of 94 dose and non‐dose features of each patient were analyzed. To determine the most significant features likely to affect patient outcome, a two‐fold optimization approach was developed. First, the feature values were evaluated by four machine learning models for accurate prediction. The model accuracy was measured in terms of tenfold cross‐validation‐based area under ROC curve (AUC). Next, the ROCs of the four models were combined. Towards that end, a Bayesian decision fusion methodology was developed. Finally, based on the combined ROC, the fusion model isolated the set of most significant features and also computed patient‐specific risk of injury. Results: Out of 94 original features, 27 were selected by the four models. AUC values corresponding to the four models were 0.75, 0.70, 0.79, and 0.73, respectively. Most notably, when the four models were combined, the AUC improved to 0.85. Furthermore, the fusion model identified only six features as most significant. They consisted of two dose features: EUD (a=2) and V30; and four non‐dose features: gender, tumor location, histology type, and chemotherapy schedule. The corresponding probabilities for injured patients were found to be significantly higher than those for non‐injured patients, demonstrating robustness of the over all predictive model. Conclusion: A framework was developed to predict the incidence of pneumonitis in lung cancer patients undergoing radiotherapy. The predicted probabilities of injury were found to correspond well with the known injury status of the patients. The framework may potentially be used in the clinic to improve the treatment decision‐making process. © 2010, American Association of Physicists in Medicine. All rights reserved.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1118/1.3469088",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "What was old is new again: using the host response to diagnose infectious disease.",
      "authors": "Ko, ER; Yang, WE; McClain, MT; Woods, CW; Ginsburg, GS; Tsalik, EL",
      "published_date": 2015,
      "doi": "10.1586/14737159.2015.1059278",
      "abstract": "A century of advances in infectious disease diagnosis and treatment changed the face of medicine. However, challenges continue to develop including multi-drug resistance, globalization that increases pandemic risks and high mortality from severe infections. These challenges can be mitigated through improved diagnostics, focusing on both pathogen discovery and the host response. Here, we review how 'omics' technologies improve sepsis diagnosis, early pathogen identification and personalize therapy. Such host response diagnostics are possible due to the confluence of advanced laboratory techniques (e.g., transcriptomics, metabolomics, proteomics) along with advanced mathematical modeling such as machine learning techniques. The road ahead is promising, but obstacles remain before the impact of such advanced diagnostic modalities is felt at the bedside.",
      "publication_location": "Expert Rev Mol Diagn",
      "link": "http://dx.doi.org/10.1586/14737159.2015.1059278",
      "citations": 18,
      "readership": 50,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Patient Phenotypes, Cardiovascular Risk, and Ezetimibe Treatment in Patients After Acute Coronary Syndromes (from IMPROVE-IT).",
      "authors": "Sharma, A; Sun, J-L; Lokhnygina, Y; Roe, MT; Ahmad, T; Desai, NR; Blazing, MA",
      "published_date": "April 15, 2019",
      "doi": "10.1016/j.amjcard.2019.01.034",
      "abstract": "Risk prediction following acute coronary syndrome (ACS) remains challenging. Data-driven machine-learning algorithms can potentially identify patients at high risk of clinical events. The Improved Reduction of Outcomes: Vytorin Efficacy International Trial randomized 18,144 post-ACS patients to ezetimibe + simvastatin or placebo + simvastatin. We performed hierarchical cluster analysis to identify patients at high risk of adverse events. Associations between clusters and outcomes were assessed using Cox proportional hazards models. The primary outcome was cardiovascular death, nonfatal myocardial infarction, nonfatal stroke, unstable angina hospitalization, or coronary revascularization ≥30 days after randomization. We evaluated ezetimibe's impact on outcomes across clusters and the ability of the cluster analysis to discriminate for outcomes compared with the Global Registry of Acute Coronary Events (GRACE) score. Five clusters were identified. In cluster 1 (n = 13,252), most patients experienced a non-STEMI (54.8%). Cluster 2 patients (n = 2,719) had the highest incidence of unstable angina (n = 83.3%). Cluster 3 patients (n = 782) all identified as Spanish descent, whereas cluster 4 patients (n = 803) were primarily from South America (56.2%). In cluster 5 (n = 587), all patients had ST elevation. Cluster analysis identified patients at high risk of adverse outcomes (log-rank p <0.0001); Cluster 2 (vs 1) patients had the highest risk of outcomes (hazards ratio 1.33, 95% confidence interval 1.24 to 1.43). Compared with GRACE risk, cluster analysis did not provide superior outcome discrimination. A consistent ezetimibe treatment effect was identified across clusters (interaction p = 0.882). In conclusion, cluster analysis identified significant difference in risk of outcomes across cluster groups. Data-driven strategies to identify patients who may differentially benefit from therapies and for risk stratification require further evaluation.",
      "publication_location": "Am J Cardiol",
      "link": "http://dx.doi.org/10.1016/j.amjcard.2019.01.034",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Dysregulation of Prefrontal Cortex-Mediated Slow-Evolving Limbic Dynamics Drives Stress-Induced Emotional Pathology.",
      "authors": "Hultman, R; Mague, SD; Li, Q; Katz, BM; Michel, N; Lin, L; Wang, J; David, LK; Blount, C; Chandy, R; Carlson, D; Ulrich, K; Carin, L; Dunson, D; Kumar, S; Deisseroth, K; Moore, SD; Dzirasa, K",
      "published_date": "July 20, 2016",
      "doi": "10.1016/j.neuron.2016.05.038",
      "abstract": "Circuits distributed across cortico-limbic brain regions compose the networks that mediate emotional behavior. The prefrontal cortex (PFC) regulates ultraslow (<1 Hz) dynamics across these networks, and PFC dysfunction is implicated in stress-related illnesses including major depressive disorder (MDD). To uncover the mechanism whereby stress-induced changes in PFC circuitry alter emotional networks to yield pathology, we used a multi-disciplinary approach including in vivo recordings in mice and chronic social defeat stress. Our network model, inferred using machine learning, linked stress-induced behavioral pathology to the capacity of PFC to synchronize amygdala and VTA activity. Direct stimulation of PFC-amygdala circuitry with DREADDs normalized PFC-dependent limbic synchrony in stress-susceptible animals and restored normal behavior. In addition to providing insights into MDD mechanisms, our findings demonstrate an interdisciplinary approach that can be used to identify the large-scale network changes that underlie complex emotional pathologies and the specific network nodes that can be used to develop targeted interventions.",
      "publication_location": "Neuron",
      "link": "http://dx.doi.org/10.1016/j.neuron.2016.05.038",
      "citations": 34,
      "readership": 192,
      "tweets": 30,
      "news_mentions": 12
    },
    {
      "title": "Brain-age in midlife is associated with accelerated biological aging and cognitive decline in a longitudinal birth cohort.",
      "authors": "Elliott, ML; Belsky, DW; Knodt, AR; Ireland, D; Melzer, TR; Poulton, R; Ramrakha, S; Caspi, A; Moffitt, TE; Hariri, AR",
      "published_date": "December 10, 2019",
      "doi": "10.1038/s41380-019-0626-7",
      "abstract": "An individual's brainAGE is the difference between chronological age and age predicted from machine-learning models of brain-imaging data. BrainAGE has been proposed as a biomarker of age-related deterioration of the brain. Having an older brainAGE has been linked to Alzheimer's, dementia, and mortality. However, these findings are largely based on cross-sectional associations which can confuse age differences with cohort differences. To illuminate the validity of brainAGE as a biomarker of accelerated brain aging, a study is needed of a large cohort all born in the same year who nevertheless vary on brainAGE. In the Dunedin Study, a population-representative 1972-73 birth cohort, we measured brainAGE at age 45 years, as well as the pace of biological aging and cognitive decline in longitudinal data from childhood to midlife (N = 869). In this cohort, all chronological age 45 years, brainAGE was measured reliably (ICC = 0.81) and ranged from 24 to 72 years. Those with older midlife brainAGEs tended to have poorer cognitive function in both adulthood and childhood, as well as impaired brain health at age 3. Furthermore, those with older brainAGEs had an accelerated pace of biological aging, older facial appearance, and early signs of cognitive decline from childhood to midlife. These findings help to validate brainAGE as a potential surrogate biomarker for midlife intervention studies that seek to measure dementia-prevention efforts in midlife. However, the findings also caution against the assumption that brainAGE scores represent only age-related deterioration of the brain as they may also index central nervous system variation present since childhood.",
      "publication_location": "Molecular Psychiatry",
      "link": "http://dx.doi.org/10.1038/s41380-019-0626-7",
      "citations": 1,
      "readership": "(None,)",
      "tweets": 42,
      "news_mentions": ""
    },
    {
      "title": "Non-invasive biomarkers of fetal brain development reflecting prenatal stress: An integrative multi-scale multi-species perspective on data collection and analysis",
      "authors": "Frasch, MG; Lobmaier, SM; Stampalija, T; Desplats, P; Pallarés, ME; Pastor, V; Brocco, MA; Wu, HT; Schulkin, J; Herry, CL; Seely, AJE; Metz, GAS; Louzoun, Y; Antonelli, MC",
      "published_date": "January 1, 2018",
      "doi": "10.1016/j.neubiorev.2018.05.026",
      "abstract": "© 2018 Elsevier Ltd Prenatal stress (PS) impacts early postnatal behavioural and cognitive development. This process of ‘fetal programming’ is mediated by the effects of the prenatal experience on the developing hypothalamic–pituitary–adrenal (HPA) axis and autonomic nervous system (ANS). We derive a multi-scale multi-species approach to devising preclinical and clinical studies to identify early non-invasively available pre- and postnatal biomarkers of PS. The multiple scales include brain epigenome, metabolome, microbiome and the ANS activity gauged via an array of advanced non-invasively obtainable properties of fetal heart rate fluctuations. The proposed framework has the potential to reveal mechanistic links between maternal stress during pregnancy and changes across these physiological scales. Such biomarkers may hence be useful as early and non-invasive predictors of neurodevelopmental trajectories influenced by the PS as well as follow-up indicators of success of therapeutic interventions to correct such altered neurodevelopmental trajectories. PS studies must be conducted on multiple scales derived from concerted observations in multiple animal models and human cohorts performed in an interactive and iterative manner and deploying machine learning for data synthesis, identification and validation of the best non-invasive detection and follow-up biomarkers, a prerequisite for designing effective therapeutic interventions.",
      "publication_location": "Neuroscience and Biobehavioral Reviews",
      "link": "http://dx.doi.org/10.1016/j.neubiorev.2018.05.026",
      "citations": 10,
      "readership": 65,
      "tweets": 9,
      "news_mentions": ""
    },
    {
      "title": "An exploration algorithm for stochastic simulators driven by energy gradients",
      "authors": "Georgiou, AS; Bello-Rivas, JM; Gear, CW; Wu, HT; Chiavazzo, E; Kevrekidis, IG",
      "published_date": "July 1, 2017",
      "doi": "10.3390/e19070294",
      "abstract": "© 2017 by the authors. In recent work, we have illustrated the construction of an exploration geometry on free energy surfaces: the adaptive computer-assisted discovery of an approximate low-dimensional manifold on which the effective dynamics of the system evolves. Constructing such an exploration geometry involves geometry-biased sampling (through both appropriately-initialized unbiased molecular dynamics and through restraining potentials) and, machine learning techniques to organize the intrinsic geometry of the data resulting from the sampling (in particular, diffusion maps, possibly enhanced through the appropriate Mahalanobis-type metric). In this contribution, we detail a method for exploring the conformational space of a stochastic gradient system whose effective free energy surface depends on a smaller number of degrees of freedom than the dimension of the phase space. Our approach comprises two steps. First, we study the local geometry of the free energy landscape using diffusion maps on samples computed through stochastic dynamics. This allows us to automatically identify the relevant coarse variables. Next, we use the information garnered in the previous step to construct a new set of initial conditions for subsequent trajectories. These initial conditions are computed so as to explore the accessible conformational space more efficiently than by continuing the previous, unbiased simulations. We showcase this method on a representative test system.",
      "publication_location": "Entropy",
      "link": "http://dx.doi.org/10.3390/e19070294",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Butterfly-Net: Optimal Function Representation Based on Convolutional\n  Neural Networks",
      "authors": "Li, Y; Cheng, X; Lu, J",
      "published_date": "",
      "doi": "",
      "abstract": "Deep networks, especially convolutional neural networks (CNNs), have been\nsuccessfully applied in various areas of machine learning as well as to\nchallenging problems in other scientific and engineering fields. This paper\nintroduces Butterfly-Net, a low-complexity CNN with structured and sparse\ncross-channel connections, together with a Butterfly initialization strategy\nfor a family of networks. Theoretical analysis of the approximation power of\nButterfly-Net to the Fourier representation of input data shows that the error\ndecays exponentially as the depth increases. Combining Butterfly-Net with a\nfully connected neural network, a large class of problems are proved to be well\napproximated with network complexity depending on the effective frequency\nbandwidth instead of the input dimension. Regular CNN is covered as a special\ncase in our analysis. Numerical experiments validate the analytical results on\nthe approximation of Fourier kernels and energy functionals of Poisson's\nequations. Moreover, all experiments support that training from Butterfly\ninitialization outperforms training from random initialization. Also, adding\nthe remaining cross-channel connections, although significantly increase the\nparameter number, does not much improve the post-training accuracy and is more\nsensitive to data distribution.",
      "publication_location": "",
      "link": "https://hdl.handle.net/10161/17831",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Lost in a random forest: Using Big Data to study rare events",
      "authors": "Bail, CA",
      "published_date": "January 1, 2015",
      "doi": "10.1177/2053951715604333",
      "abstract": "© The Author(s) 2015. Sudden, broad-scale shifts in public opinion about social problems are relatively rare. Until recently, social scientists were forced to conduct post-hoc case studies of such unusual events that ignore the broader universe of possible shifts in public opinion that do not materialize. The vast amount of data that has recently become available via social media sites such as Facebook and Twitter—as well as the mass-digitization of qualitative archives provide an unprecedented opportunity for scholars to avoid such selection on the dependent variable. Yet the sheer scale of these new data creates a new set of methodological challenges. Conventional linear models, for example, minimize the influence of rare events as “outliers”—especially within analyses of large samples. While more advanced regression models exist to analyze outliers, they suffer from an even more daunting challenge: equifinality, or the likelihood that rare events may occur via different causal pathways. I discuss a variety of possible solutions to these problems—including recent advances in fuzzy set theory and machine learning—but ultimately advocate an ecumenical approach that combines multiple techniques in iterative fashion.",
      "publication_location": "Big Data and Society",
      "link": "http://dx.doi.org/10.1177/2053951715604333",
      "citations": 4,
      "readership": 44,
      "tweets": 19,
      "news_mentions": ""
    },
    {
      "title": "Genomic Biomarkers to Predict Resistance to Hypomethylating Agents in Patients With Myelodysplastic Syndromes Using Artificial Intelligence.",
      "authors": "Nazha, A; Sekeres, MA; Bejar, R; Rauh, MJ; Othus, M; Komrokji, RS; Barnard, J; Hilton, CB; Kerr, CM; Steensma, DP; DeZern, A; Roboz, G; Garcia-Manero, G; Erba, H; Ebert, BL; Maciejewski, JP",
      "published_date": 2019,
      "doi": "10.1200/po.19.00119",
      "abstract": "PURPOSE: We developed an unbiased framework to study the association of several mutations in predicting resistance to hypomethylating agents (HMAs) in patients with myelodysplastic syndromes (MDS), analogous to consumer and commercial recommender systems in which customers who bought products A and B are likely to buy C: patients who have a mutation in gene A and gene B are likely to respond or not respond to HMAs. METHODS: We screened a cohort of 433 patients with MDS who received HMAs for the presence of common myeloid mutations in 29 genes that were obtained before the patients started therapy. The association between mutations and response was evaluated by the Apriori market basket analysis algorithm. Rules with the highest confidence (confidence that the association exists) and the highest lift (strength of the association) were chosen. We validated our biomarkers in samples from patients enrolled in the S1117 trial. RESULTS: Among 433 patients, 193 (45%) received azacitidine, 176 (40%) received decitabine, and 64 (15%) received HMA alone or in combination. The median age was 70 years (range, 31 to 100 years), and 28% were female. The median number of mutations per sample was three (range, zero to nine), and 176 patients (41%) had three or more mutations per sample. Association rules identified several genomic combinations as being highly associated with no response. These molecular signatures were present in 30% of patients with three or more mutations/sample with an accuracy rate of 87% in the training cohort and 93% in the validation cohort. CONCLUSION: Genomic biomarkers can identify, with high accuracy, approximately one third of patients with MDS who will not respond to HMAs. This study highlights the importance of machine learning technologies such as the recommender system algorithm in translating genomic data into useful clinical tools.",
      "publication_location": "Jco Precision Oncology",
      "link": "http://dx.doi.org/10.1200/po.19.00119",
      "citations": 2,
      "readership": 13,
      "tweets": 18,
      "news_mentions": ""
    },
    {
      "title": "Summary of contributions to GAW15 Group 13: candidate gene association studies.",
      "authors": "de Andrade, M; Allen, AS; Brinza, D; Cheng, R; Da, Y; de Vries, AR; Ewhida, A; Feng, Z; Jung, H; Hsieh, H-J; Köhler, K; Liu, Y; Liu-Mares, W; Luan, J; Marquard, V; Nolte, IM; Oh, S; Platt, A; Qin, X; Yoo, YJ; Yuan, A; Tian, X; Won, S",
      "published_date": 2007,
      "doi": "10.1002/gepi.20287",
      "abstract": "Here we summarize the contributions to Group 13 of the Genetic Analysis Workshop 15 held in St. Pete Beach, Florida, on November 12-14, 2006. The focus of this group was to identify candidate genes associated with rheumatoid arthritis or surrogate outcomes. The association methods proposed in this group were diverse, from better known approaches, such as logistic regression for single nucleotide polymorphism (SNP) analysis and haplotype sharing tests to methods less familiar to genetic epidemiologists, such as machine learning and visualization methods. The majority of papers analyzed Genetic Analysis Workshop 15 Problems 2 (rheumatoid arthritis data) and 3 (simulated data). The highlighted points of this group analyses were: (1) haplotype-based statistics can be more powerful than single SNP analysis for risk-locus localization; (2) considering linkage disequilibrium block structure in haplotype analysis may reduce the likelihood of false-positive results; and (3) visual representation of genetic models for continuous covariates may help identify SNPs associated with the underlying quantitative trait loci.",
      "publication_location": "Genetic Epidemiology",
      "link": "http://dx.doi.org/10.1002/gepi.20287",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Spectral data completion for dual-source x-ray CT",
      "authors": "Clark, DP; Badea, CT",
      "published_date": "January 1, 2019",
      "doi": "10.1117/12.2512825",
      "abstract": "© SPIE. Downloading of the abstract is permitted for personal use only. In the context of x-ray CT, data completion is the process of augmenting truncated projection data to avoid artifacts during reconstruction. Data completion is commonly employed in dual-source CT where physical or hardware constraints limit the field of view covered by one of the two imaging chains. Practically, data completion is accomplished by extrapolating missing data based on the imaging chain with the full field of view, including some reweighting to approximate any spectral differences. While this approach works well in clinical applications, there are applications which would benefit from improved spectral estimation over the full field of view, including model-based iterative reconstruction, contrastenhanced abdominal imaging of large patients, and combined temporal and spectral imaging. Additionally, robust spectral data completion methods could provide an alternative to interior tomography for dose management in cardiac and spectral CT applications. To illustrate challenges with and potential machine-learning (ML) solutions for the spectral data completion problem, we present two realistic simulation experiments. A circular, cone-beam experiment disambiguates three contrast materials with dual-energy data and uses a generative network to inject 3D geometric information into a 2D, image-domain completion problem. A second clinical MDCT experiment uses a sophisticated variational network based on the split Bregman method and is structured to integrate directly into existing analytical reconstruction pipelines. While further work is required to establish performance limits and expectations, the results of both experiments strongly recommend the use of ML in spectral data completion problems.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2512825",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Multi-energy CT decomposition using convolutional neural networks",
      "authors": "Clark, DP; Holbrook, M; Badea, CT",
      "published_date": "January 1, 2018",
      "doi": "10.1117/12.2293728",
      "abstract": "© 2018 SPIE. Spectral CT can provide accurate tissue composition measurements by utilizing the energy dependence of x-ray attenuation in different materials. We have introduced image reconstruction and material decomposition algorithms for multi-energy CT data acquired either with energy integrating detectors (EID) or photon counting detectors (PCD); however, material decomposition is an ill-posed problem due to the potential overlap of spectral measurements and to noise. Recently, convolutional neural networks (CNN) have generated excitement in the field of machine learning and computer vision. The goal of this work is to develop CNN-based methods for material decomposition in spectral CT. The CNN for decomposition had a U-net structure and was trained with either five-energy PCD-CT or DE-CT. As targets for training, we used simulated phantoms constructed from random combinations of water and contrast agents (iodine, barium, and calcium for five-energy PCD-CT; iodine and gold for DE EID-based CT). The experimentally measured sensitivity matrix values for iodine, barium, and calcium or iodine and gold were used to recreate the CT images corresponding to both PCD and DE-CT cases. These CT images were used to train CNNs to generate material maps at each pixel location. After training, we tested the CNNs by applying them to experimentally acquired DE-EID and PCD-based micro-CT data in mice. The predicted material maps were compared to the absolute truth in simulations and to sensitivity-based decompositions for the in vivo mouse data. The CNN-based decomposition provided higher accuracy and lower noise. In conclusion, our U-net performed a more robust spectral micro-CT decomposition because it inherently better exploits spatial and spectral correlations.",
      "publication_location": "Progress in Biomedical Optics and Imaging   Proceedings of Spie",
      "link": "http://dx.doi.org/10.1117/12.2293728",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Metabolome-based signature of disease pathology in MS.",
      "authors": "Andersen, SL; Briggs, FBS; Winnike, JH; Natanzon, Y; Maichle, S; Knagge, KJ; Newby, LK; Gregory, SG",
      "published_date": "June 2019",
      "doi": "10.1016/j.msard.2019.03.006",
      "abstract": "BACKGROUND: Diagnostic delays are common for multiple sclerosis (MS) since diagnosis typically depends on the presentation of nonspecific clinical symptoms together with radiologically-determined central nervous system (CNS) lesions. It is important to reduce diagnostic delays as earlier initiation of disease modifying therapies mitigates long-term disability. Developing a metabolomic blood-based MS biomarker is attractive, but prior efforts have largely focused on specific subsets of metabolite classes or analytical platforms. Thus, there are opportunities to interrogate metabolite profiles using more expansive and comprehensive approaches for developing MS biomarkers and for advancing our understanding of MS pathogenesis. METHODS: To identify putative blood-based MS biomarkers, we comprehensively interrogated the metabolite profiles in 12 non-Hispanic white, non-smoking, male MS cases who were drug naïve for 3 months prior to biospecimen collection and 13 non-Hispanic white, non-smoking male controls who were frequency matched to cases by age and body mass index. We performed untargeted two-dimensional gas chromatography and time-of-flight mass spectrometry (GCxGC-TOFMS) and targeted lipidomic and amino acid analysis on serum. 325 metabolites met quality control and supervised machine learning was used to identify metabolites most informative for MS status. The discrimination potential of these select metabolites were assessed using receiver operator characteristic curves based on logistic models; top candidate metabolites were defined as having area under the curves (AUC) >80%. The associations between whole-genome expression data and the top candidate metabolites were examined, followed by pathway enrichment analyses. Similar associations were examined for 175 putative MS risk variants and the top candidate metabolites. RESULTS: 12 metabolites were determined to be informative for MS status, of which 6 had AUCs >80%: pyroglutamate, laurate, acylcarnitine C14:1, N-methylmaleimide, and 2 phosphatidylcholines (PC ae 40:5, PC ae 42:5). These metabolites participate in glutathione metabolism, fatty acid metabolism/oxidation, cellular membrane composition, and transient receptor potential channel signaling. Pathway analyses based on the gene expression association for each metabolite suggested enrichment for pathways associated with apoptosis and mitochondrial dysfunction. Interestingly, the predominant MS genetic risk allele HLA-DRB1×15:01 was associated with one of the 6 top metabolites. CONCLUSION: Our analysis represents the most comprehensive description of metabolic changes associated with MS in serum, to date, with the inclusion of genomic and genetic information. We identified atypical metabolic processes that differed between MS patients and controls, which may enable the development of biological targets for diagnosis and treatment.",
      "publication_location": "Mult Scler Relat Disord",
      "link": "http://dx.doi.org/10.1016/j.msard.2019.03.006",
      "citations": 1,
      "readership": 38,
      "tweets": 11,
      "news_mentions": ""
    },
    {
      "title": "Modeling real world system geometry and detector response within a high-throughput X-ray simulation framework",
      "authors": "Coccarelli, D; Hurlock, A; Royse, C; Carpenter, JH; Greenberg, JA; Johnson, E; Bosch, C; Gehm, ME",
      "published_date": "January 1, 2019",
      "doi": "10.1117/12.2518870",
      "abstract": "© 2019 SPIE. Downloading of the abstract is permitted for personal use only. Simulations of x-ray scanners have the potential to aid in the design and understanding of system performance. We have previously shown the usefulness of a high-throughput simulation framework in pursuit of information theoretic analysis of x-ray systems employed for aviation security. While conclusions drawn from these studies were able to inform design decisions, they were limited to generic system geometries and nälve interpretations of detector responses. In collaboration with the SureScan Corporation, we have since expanded our analysis efforts to include their real world system geometry and detector response. To this extent, we present our work to simulate the SureScan x1000 scanner, a fixed-gantry spectral CT system for checked baggage. Our simulations are validated in terms of system geometry and spectral response. We show how high fidelity simulations are used with SureScan reconstruction software to analyze virtual baggage. The close match between simulated and real world measurements means that simulation can be a powerful tool in system development. Moreover, the close match allows simulation to be a straightforward avenue for producing large labeled datasets needed in machine learning approaches to automatic threat recognition (ATR).",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.2518870",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Three challenges in cyber-physical systems",
      "authors": "Mangharam, R; Abbas, H; Behl, M; Jang, K; Pajic, M; Jiang, Z",
      "published_date": "March 23, 2016",
      "doi": "10.1109/COMSNETS.2016.7440015",
      "abstract": "© 2016 IEEE. The tight coupling of computation, communication and control with physical systems such as actuation of closed-loop medical devices within the human body, peak power minimization by coordination of controllers across large industrial plants, and fast life-critical decision making by autonomous vehicles, present a set of fundamental and unique challenges. Each of these require new approaches at the intersection of multiple scientific, human and systems disciplines. We discuss five such challenges which require creative insights and application of model-based design, control systems, scheduling theory, formal methods, statistical machine learning and domain-specific experimentation. We ask the following questions: (1) An autonomous medical device is implanted to control your heart over a period of 5-7 years. How do you guarantee the software in the device provides safe and effective treatment under all physiological conditions? (2) Electricity prices in the US have summer peaks that are over 32× their average prices and winter peaks that are 86×. How can buildings respond to massive swings in energy prices at fast time scales? (3) While wireless has been successfully used for open-loop monitoring and tracking, how can we operate closed-loop control systems over a network of wireless controllers. Furthermore, how can we ensure robust, optimal and secure control in the presence of node/link failures and topology changes?",
      "publication_location": "2016 8th International Conference on Communication Systems and Networks, Comsnets 2016",
      "link": "http://dx.doi.org/10.1109/COMSNETS.2016.7440015",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Security-aware synthesis of human-UAV protocols",
      "authors": "Elfar, M; Zhu, H; Cummings, ML; Pajic, M",
      "published_date": "May 1, 2019",
      "doi": "10.1109/ICRA.2019.8794385",
      "abstract": "© 2019 IEEE. In this work, we synthesize collaboration protocols for human-unmanned aerial vehicle (H-UAV) command and control systems, where the human operator aids in securing the UAV by intermittently performing geolocation tasks to confirm its reported location. We first present a stochastic game-based model for the system that accounts for both the operator and an adversary capable of launching stealthy false-data injection attacks, causing the UAV to deviate from its path. We also describe a synthesis challenge due to the UAV's hidden-information constraint. Next, we perform human experiments using a developed RESCHU-SA testbed to recognize the geolocation strategies that operators adopt. Furthermore, we deploy machine learning techniques on the collected experimental data to predict the correctness of a geolocation task at a given location based on its geographical features. By representing the model as a delayed-action game and formalizing the system objectives, we utilize off-the-shelf model checkers to synthesize protocols for the human-UAV coalition that satisfy these objectives. Finally, we demonstrate the usefulness of the H-UAV protocol synthesis through a case study where the protocols are experimentally analyzed and further evaluated by human operators.",
      "publication_location": "Proceedings   Ieee International Conference on Robotics and Automation",
      "link": "http://dx.doi.org/10.1109/ICRA.2019.8794385",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "High-throughput prediction of finite-temperature properties using the quasi-harmonic approximation",
      "authors": "Nath, P; Plata, JJ; Usanmaz, D; Al Rahal Al Orabi, R; Fornari, M; Nardelli, MB; Toher, C; Curtarolo, S",
      "published_date": "December 1, 2016",
      "doi": "10.1016/j.commatsci.2016.07.043",
      "abstract": "© 2016 Elsevier B.V. In order to calculate thermal properties in automatic fashion, the Quasi-Harmonic Approximation (QHA) has been combined with the Automatic Phonon Library (APL) and implemented within the AFLOW framework for high-throughput computational materials science. As a benchmark test to address the accuracy of the method and implementation, the specific heat capacities, thermal expansion coefficients, Grüneisen parameters and bulk moduli have been calculated for 130 compounds. It is found that QHA-APL can reliably predict such values for several different classes of solids with root mean square relative deviation smaller than 28% with respect to experimental values. The automation, robustness, accuracy and precision of QHA-APL enable the computation of large material data sets, the implementation of repositories containing thermal properties, and finally can serve the community for data mining and machine learning studies.",
      "publication_location": "Computational Materials Science",
      "link": "http://dx.doi.org/10.1016/j.commatsci.2016.07.043",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Universal fragment descriptors for predicting properties of inorganic crystals.",
      "authors": "Isayev, O; Oses, C; Toher, C; Gossett, E; Curtarolo, S; Tropsha, A",
      "published_date": "June 5, 2017",
      "doi": "10.1038/ncomms15679",
      "abstract": "Although historically materials discovery has been driven by a laborious trial-and-error process, knowledge-driven materials design can now be enabled by the rational combination of Machine Learning methods and materials databases. Here, data from the AFLOW repository for ab initio calculations is combined with Quantitative Materials Structure-Property Relationship models to predict important properties: metal/insulator classification, band gap energy, bulk/shear moduli, Debye temperature and heat capacities. The prediction's accuracy compares well with the quality of the training data for virtually any stoichiometric inorganic crystalline material, reciprocating the available thermomechanical experimental data. The universality of the approach is attributed to the construction of the descriptors: Property-Labelled Materials Fragments. The representations require only minimal structural input allowing straightforward implementations of simple heuristic design rules.",
      "publication_location": "Nature Communications",
      "link": "http://dx.doi.org/10.1038/ncomms15679",
      "citations": 107,
      "readership": 352,
      "tweets": 25,
      "news_mentions": 11
    },
    {
      "title": "Data-driven design of inorganic materials with the Automatic Flow Framework for Materials Discovery",
      "authors": "Oses, C; Toher, C; Curtarolo, S",
      "published_date": "September 1, 2018",
      "doi": "10.1557/mrs.2018.207",
      "abstract": "© Copyright Materials Research Society 2018. The expansion of programmatically accessible materials data has cultivated opportunities for data-driven approaches. Workflows such as the Automatic Flow Framework for Materials Discovery not only manage the generation, storage, and dissemination of materials data, but also leverage the information for thermodynamic formability modeling, such as the prediction of phase diagrams and properties of disordered materials. In combination with standardized parameter sets, the wealth of data is ideal for training machine-learning algorithms, which have already been employed for property prediction, descriptor development, design rule discovery, and the identification of candidate functional materials. These methods promise to revolutionize the path to synthesis, and ultimately transform the practice of traditional materials discovery to one of rational and autonomous materials design.",
      "publication_location": "Mrs Bulletin",
      "link": "http://dx.doi.org/10.1557/mrs.2018.207",
      "citations": 10,
      "readership": 22,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Variables of importance in the Scientific Registry of Transplant Recipients database predictive of heart transplant waitlist mortality.",
      "authors": "Hsich, EM; Thuita, L; McNamara, DM; Rogers, JG; Valapour, M; Goldberg, LR; Yancy, CW; Blackstone, EH; Ishwaran, H; Transplantation of HEarts to MaxImize Survival (THEMIS) Investigators,",
      "published_date": "July 2019",
      "doi": "10.1111/ajt.15265",
      "abstract": "The prelisting variables essential for creating an accurate heart transplant allocation score based on survival are unknown. To identify these we studied mortality of adults on the active heart transplant waiting list in the Scientific Registry of Transplant Recipients database from January 1, 2004 to August 31, 2015. There were 33 069 candidates awaiting heart transplantation: 7681 UNOS Status 1A, 13 027 Status 1B, and 12 361 Status 2. During a median waitlist follow-up of 4.3 months, 5514 candidates died. Variables of importance for waitlist mortality were identified by machine learning using Random Survival Forests. Strong correlates predicting survival were estimated glomerular filtration rate (eGFR), serum albumin, extracorporeal membrane oxygenation, ventricular assist device, mechanical ventilation, peak oxygen capacity, hemodynamics, inotrope support, and type of heart disease with less predictive variables including antiarrhythmic agents, history of stroke, vascular disease, prior malignancy, and prior tobacco use. Complex interactions were identified such as an additive risk in mortality based on renal function and serum albumin, and sex-differences in mortality when eGFR >40 mL/min/1.73 m. Most predictive variables for waitlist mortality are in the current tiered allocation system except for eGFR and serum albumin which have an additive risk and complex interactions.",
      "publication_location": "Am J Transplant",
      "link": "http://dx.doi.org/10.1111/ajt.15265",
      "citations": 1,
      "readership": 23,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "Unsupervised Gaussian mixture-model with expectation maximization for detecting glaucomatous progression in standard automated perimetry visual fields",
      "authors": "Yousefi, S; Balasubramanian, M; Goldbaum, MH; Medeiros, FA; Zangwill, LM; Weinreb, RN; Liebmann, JM; Girkin, CA; Bowd, C",
      "published_date": "May 1, 2016",
      "doi": "10.1167/tvst.5.3.2",
      "abstract": "© 2016, Association for Research in Vision and Ophthalmology Inc. All rights reserved. Purpose. To validate Gaussian mixture-model with expectation maximization (GEM) and variational Bayesian independent component analysis mixture-models (VIM) for detecting glaucomatous progression along visual field (VF) defect patterns (GEM– progression of patterns (POP) and VIM-POP). To compare GEM-POP and VIM-POP with other methods. Methods. GEM and VIM models separated cross-sectional abnormal VFs from 859 eyes and normal VFs from 1117 eyes into abnormal and normal clusters. Clusters were decomposed into independent axes. The confidence limit (CL) of stability was established for each axis with a set of 84 stable eyes. Sensitivity for detecting progression was assessed in a sample of 83 eyes with known progressive glaucomatous optic neuropathy (PGON). Eyes were classified as progressed if any defect pattern progressed beyond the CL of stability. Performance of GEM-POP and VIM-POP was compared to point-wise linear regression (PLR), permutation analysis of PLR (PoPLR), and linear regression (LR) of mean deviation (MD), and visual field index (VFI). Results. Sensitivity and specificity for detecting glaucomatous VFs were 89.9% and 93.8%, respectively, for GEM and 93.0% and 97.0%, respectively, for VIM. Receiver operating characteristic (ROC) curve areas for classifying progressed eyes were 0.82 for VIM-POP, 0.86 for GEM-POP, 0.81 for PoPLR, 0.69 for LR of MD, and 0.76 for LR of VFI. Conclusions. GEM-POP was significantly more sensitive to PGON than PoPLR and linear regression of MD and VFI in our sample, while providing localized progression information. Translational Relevance. Detection of glaucomatous progression can be improved by assessing longitudinal changes in localized patterns of glaucomatous defect identified by unsupervised machine learning.",
      "publication_location": "Translational Vision Science & Technology",
      "link": "http://dx.doi.org/10.1167/tvst.5.3.2",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "The effect of disc size and severity of disease on the diagnostic accuracy of the Heidelberg Retina Tomograph Glaucoma Probability Score.",
      "authors": "Zangwill, LM; Jain, S; Racette, L; Ernstrom, KB; Bowd, C; Medeiros, FA; Sample, PA; Weinreb, RN",
      "published_date": "June 2007",
      "doi": "10.1167/iovs.06-1314",
      "abstract": "PURPOSE: To compare the effect of disc size and disease severity on the Heidelberg Retina Tomograph (HRT) Glaucoma Probability Score (GPS) and the Moorfields Regression Analysis (MRA) for discriminating between glaucomatous and healthy eyes. METHODS: Ninety-nine eyes with repeatable standard automated perimetry results showing glaucomatous damage and 62 normal eyes were included from the longitudinal Diagnostic Innovations in Glaucoma Study (DIGS). The severity of glaucomatous visual field defects ranged from early to severe (average [95% CI] pattern standard deviation [PSD] was 5.7 [5.0-6.5] dB). The GPS (HRTII ver. 3.0; Heidelberg Engineering, Heidelberg, Germany) utilizes two measures of peripapillary retinal nerve fiber layer shape (horizontal and vertical retinal nerve fiber layer curvature) and three measures of optic nerve head shape (cup depth, rim steepness, and cup size) as input into a relevance vector machine learning classifier that estimates a probability of having glaucoma. The MRA compares measured rim area with predicted rim area adjusted for disc size to categorize eyes as outside normal limits, borderline, or within normal limits. The effect of disc size and severity of disease on the diagnostic accuracy of both GPS and MRA was evaluated using the generalized estimating equation marginal logistic regression analysis. RESULTS: Using the manufacturers' suggested cutoffs for GPS global classification (>64% as outside normal limits), the sensitivity and specificity (95% CI) were 71.7% (62.2%-79.7%) and 82.3% (71.0%-89.8%), respectively. The sensitivity and specificity (95% CI) of the MRA result were 66.7% (58.0%-76.1%) and 88.7% (78.5%-94.34%), respectively. Likelihood ratios for regional GPS and MRA results outside normal limits ranged from 4.0 to 10.0, and 6.0 to infinity, respectively. Disc size and severity of disease were significantly associated with the sensitivity of both GPS and MRA. CONCLUSIONS: GPS tended to have higher sensitivities and somewhat lower specificities and lower likelihood ratios than MRA. These results suggest that in this population, GPS and MRA differentiate between glaucomatous and healthy eyes with good sensitivity and specificity. In addition, the likelihood ratios suggest that GPS may be most useful for confirming a normal disc, whereas MRA may be most helpful in confirming a suspicion of glaucoma. Larger disc size and more severe field loss were associated with improved diagnostic accuracy for both GPS and MRA.",
      "publication_location": "Investigative Ophthalmology & Visual Science",
      "link": "http://dx.doi.org/10.1167/iovs.06-1314",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Individual-Specific, Beat-to-beat Trending of Significant Human Blood Loss: The Compensatory Reserve.",
      "authors": "Convertino, VA; Howard, JT; Hinojosa-Laborde, C; Cardin, S; Batchelder, P; Mulligan, J; Grudic, GZ; Moulton, SL; MacLeod, DB",
      "published_date": "August 2015",
      "doi": "10.1097/SHK.0000000000000323",
      "abstract": "Current monitoring technologies are unable to detect early, compensatory changes that are associated with significant blood loss. We previously introduced a novel algorithm to calculate the Compensatory Reserve Index (CRI) based on the analysis of arterial waveform features obtained from photoplethysmogram recordings. In the present study, we hypothesized that the CRI would provide greater sensitivity and specificity to detect blood loss compared with traditional vital signs and other hemodynamic measures. Continuous noninvasive vital sign waveform data, including CRI, photoplethysmogram, heart rate, blood pressures, SpO2, cardiac output, and stroke volume, were analyzed from 20 subjects before, during, and after an average controlled voluntary hemorrhage of ∼1.2 L of blood. Compensatory Reserve Index decreased by 33% in a linear fashion across progressive blood volume loss, with no clinically significant alterations in vital signs. The receiver operating characteristic area under the curve for the CRI was 0.90, with a sensitivity of 0.80 and specificity of 0.76. In comparison, blood pressures, heart rate, SpO2, cardiac output, and stroke volume had significantly lower receiver operating characteristic area under the curve values and specificities for detecting the same volume of blood loss. Consistent with our hypothesis, CRI detected blood loss and restoration with significantly greater specificity than did other traditional physiologic measures. Single measurement of CRI may enable more accurate triage, whereas CRI monitoring may allow for earlier detection of casualty deterioration.",
      "publication_location": "Shock",
      "link": "http://dx.doi.org/10.1097/SHK.0000000000000323",
      "citations": 37,
      "readership": 47,
      "tweets": 7,
      "news_mentions": ""
    },
    {
      "title": "New techniques for DNA sequence classification.",
      "authors": "Wang, JT; Rozen, S; Shapiro, BA; Shasha, D; Wang, Z; Yin, M",
      "published_date": 1999,
      "doi": "10.1089/cmb.1999.6.209",
      "abstract": "DNA sequence classification is the activity of determining whether or not an unlabeled sequence S belongs to an existing class C. This paper proposes two new techniques for DNA sequence classification. The first technique works by comparing the unlabeled sequence S with a group of active motifs discovered from the elements of C and by distinction with elements outside of C. The second technique generates and matches gapped fingerprints of S with elements of C. Experimental results obtained by running these algorithms on long and well conserved Alu sequences demonstrate the good performance of the presented methods compared with FASTA. When applied to less conserved and relatively short functional sites such as splice-junctions, a variation of the second technique combining fingerprinting with consensus sequence analysis gives better results than the current classifiers employing text compression and machine learning algorithms.",
      "publication_location": "Journal of Computational Biology : a Journal of Computational Molecular Cell Biology",
      "link": "http://dx.doi.org/10.1089/cmb.1999.6.209",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Joint analysis of time-evolving binary matrices and associated documents",
      "authors": "Wang, E; Liu, D; Silva, J; Dunson, D; Carin, L",
      "published_date": "December 1, 2010",
      "doi": "",
      "abstract": "We consider problems for which one has incomplete binary matrices that evolve with time (e:g:, the votes of legislators on particular legislation, with each year characterized by a different such matrix). An objective of such analysis is to infer structure and inter-relationships underlying the matrices, here defined by latent features associated with each axis of the matrix. In addition, it is assumed that documents are available for the entities associated with at least one of the matrix axes. By jointly analyzing the matrices and documents, one may be used to inform the other within the analysis, and the model offers the opportunity to predict matrix values (e:g:, votes) based only on an associated document (e:g:, legislation). The research presented here merges two areas of machine-learning that have previously been investigated separately: incomplete-matrix analysis and topic modeling. The analysis is performed from a Bayesian perspective, with efficient inference constituted via Gibbs sampling. The framework is demonstrated by considering all voting data and available documents (legislation) during the 220-year lifetime of the United States Senate and House of Representatives.",
      "publication_location": "Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010, Nips 2010",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Synthetic breast phantoms from patient based eigenbreasts.",
      "authors": "Sturgeon, GM; Park, S; Segars, WP; Lo, JY",
      "published_date": "December 2017",
      "doi": "10.1002/mp.12579",
      "abstract": "The limited number of 3D patient-based breast phantoms available could be augmented by synthetic breast phantoms in order to facilitate virtual clinical trials (VCTs) using model observers for breast imaging optimization and evaluation.These synthetic breast phantoms were developed using Principal Component Analysis (PCA) to reduce the number of dimensions needed to describe a training set of images. PCA decomposed a training set of M breast CT volumes (with millions of voxels each) into an M-1-dimensional space of eigenvectors, which we call eigenbreasts. Each of the training breast phantoms was compactly represented by the mean image plus a weighted sum of eigenbreasts. The distribution of weights observed from training was then sampled to create new synthesized breast phantoms.The resulting synthesized breast phantoms demonstrated a high degree of realism, as supported by an observer study. Two out of three experienced physicist observers were unable to distinguish between the synthesized breast phantoms and the patient-based phantoms. The fibroglandular density and noise power law exponent of the synthesized breast phantoms agreed well with the training data.Our method extends our series of digital breast phantoms based on breast CT data, providing the capability to generate new, statistically varying ensembles consisting of tens of thousands of virtual subjects. This work represents an important step toward conducting future virtual trials for task-based assessment of breast imaging, where it is vital to have a large ensemble of realistic phantoms for statistical power as well as clinical relevance.",
      "publication_location": "Medical Physics",
      "link": "http://dx.doi.org/10.1002/mp.12579",
      "citations": 5,
      "readership": 11,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Sparse signal recovery and acquisition with graphical models",
      "authors": "Cevher, V; Indyk, P; Carin, L; Baraniuk, R",
      "published_date": "January 1, 2010",
      "doi": "10.1109/MSP.2010.938029",
      "abstract": "Many applications in digital signal processing, machine learning, and communications feature a linear regression problem in which unknown data points, hidden variables, or code words are projected into a lower dimensional space via © 2006 IEEE.",
      "publication_location": "Ieee Signal Processing Magazine",
      "link": "http://dx.doi.org/10.1109/MSP.2010.938029",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Improving Acute GI Bleeding Management Through Artificial Intelligence: Unnatural Selection?",
      "authors": "Sengupta, N; Leiman, DA",
      "published_date": "August 2019",
      "doi": "10.1007/s10620-019-05698-0",
      "abstract": "",
      "publication_location": "Dig Dis Sci",
      "link": "http://dx.doi.org/10.1007/s10620-019-05698-0",
      "citations": "(None,)",
      "readership": 2,
      "tweets": 11,
      "news_mentions": ""
    },
    {
      "title": "Efficient Gaussian process regression for large datasets",
      "authors": "Banerjee, A; Dunson, DB; Tokdar, ST",
      "published_date": 2013,
      "doi": "10.1093/biomet/ass068",
      "abstract": "Gaussian processes are widely used in nonparametric regression, classification and spatiotemporal modelling, facilitated in part by a rich literature on their theoretical properties. However, one of their practical limitations is expensive computation, typically on the order of n3 where n is the number of data points, in performing the necessary matrix inversions. For large datasets, storage and processing also lead to computational bottlenecks, and numerical stability of the estimates and predicted values degrades with increasing n. Various methods have been proposed to address these problems, including predictive processes in spatial data analysis and the subset-of-regressors technique in machine learning. The idea underlying these approaches is to use a subset of the data, but this raises questions concerning sensitivity to the choice of subset and limitations in estimating fine-scale structure in regions that are not well covered by the subset. Motivated by the literature on compressive sensing, we propose an alternative approach that involves linear projection of all the data points onto a lower-dimensional subspace. We demonstrate the superiority of this approach from a theoretical perspective and through simulated and real data examples. © 2012 Biometrika Trust.",
      "publication_location": "Biometrika",
      "link": "http://dx.doi.org/10.1093/biomet/ass068",
      "citations": 40,
      "readership": 121,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Molecular classification of human carcinomas by use of gene expression signatures.",
      "authors": "Su, AI; Welsh, JB; Sapinoso, LM; Kern, SG; Dimitrov, P; Lapp, H; Schultz, PG; Powell, SM; Moskaluk, CA; Frierson, HF; Hampton, GM",
      "published_date": "October 1, 2001",
      "doi": "",
      "abstract": "Classification of human tumors according to their primary anatomical site of origin is fundamental for the optimal treatment of patients with cancer. Here we describe the use of large-scale RNA profiling and supervised machine learning algorithms to construct a first-generation molecular classification scheme for carcinomas of the prostate, breast, lung, ovary, colorectum, kidney, liver, pancreas, bladder/ureter, and gastroesophagus, which collectively account for approximately 70% of all cancer-related deaths in the United States. The classification scheme was based on identifying gene subsets whose expression typifies each cancer class, and we quantified the extent to which these genes are characteristic of a specific tumor type by accurately and confidently predicting the anatomical site of tumor origin for 90% of 175 carcinomas, including 9 of 12 metastatic lesions. The predictor gene subsets include those whose expression is typical of specific types of normal epithelial differentiation, as well as other genes whose expression is elevated in cancer. This study demonstrates the feasibility of predicting the tissue origin of a carcinoma in the context of multiple cancer classes.",
      "publication_location": "Cancer Research",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/11606367",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Stochastic Spectral Descent for Discrete Graphical Models",
      "authors": "Carlson, D; Hsieh, YP; Collins, E; Carin, L; Cevher, V",
      "published_date": "March 1, 2016",
      "doi": "10.1109/JSTSP.2015.2505684",
      "abstract": "© 2015 IEEE. Interest in deep probabilistic graphical models has increased in recent years, due to their state-of-the-art performance on many machine learning applications. Such models are typically trained with the stochastic gradient method, which can take a significant number of iterations to converge. Since the computational cost of gradient estimation is prohibitive even for modestly sized models, training becomes slow and practically usable models are kept small. In this paper we propose a new, largely tuning-free algorithm to address this problem. Our approach derives novel majorization bounds based on the Schatten-∞ norm. Intriguingly, the minimizers of these bounds can be interpreted as gradient methods in a non-Euclidean space. We thus propose using a stochastic gradient method in non-Euclidean space. We both provide simple conditions under which our algorithm is guaranteed to converge, and demonstrate empirically that our algorithm leads to dramatically faster training and improved predictive ability compared to stochastic gradient descent for both directed and undirected graphical models.",
      "publication_location": "Ieee Journal of Selected Topics in Signal Processing",
      "link": "http://dx.doi.org/10.1109/JSTSP.2015.2505684",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "HDAC inhibitors cause site-specific chromatin remodeling at PU.1-bound enhancers in K562 cells.",
      "authors": "Frank, CL; Manandhar, D; Gordân, R; Crawford, GE",
      "published_date": 2016,
      "doi": "10.1186/s13072-016-0065-5",
      "abstract": "BACKGROUND: Small molecule inhibitors of histone deacetylases (HDACi) hold promise as anticancer agents for particular malignancies. However, clinical use is often confounded by toxicity, perhaps due to indiscriminate hyperacetylation of cellular proteins. Therefore, elucidating the mechanisms by which HDACi trigger differentiation, cell cycle arrest, or apoptosis of cancer cells could inform development of more targeted therapies. We used the myelogenous leukemia line K562 as a model of HDACi-induced differentiation to investigate chromatin accessibility (DNase-seq) and expression (RNA-seq) changes associated with this process. RESULTS: We identified several thousand specific regulatory elements [~10 % of total DNase I-hypersensitive (DHS) sites] that become significantly more or less accessible with sodium butyrate or suberanilohydroxamic acid treatment. Most of the differential DHS sites display hallmarks of enhancers, including being enriched for non-promoter regions, associating with nearby gene expression changes, and increasing luciferase reporter expression in K562 cells. Differential DHS sites were enriched for key hematopoietic lineage transcription factor motifs, including SPI1 (PU.1), a known pioneer factor. We found PU.1 increases binding at opened DHS sites with HDACi treatment by ChIP-seq, but PU.1 knockdown by shRNA fails to block the chromatin accessibility and expression changes. A machine-learning approach indicates H3K27me3 initially marks PU.1-bound sites that open with HDACi treatment, suggesting these sites are epigenetically poised. CONCLUSIONS: We find HDACi treatment of K562 cells results in site-specific chromatin remodeling at epigenetically poised regulatory elements. PU.1 shows evidence of a pioneer role in this process by marking poised enhancers but is not required for transcriptional activation.",
      "publication_location": "Epigenetics & Chromatin",
      "link": "http://dx.doi.org/10.1186/s13072-016-0065-5",
      "citations": 12,
      "readership": 36,
      "tweets": 12,
      "news_mentions": ""
    },
    {
      "title": "Kernel-matching pursuits with arbitrary loss functions.",
      "authors": "Stack, JR; Dobeck, GJ; Liao, X; Carin, L",
      "published_date": "March 2009",
      "doi": "10.1109/tnn.2008.2008337",
      "abstract": "The purpose of this research is to develop a classifier capable of state-of-the-art performance in both computational efficiency and generalization ability while allowing the algorithm designer to choose arbitrary loss functions as appropriate for a give problem domain. This is critical in applications involving heavily imbalanced, noisy, or non-Gaussian distributed data. To achieve this goal, a kernel-matching pursuit (KMP) framework is formulated where the objective is margin maximization rather than the standard error minimization. This approach enables excellent performance and computational savings in the presence of large, imbalanced training data sets and facilitates the development of two general algorithms. These algorithms support the use of arbitrary loss functions allowing the algorithm designer to control the degree to which outliers are penalized and the manner in which non-Gaussian distributed data is handled. Example loss functions are provided and algorithm performance is illustrated in two groups of experimental results. The first group demonstrates that the proposed algorithms perform equivalent to several state-of-the-art machine learning algorithms on well-published, balanced data. The second group of results illustrates superior performance by the proposed algorithms on imbalanced, non-Gaussian data achieved by employing loss functions appropriate for the data characteristics and problem domain.",
      "publication_location": "Ieee Transactions on Neural Networks",
      "link": "http://dx.doi.org/10.1109/tnn.2008.2008337",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Disease Progression Modeling in Chronic Obstructive Pulmonary Disease.",
      "authors": "Young, AL; Bragman, FJS; Rangelov, B; Han, MK; Galbán, CJ; Lynch, DA; Hawkes, DJ; Alexander, DC; Hurst, JR; COPDGene Investigators,",
      "published_date": "February 1, 2020",
      "doi": "10.1164/rccm.201908-1600OC",
      "abstract": "Rationale: The decades-long progression of chronic obstructive pulmonary disease (COPD) renders identifying different trajectories of disease progression challenging.Objectives: To identify subtypes of patients with COPD with distinct longitudinal progression patterns using a novel machine-learning tool called \"Subtype and Stage Inference\" (SuStaIn) and to evaluate the utility of SuStaIn for patient stratification in COPD.Methods: We applied SuStaIn to cross-sectional computed tomography imaging markers in 3,698 Global Initiative for Chronic Obstructive Lung Disease (GOLD) 1-4 patients and 3,479 controls from the COPDGene (COPD Genetic Epidemiology) study to identify subtypes of patients with COPD. We confirmed the identified subtypes and progression patterns using ECLIPSE (Evaluation of COPD Longitudinally to Identify Predictive Surrogate Endpoints) data. We assessed the utility of SuStaIn for patient stratification by comparing SuStaIn subtypes and stages at baseline with longitudinal follow-up data.Measurements and Main Results: We identified two trajectories of disease progression in COPD: a \"Tissue→Airway\" subtype (n = 2,354, 70.4%), in which small airway dysfunction and emphysema precede large airway wall abnormalities, and an \"Airway→Tissue\" subtype (n = 988, 29.6%), in which large airway wall abnormalities precede emphysema and small airway dysfunction. Subtypes were reproducible in ECLIPSE. Baseline stage in both subtypes correlated with future FEV1/FVC decline (r = -0.16 [P < 0.001] in the Tissue→Airway group; r = -0.14 [P = 0.011] in the Airway→Tissue group). SuStaIn placed 30% of smokers with normal lung function at elevated stages, suggesting imaging changes consistent with early COPD. Individuals with early changes were 2.5 times more likely to meet COPD diagnostic criteria at follow-up.Conclusions: We demonstrate two distinct patterns of disease progression in COPD using SuStaIn, likely representing different endotypes. One third of healthy smokers have detectable imaging changes, suggesting a new biomarker of \"early COPD.",
      "publication_location": "American Journal of Respiratory and Critical Care Medicine",
      "link": "http://dx.doi.org/10.1164/rccm.201908-1600OC",
      "citations": 1,
      "readership": 20,
      "tweets": 83,
      "news_mentions": ""
    },
    {
      "title": "Characterization of the neural stem cell gene regulatory network identifies OLIG2 as a multifunctional regulator of self-renewal.",
      "authors": "Mateo, JL; van den Berg, DLC; Haeussler, M; Drechsel, D; Gaber, ZB; Castro, DS; Robson, P; Lu, QR; Crawford, GE; Flicek, P; Ettwiller, L; Wittbrodt, J; Guillemot, F; Martynoga, B",
      "published_date": "January 2015",
      "doi": "10.1101/gr.173435.114",
      "abstract": "The gene regulatory network (GRN) that supports neural stem cell (NS cell) self-renewal has so far been poorly characterized. Knowledge of the central transcription factors (TFs), the noncoding gene regulatory regions that they bind to, and the genes whose expression they modulate will be crucial in unlocking the full therapeutic potential of these cells. Here, we use DNase-seq in combination with analysis of histone modifications to identify multiple classes of epigenetically and functionally distinct cis-regulatory elements (CREs). Through motif analysis and ChIP-seq, we identify several of the crucial TF regulators of NS cells. At the core of the network are TFs of the basic helix-loop-helix (bHLH), nuclear factor I (NFI), SOX, and FOX families, with CREs often densely bound by several of these different TFs. We use machine learning to highlight several crucial regulatory features of the network that underpin NS cell self-renewal and multipotency. We validate our predictions by functional analysis of the bHLH TF OLIG2. This TF makes an important contribution to NS cell self-renewal by concurrently activating pro-proliferation genes and preventing the untimely activation of genes promoting neuronal differentiation and stem cell quiescence.",
      "publication_location": "Genome Res",
      "link": "http://dx.doi.org/10.1101/gr.173435.114",
      "citations": 41,
      "readership": 115,
      "tweets": 14,
      "news_mentions": ""
    },
    {
      "title": "Aggregated load and generation equivalent circuit models with semi-empirical data fitting",
      "authors": "Pandey, A; Jereminov, M; Li, X; Hug, G; Pileggi, L",
      "published_date": "December 16, 2016",
      "doi": "10.1109/IGESC.2016.7790066",
      "abstract": "© 2016 IEEE. In this paper we propose a semi-empirical modeling framework for aggregated electrical load and generation using an equivalent circuit formulation. The proposed models are based on complex rectangular voltage and current state variables that provide a generalized form for accurately representing any transmission and distribution components. The model is based on the split equivalent circuit formulation that was previously shown to unify power flow, three phase power flow, harmonic power flow, and transient analyses. Importantly, this formulation establishes variables that are analytical and are compatible with model fitting and machine learning approaches. The parameters for the proposed semi-empirical load and generation models are synthesized from measurement data and can enable real-time simulations for time varying aggregated loads and generation.",
      "publication_location": "2016 Ieee Green Energy and Systems Conference, Igsec 2016",
      "link": "http://dx.doi.org/10.1109/IGESC.2016.7790066",
      "citations": 5,
      "readership": 4,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Using relative-relevance of data pieces for efficient communication, with an application to Neural data acquisition",
      "authors": "Mahzoon, M; Albalawi, H; Li, X; Grover, P",
      "published_date": "January 30, 2014",
      "doi": "10.1109/ALLERTON.2014.7028451",
      "abstract": "© 2014 IEEE. In this paper, we consider the problem of communicating data from distributed sensors for the goal of inference. Two inference problems of linear regression and binary linear classification are investigated. Assuming perfect training of the classifier, an approximation of the problem of minimizing classification error-probability under Gaussianity assumptions leads us to recover Fisher score: a metric that is commonly used for feature selection in machine learning. Further, this allows us to soften the notion of feature selection by assigning a degree of relevance to each feature based on the number of bits assigned to it. This relative relevance is used to obtain numerical results on savings on number of bits acquired and communicated for classification of neural data obtained from Electrocorticography (ECoG) experiments. The results demonstrate that significant savings on costs of communication can be achieved by compressing Big Data at the source.",
      "publication_location": "2014 52nd Annual Allerton Conference on Communication, Control, and Computing, Allerton 2014",
      "link": "http://dx.doi.org/10.1109/ALLERTON.2014.7028451",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "HASH: a program to accurately predict protein Hα shifts from neighboring backbone shifts.",
      "authors": "Zeng, J; Zhou, P; Donald, BR",
      "published_date": "January 2013",
      "doi": "10.1007/s10858-012-9693-7",
      "abstract": "Chemical shifts provide not only peak identities for analyzing nuclear magnetic resonance (NMR) data, but also an important source of conformational information for studying protein structures. Current structural studies requiring H(α) chemical shifts suffer from the following limitations. (1) For large proteins, the H(α) chemical shifts can be difficult to assign using conventional NMR triple-resonance experiments, mainly due to the fast transverse relaxation rate of C(α) that restricts the signal sensitivity. (2) Previous chemical shift prediction approaches either require homologous models with high sequence similarity or rely heavily on accurate backbone and side-chain structural coordinates. When neither sequence homologues nor structural coordinates are available, we must resort to other information to predict H(α) chemical shifts. Predicting accurate H(α) chemical shifts using other obtainable information, such as the chemical shifts of nearby backbone atoms (i.e., adjacent atoms in the sequence), can remedy the above dilemmas, and hence advance NMR-based structural studies of proteins. By specifically exploiting the dependencies on chemical shifts of nearby backbone atoms, we propose a novel machine learning algorithm, called HASH, to predict H(α) chemical shifts. HASH combines a new fragment-based chemical shift search approach with a non-parametric regression model, called the generalized additive model, to effectively solve the prediction problem. We demonstrate that the chemical shifts of nearby backbone atoms provide a reliable source of information for predicting accurate H(α) chemical shifts. Our testing results on different possible combinations of input data indicate that HASH has a wide rage of potential NMR applications in structural and biological studies of proteins.",
      "publication_location": "J Biomol Nmr",
      "link": "http://dx.doi.org/10.1007/s10858-012-9693-7",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Statistical modeling of CALGB 80405 (Alliance) to identify influential factors in metastatic colorectal cancer (CRC) dependent on primary (1o) tumor side.",
      "authors": "Furchtgott, L; Swanson, D; Hayete, B; Khalil, I; Wuest, D; Rich, K; Nixon, AB; Niedzwiecki, D; Meyerhardt, JA; O'Reilly, EM; Ou, F-S; Lenz, H-J; Innocenti, F; Venook, AP",
      "published_date": "May 20, 2017",
      "doi": "10.1200/jco.2017.35.15_suppl.3528",
      "abstract": "3528  Background: CALGB 80405 is a phase III clinical trial of FOLFOX and FOLFIRI w/ randomly assigned cetuximab or bevacizumab. Novel machine learning approaches to the study dataset provide valuable insights into CRC prognosis and management of CRC progression. Methods: Using a Monte Carlo Bayesian Generalized Linear Model analytical platform, we built an ensemble of models for overall survival (OS). We used 99 baseline and demographic variables, including 1904 patients w/ 1o side and 949 w/ KRAS wild-type status. Building an ensemble of predictive models reduces risk of overfitting, estimates model uncertainty and identifies key variables by model consensus as measured by ensemble frequency (freq). We fit gender and 1o side (L vs R) stratum-specific models to examine differences in drivers of disease in those strata. Results: 1o side (avg Cox hazard ratio = 0.89, R side reference), ECOG performance status (1.30, reference level 0), AST concentration (1.01), peripheral neutrophil percentage (1.01) and local primary and abdominal site of disease indicators (1.22; 1.26) were key variables predictive of OS ( > 75% freq). In 1o side stratum-specific models, urine protein level (1.61), treatment intent (0.75, nonpalliative as reference) and hemoglobin concentration (0.85) were more associated w/ L side progression (freq > 85% in L stratum model, < 20% in R), while liver and lung sites of disease (2.3; 1.09) were more associated w/ R side progression (freq > 65% in R stratum model, < 20% in L). Predictors of 1o left-sidedness included age (avg log odds ratio = 0.02), hemoglobin (0.41), and abdominal (3.79) and liver (0.68) sites of disease. Modest differences in disease prognostic factors existed between genders: women more influenced by metastatic status, age, liver site of disease and creatinine level; men more influenced by urine protein level and prior diabetes. Conclusions: 1o side plays a central role in potentially explaining both variation in OS and differences in drivers of OS. Availability of these measures at baseline enables better sense of disease course at initiation of treatment. Support: U10CA180821, U10CA180882, Eli Lilly & Co., Genentech, Pfizer Clinical trial information: NCT00265850.",
      "publication_location": "Journal of Clinical Oncology : Official Journal of the American Society of Clinical Oncology",
      "link": "http://dx.doi.org/10.1200/jco.2017.35.15_suppl.3528",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Automatic white matter lesion segmentation using contrast enhanced FLAIR intensity and Markov Random Field.",
      "authors": "Roy, PK; Bhuiyan, A; Janke, A; Desmond, PM; Wong, TY; Abhayaratna, WP; Storey, E; Ramamohanarao, K",
      "published_date": "October 2015",
      "doi": "10.1016/j.compmedimag.2015.08.005",
      "abstract": "White matter lesions (WMLs) are small groups of dead cells that clump together in the white matter of brain. In this paper, we propose a reliable method to automatically segment WMLs. Our method uses a novel filter to enhance the intensity of WMLs. Then a feature set containing enhanced intensity, anatomical and spatial information is used to train a random forest classifier for the initial segmentation of WMLs. Following that a reliable and robust edge potential function based Markov Random Field (MRF) is proposed to obtain the final segmentation by removing false positive WMLs. Quantitative evaluation of the proposed method is performed on 24 subjects of ENVISion study. The segmentation results are validated against the manual segmentation, performed under the supervision of an expert neuroradiologist. The results show a dice similarity index of 0.76 for severe lesion load, 0.73 for moderate lesion load and 0.61 for mild lesion load. In addition to that we have compared our method with three state of the art methods on 20 subjects of Medical Image Computing and Computer Aided Intervention Society's (MICCAI's) MS lesion challenge dataset, where our method shows better segmentation accuracy compare to the state of the art methods. These results indicate that the proposed method can assist the neuroradiologists in assessing the WMLs in clinical practice.",
      "publication_location": "Comput Med Imaging Graph",
      "link": "http://dx.doi.org/10.1016/j.compmedimag.2015.08.005",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Focal edge association to glaucoma diagnosis.",
      "authors": "Cheng, J; Liu, J; Wong, DWK; Tan, NM; Lee, BH; Cheung, C; Baskaran, M; Wong, TY; Aung, T",
      "published_date": 2011,
      "doi": "10.1109/IEMBS.2011.6091111",
      "abstract": "Glaucoma is an optic nerve disease resulting in the loss of vision. There are two common types of glaucoma: open angle glaucoma and angle closure glaucoma. Glaucoma type classification is important in glaucoma diagnosis. Clinically, ophthalmologists examine the iridocorneal angle between iris and cornea to determine the glaucoma type as well as the degree of closure. However, manual grading of the iridocorneal angle images is subjective and often time consuming. In this paper, we propose focal edge for automated iridocorneal angle grading. The iris surface is located to determine focal region and focal edges. The association between focal edges and angle grades is built through machine learning. A modified grading system with three grades is adopted. The experimental results show that the proposed method can correctly classify 87.3% open angle and 88.4% closed angle. Moreover, it can correctly classify 75.0% grade 1 and 77.4% grade 0 for angle closure cases.",
      "publication_location": "Conference Proceedings : ... Annual International Conference of the Ieee Engineering in Medicine and Biology Society. Ieee Engineering in Medicine and Biology Society. Annual Conference",
      "link": "http://dx.doi.org/10.1109/IEMBS.2011.6091111",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian Approximate Kernel Regression with Variable Selection.",
      "authors": "Crawford, L; Wood, KC; Zhou, X; Mukherjee, S",
      "published_date": 2018,
      "doi": "10.1080/01621459.2017.1361830",
      "abstract": "Nonlinear kernel regression models are often used in statistics and machine learning because they are more accurate than linear models. Variable selection for kernel regression models is a challenge partly because, unlike the linear regression setting, there is no clear concept of an effect size for regression coefficients. In this paper, we propose a novel framework that provides an effect size analog for each explanatory variable in Bayesian kernel regression models when the kernel is shift-invariant - for example, the Gaussian kernel. We use function analytic properties of shift-invariant reproducing kernel Hilbert spaces (RKHS) to define a linear vector space that: (i) captures nonlinear structure, and (ii) can be projected onto the original explanatory variables. This projection onto the original explanatory variables serves as an analog of effect sizes. The specific function analytic property we use is that shift-invariant kernel functions can be approximated via random Fourier bases. Based on the random Fourier expansion, we propose a computationally efficient class of Bayesian approximate kernel regression (BAKR) models for both nonlinear regression and binary classification for which one can compute an analog of effect sizes. We illustrate the utility of BAKR by examining two important problems in statistical genetics: genomic selection (i.e. phenotypic prediction) and association mapping (i.e. inference of significant variants or loci). State-of-the-art methods for genomic selection and association mapping are based on kernel regression and linear models, respectively. BAKR is the first method that is competitive in both settings.",
      "publication_location": "Journal of the American Statistical Association",
      "link": "http://dx.doi.org/10.1080/01621459.2017.1361830",
      "citations": 9,
      "readership": 41,
      "tweets": 15,
      "news_mentions": ""
    },
    {
      "title": "Probabilistic programming: A review for environmental modellers",
      "authors": "Krapu, C; Borsuk, M",
      "published_date": "April 1, 2019",
      "doi": "10.1016/j.envsoft.2019.01.014",
      "abstract": "© 2019 The development process for an environmental model involves multiple iterations of a planning-implementation-assessment cycle. Probabilistic programming languages (PPLs) are designed to expedite this process with general-purpose methods for implementing models, efficiently inferring their parameters, and generating probabilistic predictions. Probabilistic programming exists at the intersection of Bayesian statistics, machine learning, and process-based modelling and therefore can be of value to the environmental modelling community. In this review article, we explain how it can be used to accelerate model development and allow for statistical inference using more complicated models and larger data sets than previously possible. Specific challenges and limitations to employing such frameworks are also raised. We provide guidance to help modellers decide whether incorporating probabilistic programming in their work may improve the efficiency and quality of their analyses.",
      "publication_location": "Environmental Modelling & Software",
      "link": "http://dx.doi.org/10.1016/j.envsoft.2019.01.014",
      "citations": 6,
      "readership": 40,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Relationship Between Sleep and Behavior in Autism Spectrum Disorder: Exploring the Impact of Sleep Variability.",
      "authors": "Bangerter, A; Chatterjee, M; Manyakov, NV; Ness, S; Lewin, D; Skalkin, A; Boice, M; Goodwin, MS; Dawson, G; Hendren, R; Leventhal, B; Shic, F; Esbensen, A; Pandina, G",
      "published_date": 2020,
      "doi": "10.3389/fnins.2020.00211",
      "abstract": "Objective: The relationship between sleep (caregiver-reported and actigraphy-measured) and other caregiver-reported behaviors in children and adults with autism spectrum disorder (ASD) was examined, including the use of machine learning to identify sleep variables important in predicting anxiety in ASD. Methods: Caregivers of ASD (n = 144) and typically developing (TD) (n = 41) participants reported on sleep and other behaviors. ASD participants wore an actigraphy device at nighttime during an 8 or 10-week non-interventional study. Mean and variability of actigraphy measures for ASD participants in the week preceding midpoint and endpoint were calculated and compared with caregiver-reported and clinician-reported symptoms using a mixed effects model. An elastic-net model was developed to examine which sleep measures may drive prediction of anxiety. Results: Prevalence of caregiver-reported sleep difficulties in ASD was approximately 70% and correlated significantly (p < 0.05) with sleep efficiency measured by actigraphy. Mean and variability of actigraphy measures like sleep efficiency and number of awakenings were related significantly (p < 0.05) to ASD symptom severity, hyperactivity and anxiety. In the elastic net model, caregiver-reported sleep, and variability of sleep efficiency and awakenings were amongst the important predictors of anxiety. Conclusion: Caregivers report problems with sleep in the majority of children and adults with ASD. Reported problems and actigraphy measures of sleep, particularly variability, are related to parent reported behaviors. Measuring variability in sleep may prove useful in understanding the relationship between sleep problems and behavior in individuals with ASD. These findings may have implications for both intervention and monitoring outcomes in ASD.",
      "publication_location": "Frontiers in Neuroscience",
      "link": "http://dx.doi.org/10.3389/fnins.2020.00211",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 7,
      "news_mentions": ""
    },
    {
      "title": "Hierarchical Clustering Analyses of Plasma Proteins in Subjects With Cardiovascular Risk Factors Identify Informative Subsets Based on Differential Levels of Angiogenic and Inflammatory Biomarkers",
      "authors": "Winder, Z; Sudduth, TL; Fardo, D; Cheng, Q; Goldstein, LB; Nelson, PT; Schmitt, FA; Jicha, GA; Wilcock, DM",
      "published_date": "February 6, 2020",
      "doi": "10.3389/fnins.2020.00084",
      "abstract": "© Copyright © 2020 Winder, Sudduth, Fardo, Cheng, Goldstein, Nelson, Schmitt, Jicha and Wilcock. Agglomerative hierarchical clustering analysis (HCA) is a commonly used unsupervised machine learning approach for identifying informative natural clusters of observations. HCA is performed by calculating a pairwise dissimilarity matrix and then clustering similar observations until all observations are grouped within a cluster. Verifying the empirical clusters produced by HCA is complex and not well studied in biomedical applications. Here, we demonstrate the comparability of a novel HCA technique with one that was used in previous biomedical applications while applying both techniques to plasma angiogenic (FGF, FLT, PIGF, Tie-2, VEGF, VEGF-D) and inflammatory (MMP1, MMP3, MMP9, IL8, TNFα) protein data to identify informative subsets of individuals. Study subjects were diagnosed with mild cognitive impairment due to cerebrovascular disease (MCI-CVD). Through comparison of the two HCA techniques, we were able to identify subsets of individuals, based on differences in VEGF (p < 0.001), MMP1 (p < 0.001), and IL8 (p < 0.001) levels. These profiles provide novel insights into angiogenic and inflammatory pathologies that may contribute to VCID.",
      "publication_location": "Frontiers in Neuroscience",
      "link": "http://dx.doi.org/10.3389/fnins.2020.00084",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "101 Dothideomycetes genomes: A test case for predicting lifestyles and emergence of pathogens.",
      "authors": "Haridas, S; Albert, R; Binder, M; Bloem, J; LaButti, K; Salamov, A; Andreopoulos, B; Baker, SE; Barry, K; Bills, G; Bluhm, BH; Cannon, C; Castanera, R; Culley, DE; Daum, C; Ezra, D; González, JB; Henrissat, B; Kuo, A; Liang, C; Lipzen, A; Lutzoni, F; Magnuson, J; Mondo, SJ; Nolan, M; Ohm, RA; Pangilinan, J; Park, H-J; Ramírez, L; Alfaro, M; Sun, H; Tritt, A; Yoshinaga, Y; Zwiers, L-H; Turgeon, BG; Goodwin, SB; Spatafora, JW; Crous, PW; Grigoriev, IV",
      "published_date": "June 2020",
      "doi": "10.1016/j.simyco.2020.01.003",
      "abstract": "Dothideomycetes is the largest class of kingdom Fungi and comprises an incredible diversity of lifestyles, many of which have evolved multiple times. Plant pathogens represent a major ecological niche of the class Dothideomycetes and they are known to infect most major food crops and feedstocks for biomass and biofuel production. Studying the ecology and evolution of Dothideomycetes has significant implications for our fundamental understanding of fungal evolution, their adaptation to stress and host specificity, and practical implications with regard to the effects of climate change and on the food, feed, and livestock elements of the agro-economy. In this study, we present the first large-scale, whole-genome comparison of 101 Dothideomycetes introducing 55 newly sequenced species. The availability of whole-genome data produced a high-confidence phylogeny leading to reclassification of 25 organisms, provided a clearer picture of the relationships among the various families, and indicated that pathogenicity evolved multiple times within this class. We also identified gene family expansions and contractions across the Dothideomycetes phylogeny linked to ecological niches providing insights into genome evolution and adaptation across this group. Using machine-learning methods we classified fungi into lifestyle classes with >95 % accuracy and identified a small number of gene families that positively correlated with these distinctions. This can become a valuable tool for genome-based prediction of species lifestyle, especially for rarely seen and poorly studied species.",
      "publication_location": "Studies in Mycology",
      "link": "http://dx.doi.org/10.1016/j.simyco.2020.01.003",
      "citations": 3,
      "readership": "(None,)",
      "tweets": 39,
      "news_mentions": ""
    },
    {
      "title": "Nasal consonant discrimination in infant- And adult-directed speech",
      "authors": "Ludusan, B; Jorschick, A; Mazuka, R",
      "published_date": "January 1, 2019",
      "doi": "10.21437/Interspeech.2019-1737",
      "abstract": "Copyright © 2019 ISCA Infant-directed speech (IDS) is thought to play a facilitating role in language acquisition, by simplifying the input infants receive. In particular, the hypothesis that the acoustic level is enhanced to make the input more clear for infants, has been extensively studied in the case of vowels, but less so in the case of consonants. An investigation into how nasal consonants can be discriminated in infant- compared to adult-directed speech (ADS) was performed, on a corpus of Japanese mother-infant spontaneous conversations, by examining all bilabial and alveolar nasals occurring in intervocalic position. The Pearson correlation between corresponding spectrum slices of nasal consonants, in identical vowel contexts, was employed as similarity measure and a statistical model was fit using this information. It revealed a decrease in similarity between the nasal classes, in IDS compared to ADS, although the effect was not statistically significant. We confirmed these results, using an unsupervised machine learning algorithm to discriminate between the two nasal classes, obtaining similar classification performance in IDS and ADS. We discuss our findings in the context of the current literature on infant-directed speech.",
      "publication_location": "Proceedings of the Annual Conference of the International Speech Communication Association, Interspeech",
      "link": "http://dx.doi.org/10.21437/Interspeech.2019-1737",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Large Deviations of Convex Polyominoes",
      "authors": "Soloveychik, I; Tarokh, V",
      "published_date": "",
      "doi": "",
      "abstract": "Enumeration of various types of lattice polygons and in particular\npolyominoes is of primary importance in many machine learning, pattern\nrecognition, and geometric analysis problems. In this work, we develop a large\ndeviation principle for convex polyominoes under different restrictions, such\nas fixed area and/or perimeter.",
      "publication_location": "",
      "link": "http://arxiv.org/abs/1802.03849v5",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Utilizing Precision Medicine to Estimate Timing for Surgical Closure of Traumatic Extremity Wounds.",
      "authors": "Lisboa, FA; Dente, CJ; Schobel, SA; Khatri, V; Potter, BK; Kirk, AD; Elster, EA",
      "published_date": "September 2019",
      "doi": "10.1097/SLA.0000000000003470",
      "abstract": "BACKGROUND: Both the frequency and high complication rates associated with extremity wounds in recent military conflicts have highlighted the need for clinical decision support tools (CDST) to decrease time to wound closure and wound failure rates. METHODS: Machine learning was used to estimate both successful wound closure (based on penultimate debridement biomarker data) and the necessary number of surgical debridements (based on presentation biomarkers) in 73 service members treated according to military guidelines based on clinical data and the local/systemic level of 32 cytokines. Models were trained to estimate successful closure including an additional 8 of 80 civilian patients with similar injury patterns. Previous analysis has demonstrated the potential to reduce the number of operative debridements by 2, with resulting decreases in ICU and hospital LOS, while decreasing the rate of wound failure. RESULTS: Analysis showed similar cytokine responses when civilians followed a military-like treatment schedule with surgical debridements every 24 to 72 hours. A model estimating successful closure had AUC of 0.89. Model performance in civilians degraded when these had a debridement interval > 72 hours (73 of the 80 civilians). A separate model estimating the number of debridements required to achieve successful closure had a multiclass AUC of 0.81. CONCLUSION: CDSTs can be developed using biologically compatible civilian and military populations as cytokine response is highly influenced by surgical treatment. Our CDSTs may help identify who may require serial debridements versus early closure, and precisely when traumatic wounds should optimally be closed.",
      "publication_location": "Ann Surg",
      "link": "http://dx.doi.org/10.1097/SLA.0000000000003470",
      "citations": 2,
      "readership": "(None,)",
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Cardiac surgery risk models: a position article.",
      "authors": "Shahian, DM; Blackstone, EH; Edwards, FH; Grover, FL; Grunkemeier, GL; Naftel, DC; Nashef, SAM; Nugent, WC; Peterson, ED; STS workforce on evidence-based surgery,",
      "published_date": "November 2004",
      "doi": "10.1016/j.athoracsur.2004.05.054",
      "abstract": "Differences in medical outcomes may result from disease severity, treatment effectiveness, or chance. Because most outcome studies are observational rather than randomized, risk adjustment is necessary to account for case mix. This has usually been accomplished through the use of standard logistic regression models, although Bayesian models, hierarchical linear models, and machine-learning techniques such as neural networks have also been used. Many factors are essential to insuring the accuracy and usefulness of such models, including selection of an appropriate clinical database, inclusion of critical core variables, precise definitions for predictor variables and endpoints, proper model development, validation, and audit. Risk models may be used to assess the impact of specific predictors on outcome, to aid in patient counseling and treatment selection, to profile provider quality, and to serve as the basis of continuous quality improvement activities.",
      "publication_location": "The Annals of Thoracic Surgery",
      "link": "http://dx.doi.org/10.1016/j.athoracsur.2004.05.054",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Random forest modeling can predict infectious complications following trauma laparotomy.",
      "authors": "Gelbard, RB; Hensman, H; Schobel, S; Khatri, V; Tracy, BM; Dente, CJ; Buchman, T; Kirk, A; Elster, E",
      "published_date": "November 2019",
      "doi": "10.1097/TA.0000000000002486",
      "abstract": "BACKGROUND: Identifying clinical and biomarker profiles of trauma patients may facilitate the creation of models that predict postoperative complications. We sought to determine the utility of modeling for predicting severe sepsis (SS) and organ space infections (OSI) following laparotomy for abdominal trauma. METHODS: Clinical and molecular biomarker data were collected prospectively from patients undergoing exploratory laparotomy for abdominal trauma at a Level I trauma center between 2014 and 2017. Machine learning algorithms were used to develop models predicting SS and OSI. Random forest (RF) was performed, and features were selected using backward elimination. The SS model was trained on 117 records and validated using the leave-one-out method on the remaining 15 records. The OSI model was trained on 113 records and validated on the remaining 19. Models were assessed using areas under the curve. RESULTS: One hundred thirty-two patients were included (median age, 30 years [23-42 years], 68.9% penetrating injury, median Injury Severity Score of 18 [10-27]). Of these, 10.6% (14 of 132) developed SS and 13.6% (18 of 132) developed OSI. The final RF model resulted in five variables for SS (Penetrating Abdominal Trauma Index, serum epidermal growth factor, monocyte chemoattractant protein-1, interleukin-6, and eotaxin) and four variables for OSI (Penetrating Abdominal Trauma Index, serum epidermal growth factor, monocyte chemoattractant protein-1, and interleukin-8). The RF models predicted SS and OSI with areas under the curve of 0.798 and 0.774, respectively. CONCLUSION: Random forests with RFE can help identify clinical and biomarker profiles predictive of SS and OSI after trauma laparotomy. Once validated, these models could be used as clinical decision support tools for earlier detection and treatment of infectious complications following injury. LEVEL OF EVIDENCE: Prognostic, level III.",
      "publication_location": "J Trauma Acute Care Surg",
      "link": "http://dx.doi.org/10.1097/TA.0000000000002486",
      "citations": "(None,)",
      "readership": 4,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Advanced Modeling to Predict Pneumonia in Combat Trauma Patients.",
      "authors": "Bradley, M; Dente, C; Khatri, V; Schobel, S; Lisboa, F; Shi, A; Hensman, H; Kirk, A; Buchman, TG; Elster, E",
      "published_date": "November 20, 2019",
      "doi": "10.1007/s00268-019-05294-3",
      "abstract": "BACKGROUND: Tools to assist clinicians in predicting pneumonia could lead to a significant decline in morbidity. Therefore, we sought to develop a model in combat trauma patients for identifying those at highest risk of pneumonia. METHODS: This was a retrospective study of 73 primarily blast-injured casualties with combat extremity wounds. Binary classification models for pneumonia prediction were developed with measurements of injury severity from the Abbreviated Injury Scale (AIS), transfusion blood products received before arrival at Walter Reed National Military Medical Center (WRNMMC), and serum protein levels. Predictive models were generated with leave-one-out-cross-validation using the variable selection method of backward elimination (BE) and the machine learning algorithms of random forests (RF) and logistic regression (LR). BE was attempted with two predictor sets: (1) all variables and (2) serum proteins alone. RESULTS: Incidence of pneumonia was 12% (n = 9). Different variable sets were produced by BE when considering all variables and just serum proteins alone. BE selected the variables ISS, AIS chest, and cryoprecipitate within the first 24 h following injury for the first predictor set 1 and FGF-basic, IL-2R, and IL-6 for predictor set 2. Using both variable sets, a RF was generated with AUCs of 0.95 and 0.87-both higher than LR algorithms. CONCLUSION: Advanced modeling allowed for the identification of clinical and biomarker data predictive of pneumonia in a cohort of predominantly blast-injured combat trauma patients. The generalizability of the models developed here will require an external validation dataset.",
      "publication_location": "World J Surg",
      "link": "http://dx.doi.org/10.1007/s00268-019-05294-3",
      "citations": "(None,)",
      "readership": "(None,)",
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Heterogeneous systems with reconfigurable neuromorphic computing accelerators",
      "authors": "Li, S; Liu, X; Mao, M; Li, HH; Chen, Y; Li, B; Wang, Y",
      "published_date": "July 29, 2016",
      "doi": "10.1109/ISCAS.2016.7527186",
      "abstract": "© 2016 IEEE. Developing heterogeneous system with hardware accelerator is a promising solution to implement high performance applications where explicitly programmed, rule-based algorithms are either infeasible or inefficient. However, mapping a neural network model to a hardware representation is a complex process, where balancing computation resources and memory accesses is crucial. In this work, we present a systematic approach o optimize the heterogeneous system with a FPGA-based neuromorphic computing accelerator (NCA). For any applications, the neural network topology and computation flow of the accelerator can be configured through a NCA-aware compiler. The FPGA-based NCA contains a generic multi-layer neural network composed of a set of parallel neural processing elements. Such a scheme imitates the human cognition process and follows the hierarchy of neocortex. At architectural level, we decrease the computing resource requirement to enhance computation efficiency. The hardware implementation primarily targets at reducing data communication load: a multi-thread computation engine is utilized to mask the long memory latency. Such a combined solution can well accommodate the ever increasing complexity and scalability of machine learning applications and improve the system performance and efficiency. Through the evaluation across eight representative benchmarks, we observed on average 12.1× speedup and 45.8× energy reduction, with marginal accuracy loss comparing with CPU-only computation.",
      "publication_location": "Proceedings   Ieee International Symposium on Circuits and Systems",
      "link": "http://dx.doi.org/10.1109/ISCAS.2016.7527186",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "An overview on memristor crossabr based neuromorphic circuit and architecture",
      "authors": "Li, Z; Liu, C; Wang, Y; Yan, B; Yang, C; Yang, J; Li, H",
      "published_date": "October 30, 2015",
      "doi": "10.1109/VLSI-SoC.2015.7314391",
      "abstract": "© 2015 IEEE. As technology advances, artificial intelligence becomes pervasive in society and ubiquitous in our lives, which stimulates the desire for embedded-everywhere and human-centric intelligent computation paradigm. However, conventional instruction-based computer architecture was designed for algorithmic and exact calculations. It is not suitable for handling the applications of machine learning and neural networks that usually involve a large sets of noisy and incomplete natural data. Instead, neuromorphic systems inspired by the working mechanism of human brains create promising potential. Neuromorphic systems possess a massively parallel architecture with closely coupled memory and computing. Moreover, through the sparse utilizations of hardware resources in time and space, extremely high power efficiency can be achieved. In recent years, the use of memristor technology in neuromorphic systems has attracted growing attention for its distinctive properties, such as nonvolatility, reconfigurability, and analog processing capability. In this paper, we summarize the research efforts in the development of memristor crossbar based neuromorphic design from the perspectives of device modeling, circuit, architecture, and design automation.",
      "publication_location": "Ieee/Ifip International Conference on Vlsi and System on Chip, Vlsi Soc",
      "link": "http://dx.doi.org/10.1109/VLSI-SoC.2015.7314391",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Development of predictive models for all individual questions of SRS-22R after adult spinal deformity surgery: a step toward individualized medicine.",
      "authors": "Ames, CP; Smith, JS; Pellisé, F; Kelly, M; Gum, JL; Alanay, A; Acaroğlu, E; Pérez-Grueso, FJS; Kleinstück, FS; Obeid, I; Vila-Casademunt, A; Shaffrey, CI; Burton, DC; Lafage, V; Schwab, FJ; Bess, S; Serra-Burriel, M; European Spine Study Group, ; International Spine Study Group,",
      "published_date": "September 2019",
      "doi": "10.1007/s00586-019-06079-x",
      "abstract": "PURPOSE: Health-related quality of life (HRQL) instruments are essential in value-driven health care, but patients often have more specific, personal priorities when seeking surgical care. The Scoliosis Research Society-22R (SRS-22R), an HRQL instrument for spinal deformity, provides summary scores spanning several health domains, but these may be difficult for patients to utilize in planning their specific care goals. Our objective was to create preoperative predictive models for responses to individual SRS-22R questions at 1 and 2 years after adult spinal deformity (ASD) surgery to facilitate precision surgical care. METHODS: Two prospective observational cohorts were queried for ASD patients with SRS-22R data at baseline and 1 and 2 years after surgery. In total, 150 covariates were used in training machine learning models, including demographics, surgical data and perioperative complications. Validation was accomplished via an 80%/20% data split for training and testing, respectively. Goodness of fit was measured using area under receiver operating characteristic (AUROC) curves. RESULTS: In total, 561 patients met inclusion criteria. The AUROC ranged from 56.5 to 86.9%, reflecting successful fits for most questions. SRS-22R questions regarding pain, disability and social and labor function were the most accurately predicted. Models were less sensitive to questions regarding general satisfaction, depression/anxiety and appearance. CONCLUSIONS: To the best of our knowledge, this is the first study to explicitly model the prediction of individual answers to the SRS-22R questionnaire at 1 and 2 years after deformity surgery. The ability to predict individual question responses may prove useful in preoperative counseling in the age of individualized medicine. These slides can be retrieved under Electronic Supplementary Material.",
      "publication_location": "European Spine Journal : Official Publication of the European Spine Society, the European Spinal Deformity Society, and the European Section of the Cervical Spine Research Society",
      "link": "http://dx.doi.org/10.1007/s00586-019-06079-x",
      "citations": 1,
      "readership": 24,
      "tweets": 1,
      "news_mentions": ""
    },
    {
      "title": "Gene Expression Profiling of Bronchoalveolar Lavage Cells Preceding a Clinical Diagnosis of Chronic Lung Allograft Dysfunction.",
      "authors": "Weigt, SS; Wang, X; Palchevskiy, V; Gregson, AL; Patel, N; DerHovanessian, A; Shino, MY; Sayah, DM; Birjandi, S; Lynch, JP; Saggar, R; Ardehali, A; Ross, DJ; Palmer, SM; Elashoff, D; Belperio, JA",
      "published_date": 2017,
      "doi": "10.1371/journal.pone.0169894",
      "abstract": "BACKGROUND: Chronic Lung Allograft Dysfunction (CLAD) is the main limitation to long-term survival after lung transplantation. Although CLAD is usually not responsive to treatment, earlier identification may improve treatment prospects. METHODS: In a nested case control study, 1-year post transplant surveillance bronchoalveolar lavage (BAL) fluid samples were obtained from incipient CLAD (n = 9) and CLAD free (n = 8) lung transplant recipients. Incipient CLAD cases were diagnosed with CLAD within 2 years, while controls were free from CLAD for at least 4 years following bronchoscopy. Transcription profiles in the BAL cell pellets were assayed with the HG-U133 Plus 2.0 microarray (Affymetrix). Differential gene expression analysis, based on an absolute fold change (incipient CLAD vs no CLAD) >2.0 and an unadjusted p-value ≤0.05, generated a candidate list containing 55 differentially expressed probe sets (51 up-regulated, 4 down-regulated). RESULTS: The cell pellets in incipient CLAD cases were skewed toward immune response pathways, dominated by genes related to recruitment, retention, activation and proliferation of cytotoxic lymphocytes (CD8+ T-cells and natural killer cells). Both hierarchical clustering and a supervised machine learning tool were able to correctly categorize most samples (82.3% and 94.1% respectively) into incipient CLAD and CLAD-free categories. CONCLUSIONS: These findings suggest that a pathobiology, similar to AR, precedes a clinical diagnosis of CLAD. A larger prospective investigation of the BAL cell pellet transcriptome as a biomarker for CLAD risk stratification is warranted.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0169894",
      "citations": 17,
      "readership": 20,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "Model Selection Techniques: An Overview",
      "authors": "Ding, J; Tarokh, V; Yang, Y",
      "published_date": "November 1, 2018",
      "doi": "10.1109/MSP.2018.2867638",
      "abstract": "© 2018 IEEE. In the era of big data, analysts usually explore various statistical models or machine-learning methods for observed data to facilitate scientific discoveries or gain predictive power. Whatever data and fitting procedures are employed, a crucial step is to select the most appropriate model or method from a set of candidates. Model selection is a key ingredient in data analysis for reliable and reproducible statistical inference or prediction, and thus it is central to scientific studies in such fields as ecology, economics, engineering, finance, political science, biology, and epidemiology. There has been a long history of model selection techniques that arise from researches in statistics, information theory, and signal processing. A considerable number of methods has been proposed, following different philosophies and exhibiting varying performances. The purpose of this article is to provide a comprehensive overview of them, in terms of their motivation, large sample performance, and applicability. We provide integrated and practically relevant discussions on theoretical properties of state-of-the-art model selection approaches. We also share our thoughts on some controversial views on the practice of model selection.",
      "publication_location": "Ieee Signal Processing Magazine",
      "link": "http://dx.doi.org/10.1109/MSP.2018.2867638",
      "citations": 13,
      "readership": 99,
      "tweets": 32,
      "news_mentions": ""
    },
    {
      "title": "Fine epitope signature of antibody neutralization breadth at the HIV-1 envelope CD4-binding site.",
      "authors": "Cheng, HD; Grimm, SK; Gilman, MS; Gwom, LC; Sok, D; Sundling, C; Donofrio, G; Karlsson Hedestam, GB; Bonsignori, M; Haynes, BF; Lahey, TP; Maro, I; von Reyn, CF; Gorny, MK; Zolla-Pazner, S; Walker, BD; Alter, G; Burton, DR; Robb, ML; Krebs, SJ; Seaman, MS; Bailey-Kellogg, C; Ackerman, ME",
      "published_date": "March 8, 2018",
      "doi": "10.1172/jci.insight.97018",
      "abstract": "Major advances in donor identification, antigen probe design, and experimental methods to clone pathogen-specific antibodies have led to an exponential growth in the number of newly characterized broadly neutralizing antibodies (bnAbs) that recognize the HIV-1 envelope glycoprotein. Characterization of these bnAbs has defined new epitopes and novel modes of recognition that can result in potent neutralization of HIV-1. However, the translation of envelope recognition profiles in biophysical assays into an understanding of in vivo activity has lagged behind, and identification of subjects and mAbs with potent antiviral activity has remained reliant on empirical evaluation of neutralization potency and breadth. To begin to address this discrepancy between recombinant protein recognition and virus neutralization, we studied the fine epitope specificity of a panel of CD4-binding site (CD4bs) antibodies to define the molecular recognition features of functionally potent humoral responses targeting the HIV-1 envelope site bound by CD4. Whereas previous studies have used neutralization data and machine-learning methods to provide epitope maps, here, this approach was reversed, demonstrating that simple binding assays of fine epitope specificity can prospectively identify broadly neutralizing CD4bs-specific mAbs. Building on this result, we show that epitope mapping and prediction of neutralization breadth can also be accomplished in the assessment of polyclonal serum responses. Thus, this study identifies a set of CD4bs bnAb signature amino acid residues and demonstrates that sensitivity to mutations at signature positions is sufficient to predict neutralization breadth of polyclonal sera with a high degree of accuracy across cohorts and across clades.",
      "publication_location": "Jci Insight",
      "link": "http://dx.doi.org/10.1172/jci.insight.97018",
      "citations": 6,
      "readership": 28,
      "tweets": 3,
      "news_mentions": ""
    },
    {
      "title": "If you are happy and you know it... tweet",
      "authors": "Asiaee T., A; Tepper, M; Banerjee, A; Sapiro, G",
      "published_date": "December 19, 2012",
      "doi": "10.1145/2396761.2398481",
      "abstract": "Extracting sentiment from Twitter data is one of the fundamental problems in social media analytics. Twitter's length constraint renders determining the positive/negative sentiment of a tweet difficult, even for a human judge. In this work we present a general framework for per-tweet (in contrast with batches of tweets) sentiment analysis which consists of: (1) extracting tweets about a desired target subject, (2) separating tweets with sentiment, and (3) setting apart positive from negative tweets. For each step, we study the performance of a number of classical and new machine learning algorithms. We also show that the intrinsic sparsity of tweets allows performing classification in a low dimensional space, via random projections, without losing accuracy. In addition, we present weighted variants of all employed algorithms, exploiting the available labeling uncertainty, which further improve classification accuracy. Finally, we show that spatially aggregating our per-tweet classification results produces a very satisfactory outcome, making our approach a good candidate for batch tweet sentiment analysis. © 2012 ACM.",
      "publication_location": "Acm International Conference Proceeding Series",
      "link": "http://dx.doi.org/10.1145/2396761.2398481",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Explainable Artificial Intelligence for Neuroscience: Behavioral Neurostimulation.",
      "authors": "Fellous, J-M; Sapiro, G; Rossi, A; Mayberg, H; Ferrante, M",
      "published_date": "January 2019",
      "doi": "10.3389/fnins.2019.01346",
      "abstract": "The use of Artificial Intelligence and machine learning in basic research and clinical neuroscience is increasing. AI methods enable the interpretation of large multimodal datasets that can provide unbiased insights into the fundamental principles of brain function, potentially paving the way for earlier and more accurate detection of brain disorders and better informed intervention protocols. Despite AI's ability to create accurate predictions and classifications, in most cases it lacks the ability to provide a mechanistic understanding of how inputs and outputs relate to each other. Explainable Artificial Intelligence (XAI) is a new set of techniques that attempts to provide such an understanding, here we report on some of these practical approaches. We discuss the potential value of XAI to the field of neurostimulation for both basic scientific inquiry and therapeutic purposes, as well as, outstanding questions and obstacles to the success of the XAI approach.",
      "publication_location": "Frontiers in Neuroscience",
      "link": "http://dx.doi.org/10.3389/fnins.2019.01346",
      "citations": 2,
      "readership": "(None,)",
      "tweets": 28,
      "news_mentions": ""
    },
    {
      "title": "Computer vision and behavioral phenotyping: an autism case study",
      "authors": "Sapiro, G; Hashemi, J; Dawson, G",
      "published_date": "March 1, 2019",
      "doi": "10.1016/j.cobme.2018.12.002",
      "abstract": "© 2018 Elsevier Inc. Despite significant recent advances in molecular genetics and neuroscience, behavioral ratings based on clinical observations are still the gold standard for screening, diagnosing, and assessing outcomes in neurodevelopmental disorders, including autism spectrum disorder. Such behavioral ratings are subjective, require significant clinician expertise and training, typically do not capture data from the children in their natural environments such as homes or schools, and are not scalable for large population screening, low-income communities, or longitudinal monitoring, all of which are critical for outcome evaluation in multisite studies and for understanding and evaluating symptoms in the general population. The development of computational approaches to standardized objective behavioral assessment is, thus, a significant unmet need in autism spectrum disorder in particular and developmental and neurodegenerative disorders in general. Here, we discuss how computer vision, and machine learning, can develop scalable low-cost mobile health methods for automatically and consistently assessing existing biomarkers, from eye tracking to movement patterns and affect, while also providing tools and big data for novel discovery.",
      "publication_location": "Current Opinion in Biomedical Engineering",
      "link": "http://dx.doi.org/10.1016/j.cobme.2018.12.002",
      "citations": 2,
      "readership": 42,
      "tweets": 8,
      "news_mentions": ""
    },
    {
      "title": "Automated segmentation of the canine corpus callosum for the measurement of diffusion tensor imaging.",
      "authors": "Peterson, DE; Chen, SD; Calabrese, E; White, LE; Provenzale, JM",
      "published_date": "February 2016",
      "doi": "10.1177/1971400915610924",
      "abstract": "The goal of this study was to apply image registration-based automated segmentation methods to measure diffusion tensor imaging (DTI) metrics within the canine brain. Specifically, we hypothesized that this method could measure DTI metrics within the canine brain with greater reproducibility than with hand-drawn region of interest (ROI) methods. We performed high-resolution post-mortem DTI imaging on two canine brains on a 7 T MR scanner. We designated the two brains as brain 1 and brain 2. We measured DTI metrics within the corpus callosum of brain 1 using a hand-drawn ROI method and an automated segmentation method in which ROIs from brain 2 were transformed into the space of brain 1. We repeated both methods in order to measure their reliability. Mean differences between the two sets of hand-drawn ROIs ranged from 4% to 10%. Mean differences between the hand-drawn ROIs and the automated ROIs were less than 3%. The mean differences between the first and second automated ROIs were all less than 0.25%. Our findings indicate that the image registration-based automated segmentation method was clearly the more reproducible method. These results provide the groundwork for using image registration-based automated segmentation methods to measure DTI metrics within the canine brain. Such methods will facilitate the study of white matter pathology in canine models of neurologic disease.",
      "publication_location": "The Neuroradiology Journal",
      "link": "http://dx.doi.org/10.1177/1971400915610924",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Brain and blood metabolite signatures of pathology and progression in Alzheimer disease: A targeted metabolomics study.",
      "authors": "Varma, VR; Oommen, AM; Varma, S; Casanova, R; An, Y; Andrews, RM; O'Brien, R; Pletnikova, O; Troncoso, JC; Toledo, J; Baillie, R; Arnold, M; Kastenmueller, G; Nho, K; Doraiswamy, PM; Saykin, AJ; Kaddurah-Daouk, R; Legido-Quigley, C; Thambisetty, M",
      "published_date": "January 2018",
      "doi": "10.1371/journal.pmed.1002482",
      "abstract": "BACKGROUND: The metabolic basis of Alzheimer disease (AD) is poorly understood, and the relationships between systemic abnormalities in metabolism and AD pathogenesis are unclear. Understanding how global perturbations in metabolism are related to severity of AD neuropathology and the eventual expression of AD symptoms in at-risk individuals is critical to developing effective disease-modifying treatments. In this study, we undertook parallel metabolomics analyses in both the brain and blood to identify systemic correlates of neuropathology and their associations with prodromal and preclinical measures of AD progression. METHODS AND FINDINGS: Quantitative and targeted metabolomics (Biocrates AbsoluteIDQ [identification and quantification] p180) assays were performed on brain tissue samples from the autopsy cohort of the Baltimore Longitudinal Study of Aging (BLSA) (N = 44, mean age = 81.33, % female = 36.36) from AD (N = 15), control (CN; N = 14), and \"asymptomatic Alzheimer's disease\" (ASYMAD, i.e., individuals with significant AD pathology but no cognitive impairment during life; N = 15) participants. Using machine-learning methods, we identified a panel of 26 metabolites from two main classes-sphingolipids and glycerophospholipids-that discriminated AD and CN samples with accuracy, sensitivity, and specificity of 83.33%, 86.67%, and 80%, respectively. We then assayed these 26 metabolites in serum samples from two well-characterized longitudinal cohorts representing prodromal (Alzheimer's Disease Neuroimaging Initiative [ADNI], N = 767, mean age = 75.19, % female = 42.63) and preclinical (BLSA) (N = 207, mean age = 78.68, % female = 42.63) AD, in which we tested their associations with magnetic resonance imaging (MRI) measures of AD-related brain atrophy, cerebrospinal fluid (CSF) biomarkers of AD pathology, risk of conversion to incident AD, and trajectories of cognitive performance. We developed an integrated blood and brain endophenotype score that summarized the relative importance of each metabolite to severity of AD pathology and disease progression (Endophenotype Association Score in Early Alzheimer's Disease [EASE-AD]). Finally, we mapped the main metabolite classes emerging from our analyses to key biological pathways implicated in AD pathogenesis. We found that distinct sphingolipid species including sphingomyelin (SM) with acyl residue sums C16:0, C18:1, and C16:1 (SM C16:0, SM C18:1, SM C16:1) and hydroxysphingomyelin with acyl residue sum C14:1 (SM (OH) C14:1) were consistently associated with severity of AD pathology at autopsy and AD progression across prodromal and preclinical stages. Higher log-transformed blood concentrations of all four sphingolipids in cognitively normal individuals were significantly associated with increased risk of future conversion to incident AD: SM C16:0 (hazard ratio [HR] = 4.430, 95% confidence interval [CI] = 1.703-11.520, p = 0.002), SM C16:1 (HR = 3.455, 95% CI = 1.516-7.873, p = 0.003), SM (OH) C14:1 (HR = 3.539, 95% CI = 1.373-9.122, p = 0.009), and SM C18:1 (HR = 2.255, 95% CI = 1.047-4.855, p = 0.038). The sphingolipid species identified map to several biologically relevant pathways implicated in AD, including tau phosphorylation, amyloid-β (Aβ) metabolism, calcium homeostasis, acetylcholine biosynthesis, and apoptosis. Our study has limitations: the relatively small number of brain tissue samples may have limited our power to detect significant associations, control for heterogeneity between groups, and replicate our findings in independent, autopsy-derived brain samples. CONCLUSIONS: We present a novel framework to identify biologically relevant brain and blood metabolites associated with disease pathology and progression during the prodromal and preclinical stages of AD. Our results show that perturbations in sphingolipid metabolism are consistently associated with endophenotypes across preclinical and prodromal AD, as well as with AD pathology at autopsy. Sphingolipids may be biologically relevant biomarkers for the early detection of AD, and correcting perturbations in sphingolipid metabolism may be a plausible and novel therapeutic strategy in AD.",
      "publication_location": "Plos Medicine",
      "link": "http://dx.doi.org/10.1371/journal.pmed.1002482",
      "citations": 68,
      "readership": 190,
      "tweets": 40,
      "news_mentions": ""
    },
    {
      "title": "Emergent coordination underlying learning to reach to grasp with a brain-machine interface.",
      "authors": "Vaidya, M; Balasubramanian, K; Southerland, J; Badreldin, I; Eleryan, A; Shattuck, K; Gururangan, S; Slutzky, M; Osborne, L; Fagg, A; Oweiss, K; Hatsopoulos, NG",
      "published_date": "April 1, 2018",
      "doi": "10.1152/jn.00982.2016",
      "abstract": "The development of coordinated reach-to-grasp movement has been well studied in infants and children. However, the role of motor cortex during this development is unclear because it is difficult to study in humans. We took the approach of using a brain-machine interface (BMI) paradigm in rhesus macaques with prior therapeutic amputations to examine the emergence of novel, coordinated reach to grasp. Previous research has shown that after amputation, the cortical area previously involved in the control of the lost limb undergoes reorganization, but prior BMI work has largely relied on finding neurons that already encode specific movement-related information. In this study, we taught macaques to cortically control a robotic arm and hand through operant conditioning, using neurons that were not explicitly reach or grasp related. Over the course of training, stereotypical patterns emerged and stabilized in the cross-covariance between the reaching and grasping velocity profiles, between pairs of neurons involved in controlling reach and grasp, and to a comparable, but lesser, extent between other stable neurons in the network. In fact, we found evidence of this structured coordination between pairs composed of all combinations of neurons decoding reach or grasp and other stable neurons in the network. The degree of and participation in coordination was highly correlated across all pair types. Our approach provides a unique model for studying the development of novel, coordinated reach-to-grasp movement at the behavioral and cortical levels. NEW & NOTEWORTHY Given that motor cortex undergoes reorganization after amputation, our work focuses on training nonhuman primates with chronic amputations to use neurons that are not reach or grasp related to control a robotic arm to reach to grasp through the use of operant conditioning, mimicking early development. We studied the development of a novel, coordinated behavior at the behavioral and cortical level, and the neural plasticity in M1 associated with learning to use a brain-machine interface.",
      "publication_location": "J Neurophysiol",
      "link": "http://dx.doi.org/10.1152/jn.00982.2016",
      "citations": 6,
      "readership": 42,
      "tweets": 5,
      "news_mentions": ""
    },
    {
      "title": "Surveying the Landscape: What is the Role of Machine Translation in Language Learning?",
      "authors": "Merschel, LM; Clifford, J; Munné, J",
      "published_date": 2013,
      "doi": "",
      "abstract": "",
      "publication_location": "@Tic Revista D’Innovació Educativa",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning mappings in brain machine interfaces with echo state networks",
      "authors": "Rao, YN; Kim, SP; Sanchez, JC; Erdogmus, D; Principe, JC; Carmena, JM; Lebedev, MA; Nicolelis, MA",
      "published_date": "January 1, 2005",
      "doi": "10.1109/ICASSP.2005.1416283",
      "abstract": "Brain Machine Interfaces (BMI) utilize linear or non-linear models to map the neural activity to the associated behavior which is typically the 2-D or 3-D hand position of a primate. Linear models are plagued by the massive disparity of the input and output dimensions thereby leading to poor generalization. A solution would be to use non-linear models like the Recurrent Multi-Layer Perceptron (RMLP) that provide parsimonious mapping functions with better generalization. However, this results in a drastic increase in the training complexity, which can be critical for practical use of a BMI. This paper bridges the gap between superior performance per trained weight and model learning complexity. Towards this end, we propose to use Echo State Networks (ESN) to transform the neuronal firing activity into a higher dimensional space and then derive an optimal sparse linear mapping in the transformed space to match the hand position. The sparse mapping is obtained using a weight constrained cost function whose optimal solution is determined using a stochastic gradient algorithm. © 2005 IEEE.",
      "publication_location": "2015 Ieee International Conference on Acoustics, Speech, and Signal Processing (Icassp)",
      "link": "http://dx.doi.org/10.1109/ICASSP.2005.1416283",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning to control a brain-machine interface for reaching and grasping by primates.",
      "authors": "Carmena, JM; Lebedev, MA; Crist, RE; O'Doherty, JE; Santucci, DM; Dimitrov, DF; Patil, PG; Henriquez, CS; Nicolelis, MAL",
      "published_date": "November 2003",
      "doi": "10.1371/journal.pbio.0000042",
      "abstract": "Reaching and grasping in primates depend on the coordination of neural activity in large frontoparietal ensembles. Here we demonstrate that primates can learn to reach and grasp virtual objects by controlling a robot arm through a closed-loop brain-machine interface (BMIc) that uses multiple mathematical models to extract several motor parameters (i.e., hand position, velocity, gripping force, and the EMGs of multiple arm muscles) from the electrical activity of frontoparietal neuronal ensembles. As single neurons typically contribute to the encoding of several motor parameters, we observed that high BMIc accuracy required recording from large neuronal ensembles. Continuous BMIc operation by monkeys led to significant improvements in both model predictions and behavioral performance. Using visual feedback, monkeys succeeded in producing robot reach-and-grasp movements even when their arms did not move. Learning to operate the BMIc was paralleled by functional reorganization in multiple cortical areas, suggesting that the dynamic properties of the BMIc were incorporated into motor and sensory cortical representations.",
      "publication_location": "Plos Biology",
      "link": "http://dx.doi.org/10.1371/journal.pbio.0000042",
      "citations": 1210,
      "readership": 1312,
      "tweets": 16,
      "news_mentions": 4
    },
    {
      "title": "Semisupervised multitask learning.",
      "authors": "Liu, Q; Liao, X; Carin, HL; Stack, JR; Carin, L",
      "published_date": "June 2009",
      "doi": "10.1109/tpami.2008.296",
      "abstract": "Context plays an important role when performing classification, and in this paper we examine context from two perspectives. First, the classification of items within a single task is placed within the context of distinct concurrent or previous classification tasks (multiple distinct data collections). This is referred to as multi-task learning (MTL), and is implemented here in a statistical manner, using a simplified form of the Dirichlet process. In addition, when performing many classification tasks one has simultaneous access to all unlabeled data that must be classified, and therefore there is an opportunity to place the classification of any one feature vector within the context of all unlabeled feature vectors; this is referred to as semi-supervised learning. In this paper we integrate MTL and semi-supervised learning into a single framework, thereby exploiting two forms of contextual information. Example results are presented on a \"toy\" example, to demonstrate the concept, and the algorithm is also applied to three real data sets.",
      "publication_location": "Ieee Transactions on Pattern Analysis and Machine Intelligence",
      "link": "http://dx.doi.org/10.1109/tpami.2008.296",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "From Machine to Machine: An OCT-Trained Deep Learning Algorithm for Objective Quantification of Glaucomatous Damage in Fundus Photographs.",
      "authors": "Medeiros, FA; Jammal, AA; Thompson, AC",
      "published_date": "April 2019",
      "doi": "10.1016/j.ophtha.2018.12.033",
      "abstract": "PURPOSE: Previous approaches using deep learning (DL) algorithms to classify glaucomatous damage on fundus photographs have been limited by the requirement for human labeling of a reference training set. We propose a new approach using quantitative spectral-domain (SD) OCT data to train a DL algorithm to quantify glaucomatous structural damage on optic disc photographs. DESIGN: Cross-sectional study. PARTICIPANTS: A total of 32 820 pairs of optic disc photographs and SD OCT retinal nerve fiber layer (RNFL) scans from 2312 eyes of 1198 participants. METHODS: The sample was divided randomly into validation plus training (80%) and test (20%) sets, with randomization performed at the patient level. A DL convolutional neural network was trained to assess optic disc photographs and predict SD OCT average RNFL thickness. MAIN OUTCOME MEASURES: The DL algorithm performance was evaluated in the test sample by evaluating correlation and agreement between the predictions and actual SD OCT measurements. We also assessed the ability to discriminate eyes with glaucomatous visual field loss from healthy eyes with area under the receiver operating characteristic (ROC) curves. RESULTS: The mean prediction of average RNFL thickness from all 6292 optic disc photographs in the test set was 83.3±14.5 μm, whereas the mean average RNFL thickness from all corresponding SD OCT scans was 82.5±16.8 μm (P = 0.164). There was a very strong correlation between predicted and observed RNFL thickness values (Pearson r = 0.832; R2 = 69.3%; P < 0.001), with mean absolute error of the predictions of 7.39 μm. The area under the ROC curves for discriminating glaucomatous from healthy eyes with the DL predictions and actual SD OCT average RNFL thickness measurements were 0.944 (95% confidence interval [CI], 0.912-0.966) and 0.940 (95% CI, 0.902-0.966), respectively (P = 0.724). CONCLUSIONS: We introduced a novel DL approach to assess fundus photographs and provide quantitative information about the amount of neural damage that can be used to diagnose and stage glaucoma. In addition, training neural networks to predict SD OCT data objectively represents a new approach that overcomes limitations of human labeling and could be useful in other areas of ophthalmology.",
      "publication_location": "Ophthalmology",
      "link": "http://dx.doi.org/10.1016/j.ophtha.2018.12.033",
      "citations": 21,
      "readership": 67,
      "tweets": 24,
      "news_mentions": ""
    },
    {
      "title": "Control of a center-out reaching task using a reinforcement learning Brain-Machine Interface",
      "authors": "Sanchez, JC; Tarigoppula, A; Choi, JS; Marsh, BT; Chhatbar, PY; Mahmoudi, B; Francis, JT",
      "published_date": "July 20, 2011",
      "doi": "10.1109/NER.2011.5910601",
      "abstract": "In this work, we develop an experimental primate test bed for a center-out reaching task to test the performance of reinforcement learning based decoders for Brain-Machine Interfaces. Neural recordings obtained from the primary motor cortex were used to adapt a decoder using only sequences of neuronal activation and reinforced interaction with the environment. From a nave state, the system was able to achieve 100% of the targets without any a priori knowledge of the correct neural-to-motor mapping. Results show that the coupling of motor and reward information in an adaptive BMI decoder has the potential to create more realistic and functional models necessary for future BMI control. © 2011 IEEE.",
      "publication_location": "2011 5th International Ieee/Embs Conference on Neural Engineering, Ner 2011",
      "link": "http://dx.doi.org/10.1109/NER.2011.5910601",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Human-machine partnership with artificial intelligence for chest radiograph diagnosis.",
      "authors": "Patel, BN; Rosenberg, L; Willcox, G; Baltaxe, D; Lyons, M; Irvin, J; Rajpurkar, P; Amrhein, T; Gupta, R; Halabi, S; Langlotz, C; Lo, E; Mammarappallil, J; Mariano, AJ; Riley, G; Seekins, J; Shen, L; Zucker, E; Lungren, M",
      "published_date": 2019,
      "doi": "10.1038/s41746-019-0189-7",
      "abstract": "Human-in-the-loop (HITL) AI may enable an ideal symbiosis of human experts and AI models, harnessing the advantages of both while at the same time overcoming their respective limitations. The purpose of this study was to investigate a novel collective intelligence technology designed to amplify the diagnostic accuracy of networked human groups by forming real-time systems modeled on biological swarms. Using small groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs and compared against human experts alone, as well as two state-of-the-art deep learning AI models. Our work demonstrates that both the swarm-based technology and deep-learning technology achieved superior diagnostic accuracy than the human experts alone. Our work further demonstrates that when used in combination, the swarm-based technology and deep-learning technology outperformed either method alone. The superior diagnostic accuracy of the combined HITL AI solution compared to radiologists and AI alone has broad implications for the surging clinical AI deployment and implementation strategies in future practice.",
      "publication_location": "Npj Digital Medicine",
      "link": "http://dx.doi.org/10.1038/s41746-019-0189-7",
      "citations": 2,
      "readership": 25,
      "tweets": 205,
      "news_mentions": 7
    },
    {
      "title": "Deep Learning with Hierarchical Convolutional Factor Analysis.",
      "authors": "Chen, B; Polatkan, G; Sapiro, G; Blei, D; Dunson, D; Carin, L",
      "published_date": "January 2013",
      "doi": "",
      "abstract": "Unsupervised multi-layered (\"deep\") models are considered for general data, with a particular focus on imagery. The model is represented using a hierarchical convolutional factor-analysis construction, with sparse factor loadings and scores. The computation of layer-dependent model parameters is implemented within a Bayesian setting, employing a Gibbs sampler and variational Bayesian (VB) analysis, that explicitly exploit the convolutional nature of the expansion. In order to address large-scale and streaming data, an online version of VB is also developed. The number of basis functions or dictionary elements at each layer is inferred from the data, based on a beta-Bernoulli implementation of the Indian buffet process. Example results are presented for several image-processing applications, with comparisons to related models in the literature.",
      "publication_location": "Ieee Transactions on Pattern Analysis and Machine Intelligence",
      "link": "http://www.ncbi.nlm.nih.gov/pmc/articles/23319498",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Learning the contributions of the motor, premotor, and posterior parietal cortices for hand trajectory reconstruction in a brain machine interface",
      "authors": "Sanchez, JC; Erdogmus, D; Rao, Y; Principe, JC; Nicolelis, M; Wessberg, J",
      "published_date": "January 1, 2003",
      "doi": "10.1109/CNE.2003.1196755",
      "abstract": "© 2003 IEEE. The ability to record, in real-time, the activity of hundreds of cortical neurons gives the ability to selectively study the function of clusters of cortical neurons in Brain Machine Interface (BMI) experiments. We have demonstrated using a recursive multilayer perceptron (RMLP) that using the appropriate signal processing theory in a well-chosen parsimonious model, we can develop constructs that agree with basic physiological modeling of neural control. By looking through the trained model, we have found interesting relationships between the neuronal firing and the movement. The RMLP allows us to continuously study the relationship between neural activity and behavior without the active interference of the experimenter. The findings presented in this study offer an opportunity for the neuroscience community to compare the cortical interactions as constructed by the RMLP to what is known about motor neurophysiology.",
      "publication_location": "International Ieee/Embs Conference on Neural Engineering, Ner",
      "link": "http://dx.doi.org/10.1109/CNE.2003.1196755",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Open-source, machine and deep learning-based automated algorithm for gestational age estimation through smartphone lens imaging.",
      "authors": "Desai, AD; Peng, C; Fang, L; Mukherjee, D; Yeung, A; Jaffe, SJ; Griffin, JB; Farsiu, S",
      "published_date": "December 2018",
      "doi": "10.1364/BOE.9.006038",
      "abstract": "Gestational age estimation at time of birth is critical for determining the degree of prematurity of the infant and for administering appropriate postnatal treatment. We present a fully automated algorithm for estimating gestational age of premature infants through smartphone lens imaging of the anterior lens capsule vasculature (ALCV). Our algorithm uses a fully convolutional network and blind image quality analyzers to segment usable anterior capsule regions. Then, it extracts ALCV features using a residual neural network architecture and trains on these features using a support vector machine-based classifier. The classification algorithm is validated using leave-one-out cross-validation on videos captured from 124 neonates. The algorithm is expected to be an influential tool for remote and point-of-care gestational age estimation of premature neonates in low-income countries. To this end, we have made the software open source.",
      "publication_location": "Biomedical Optics Express",
      "link": "http://dx.doi.org/10.1364/BOE.9.006038",
      "citations": 4,
      "readership": 23,
      "tweets": 1,
      "news_mentions": 4
    },
    {
      "title": "Automated and on-demand provisioning of virtual machines for database applications",
      "authors": "Shivam, P; Demberel, A; Gunda, P; Irwin, D; Grit, L; Yumerefendi, A; Babu, S; Chase, J",
      "published_date": "October 30, 2007",
      "doi": "10.1145/1247480.1247612",
      "abstract": "Utility computing delivers compute and storage resources to applications as an 'on-demand utility', much like electricity, from a distributed collection of computing resources. There is great interest in running database applications on utility resources (e.g., Oracle's Grid initiative) due to reduced infrastructure and management costs, higher resource utilization, and the ability to handle sudden load surges. Virtual Machine (VM) technology offers powerful mechanisms to manage a utility resource infrastructure. However, provisioning VMs for applications to meet system performance goals, e.g., to meet service level agreements (SLAs), is an open problem. We are building two systems at Duke - Shirako and NIMO - that collectively address this problem. Shirako is a toolkit for leasing VMs to an application from a utility resource infrastructure. NIMO learns application performance models using novel techniques based on active learning, and uses these models to guide VM provisioning in Shirako. We will demonstrate: (a) how NIMO learns performance models in an online and automatic fashion using active learning; and (b) how NIMO uses these models to do automated and on-demand provisioning of VMs in Shirako for two classes of database applications - multi-tier web services and computational science workflows.",
      "publication_location": "Proceedings of the Acm Sigmod International Conference on Management of Data",
      "link": "http://dx.doi.org/10.1145/1247480.1247612",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bayesian nonlinear support vector machines and discriminative factor modeling",
      "authors": "Henao, R; Yuan, X; Carin, L",
      "published_date": "January 1, 2014",
      "doi": "",
      "abstract": "A new Bayesian formulation is developed for nonlinear support vector machines (SVMs), based on a Gaussian process and with the SVM hinge loss expressed as a scaled mixture of normals. We then integrate the Bayesian SVM into a factor model, in which feature learning and nonlinear classifier design are performed jointly; almost all previous work on such discriminative feature learning has assumed a linear classifier. Inference is performed with expectation conditional maximization (ECM) and Markov Chain Monte Carlo (MCMC). An extensive set of experiments demonstrate the utility of using a nonlinear Bayesian SVM within discriminative feature learning and factor modeling, from the standpoints of accuracy and interpretability.",
      "publication_location": "Advances in Neural Information Processing Systems",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Application of support vector machines to breast cancer screening using mammogram and clinical history data",
      "authors": "Land, WH; McKee, D; Velazquez, R; Wong, L; Lo, JY; Anderson, F",
      "published_date": "September 15, 2003",
      "doi": "10.1117/12.480235",
      "abstract": "The objectives of this paper are to discuss: (1) the development and testing of a new Evolutionary Programming (EP) method to optimally configure Support Vector Machine (SVM) parameters for facilitating the diagnosis of breast cancer; (2) evaluation of EP derived learning machines when the number of BI-RADS™ and clinical history discriminators are reduced from 16 to 7; (3) establishing system performance for several SVM kernels in addition to the EP/Adaptive Boosting (EP/AB) hybrid using the Digital Database for Screening Mammography, University of South Florida (DDSM USF) and Duke data sets; and (4) obtaining a preliminary evaluation of the measurement of SVM learning machine inter-institutional generalization capability using BI-RADS™ data. Measuring performance of the SVM designs and EP/AB hybrid against these objectives will provide quantative evidence that the software packages described can generalize to larger patient data sets from different institutions. Most iterative methods currently in use to optimize learning machine parameters are time consuming processes, which sometimes yield sub-optimal values resulting in performance degradation. SVMs are new machine Intelligence paradigms, which use the Structural Risk Minimization (SRM) concept to develop learning machines. These learning machines can always be trained to provide global minima, given that the machine parameters are optimally computed. In addition, several system performance studies are described which include EP derived SVM performance as a function of: (a) population and generation size as well as a method for generating initial populations and (b) iteratively derived versus EP derived learning machine parameters. Finally, the authors describe a set of experiments providing preliminary evidence that both the EP/AB hybrid and SVM Computer Aided Diagnostic C++ software packages will work across a large population of patients, based on a data set of approximately 2,500 samples from five different institutions.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.480235",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A context-Aware topic model for statistical machine translation",
      "authors": "",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015 Association for Computational Linguistics. Lexical selection is crucial for statistical machine translation. Previous studies separately exploit sentence-level contexts and documentlevel topics for lexical selection, neglecting their correlations. In this paper, we propose a context-Aware topic model for lexical selection, which not only models local contexts and global topics but also captures their correlations. The model uses target-side translations as hidden variables to connect document topics and source-side local contextual words. In order to learn hidden variables and distributions from data, we introduce a Gibbs sampling algorithm for statistical estimation and inference. A new translation probability based on distributions learned by the model is integrated into a translation system for lexical selection. Experiment results on NIST Chinese-English test sets demonstrate that 1) our model significantly outperforms previous lexical selection methods and 2) modeling correlations between local words and global topics can further improve translation quality.",
      "publication_location": "Acl Ijcnlp 2015   53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, Proceedings of the Conference",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Bilingual correspondence recursive autoencoders for statistical machine translation",
      "authors": "",
      "published_date": "January 1, 2015",
      "doi": "",
      "abstract": "© 2015 Association for Computational Linguistics. Learning semantic representations and tree structures of bilingual phrases is beneficial for statistical machine translation. In this paper, we propose a new neural network model called Bilingual Correspondence Recursive Autoencoder (BCorrRAE) to model bilingual phrases in translation. We incorporate word alignments into BCorrRAE to allow it freely access bilingual constraints at different levels. BCorrRAE minimizes a joint objective on the combination of a recursive autoencoder reconstruction error, a structural alignment consistency error and a crosslingual reconstruction error so as to not only generate alignment-consistent phrase structures, but also capture different levels of semantic relations within bilingual phrases. In order to examine the effectiveness of BCorrRAE, we incorporate both semantic and structural similarity features built on bilingual phrase representations and tree structures learned by BCorrRAE into a state-of-the-art SMT system. Experiments on NIST Chinese-English test sets show that our model achieves a substantial improvement of up to 1.55 BLEU points over the baseline.",
      "publication_location": "Conference Proceedings   Emnlp 2015: Conference on Empirical Methods in Natural Language Processing",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Cortical modulations increase in early sessions with brain-machine interface.",
      "authors": "Zacksenhouse, M; Lebedev, MA; Carmena, JM; O'Doherty, JE; Henriquez, C; Nicolelis, MAL",
      "published_date": "July 18, 2007",
      "doi": "10.1371/journal.pone.0000619",
      "abstract": "BACKGROUND: During planning and execution of reaching movements, the activity of cortical motor neurons is modulated by a diversity of motor, sensory, and cognitive signals. Brain-machine interfaces (BMIs) extract part of these modulations to directly control artificial actuators. However, cortical modulations that emerge in the novel context of operating the BMI are poorly understood. METHODOLOGY/PRINCIPAL FINDINGS: Here we analyzed the changes in neuronal modulations that occurred in different cortical motor areas as monkeys learned to use a BMI to control reaching movements. Using spike-train analysis methods we demonstrate that the modulations of the firing-rates of cortical neurons increased abruptly after the monkeys started operating the BMI. Regression analysis revealed that these enhanced modulations were not correlated with the kinematics of the movement. The initial enhancement in firing rate modulations declined gradually with subsequent training in parallel with the improvement in behavioral performance. CONCLUSIONS/SIGNIFICANCE: We conclude that the enhanced modulations are related to computational tasks that are significant especially in novel motor contexts. Although the function and neuronal mechanism of the enhanced cortical modulations are open for further inquiries, we discuss their potential role in processing execution errors and representing corrective or explorative activity. These representations are expected to contribute to the formation of internal models of the external actuator and their decoding may facilitate BMI improvement.",
      "publication_location": "Plos One",
      "link": "http://dx.doi.org/10.1371/journal.pone.0000619",
      "citations": 48,
      "readership": 116,
      "tweets": "(None,)",
      "news_mentions": ""
    },
    {
      "title": "Using evolutionary programming to configure support vector machines for the diagnosis of breast cancer",
      "authors": "Land, WH; Lo, JY; Velázquez, R",
      "published_date": "December 1, 2002",
      "doi": "",
      "abstract": "Support Vector Machines(s) (SVMs) are new machine intelligence paradigms that use the Structural Risk Minimization (SRM) concept to develop learning machines. SVMs can always be trained to provide global minima, given that the leaning machine parameters are optimally computed. The current most prevalent methods to select these parameters are numerical iterative techniques. While useful, these methods frequently have no basis in theory, and cannot guarantee that the resultant parameters will yield optimum learning machine performance. The purpose of this paper is to discuss and demonstrate the application of Evolutionary Programming (EP) concepts to develop learning machine parameters and demonstrate the effectiveness of this process. This paper will also demonstrate that the applied EP process will reduce the amount of time required to configure a learning machine for those data sets studied, while developing optimal learning parameters with minimal user intervention. Specifically, this research has demonstrated, using the Duke mammogram data set, that SVMs derived using this modified EP process improved the specificity by a significant 45.3% at 100% sensitivity (missing no cancers) as well as improving the specificity by 17.5% at 95% sensitivity (missing 5% of the cancers) when compared to the performance of SVMs whose parameters were computed using the standard iterative method. The practical consequence of these results is that many women, who currently have false positive diagnoses resulting from the application of existing methods, will no longer be required to undergo biopsy with the resultant cost, morbidity and physical disfigurement that frequently results from these procedures. This approach, in addition, may also be used in linear separable; linear, non-separable; and nonlinear, non-separable environments.",
      "publication_location": "Intelligent Engineering Systems Through Artificial Neural Networks",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "A brain-machine interface enables bimanual arm movements in monkeys.",
      "authors": "Ifft, PJ; Shokur, S; Li, Z; Lebedev, MA; Nicolelis, MAL",
      "published_date": "November 6, 2013",
      "doi": "10.1126/scitranslmed.3006159",
      "abstract": "Brain-machine interfaces (BMIs) are artificial systems that aim to restore sensation and movement to paralyzed patients. So far, BMIs have enabled only one arm to be moved at a time. Control of bimanual arm movements remains a major challenge. We have developed and tested a bimanual BMI that enables rhesus monkeys to control two avatar arms simultaneously. The bimanual BMI was based on the extracellular activity of 374 to 497 neurons recorded from several frontal and parietal cortical areas of both cerebral hemispheres. Cortical activity was transformed into movements of the two arms with a decoding algorithm called a fifth-order unscented Kalman filter (UKF). The UKF was trained either during a manual task performed with two joysticks or by having the monkeys passively observe the movements of avatar arms. Most cortical neurons changed their modulation patterns when both arms were engaged simultaneously. Representing the two arms jointly in a single UKF decoder resulted in improved decoding performance compared with using separate decoders for each arm. As the animals' performance in bimanual BMI control improved over time, we observed widespread plasticity in frontal and parietal cortical areas. Neuronal representation of the avatar and reach targets was enhanced with learning, whereas pairwise correlations between neurons initially increased and then decreased. These results suggest that cortical networks may assimilate the two avatar arms through BMI control. These findings should help in the design of more sophisticated BMIs capable of enabling bimanual motor control in human patients.",
      "publication_location": "Sci Transl Med",
      "link": "http://dx.doi.org/10.1126/scitranslmed.3006159",
      "citations": 109,
      "readership": 233,
      "tweets": 42,
      "news_mentions": 28
    },
    {
      "title": "Adaptive decoding for brain-machine interfaces through Bayesian parameter updates.",
      "authors": "Li, Z; O'Doherty, JE; Lebedev, MA; Nicolelis, MAL",
      "published_date": "December 2011",
      "doi": "10.1162/NECO_a_00207",
      "abstract": "Brain-machine interfaces (BMIs) transform the activity of neurons recorded in motor areas of the brain into movements of external actuators. Representation of movements by neuronal populations varies over time, during both voluntary limb movements and movements controlled through BMIs, due to motor learning, neuronal plasticity, and instability in recordings. To ensure accurate BMI performance over long time spans, BMI decoders must adapt to these changes. We propose the Bayesian regression self-training method for updating the parameters of an unscented Kalman filter decoder. This novel paradigm uses the decoder's output to periodically update its neuronal tuning model in a Bayesian linear regression. We use two previously known statistical formulations of Bayesian linear regression: a joint formulation, which allows fast and exact inference, and a factorized formulation, which allows the addition and temporary omission of neurons from updates but requires approximate variational inference. To evaluate these methods, we performed offline reconstructions and closed-loop experiments with rhesus monkeys implanted cortically with microwire electrodes. Offline reconstructions used data recorded in areas M1, S1, PMd, SMA, and PP of three monkeys while they controlled a cursor using a handheld joystick. The Bayesian regression self-training updates significantly improved the accuracy of offline reconstructions compared to the same decoder without updates. We performed 11 sessions of real-time, closed-loop experiments with a monkey implanted in areas M1 and S1. These sessions spanned 29 days. The monkey controlled the cursor using the decoder with and without updates. The updates maintained control accuracy and did not require information about monkey hand movements, assumptions about desired movements, or knowledge of the intended movement goals as training signals. These results indicate that Bayesian regression self-training can maintain BMI control accuracy over long periods, making clinical neuroprosthetics more viable.",
      "publication_location": "Neural Comput",
      "link": "http://dx.doi.org/10.1162/NECO_a_00207",
      "citations": 82,
      "readership": 106,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Wireless Cortical Brain-Machine Interface for Whole-Body Navigation in Primates.",
      "authors": "Rajangam, S; Tseng, P-H; Yin, A; Lehew, G; Schwarz, D; Lebedev, MA; Nicolelis, MAL",
      "published_date": "March 3, 2016",
      "doi": "10.1038/srep22170",
      "abstract": "Several groups have developed brain-machine-interfaces (BMIs) that allow primates to use cortical activity to control artificial limbs. Yet, it remains unknown whether cortical ensembles could represent the kinematics of whole-body navigation and be used to operate a BMI that moves a wheelchair continuously in space. Here we show that rhesus monkeys can learn to navigate a robotic wheelchair, using their cortical activity as the main control signal. Two monkeys were chronically implanted with multichannel microelectrode arrays that allowed wireless recordings from ensembles of premotor and sensorimotor cortical neurons. Initially, while monkeys remained seated in the robotic wheelchair, passive navigation was employed to train a linear decoder to extract 2D wheelchair kinematics from cortical activity. Next, monkeys employed the wireless BMI to translate their cortical activity into the robotic wheelchair's translational and rotational velocities. Over time, monkeys improved their ability to navigate the wheelchair toward the location of a grape reward. The navigation was enacted by populations of cortical neurons tuned to whole-body displacement. During practice with the apparatus, we also noticed the presence of a cortical representation of the distance to reward location. These results demonstrate that intracranial BMIs could restore whole-body mobility to severely paralyzed patients in the future.",
      "publication_location": "Scientific Reports",
      "link": "http://dx.doi.org/10.1038/srep22170",
      "citations": 40,
      "readership": 161,
      "tweets": 165,
      "news_mentions": 91
    },
    {
      "title": "A self-learning camera for the validation of highly variable and pseudo-random patterns",
      "authors": "",
      "published_date": "December 1, 2004",
      "doi": "10.1117/12.527149",
      "abstract": "Reliable and productive manufacturing operations have depended on people to quickly detect and solve problems whenever they appear. Over the last 20 years, more and more manufacturing operations have embraced machine vision systems to increase productivity, reliability and cost-effectiveness, including reducing the number of human operators required. Although machine vision technology has long been capable of solving simple problems, it has still not been broadly implemented. The reason is that until now, no machine vision system has been designed to meet the unique demands of complicated pattern recognition. The ZiCAM™ family was specifically developed to be the first practical hardware to meet these needs. To be able to address non-traditional applications, the machine vision industry must include smart camera technology that meets its users' demands for lower costs, better performance and the ability to address applications of irregular lighting, patterns and color. The next-generation smart cameras will need to evolve as a fundamentally different kind of sensor, with new technology that behaves like a human but performs like a computer. Neural network based systems, coupled with self-taught, n-space, non-linear modeling, promises to be the enabler of that next generation of machine vision equipment. Image processing technology is now available that enables a system to match an operator's subjectivity. A Zero-Instruction-Set- Computer (ZISC) powered smart camera allows high-speed fuzzy-logic processing, without the need for computer programming. This can address applications of validating highly variable and pseudo-random patterns. A hardware-based implementation of a neural network, Zero-Instruction-SetComputer, enables a vision system to \"think\" and \"inspect\" like a human, with the speed and reliability of a machine.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.527149",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "On the noise model of support vector machines regression",
      "authors": "",
      "published_date": "January 1, 2000",
      "doi": "",
      "abstract": "© Springer-Verlag Berlin Heidelberg 2000. Support Vector Machines Regression (SVMR) is a learning technique where the goodness of fit is measured not by the usual quadratic loss function (the mean square error), but by a different loss function called the -Insensitive Loss Function (ILF), which is similar to loss functions used in the field of robust statistics. The quadratic loss function is well justified under the assumption of Gaussian additive noise. However, the noise model underlying the choice of the ILF is not clear. In this paper the use of the ILF is justified under the assumption that the noise is additive and Gaussian, where the variance and mean of the Gaussian are random variables. The probability distributions for the variance and mean will be stated explicitly. While this work is presented in the framework of SVMR, it can be extended to justify non-quadratic loss functions in any Maximum Likelihood or Maximum A Posteriori approach. It applies not only to the ILF, but to a much broader class of loss functions.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Application of support vector machines to breast cancer screening using mammogram and history data",
      "authors": "Land, WH; Akanda, A; Lo, JY; Anderson, F; Bryden, M",
      "published_date": "January 1, 2002",
      "doi": "10.1117/12.467206",
      "abstract": "Support Vector Machines (SVMs) are a new and radically different type of classifiers and learning machines that use a hypothesis space of linear functions in a high dimensional feature space. This relatively new paradigm, based on Statistical Learning theory (SLT) and Structural Risk Minimization (SRM), has many advantages when compared to traditional neural networks, which are based on Empirical Risk Minimization (ERM). Unlike neural networks, SVM training always finds a global minimum. Furthermore, SVMs have inherent ability to solve pattern classification without incorporating any problem-domain knowledge. In this study, the SVM was employed as a pattern classifier, operating on mammography data used for breast cancer detection. The main focus was to formulate the best learning machine configurations for optimum specificity and positive predictive value at very high sensitivities. Using a mammogram database of 500 biopsy-proven samples, the best performing SVM, on average, was able to achieve (under statistical 5-fold cross-validation) a specificity of 45.0% and a positive predictive value (PPV) of 50.1% at 100% sensitivity. At 97% sensitivity, a specificity of 55.8% and a PPV of 55.2% were obtained. © 2002 SPIE · 1605-7422/02/$15.00.",
      "publication_location": "Smart Structures and Materials 2005: Active Materials: Behavior and Mechanics",
      "link": "http://dx.doi.org/10.1117/12.467206",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Variational Bayes for continuous hidden Markov models and its application to active learning.",
      "authors": "Ji, S; Krishnapuram, B; Carin, L",
      "published_date": "April 2006",
      "doi": "10.1109/tpami.2006.85",
      "abstract": "In this paper, we present a varitional Bayes (VB) framework for learning continuous hidden Markov models (CHMMs), and we examine the VB framework within active learning. Unlike a maximum likelihood or maximum a posteriori training procedure, which yield a point estimate of the CHMM parameters, VB-based training yields an estimate of the full posterior of the model parameters. This is particularly important for small training sets since it gives a measure of confidence in the accuracy of the learned model. This is utilized within the context of active learning, for which we acquire labels for those feature vectors for which knowledge of the associated label would be most informative for reducing model-parameter uncertainty. Three active learning algorithms are considered in this paper: 1) query by committee (QBC), with the goal of selecting data for labeling that minimize the classification variance, 2) a maximum expected information gain method that seeks to label data with the goal of reducing the entropy of the model parameters, and 3) an error-reduction-based procedure that attempts to minimize classification error over the test data. The experimental results are presented for synthetic and measured data. We demonstrate that all of these active learning methods can significantly reduce the amount of required labeling, compared to random selection of samples for labeling.",
      "publication_location": "Ieee Transactions on Pattern Analysis and Machine Intelligence",
      "link": "http://dx.doi.org/10.1109/tpami.2006.85",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Semisupervised learning of hidden Markov models via a homotopy method.",
      "authors": "Ji, S; Watson, LT; Carin, L",
      "published_date": "February 2009",
      "doi": "10.1109/tpami.2008.71",
      "abstract": "Hidden Markov model (HMM) classifier design is considered for the analysis of sequential data, incorporating both labeled and unlabeled data for training; the balance between the use of labeled and unlabeled data is controlled by an allocation parameter \\lambda \\in [0, 1), where \\lambda = 0 corresponds to purely supervised HMM learning (based only on the labeled data) and \\lambda = 1 corresponds to unsupervised HMM-based clustering (based only on the unlabeled data). The associated estimation problem can typically be reduced to solving a set of fixed-point equations in the form of a \"natural-parameter homotopy.\" This paper applies a homotopy method to track a continuous path of solutions, starting from a local supervised solution (\\lambda = 0) to a local unsupervised solution (\\lambda = 1). The homotopy method is guaranteed to track with probability one from \\lambda = 0 to \\lambda = 1 if the \\lambda = 0 solution is unique; this condition is not satisfied for the HMM since the maximum likelihood supervised solution (\\lambda = 0) is characterized by many local optima. A modified form of the homotopy map for HMMs assures a track from \\lambda = 0 to \\lambda = 1. Following this track leads to a formulation for selecting \\lambda \\in [0, 1) for a semisupervised solution and it also provides a tool for selection from among multiple local-optimal supervised solutions. The results of applying the proposed method to measured and synthetic sequential data verify its robustness and feasibility compared to the conventional EM approach for semisupervised HMM training.",
      "publication_location": "Ieee Transactions on Pattern Analysis and Machine Intelligence",
      "link": "http://dx.doi.org/10.1109/tpami.2008.71",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    },
    {
      "title": "Deep learning with hierarchical convolutional factor analysis.",
      "authors": "Chen, B; Polatkan, G; Sapiro, G; Blei, D; Dunson, D; Carin, L",
      "published_date": "August 2013",
      "doi": "10.1109/TPAMI.2013.19",
      "abstract": "Unsupervised multilayered (“deep”) models are considered for imagery. The model is represented using a hierarchical convolutional factor-analysis construction, with sparse factor loadings and scores. The computation of layer-dependent model parameters is implemented within a Bayesian setting, employing a Gibbs sampler and variational Bayesian (VB) analysis that explicitly exploit the convolutional nature of the expansion. To address large-scale and streaming data, an online version of VB is also developed. The number of dictionary elements at each layer is inferred from the data, based on a beta-Bernoulli implementation of the Indian buffet process. Example results are presented for several image-processing applications, with comparisons to related models in the literature.",
      "publication_location": "Ieee Transactions on Pattern Analysis and Machine Intelligence",
      "link": "http://dx.doi.org/10.1109/TPAMI.2013.19",
      "citations": 61,
      "readership": 219,
      "tweets": 2,
      "news_mentions": ""
    },
    {
      "title": "Cortical ensemble adaptation to represent velocity of an artificial actuator controlled by a brain-machine interface.",
      "authors": "Lebedev, MA; Carmena, JM; O'Doherty, JE; Zacksenhouse, M; Henriquez, CS; Principe, JC; Nicolelis, MAL",
      "published_date": "May 11, 2005",
      "doi": "10.1523/JNEUROSCI.4088-04.2005",
      "abstract": "Monkeys can learn to directly control the movements of an artificial actuator by using a brain-machine interface (BMI) driven by the activity of a sample of cortical neurons. Eventually, they can do so without moving their limbs. Neuronal adaptations underlying the transition from control of the limb to control of the actuator are poorly understood. Here, we show that rapid modifications in neuronal representation of velocity of the hand and actuator occur in multiple cortical areas during the operation of a BMI. Initially, monkeys controlled the actuator by moving a hand-held pole. During this period, the BMI was trained to predict the actuator velocity. As the monkeys started using their cortical activity to control the actuator, the activity of individual neurons and neuronal populations became less representative of the animal's hand movements while representing the movements of the actuator. As a result of this adaptation, the animals could eventually stop moving their hands yet continue to control the actuator. These results show that, during BMI control, cortical ensembles represent behaviorally significant motor parameters, even if these are not associated with movements of the animal's own limb.",
      "publication_location": "Journal of Neuroscience",
      "link": "http://dx.doi.org/10.1523/JNEUROSCI.4088-04.2005",
      "citations": 213,
      "readership": 338,
      "tweets": 6,
      "news_mentions": ""
    },
    {
      "title": "A learning method for automated polyp detection",
      "authors": "Gokturk, SB; Tomasi, C; Acar, B; Paik, D; Beaulieu, C; Napel, S",
      "published_date": "January 1, 2001",
      "doi": "10.1007/3-540-45468-3_11",
      "abstract": "© Springer-Verlag Berlin Heidelberg 2001. Adenomatous polyps in the colon have a high probability of developing into subsequent colorectal carcinoma, the second leading cause of cancer deaths in United States. In this paper, we propose a new method for computer-aided diagnosis of polyps. Initial work with shape detection has shown high sensitivity for polyp detection, but at a cost of too many false positive detections. We present a statistical approach that uses support vector machines to distinguish the differentiating characteristics of polyps and healthy tissue, and subsequently uses this information for the classification of the new cases. One of the main contributions of the paper is a new 3-D pattern analysis approach, which combines the information from many random images to generate reliable signatures of the shapes. At 80% polyp detection rate, the proposed system reduces the false positive rate by 80% compared to previous work.",
      "publication_location": "Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "link": "http://dx.doi.org/10.1007/3-540-45468-3_11",
      "citations": "",
      "readership": "",
      "tweets": "",
      "news_mentions": ""
    }
  ]